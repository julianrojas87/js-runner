#!/usr/bin/env node
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getProtoOf = Object.getPrototypeOf;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __toESM = (mod, isNodeMode, target) => {
  target = mod != null ? __create(__getProtoOf(mod)) : {};
  const to = isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target;
  for (let key of __getOwnPropNames(mod))
    if (!__hasOwnProp.call(to, key))
      __defProp(to, key, {
        get: () => mod[key],
        enumerable: true
      });
  return to;
};
var __commonJS = (cb, mod) => () => (mod || cb((mod = { exports: {} }).exports, mod), mod.exports);
import Module from "node:module";
const __require = Module.createRequire(import.meta.url);

// node_modules/n3/lib/IRIs.js
var require_IRIs = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = undefined;
  var RDF = "http://www.w3.org/1999/02/22-rdf-syntax-ns#";
  var XSD = "http://www.w3.org/2001/XMLSchema#";
  var SWAP = "http://www.w3.org/2000/10/swap/";
  var _default = {
    xsd: {
      decimal: `${XSD}decimal`,
      boolean: `${XSD}boolean`,
      double: `${XSD}double`,
      integer: `${XSD}integer`,
      string: `${XSD}string`
    },
    rdf: {
      type: `${RDF}type`,
      nil: `${RDF}nil`,
      first: `${RDF}first`,
      rest: `${RDF}rest`,
      langString: `${RDF}langString`
    },
    owl: {
      sameAs: "http://www.w3.org/2002/07/owl#sameAs"
    },
    r: {
      forSome: `${SWAP}reify#forSome`,
      forAll: `${SWAP}reify#forAll`
    },
    log: {
      implies: `${SWAP}log#implies`
    }
  };
  exports.default = _default;
});

// node_modules/queue-microtask/index.js
var require_queue_microtask = __commonJS((exports, module) => {
  /*! queue-microtask. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
  var promise;
  module.exports = typeof queueMicrotask === "function" ? queueMicrotask.bind(typeof window !== "undefined" ? window : global) : (cb) => (promise || (promise = Promise.resolve())).then(cb).catch((err) => setTimeout(() => {
    throw err;
  }, 0));
});

// node_modules/n3/lib/N3Lexer.js
var require_N3Lexer = __commonJS((exports) => {
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = undefined;
  var _IRIs = _interopRequireDefault(require_IRIs());
  var _queueMicrotask = _interopRequireDefault(require_queue_microtask());
  var {
    xsd
  } = _IRIs.default;
  var escapeSequence = /\\u([a-fA-F0-9]{4})|\\U([a-fA-F0-9]{8})|\\([^])/g;
  var escapeReplacements = {
    "\\": "\\",
    "'": "'",
    '"': '"',
    n: "\n",
    r: "\r",
    t: "\t",
    f: "\f",
    b: "\b",
    _: "_",
    "~": "~",
    ".": ".",
    "-": "-",
    "!": "!",
    $: "$",
    "&": "&",
    "(": "(",
    ")": ")",
    "*": "*",
    "+": "+",
    ",": ",",
    ";": ";",
    "=": "=",
    "/": "/",
    "?": "?",
    "#": "#",
    "@": "@",
    "%": "%"
  };
  var illegalIriChars = /[\x00-\x20<>\\"\{\}\|\^\`]/;
  var lineModeRegExps = {
    _iri: true,
    _unescapedIri: true,
    _simpleQuotedString: true,
    _langcode: true,
    _blank: true,
    _newline: true,
    _comment: true,
    _whitespace: true,
    _endOfFile: true
  };
  var invalidRegExp = /$0^/;

  class N3Lexer {
    constructor(options) {
      this._iri = /^<((?:[^ <>{}\\]|\\[uU])+)>[ \t]*/;
      this._unescapedIri = /^<([^\x00-\x20<>\\"\{\}\|\^\`]*)>[ \t]*/;
      this._simpleQuotedString = /^"([^"\\\r\n]*)"(?=[^"])/;
      this._simpleApostropheString = /^'([^'\\\r\n]*)'(?=[^'])/;
      this._langcode = /^@([a-z]+(?:-[a-z0-9]+)*)(?=[^a-z0-9\-])/i;
      this._prefix = /^((?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:\.?[\-0-9A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)?:(?=[#\s<])/;
      this._prefixed = /^((?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:\.?[\-0-9A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)?:((?:(?:[0-:A-Z_a-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff]|%[0-9a-fA-F]{2}|\\[!#-\/;=?\-@_~])(?:(?:[\.\-0-:A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff]|%[0-9a-fA-F]{2}|\\[!#-\/;=?\-@_~])*(?:[\-0-:A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff]|%[0-9a-fA-F]{2}|\\[!#-\/;=?\-@_~]))?)?)(?:[ \t]+|(?=\.?[,;!\^\s#()\[\]\{\}"'<>]))/;
      this._variable = /^\?(?:(?:[A-Z_a-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:[\-0-:A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)(?=[.,;!\^\s#()\[\]\{\}"'<>])/;
      this._blank = /^_:((?:[0-9A-Z_a-z\xc0-\xd6\xd8-\xf6\xf8-\u02ff\u0370-\u037d\u037f-\u1fff\u200c\u200d\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])(?:\.?[\-0-9A-Z_a-z\xb7\xc0-\xd6\xd8-\xf6\xf8-\u037d\u037f-\u1fff\u200c\u200d\u203f\u2040\u2070-\u218f\u2c00-\u2fef\u3001-\ud7ff\uf900-\ufdcf\ufdf0-\ufffd]|[\ud800-\udb7f][\udc00-\udfff])*)(?:[ \t]+|(?=\.?[,;:\s#()\[\]\{\}"'<>]))/;
      this._number = /^[\-+]?(?:(\d+\.\d*|\.?\d+)[eE][\-+]?|\d*(\.)?)\d+(?=\.?[,;:\s#()\[\]\{\}"'<>])/;
      this._boolean = /^(?:true|false)(?=[.,;\s#()\[\]\{\}"'<>])/;
      this._keyword = /^@[a-z]+(?=[\s#<:])/i;
      this._sparqlKeyword = /^(?:PREFIX|BASE|GRAPH)(?=[\s#<])/i;
      this._shortPredicates = /^a(?=[\s#()\[\]\{\}"'<>])/;
      this._newline = /^[ \t]*(?:#[^\n\r]*)?(?:\r\n|\n|\r)[ \t]*/;
      this._comment = /#([^\n\r]*)/;
      this._whitespace = /^[ \t]+/;
      this._endOfFile = /^(?:#[^\n\r]*)?$/;
      options = options || {};
      if (this._lineMode = !!options.lineMode) {
        this._n3Mode = false;
        for (const key in this) {
          if (!(key in lineModeRegExps) && this[key] instanceof RegExp)
            this[key] = invalidRegExp;
        }
      } else {
        this._n3Mode = options.n3 !== false;
      }
      this._comments = !!options.comments;
      this._literalClosingPos = 0;
    }
    _tokenizeToEnd(callback, inputFinished) {
      let input = this._input;
      let currentLineLength = input.length;
      while (true) {
        let whiteSpaceMatch, comment;
        while (whiteSpaceMatch = this._newline.exec(input)) {
          if (this._comments && (comment = this._comment.exec(whiteSpaceMatch[0])))
            emitToken("comment", comment[1], "", this._line, whiteSpaceMatch[0].length);
          input = input.substr(whiteSpaceMatch[0].length, input.length);
          currentLineLength = input.length;
          this._line++;
        }
        if (!whiteSpaceMatch && (whiteSpaceMatch = this._whitespace.exec(input)))
          input = input.substr(whiteSpaceMatch[0].length, input.length);
        if (this._endOfFile.test(input)) {
          if (inputFinished) {
            if (this._comments && (comment = this._comment.exec(input)))
              emitToken("comment", comment[1], "", this._line, input.length);
            input = null;
            emitToken("eof", "", "", this._line, 0);
          }
          return this._input = input;
        }
        const line = this._line, firstChar = input[0];
        let type = "", value = "", prefix = "", match = null, matchLength = 0, inconclusive = false;
        switch (firstChar) {
          case "^":
            if (input.length < 3)
              break;
            else if (input[1] === "^") {
              this._previousMarker = "^^";
              input = input.substr(2);
              if (input[0] !== "<") {
                inconclusive = true;
                break;
              }
            } else {
              if (this._n3Mode) {
                matchLength = 1;
                type = "^";
              }
              break;
            }
          case "<":
            if (match = this._unescapedIri.exec(input))
              type = "IRI", value = match[1];
            else if (match = this._iri.exec(input)) {
              value = this._unescape(match[1]);
              if (value === null || illegalIriChars.test(value))
                return reportSyntaxError(this);
              type = "IRI";
            } else if (input.length > 1 && input[1] === "<")
              type = "<<", matchLength = 2;
            else if (this._n3Mode && input.length > 1 && input[1] === "=")
              type = "inverse", matchLength = 2, value = ">";
            break;
          case ">":
            if (input.length > 1 && input[1] === ">")
              type = ">>", matchLength = 2;
            break;
          case "_":
            if ((match = this._blank.exec(input)) || inputFinished && (match = this._blank.exec(`${input} `)))
              type = "blank", prefix = "_", value = match[1];
            break;
          case '"':
            if (match = this._simpleQuotedString.exec(input))
              value = match[1];
            else {
              ({
                value,
                matchLength
              } = this._parseLiteral(input));
              if (value === null)
                return reportSyntaxError(this);
            }
            if (match !== null || matchLength !== 0) {
              type = "literal";
              this._literalClosingPos = 0;
            }
            break;
          case "'":
            if (!this._lineMode) {
              if (match = this._simpleApostropheString.exec(input))
                value = match[1];
              else {
                ({
                  value,
                  matchLength
                } = this._parseLiteral(input));
                if (value === null)
                  return reportSyntaxError(this);
              }
              if (match !== null || matchLength !== 0) {
                type = "literal";
                this._literalClosingPos = 0;
              }
            }
            break;
          case "?":
            if (this._n3Mode && (match = this._variable.exec(input)))
              type = "var", value = match[0];
            break;
          case "@":
            if (this._previousMarker === "literal" && (match = this._langcode.exec(input)))
              type = "langcode", value = match[1];
            else if (match = this._keyword.exec(input))
              type = match[0];
            break;
          case ".":
            if (input.length === 1 ? inputFinished : input[1] < "0" || input[1] > "9") {
              type = ".";
              matchLength = 1;
              break;
            }
          case "0":
          case "1":
          case "2":
          case "3":
          case "4":
          case "5":
          case "6":
          case "7":
          case "8":
          case "9":
          case "+":
          case "-":
            if (match = this._number.exec(input) || inputFinished && (match = this._number.exec(`${input} `))) {
              type = "literal", value = match[0];
              prefix = typeof match[1] === "string" ? xsd.double : typeof match[2] === "string" ? xsd.decimal : xsd.integer;
            }
            break;
          case "B":
          case "b":
          case "p":
          case "P":
          case "G":
          case "g":
            if (match = this._sparqlKeyword.exec(input))
              type = match[0].toUpperCase();
            else
              inconclusive = true;
            break;
          case "f":
          case "t":
            if (match = this._boolean.exec(input))
              type = "literal", value = match[0], prefix = xsd.boolean;
            else
              inconclusive = true;
            break;
          case "a":
            if (match = this._shortPredicates.exec(input))
              type = "abbreviation", value = "a";
            else
              inconclusive = true;
            break;
          case "=":
            if (this._n3Mode && input.length > 1) {
              type = "abbreviation";
              if (input[1] !== ">")
                matchLength = 1, value = "=";
              else
                matchLength = 2, value = ">";
            }
            break;
          case "!":
            if (!this._n3Mode)
              break;
          case ",":
          case ";":
          case "[":
          case "]":
          case "(":
          case ")":
          case "}":
            if (!this._lineMode) {
              matchLength = 1;
              type = firstChar;
            }
            break;
          case "{":
            if (!this._lineMode && input.length >= 2) {
              if (input[1] === "|")
                type = "{|", matchLength = 2;
              else
                type = firstChar, matchLength = 1;
            }
            break;
          case "|":
            if (input.length >= 2 && input[1] === "}")
              type = "|}", matchLength = 2;
            break;
          default:
            inconclusive = true;
        }
        if (inconclusive) {
          if ((this._previousMarker === "@prefix" || this._previousMarker === "PREFIX") && (match = this._prefix.exec(input)))
            type = "prefix", value = match[1] || "";
          else if ((match = this._prefixed.exec(input)) || inputFinished && (match = this._prefixed.exec(`${input} `)))
            type = "prefixed", prefix = match[1] || "", value = this._unescape(match[2]);
        }
        if (this._previousMarker === "^^") {
          switch (type) {
            case "prefixed":
              type = "type";
              break;
            case "IRI":
              type = "typeIRI";
              break;
            default:
              type = "";
          }
        }
        if (!type) {
          if (inputFinished || !/^'''|^"""/.test(input) && /\n|\r/.test(input))
            return reportSyntaxError(this);
          else
            return this._input = input;
        }
        const length = matchLength || match[0].length;
        const token = emitToken(type, value, prefix, line, length);
        this.previousToken = token;
        this._previousMarker = type;
        input = input.substr(length, input.length);
      }
      function emitToken(type, value, prefix, line, length) {
        const start = input ? currentLineLength - input.length : currentLineLength;
        const end = start + length;
        const token = {
          type,
          value,
          prefix,
          line,
          start,
          end
        };
        callback(null, token);
        return token;
      }
      function reportSyntaxError(self2) {
        callback(self2._syntaxError(/^\S*/.exec(input)[0]));
      }
    }
    _unescape(item) {
      let invalid = false;
      const replaced = item.replace(escapeSequence, (sequence, unicode4, unicode8, escapedChar) => {
        if (typeof unicode4 === "string")
          return String.fromCharCode(Number.parseInt(unicode4, 16));
        if (typeof unicode8 === "string") {
          let charCode = Number.parseInt(unicode8, 16);
          return charCode <= 65535 ? String.fromCharCode(Number.parseInt(unicode8, 16)) : String.fromCharCode(55296 + ((charCode -= 65536) >> 10), 56320 + (charCode & 1023));
        }
        if (escapedChar in escapeReplacements)
          return escapeReplacements[escapedChar];
        invalid = true;
        return "";
      });
      return invalid ? null : replaced;
    }
    _parseLiteral(input) {
      if (input.length >= 3) {
        const opening = input.match(/^(?:"""|"|'''|'|)/)[0];
        const openingLength = opening.length;
        let closingPos = Math.max(this._literalClosingPos, openingLength);
        while ((closingPos = input.indexOf(opening, closingPos)) > 0) {
          let backslashCount = 0;
          while (input[closingPos - backslashCount - 1] === "\\")
            backslashCount++;
          if (backslashCount % 2 === 0) {
            const raw = input.substring(openingLength, closingPos);
            const lines = raw.split(/\r\n|\r|\n/).length - 1;
            const matchLength = closingPos + openingLength;
            if (openingLength === 1 && lines !== 0 || openingLength === 3 && this._lineMode)
              break;
            this._line += lines;
            return {
              value: this._unescape(raw),
              matchLength
            };
          }
          closingPos++;
        }
        this._literalClosingPos = input.length - openingLength + 1;
      }
      return {
        value: "",
        matchLength: 0
      };
    }
    _syntaxError(issue) {
      this._input = null;
      const err = new Error(`Unexpected "${issue}" on line ${this._line}.`);
      err.context = {
        token: undefined,
        line: this._line,
        previousToken: this.previousToken
      };
      return err;
    }
    _readStartingBom(input) {
      return input.startsWith("\uFEFF") ? input.substr(1) : input;
    }
    tokenize(input, callback) {
      this._line = 1;
      if (typeof input === "string") {
        this._input = this._readStartingBom(input);
        if (typeof callback === "function")
          (0, _queueMicrotask.default)(() => this._tokenizeToEnd(callback, true));
        else {
          const tokens = [];
          let error;
          this._tokenizeToEnd((e, t) => e ? error = e : tokens.push(t), true);
          if (error)
            throw error;
          return tokens;
        }
      } else {
        this._pendingBuffer = null;
        if (typeof input.setEncoding === "function")
          input.setEncoding("utf8");
        input.on("data", (data) => {
          if (this._input !== null && data.length !== 0) {
            if (this._pendingBuffer) {
              data = Buffer.concat([this._pendingBuffer, data]);
              this._pendingBuffer = null;
            }
            if (data[data.length - 1] & 128) {
              this._pendingBuffer = data;
            } else {
              if (typeof this._input === "undefined")
                this._input = this._readStartingBom(typeof data === "string" ? data : data.toString());
              else
                this._input += data;
              this._tokenizeToEnd(callback, false);
            }
          }
        });
        input.on("end", () => {
          if (typeof this._input === "string")
            this._tokenizeToEnd(callback, true);
        });
        input.on("error", callback);
      }
    }
  }
  exports.default = N3Lexer;
});

// node_modules/n3/lib/N3Util.js
var require_N3Util = __commonJS((exports) => {
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  var isNamedNode = function(term) {
    return !!term && term.termType === "NamedNode";
  };
  var isBlankNode = function(term) {
    return !!term && term.termType === "BlankNode";
  };
  var isLiteral = function(term) {
    return !!term && term.termType === "Literal";
  };
  var isVariable = function(term) {
    return !!term && term.termType === "Variable";
  };
  var isDefaultGraph = function(term) {
    return !!term && term.termType === "DefaultGraph";
  };
  var inDefaultGraph = function(quad) {
    return isDefaultGraph(quad.graph);
  };
  var prefix = function(iri, factory) {
    return prefixes({
      "": iri.value || iri
    }, factory)("");
  };
  var prefixes = function(defaultPrefixes, factory) {
    const prefixes2 = Object.create(null);
    for (const prefix2 in defaultPrefixes)
      processPrefix(prefix2, defaultPrefixes[prefix2]);
    factory = factory || _N3DataFactory.default;
    function processPrefix(prefix2, iri) {
      if (typeof iri === "string") {
        const cache = Object.create(null);
        prefixes2[prefix2] = (local) => {
          return cache[local] || (cache[local] = factory.namedNode(iri + local));
        };
      } else if (!(prefix2 in prefixes2)) {
        throw new Error(`Unknown prefix: ${prefix2}`);
      }
      return prefixes2[prefix2];
    }
    return processPrefix;
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.inDefaultGraph = inDefaultGraph;
  exports.isBlankNode = isBlankNode;
  exports.isDefaultGraph = isDefaultGraph;
  exports.isLiteral = isLiteral;
  exports.isNamedNode = isNamedNode;
  exports.isVariable = isVariable;
  exports.prefix = prefix;
  exports.prefixes = prefixes;
  var _N3DataFactory = _interopRequireDefault(require_N3DataFactory());
});

// node_modules/n3/lib/N3DataFactory.js
var require_N3DataFactory = __commonJS((exports) => {
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  var termFromId = function(id, factory) {
    factory = factory || DataFactory;
    if (!id)
      return factory.defaultGraph();
    switch (id[0]) {
      case "?":
        return factory.variable(id.substr(1));
      case "_":
        return factory.blankNode(id.substr(2));
      case '"':
        if (factory === DataFactory)
          return new Literal(id);
        if (id[id.length - 1] === '"')
          return factory.literal(id.substr(1, id.length - 2));
        const endPos = id.lastIndexOf('"', id.length - 1);
        return factory.literal(id.substr(1, endPos - 1), id[endPos + 1] === "@" ? id.substr(endPos + 2) : factory.namedNode(id.substr(endPos + 3)));
      case "<":
        const components = quadId.exec(id);
        return factory.quad(termFromId(unescapeQuotes(components[1]), factory), termFromId(unescapeQuotes(components[2]), factory), termFromId(unescapeQuotes(components[3]), factory), components[4] && termFromId(unescapeQuotes(components[4]), factory));
      default:
        return factory.namedNode(id);
    }
  };
  var termToId = function(term) {
    if (typeof term === "string")
      return term;
    if (term instanceof Term && term.termType !== "Quad")
      return term.id;
    if (!term)
      return DEFAULTGRAPH.id;
    switch (term.termType) {
      case "NamedNode":
        return term.value;
      case "BlankNode":
        return `_:${term.value}`;
      case "Variable":
        return `?${term.value}`;
      case "DefaultGraph":
        return "";
      case "Literal":
        return `"${term.value}"${term.language ? `@${term.language}` : term.datatype && term.datatype.value !== xsd.string ? `^^${term.datatype.value}` : ""}`;
      case "Quad":
        return `<<${escapeQuotes(termToId(term.subject))} ${escapeQuotes(termToId(term.predicate))} ${escapeQuotes(termToId(term.object))}${(0, _N3Util.isDefaultGraph)(term.graph) ? "" : ` ${termToId(term.graph)}`}>>`;
      default:
        throw new Error(`Unexpected termType: ${term.termType}`);
    }
  };
  var escapeQuotes = function(id) {
    return id.replace(escapedLiteral, (_, quoted) => `"${quoted.replace(/"/g, '""')}`);
  };
  var unescapeQuotes = function(id) {
    return id.replace(escapedLiteral, (_, quoted) => `"${quoted.replace(/""/g, '"')}`);
  };
  var namedNode = function(iri) {
    return new NamedNode(iri);
  };
  var blankNode = function(name) {
    return new BlankNode(name || `n3-${_blankNodeCounter++}`);
  };
  var literal = function(value, languageOrDataType) {
    if (typeof languageOrDataType === "string")
      return new Literal(`"${value}"@${languageOrDataType.toLowerCase()}`);
    let datatype = languageOrDataType ? languageOrDataType.value : "";
    if (datatype === "") {
      if (typeof value === "boolean")
        datatype = xsd.boolean;
      else if (typeof value === "number") {
        if (Number.isFinite(value))
          datatype = Number.isInteger(value) ? xsd.integer : xsd.double;
        else {
          datatype = xsd.double;
          if (!Number.isNaN(value))
            value = value > 0 ? "INF" : "-INF";
        }
      }
    }
    return datatype === "" || datatype === xsd.string ? new Literal(`"${value}"`) : new Literal(`"${value}"^^${datatype}`);
  };
  var variable = function(name) {
    return new Variable(name);
  };
  var defaultGraph = function() {
    return DEFAULTGRAPH;
  };
  var quad = function(subject, predicate, object, graph) {
    return new Quad(subject, predicate, object, graph);
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = exports.Variable = exports.Triple = exports.Term = exports.Quad = exports.NamedNode = exports.Literal = exports.DefaultGraph = exports.BlankNode = undefined;
  exports.escapeQuotes = escapeQuotes;
  exports.termFromId = termFromId;
  exports.termToId = termToId;
  exports.unescapeQuotes = unescapeQuotes;
  var _IRIs = _interopRequireDefault(require_IRIs());
  var _N3Util = require_N3Util();
  var {
    rdf,
    xsd
  } = _IRIs.default;
  var DEFAULTGRAPH;
  var _blankNodeCounter = 0;
  var escapedLiteral = /^"(.*".*)(?="[^"]*$)/;
  var quadId = /^<<("(?:""|[^"])*"[^ ]*|[^ ]+) ("(?:""|[^"])*"[^ ]*|[^ ]+) ("(?:""|[^"])*"[^ ]*|[^ ]+) ?("(?:""|[^"])*"[^ ]*|[^ ]+)?>>$/;
  var DataFactory = {
    namedNode,
    blankNode,
    variable,
    literal,
    defaultGraph,
    quad,
    triple: quad
  };
  var _default = DataFactory;
  exports.default = _default;

  class Term {
    constructor(id) {
      this.id = id;
    }
    get value() {
      return this.id;
    }
    equals(other) {
      if (other instanceof Term)
        return this.id === other.id;
      return !!other && this.termType === other.termType && this.value === other.value;
    }
    hashCode() {
      return 0;
    }
    toJSON() {
      return {
        termType: this.termType,
        value: this.value
      };
    }
  }
  exports.Term = Term;

  class NamedNode extends Term {
    get termType() {
      return "NamedNode";
    }
  }
  exports.NamedNode = NamedNode;

  class Literal extends Term {
    get termType() {
      return "Literal";
    }
    get value() {
      return this.id.substring(1, this.id.lastIndexOf('"'));
    }
    get language() {
      const id = this.id;
      let atPos = id.lastIndexOf('"') + 1;
      return atPos < id.length && id[atPos++] === "@" ? id.substr(atPos).toLowerCase() : "";
    }
    get datatype() {
      return new NamedNode(this.datatypeString);
    }
    get datatypeString() {
      const id = this.id, dtPos = id.lastIndexOf('"') + 1;
      const char = dtPos < id.length ? id[dtPos] : "";
      return char === "^" ? id.substr(dtPos + 2) : char !== "@" ? xsd.string : rdf.langString;
    }
    equals(other) {
      if (other instanceof Literal)
        return this.id === other.id;
      return !!other && !!other.datatype && this.termType === other.termType && this.value === other.value && this.language === other.language && this.datatype.value === other.datatype.value;
    }
    toJSON() {
      return {
        termType: this.termType,
        value: this.value,
        language: this.language,
        datatype: {
          termType: "NamedNode",
          value: this.datatypeString
        }
      };
    }
  }
  exports.Literal = Literal;

  class BlankNode extends Term {
    constructor(name) {
      super(`_:${name}`);
    }
    get termType() {
      return "BlankNode";
    }
    get value() {
      return this.id.substr(2);
    }
  }
  exports.BlankNode = BlankNode;

  class Variable extends Term {
    constructor(name) {
      super(`?${name}`);
    }
    get termType() {
      return "Variable";
    }
    get value() {
      return this.id.substr(1);
    }
  }
  exports.Variable = Variable;

  class DefaultGraph extends Term {
    constructor() {
      super("");
      return DEFAULTGRAPH || this;
    }
    get termType() {
      return "DefaultGraph";
    }
    equals(other) {
      return this === other || !!other && this.termType === other.termType;
    }
  }
  exports.DefaultGraph = DefaultGraph;
  DEFAULTGRAPH = new DefaultGraph;

  class Quad extends Term {
    constructor(subject, predicate, object, graph) {
      super("");
      this._subject = subject;
      this._predicate = predicate;
      this._object = object;
      this._graph = graph || DEFAULTGRAPH;
    }
    get termType() {
      return "Quad";
    }
    get subject() {
      return this._subject;
    }
    get predicate() {
      return this._predicate;
    }
    get object() {
      return this._object;
    }
    get graph() {
      return this._graph;
    }
    toJSON() {
      return {
        termType: this.termType,
        subject: this._subject.toJSON(),
        predicate: this._predicate.toJSON(),
        object: this._object.toJSON(),
        graph: this._graph.toJSON()
      };
    }
    equals(other) {
      return !!other && this._subject.equals(other.subject) && this._predicate.equals(other.predicate) && this._object.equals(other.object) && this._graph.equals(other.graph);
    }
  }
  exports.Triple = exports.Quad = Quad;
});

// node_modules/n3/lib/N3Parser.js
var require_N3Parser = __commonJS((exports) => {
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  var noop = function() {
  };
  var initDataFactory = function(parser, factory) {
    const namedNode = factory.namedNode;
    parser._namedNode = namedNode;
    parser._blankNode = factory.blankNode;
    parser._literal = factory.literal;
    parser._variable = factory.variable;
    parser._quad = factory.quad;
    parser.DEFAULTGRAPH = factory.defaultGraph();
    parser.RDF_FIRST = namedNode(_IRIs.default.rdf.first);
    parser.RDF_REST = namedNode(_IRIs.default.rdf.rest);
    parser.RDF_NIL = namedNode(_IRIs.default.rdf.nil);
    parser.N3_FORALL = namedNode(_IRIs.default.r.forAll);
    parser.N3_FORSOME = namedNode(_IRIs.default.r.forSome);
    parser.ABBREVIATIONS = {
      a: namedNode(_IRIs.default.rdf.type),
      "=": namedNode(_IRIs.default.owl.sameAs),
      ">": namedNode(_IRIs.default.log.implies)
    };
    parser.QUANTIFIERS_GRAPH = namedNode("urn:n3:quantifiers");
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = undefined;
  var _N3Lexer = _interopRequireDefault(require_N3Lexer());
  var _N3DataFactory = _interopRequireDefault(require_N3DataFactory());
  var _IRIs = _interopRequireDefault(require_IRIs());
  var blankNodePrefix = 0;

  class N3Parser {
    constructor(options) {
      this._contextStack = [];
      this._graph = null;
      options = options || {};
      this._setBase(options.baseIRI);
      options.factory && initDataFactory(this, options.factory);
      const format = typeof options.format === "string" ? options.format.match(/\w*$/)[0].toLowerCase() : "", isTurtle = /turtle/.test(format), isTriG = /trig/.test(format), isNTriples = /triple/.test(format), isNQuads = /quad/.test(format), isN3 = this._n3Mode = /n3/.test(format), isLineMode = isNTriples || isNQuads;
      if (!(this._supportsNamedGraphs = !(isTurtle || isN3)))
        this._readPredicateOrNamedGraph = this._readPredicate;
      this._supportsQuads = !(isTurtle || isTriG || isNTriples || isN3);
      this._supportsRDFStar = format === "" || /star|\*$/.test(format);
      if (isLineMode)
        this._resolveRelativeIRI = (iri) => {
          return null;
        };
      this._blankNodePrefix = typeof options.blankNodePrefix !== "string" ? "" : options.blankNodePrefix.replace(/^(?!_:)/, "_:");
      this._lexer = options.lexer || new _N3Lexer.default({
        lineMode: isLineMode,
        n3: isN3
      });
      this._explicitQuantifiers = !!options.explicitQuantifiers;
    }
    static _resetBlankNodePrefix() {
      blankNodePrefix = 0;
    }
    _setBase(baseIRI) {
      if (!baseIRI) {
        this._base = "";
        this._basePath = "";
      } else {
        const fragmentPos = baseIRI.indexOf("#");
        if (fragmentPos >= 0)
          baseIRI = baseIRI.substr(0, fragmentPos);
        this._base = baseIRI;
        this._basePath = baseIRI.indexOf("/") < 0 ? baseIRI : baseIRI.replace(/[^\/?]*(?:\?.*)?$/, "");
        baseIRI = baseIRI.match(/^(?:([a-z][a-z0-9+.-]*:))?(?:\/\/[^\/]*)?/i);
        this._baseRoot = baseIRI[0];
        this._baseScheme = baseIRI[1];
      }
    }
    _saveContext(type, graph, subject, predicate, object) {
      const n3Mode = this._n3Mode;
      this._contextStack.push({
        type,
        subject,
        predicate,
        object,
        graph,
        inverse: n3Mode ? this._inversePredicate : false,
        blankPrefix: n3Mode ? this._prefixes._ : "",
        quantified: n3Mode ? this._quantified : null
      });
      if (n3Mode) {
        this._inversePredicate = false;
        this._prefixes._ = this._graph ? `${this._graph.value}.` : ".";
        this._quantified = Object.create(this._quantified);
      }
    }
    _restoreContext(type, token) {
      const context = this._contextStack.pop();
      if (!context || context.type !== type)
        return this._error(`Unexpected ${token.type}`, token);
      this._subject = context.subject;
      this._predicate = context.predicate;
      this._object = context.object;
      this._graph = context.graph;
      if (this._n3Mode) {
        this._inversePredicate = context.inverse;
        this._prefixes._ = context.blankPrefix;
        this._quantified = context.quantified;
      }
    }
    _readInTopContext(token) {
      switch (token.type) {
        case "eof":
          if (this._graph !== null)
            return this._error("Unclosed graph", token);
          delete this._prefixes._;
          return this._callback(null, null, this._prefixes);
        case "PREFIX":
          this._sparqlStyle = true;
        case "@prefix":
          return this._readPrefix;
        case "BASE":
          this._sparqlStyle = true;
        case "@base":
          return this._readBaseIRI;
        case "{":
          if (this._supportsNamedGraphs) {
            this._graph = "";
            this._subject = null;
            return this._readSubject;
          }
        case "GRAPH":
          if (this._supportsNamedGraphs)
            return this._readNamedGraphLabel;
        default:
          return this._readSubject(token);
      }
    }
    _readEntity(token, quantifier) {
      let value;
      switch (token.type) {
        case "IRI":
        case "typeIRI":
          const iri = this._resolveIRI(token.value);
          if (iri === null)
            return this._error("Invalid IRI", token);
          value = this._namedNode(iri);
          break;
        case "type":
        case "prefixed":
          const prefix = this._prefixes[token.prefix];
          if (prefix === undefined)
            return this._error(`Undefined prefix "${token.prefix}:"`, token);
          value = this._namedNode(prefix + token.value);
          break;
        case "blank":
          value = this._blankNode(this._prefixes[token.prefix] + token.value);
          break;
        case "var":
          value = this._variable(token.value.substr(1));
          break;
        default:
          return this._error(`Expected entity but got ${token.type}`, token);
      }
      if (!quantifier && this._n3Mode && (value.id in this._quantified))
        value = this._quantified[value.id];
      return value;
    }
    _readSubject(token) {
      this._predicate = null;
      switch (token.type) {
        case "[":
          this._saveContext("blank", this._graph, this._subject = this._blankNode(), null, null);
          return this._readBlankNodeHead;
        case "(":
          this._saveContext("list", this._graph, this.RDF_NIL, null, null);
          this._subject = null;
          return this._readListItem;
        case "{":
          if (!this._n3Mode)
            return this._error("Unexpected graph", token);
          this._saveContext("formula", this._graph, this._graph = this._blankNode(), null, null);
          return this._readSubject;
        case "}":
          return this._readPunctuation(token);
        case "@forSome":
          if (!this._n3Mode)
            return this._error('Unexpected "@forSome"', token);
          this._subject = null;
          this._predicate = this.N3_FORSOME;
          this._quantifier = this._blankNode;
          return this._readQuantifierList;
        case "@forAll":
          if (!this._n3Mode)
            return this._error('Unexpected "@forAll"', token);
          this._subject = null;
          this._predicate = this.N3_FORALL;
          this._quantifier = this._variable;
          return this._readQuantifierList;
        case "literal":
          if (!this._n3Mode)
            return this._error("Unexpected literal", token);
          if (token.prefix.length === 0) {
            this._literalValue = token.value;
            return this._completeSubjectLiteral;
          } else
            this._subject = this._literal(token.value, this._namedNode(token.prefix));
          break;
        case "<<":
          if (!this._supportsRDFStar)
            return this._error("Unexpected RDF* syntax", token);
          this._saveContext("<<", this._graph, null, null, null);
          this._graph = null;
          return this._readSubject;
        default:
          if ((this._subject = this._readEntity(token)) === undefined)
            return;
          if (this._n3Mode)
            return this._getPathReader(this._readPredicateOrNamedGraph);
      }
      return this._readPredicateOrNamedGraph;
    }
    _readPredicate(token) {
      const type = token.type;
      switch (type) {
        case "inverse":
          this._inversePredicate = true;
        case "abbreviation":
          this._predicate = this.ABBREVIATIONS[token.value];
          break;
        case ".":
        case "]":
        case "}":
          if (this._predicate === null)
            return this._error(`Unexpected ${type}`, token);
          this._subject = null;
          return type === "]" ? this._readBlankNodeTail(token) : this._readPunctuation(token);
        case ";":
          return this._predicate !== null ? this._readPredicate : this._error("Expected predicate but got ;", token);
        case "[":
          if (this._n3Mode) {
            this._saveContext("blank", this._graph, this._subject, this._subject = this._blankNode(), null);
            return this._readBlankNodeHead;
          }
        case "blank":
          if (!this._n3Mode)
            return this._error("Disallowed blank node as predicate", token);
        default:
          if ((this._predicate = this._readEntity(token)) === undefined)
            return;
      }
      return this._readObject;
    }
    _readObject(token) {
      switch (token.type) {
        case "literal":
          if (token.prefix.length === 0) {
            this._literalValue = token.value;
            return this._readDataTypeOrLang;
          } else
            this._object = this._literal(token.value, this._namedNode(token.prefix));
          break;
        case "[":
          this._saveContext("blank", this._graph, this._subject, this._predicate, this._subject = this._blankNode());
          return this._readBlankNodeHead;
        case "(":
          this._saveContext("list", this._graph, this._subject, this._predicate, this.RDF_NIL);
          this._subject = null;
          return this._readListItem;
        case "{":
          if (!this._n3Mode)
            return this._error("Unexpected graph", token);
          this._saveContext("formula", this._graph, this._subject, this._predicate, this._graph = this._blankNode());
          return this._readSubject;
        case "<<":
          if (!this._supportsRDFStar)
            return this._error("Unexpected RDF* syntax", token);
          this._saveContext("<<", this._graph, this._subject, this._predicate, null);
          this._graph = null;
          return this._readSubject;
        default:
          if ((this._object = this._readEntity(token)) === undefined)
            return;
          if (this._n3Mode)
            return this._getPathReader(this._getContextEndReader());
      }
      return this._getContextEndReader();
    }
    _readPredicateOrNamedGraph(token) {
      return token.type === "{" ? this._readGraph(token) : this._readPredicate(token);
    }
    _readGraph(token) {
      if (token.type !== "{")
        return this._error(`Expected graph but got ${token.type}`, token);
      this._graph = this._subject, this._subject = null;
      return this._readSubject;
    }
    _readBlankNodeHead(token) {
      if (token.type === "]") {
        this._subject = null;
        return this._readBlankNodeTail(token);
      } else {
        this._predicate = null;
        return this._readPredicate(token);
      }
    }
    _readBlankNodeTail(token) {
      if (token.type !== "]")
        return this._readBlankNodePunctuation(token);
      if (this._subject !== null)
        this._emit(this._subject, this._predicate, this._object, this._graph);
      const empty = this._predicate === null;
      this._restoreContext("blank", token);
      if (this._object !== null)
        return this._getContextEndReader();
      else if (this._predicate !== null)
        return this._readObject;
      else
        return empty ? this._readPredicateOrNamedGraph : this._readPredicateAfterBlank;
    }
    _readPredicateAfterBlank(token) {
      switch (token.type) {
        case ".":
        case "}":
          this._subject = null;
          return this._readPunctuation(token);
        default:
          return this._readPredicate(token);
      }
    }
    _readListItem(token) {
      let item = null, list = null, next = this._readListItem;
      const previousList = this._subject, stack = this._contextStack, parent = stack[stack.length - 1];
      switch (token.type) {
        case "[":
          this._saveContext("blank", this._graph, list = this._blankNode(), this.RDF_FIRST, this._subject = item = this._blankNode());
          next = this._readBlankNodeHead;
          break;
        case "(":
          this._saveContext("list", this._graph, list = this._blankNode(), this.RDF_FIRST, this.RDF_NIL);
          this._subject = null;
          break;
        case ")":
          this._restoreContext("list", token);
          if (stack.length !== 0 && stack[stack.length - 1].type === "list")
            this._emit(this._subject, this._predicate, this._object, this._graph);
          if (this._predicate === null) {
            next = this._readPredicate;
            if (this._subject === this.RDF_NIL)
              return next;
          } else {
            next = this._getContextEndReader();
            if (this._object === this.RDF_NIL)
              return next;
          }
          list = this.RDF_NIL;
          break;
        case "literal":
          if (token.prefix.length === 0) {
            this._literalValue = token.value;
            next = this._readListItemDataTypeOrLang;
          } else {
            item = this._literal(token.value, this._namedNode(token.prefix));
            next = this._getContextEndReader();
          }
          break;
        case "{":
          if (!this._n3Mode)
            return this._error("Unexpected graph", token);
          this._saveContext("formula", this._graph, this._subject, this._predicate, this._graph = this._blankNode());
          return this._readSubject;
        default:
          if ((item = this._readEntity(token)) === undefined)
            return;
      }
      if (list === null)
        this._subject = list = this._blankNode();
      if (previousList === null) {
        if (parent.predicate === null)
          parent.subject = list;
        else
          parent.object = list;
      } else {
        this._emit(previousList, this.RDF_REST, list, this._graph);
      }
      if (item !== null) {
        if (this._n3Mode && (token.type === "IRI" || token.type === "prefixed")) {
          this._saveContext("item", this._graph, list, this.RDF_FIRST, item);
          this._subject = item, this._predicate = null;
          return this._getPathReader(this._readListItem);
        }
        this._emit(list, this.RDF_FIRST, item, this._graph);
      }
      return next;
    }
    _readDataTypeOrLang(token) {
      return this._completeObjectLiteral(token, false);
    }
    _readListItemDataTypeOrLang(token) {
      return this._completeObjectLiteral(token, true);
    }
    _completeLiteral(token) {
      let literal = this._literal(this._literalValue);
      switch (token.type) {
        case "type":
        case "typeIRI":
          const datatype = this._readEntity(token);
          if (datatype === undefined)
            return;
          literal = this._literal(this._literalValue, datatype);
          token = null;
          break;
        case "langcode":
          literal = this._literal(this._literalValue, token.value);
          token = null;
          break;
      }
      return {
        token,
        literal
      };
    }
    _completeSubjectLiteral(token) {
      this._subject = this._completeLiteral(token).literal;
      return this._readPredicateOrNamedGraph;
    }
    _completeObjectLiteral(token, listItem) {
      const completed = this._completeLiteral(token);
      if (!completed)
        return;
      this._object = completed.literal;
      if (listItem)
        this._emit(this._subject, this.RDF_FIRST, this._object, this._graph);
      if (completed.token === null)
        return this._getContextEndReader();
      else {
        this._readCallback = this._getContextEndReader();
        return this._readCallback(completed.token);
      }
    }
    _readFormulaTail(token) {
      if (token.type !== "}")
        return this._readPunctuation(token);
      if (this._subject !== null)
        this._emit(this._subject, this._predicate, this._object, this._graph);
      this._restoreContext("formula", token);
      return this._object === null ? this._readPredicate : this._getContextEndReader();
    }
    _readPunctuation(token) {
      let next, graph = this._graph;
      const subject = this._subject, inversePredicate = this._inversePredicate;
      switch (token.type) {
        case "}":
          if (this._graph === null)
            return this._error("Unexpected graph closing", token);
          if (this._n3Mode)
            return this._readFormulaTail(token);
          this._graph = null;
        case ".":
          this._subject = null;
          next = this._contextStack.length ? this._readSubject : this._readInTopContext;
          if (inversePredicate)
            this._inversePredicate = false;
          break;
        case ";":
          next = this._readPredicate;
          break;
        case ",":
          next = this._readObject;
          break;
        case "{|":
          if (!this._supportsRDFStar)
            return this._error("Unexpected RDF* syntax", token);
          const predicate = this._predicate, object = this._object;
          this._subject = this._quad(subject, predicate, object, this.DEFAULTGRAPH);
          next = this._readPredicate;
          break;
        case "|}":
          if (this._subject.termType !== "Quad")
            return this._error("Unexpected asserted triple closing", token);
          this._subject = null;
          next = this._readPunctuation;
          break;
        default:
          if (this._supportsQuads && this._graph === null && (graph = this._readEntity(token)) !== undefined) {
            next = this._readQuadPunctuation;
            break;
          }
          return this._error(`Expected punctuation to follow "${this._object.id}"`, token);
      }
      if (subject !== null) {
        const predicate = this._predicate, object = this._object;
        if (!inversePredicate)
          this._emit(subject, predicate, object, graph);
        else
          this._emit(object, predicate, subject, graph);
      }
      return next;
    }
    _readBlankNodePunctuation(token) {
      let next;
      switch (token.type) {
        case ";":
          next = this._readPredicate;
          break;
        case ",":
          next = this._readObject;
          break;
        default:
          return this._error(`Expected punctuation to follow "${this._object.id}"`, token);
      }
      this._emit(this._subject, this._predicate, this._object, this._graph);
      return next;
    }
    _readQuadPunctuation(token) {
      if (token.type !== ".")
        return this._error("Expected dot to follow quad", token);
      return this._readInTopContext;
    }
    _readPrefix(token) {
      if (token.type !== "prefix")
        return this._error("Expected prefix to follow @prefix", token);
      this._prefix = token.value;
      return this._readPrefixIRI;
    }
    _readPrefixIRI(token) {
      if (token.type !== "IRI")
        return this._error(`Expected IRI to follow prefix "${this._prefix}:"`, token);
      const prefixNode = this._readEntity(token);
      this._prefixes[this._prefix] = prefixNode.value;
      this._prefixCallback(this._prefix, prefixNode);
      return this._readDeclarationPunctuation;
    }
    _readBaseIRI(token) {
      const iri = token.type === "IRI" && this._resolveIRI(token.value);
      if (!iri)
        return this._error("Expected valid IRI to follow base declaration", token);
      this._setBase(iri);
      return this._readDeclarationPunctuation;
    }
    _readNamedGraphLabel(token) {
      switch (token.type) {
        case "IRI":
        case "blank":
        case "prefixed":
          return this._readSubject(token), this._readGraph;
        case "[":
          return this._readNamedGraphBlankLabel;
        default:
          return this._error("Invalid graph label", token);
      }
    }
    _readNamedGraphBlankLabel(token) {
      if (token.type !== "]")
        return this._error("Invalid graph label", token);
      this._subject = this._blankNode();
      return this._readGraph;
    }
    _readDeclarationPunctuation(token) {
      if (this._sparqlStyle) {
        this._sparqlStyle = false;
        return this._readInTopContext(token);
      }
      if (token.type !== ".")
        return this._error("Expected declaration to end with a dot", token);
      return this._readInTopContext;
    }
    _readQuantifierList(token) {
      let entity;
      switch (token.type) {
        case "IRI":
        case "prefixed":
          if ((entity = this._readEntity(token, true)) !== undefined)
            break;
        default:
          return this._error(`Unexpected ${token.type}`, token);
      }
      if (!this._explicitQuantifiers)
        this._quantified[entity.id] = this._quantifier(this._blankNode().value);
      else {
        if (this._subject === null)
          this._emit(this._graph || this.DEFAULTGRAPH, this._predicate, this._subject = this._blankNode(), this.QUANTIFIERS_GRAPH);
        else
          this._emit(this._subject, this.RDF_REST, this._subject = this._blankNode(), this.QUANTIFIERS_GRAPH);
        this._emit(this._subject, this.RDF_FIRST, entity, this.QUANTIFIERS_GRAPH);
      }
      return this._readQuantifierPunctuation;
    }
    _readQuantifierPunctuation(token) {
      if (token.type === ",")
        return this._readQuantifierList;
      else {
        if (this._explicitQuantifiers) {
          this._emit(this._subject, this.RDF_REST, this.RDF_NIL, this.QUANTIFIERS_GRAPH);
          this._subject = null;
        }
        this._readCallback = this._getContextEndReader();
        return this._readCallback(token);
      }
    }
    _getPathReader(afterPath) {
      this._afterPath = afterPath;
      return this._readPath;
    }
    _readPath(token) {
      switch (token.type) {
        case "!":
          return this._readForwardPath;
        case "^":
          return this._readBackwardPath;
        default:
          const stack = this._contextStack, parent = stack.length && stack[stack.length - 1];
          if (parent && parent.type === "item") {
            const item = this._subject;
            this._restoreContext("item", token);
            this._emit(this._subject, this.RDF_FIRST, item, this._graph);
          }
          return this._afterPath(token);
      }
    }
    _readForwardPath(token) {
      let subject, predicate;
      const object = this._blankNode();
      if ((predicate = this._readEntity(token)) === undefined)
        return;
      if (this._predicate === null)
        subject = this._subject, this._subject = object;
      else
        subject = this._object, this._object = object;
      this._emit(subject, predicate, object, this._graph);
      return this._readPath;
    }
    _readBackwardPath(token) {
      const subject = this._blankNode();
      let predicate, object;
      if ((predicate = this._readEntity(token)) === undefined)
        return;
      if (this._predicate === null)
        object = this._subject, this._subject = subject;
      else
        object = this._object, this._object = subject;
      this._emit(subject, predicate, object, this._graph);
      return this._readPath;
    }
    _readRDFStarTailOrGraph(token) {
      if (token.type !== ">>") {
        if (this._supportsQuads && this._graph === null && (this._graph = this._readEntity(token)) !== undefined)
          return this._readRDFStarTail;
        return this._error(`Expected >> to follow "${this._object.id}"`, token);
      }
      return this._readRDFStarTail(token);
    }
    _readRDFStarTail(token) {
      if (token.type !== ">>")
        return this._error(`Expected >> but got ${token.type}`, token);
      const quad = this._quad(this._subject, this._predicate, this._object, this._graph || this.DEFAULTGRAPH);
      this._restoreContext("<<", token);
      if (this._subject === null) {
        this._subject = quad;
        return this._readPredicate;
      } else {
        this._object = quad;
        return this._getContextEndReader();
      }
    }
    _getContextEndReader() {
      const contextStack = this._contextStack;
      if (!contextStack.length)
        return this._readPunctuation;
      switch (contextStack[contextStack.length - 1].type) {
        case "blank":
          return this._readBlankNodeTail;
        case "list":
          return this._readListItem;
        case "formula":
          return this._readFormulaTail;
        case "<<":
          return this._readRDFStarTailOrGraph;
      }
    }
    _emit(subject, predicate, object, graph) {
      this._callback(null, this._quad(subject, predicate, object, graph || this.DEFAULTGRAPH));
    }
    _error(message, token) {
      const err = new Error(`${message} on line ${token.line}.`);
      err.context = {
        token,
        line: token.line,
        previousToken: this._lexer.previousToken
      };
      this._callback(err);
      this._callback = noop;
    }
    _resolveIRI(iri) {
      return /^[a-z][a-z0-9+.-]*:/i.test(iri) ? iri : this._resolveRelativeIRI(iri);
    }
    _resolveRelativeIRI(iri) {
      if (!iri.length)
        return this._base;
      switch (iri[0]) {
        case "#":
          return this._base + iri;
        case "?":
          return this._base.replace(/(?:\?.*)?$/, iri);
        case "/":
          return (iri[1] === "/" ? this._baseScheme : this._baseRoot) + this._removeDotSegments(iri);
        default:
          return /^[^/:]*:/.test(iri) ? null : this._removeDotSegments(this._basePath + iri);
      }
    }
    _removeDotSegments(iri) {
      if (!/(^|\/)\.\.?($|[/#?])/.test(iri))
        return iri;
      const length = iri.length;
      let result = "", i = -1, pathStart = -1, segmentStart = 0, next = "/";
      while (i < length) {
        switch (next) {
          case ":":
            if (pathStart < 0) {
              if (iri[++i] === "/" && iri[++i] === "/")
                while ((pathStart = i + 1) < length && iri[pathStart] !== "/")
                  i = pathStart;
            }
            break;
          case "?":
          case "#":
            i = length;
            break;
          case "/":
            if (iri[i + 1] === ".") {
              next = iri[++i + 1];
              switch (next) {
                case "/":
                  result += iri.substring(segmentStart, i - 1);
                  segmentStart = i + 1;
                  break;
                case undefined:
                case "?":
                case "#":
                  return result + iri.substring(segmentStart, i) + iri.substr(i + 1);
                case ".":
                  next = iri[++i + 1];
                  if (next === undefined || next === "/" || next === "?" || next === "#") {
                    result += iri.substring(segmentStart, i - 2);
                    if ((segmentStart = result.lastIndexOf("/")) >= pathStart)
                      result = result.substr(0, segmentStart);
                    if (next !== "/")
                      return `${result}/${iri.substr(i + 1)}`;
                    segmentStart = i + 1;
                  }
              }
            }
        }
        next = iri[++i];
      }
      return result + iri.substring(segmentStart);
    }
    parse(input, quadCallback, prefixCallback) {
      this._readCallback = this._readInTopContext;
      this._sparqlStyle = false;
      this._prefixes = Object.create(null);
      this._prefixes._ = this._blankNodePrefix ? this._blankNodePrefix.substr(2) : `b${blankNodePrefix++}_`;
      this._prefixCallback = prefixCallback || noop;
      this._inversePredicate = false;
      this._quantified = Object.create(null);
      if (!quadCallback) {
        const quads = [];
        let error;
        this._callback = (e, t) => {
          e ? error = e : t && quads.push(t);
        };
        this._lexer.tokenize(input).every((token) => {
          return this._readCallback = this._readCallback(token);
        });
        if (error)
          throw error;
        return quads;
      }
      this._callback = quadCallback;
      this._lexer.tokenize(input, (error, token) => {
        if (error !== null)
          this._callback(error), this._callback = noop;
        else if (this._readCallback)
          this._readCallback = this._readCallback(token);
      });
    }
  }
  exports.default = N3Parser;
  initDataFactory(N3Parser.prototype, _N3DataFactory.default);
});

// node_modules/n3/lib/N3Writer.js
var require_N3Writer = __commonJS((exports) => {
  var _getRequireWildcardCache = function(nodeInterop) {
    if (typeof WeakMap !== "function")
      return null;
    var cacheBabelInterop = new WeakMap;
    var cacheNodeInterop = new WeakMap;
    return (_getRequireWildcardCache = function(nodeInterop2) {
      return nodeInterop2 ? cacheNodeInterop : cacheBabelInterop;
    })(nodeInterop);
  };
  var _interopRequireWildcard = function(obj, nodeInterop) {
    if (!nodeInterop && obj && obj.__esModule) {
      return obj;
    }
    if (obj === null || typeof obj !== "object" && typeof obj !== "function") {
      return { default: obj };
    }
    var cache = _getRequireWildcardCache(nodeInterop);
    if (cache && cache.has(obj)) {
      return cache.get(obj);
    }
    var newObj = {};
    var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor;
    for (var key in obj) {
      if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) {
        var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null;
        if (desc && (desc.get || desc.set)) {
          Object.defineProperty(newObj, key, desc);
        } else {
          newObj[key] = obj[key];
        }
      }
    }
    newObj.default = obj;
    if (cache) {
      cache.set(obj, newObj);
    }
    return newObj;
  };
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  var characterReplacer = function(character) {
    let result = escapedCharacters[character];
    if (result === undefined) {
      if (character.length === 1) {
        result = character.charCodeAt(0).toString(16);
        result = "\\u0000".substr(0, 6 - result.length) + result;
      } else {
        result = ((character.charCodeAt(0) - 55296) * 1024 + character.charCodeAt(1) + 9216).toString(16);
        result = "\\U00000000".substr(0, 10 - result.length) + result;
      }
    }
    return result;
  };
  var escapeRegex = function(regex) {
    return regex.replace(/[\]\/\(\)\*\+\?\.\\\$]/g, "\\$&");
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = undefined;
  var _IRIs = _interopRequireDefault(require_IRIs());
  var _N3DataFactory = _interopRequireWildcard(require_N3DataFactory());
  var _N3Util = require_N3Util();
  var DEFAULTGRAPH = _N3DataFactory.default.defaultGraph();
  var {
    rdf,
    xsd
  } = _IRIs.default;
  var escape = /["\\\t\n\r\b\f\u0000-\u0019\ud800-\udbff]/;
  var escapeAll = /["\\\t\n\r\b\f\u0000-\u0019]|[\ud800-\udbff][\udc00-\udfff]/g;
  var escapedCharacters = {
    "\\": "\\\\",
    '"': '\\"',
    "\t": "\\t",
    "\n": "\\n",
    "\r": "\\r",
    "\b": "\\b",
    "\f": "\\f"
  };

  class SerializedTerm extends _N3DataFactory.Term {
    equals(other) {
      return other === this;
    }
  }

  class N3Writer {
    constructor(outputStream, options) {
      this._prefixRegex = /$0^/;
      if (outputStream && typeof outputStream.write !== "function")
        options = outputStream, outputStream = null;
      options = options || {};
      this._lists = options.lists;
      if (!outputStream) {
        let output = "";
        this._outputStream = {
          write(chunk, encoding, done) {
            output += chunk;
            done && done();
          },
          end: (done) => {
            done && done(null, output);
          }
        };
        this._endStream = true;
      } else {
        this._outputStream = outputStream;
        this._endStream = options.end === undefined ? true : !!options.end;
      }
      this._subject = null;
      if (!/triple|quad/i.test(options.format)) {
        this._lineMode = false;
        this._graph = DEFAULTGRAPH;
        this._prefixIRIs = Object.create(null);
        options.prefixes && this.addPrefixes(options.prefixes);
        if (options.baseIRI) {
          this._baseMatcher = new RegExp(`^${escapeRegex(options.baseIRI)}${options.baseIRI.endsWith("/") ? "" : "[#?]"}`);
          this._baseLength = options.baseIRI.length;
        }
      } else {
        this._lineMode = true;
        this._writeQuad = this._writeQuadLine;
      }
    }
    get _inDefaultGraph() {
      return DEFAULTGRAPH.equals(this._graph);
    }
    _write(string, callback) {
      this._outputStream.write(string, "utf8", callback);
    }
    _writeQuad(subject, predicate, object, graph, done) {
      try {
        if (!graph.equals(this._graph)) {
          this._write((this._subject === null ? "" : this._inDefaultGraph ? ".\n" : "\n}\n") + (DEFAULTGRAPH.equals(graph) ? "" : `${this._encodeIriOrBlank(graph)} {\n`));
          this._graph = graph;
          this._subject = null;
        }
        if (subject.equals(this._subject)) {
          if (predicate.equals(this._predicate))
            this._write(`, ${this._encodeObject(object)}`, done);
          else
            this._write(`;\n    ${this._encodePredicate(this._predicate = predicate)} ${this._encodeObject(object)}`, done);
        } else
          this._write(`${(this._subject === null ? "" : ".\n") + this._encodeSubject(this._subject = subject)} ${this._encodePredicate(this._predicate = predicate)} ${this._encodeObject(object)}`, done);
      } catch (error) {
        done && done(error);
      }
    }
    _writeQuadLine(subject, predicate, object, graph, done) {
      delete this._prefixMatch;
      this._write(this.quadToString(subject, predicate, object, graph), done);
    }
    quadToString(subject, predicate, object, graph) {
      return `${this._encodeSubject(subject)} ${this._encodeIriOrBlank(predicate)} ${this._encodeObject(object)}${graph && graph.value ? ` ${this._encodeIriOrBlank(graph)} .\n` : " .\n"}`;
    }
    quadsToString(quads) {
      return quads.map((t) => {
        return this.quadToString(t.subject, t.predicate, t.object, t.graph);
      }).join("");
    }
    _encodeSubject(entity) {
      return entity.termType === "Quad" ? this._encodeQuad(entity) : this._encodeIriOrBlank(entity);
    }
    _encodeIriOrBlank(entity) {
      if (entity.termType !== "NamedNode") {
        if (this._lists && (entity.value in this._lists))
          entity = this.list(this._lists[entity.value]);
        return "id" in entity ? entity.id : `_:${entity.value}`;
      }
      let iri = entity.value;
      if (this._baseMatcher && this._baseMatcher.test(iri))
        iri = iri.substr(this._baseLength);
      if (escape.test(iri))
        iri = iri.replace(escapeAll, characterReplacer);
      const prefixMatch = this._prefixRegex.exec(iri);
      return !prefixMatch ? `<${iri}>` : !prefixMatch[1] ? iri : this._prefixIRIs[prefixMatch[1]] + prefixMatch[2];
    }
    _encodeLiteral(literal) {
      let value = literal.value;
      if (escape.test(value))
        value = value.replace(escapeAll, characterReplacer);
      if (literal.language)
        return `"${value}"@${literal.language}`;
      if (this._lineMode) {
        if (literal.datatype.value === xsd.string)
          return `"${value}"`;
      } else {
        switch (literal.datatype.value) {
          case xsd.string:
            return `"${value}"`;
          case xsd.boolean:
            if (value === "true" || value === "false")
              return value;
            break;
          case xsd.integer:
            if (/^[+-]?\d+$/.test(value))
              return value;
            break;
          case xsd.decimal:
            if (/^[+-]?\d*\.\d+$/.test(value))
              return value;
            break;
          case xsd.double:
            if (/^[+-]?(?:\d+\.\d*|\.?\d+)[eE][+-]?\d+$/.test(value))
              return value;
            break;
        }
      }
      return `"${value}"^^${this._encodeIriOrBlank(literal.datatype)}`;
    }
    _encodePredicate(predicate) {
      return predicate.value === rdf.type ? "a" : this._encodeIriOrBlank(predicate);
    }
    _encodeObject(object) {
      switch (object.termType) {
        case "Quad":
          return this._encodeQuad(object);
        case "Literal":
          return this._encodeLiteral(object);
        default:
          return this._encodeIriOrBlank(object);
      }
    }
    _encodeQuad({
      subject,
      predicate,
      object,
      graph
    }) {
      return `<<${this._encodeSubject(subject)} ${this._encodePredicate(predicate)} ${this._encodeObject(object)}${(0, _N3Util.isDefaultGraph)(graph) ? "" : ` ${this._encodeIriOrBlank(graph)}`}>>`;
    }
    _blockedWrite() {
      throw new Error("Cannot write because the writer has been closed.");
    }
    addQuad(subject, predicate, object, graph, done) {
      if (object === undefined)
        this._writeQuad(subject.subject, subject.predicate, subject.object, subject.graph, predicate);
      else if (typeof graph === "function")
        this._writeQuad(subject, predicate, object, DEFAULTGRAPH, graph);
      else
        this._writeQuad(subject, predicate, object, graph || DEFAULTGRAPH, done);
    }
    addQuads(quads) {
      for (let i = 0;i < quads.length; i++)
        this.addQuad(quads[i]);
    }
    addPrefix(prefix, iri, done) {
      const prefixes = {};
      prefixes[prefix] = iri;
      this.addPrefixes(prefixes, done);
    }
    addPrefixes(prefixes, done) {
      if (!this._prefixIRIs)
        return done && done();
      let hasPrefixes = false;
      for (let prefix in prefixes) {
        let iri = prefixes[prefix];
        if (typeof iri !== "string")
          iri = iri.value;
        hasPrefixes = true;
        if (this._subject !== null) {
          this._write(this._inDefaultGraph ? ".\n" : "\n}\n");
          this._subject = null, this._graph = "";
        }
        this._prefixIRIs[iri] = prefix += ":";
        this._write(`@prefix ${prefix} <${iri}>.\n`);
      }
      if (hasPrefixes) {
        let IRIlist = "", prefixList = "";
        for (const prefixIRI in this._prefixIRIs) {
          IRIlist += IRIlist ? `|${prefixIRI}` : prefixIRI;
          prefixList += (prefixList ? "|" : "") + this._prefixIRIs[prefixIRI];
        }
        IRIlist = escapeRegex(IRIlist, /[\]\/\(\)\*\+\?\.\\\$]/g, "\\$&");
        this._prefixRegex = new RegExp(`^(?:${prefixList})[^/]*$|` + `^(${IRIlist})([_a-zA-Z][\\-_a-zA-Z0-9]*)\$`);
      }
      this._write(hasPrefixes ? "\n" : "", done);
    }
    blank(predicate, object) {
      let children = predicate, child, length;
      if (predicate === undefined)
        children = [];
      else if (predicate.termType)
        children = [{
          predicate,
          object
        }];
      else if (!("length" in predicate))
        children = [predicate];
      switch (length = children.length) {
        case 0:
          return new SerializedTerm("[]");
        case 1:
          child = children[0];
          if (!(child.object instanceof SerializedTerm))
            return new SerializedTerm(`[ ${this._encodePredicate(child.predicate)} ${this._encodeObject(child.object)} ]`);
        default:
          let contents = "[";
          for (let i = 0;i < length; i++) {
            child = children[i];
            if (child.predicate.equals(predicate))
              contents += `, ${this._encodeObject(child.object)}`;
            else {
              contents += `${(i ? ";\n  " : "\n  ") + this._encodePredicate(child.predicate)} ${this._encodeObject(child.object)}`;
              predicate = child.predicate;
            }
          }
          return new SerializedTerm(`${contents}\n]`);
      }
    }
    list(elements) {
      const length = elements && elements.length || 0, contents = new Array(length);
      for (let i = 0;i < length; i++)
        contents[i] = this._encodeObject(elements[i]);
      return new SerializedTerm(`(${contents.join(" ")})`);
    }
    end(done) {
      if (this._subject !== null) {
        this._write(this._inDefaultGraph ? ".\n" : "\n}\n");
        this._subject = null;
      }
      this._write = this._blockedWrite;
      let singleDone = done && ((error, result) => {
        singleDone = null, done(error, result);
      });
      if (this._endStream) {
        try {
          return this._outputStream.end(singleDone);
        } catch (error) {
        }
      }
      singleDone && singleDone();
    }
  }
  exports.default = N3Writer;
});

// node_modules/readable-stream/lib/ours/primordials.js
var require_primordials = __commonJS((exports, module) => {
  module.exports = {
    ArrayIsArray(self2) {
      return Array.isArray(self2);
    },
    ArrayPrototypeIncludes(self2, el) {
      return self2.includes(el);
    },
    ArrayPrototypeIndexOf(self2, el) {
      return self2.indexOf(el);
    },
    ArrayPrototypeJoin(self2, sep) {
      return self2.join(sep);
    },
    ArrayPrototypeMap(self2, fn) {
      return self2.map(fn);
    },
    ArrayPrototypePop(self2, el) {
      return self2.pop(el);
    },
    ArrayPrototypePush(self2, el) {
      return self2.push(el);
    },
    ArrayPrototypeSlice(self2, start, end) {
      return self2.slice(start, end);
    },
    Error,
    FunctionPrototypeCall(fn, thisArgs, ...args) {
      return fn.call(thisArgs, ...args);
    },
    FunctionPrototypeSymbolHasInstance(self2, instance) {
      return Function.prototype[Symbol.hasInstance].call(self2, instance);
    },
    MathFloor: Math.floor,
    Number,
    NumberIsInteger: Number.isInteger,
    NumberIsNaN: Number.isNaN,
    NumberMAX_SAFE_INTEGER: Number.MAX_SAFE_INTEGER,
    NumberMIN_SAFE_INTEGER: Number.MIN_SAFE_INTEGER,
    NumberParseInt: Number.parseInt,
    ObjectDefineProperties(self2, props) {
      return Object.defineProperties(self2, props);
    },
    ObjectDefineProperty(self2, name, prop) {
      return Object.defineProperty(self2, name, prop);
    },
    ObjectGetOwnPropertyDescriptor(self2, name) {
      return Object.getOwnPropertyDescriptor(self2, name);
    },
    ObjectKeys(obj) {
      return Object.keys(obj);
    },
    ObjectSetPrototypeOf(target, proto) {
      return Object.setPrototypeOf(target, proto);
    },
    Promise,
    PromisePrototypeCatch(self2, fn) {
      return self2.catch(fn);
    },
    PromisePrototypeThen(self2, thenFn, catchFn) {
      return self2.then(thenFn, catchFn);
    },
    PromiseReject(err) {
      return Promise.reject(err);
    },
    ReflectApply: Reflect.apply,
    RegExpPrototypeTest(self2, value) {
      return self2.test(value);
    },
    SafeSet: Set,
    String,
    StringPrototypeSlice(self2, start, end) {
      return self2.slice(start, end);
    },
    StringPrototypeToLowerCase(self2) {
      return self2.toLowerCase();
    },
    StringPrototypeToUpperCase(self2) {
      return self2.toUpperCase();
    },
    StringPrototypeTrim(self2) {
      return self2.trim();
    },
    Symbol,
    SymbolFor: Symbol.for,
    SymbolAsyncIterator: Symbol.asyncIterator,
    SymbolHasInstance: Symbol.hasInstance,
    SymbolIterator: Symbol.iterator,
    TypedArrayPrototypeSet(self2, buf, len) {
      return self2.set(buf, len);
    },
    Uint8Array
  };
});

// node_modules/readable-stream/lib/ours/util.js
var require_util = __commonJS((exports, module) => {
  var bufferModule = __require("buffer");
  var AsyncFunction = Object.getPrototypeOf(async function() {
  }).constructor;
  var Blob = globalThis.Blob || bufferModule.Blob;
  var isBlob = typeof Blob !== "undefined" ? function isBlob(b) {
    return b instanceof Blob;
  } : function isBlob(b) {
    return false;
  };

  class AggregateError extends Error {
    constructor(errors) {
      if (!Array.isArray(errors)) {
        throw new TypeError(`Expected input to be an Array, got ${typeof errors}`);
      }
      let message = "";
      for (let i = 0;i < errors.length; i++) {
        message += `    ${errors[i].stack}\n`;
      }
      super(message);
      this.name = "AggregateError";
      this.errors = errors;
    }
  }
  module.exports = {
    AggregateError,
    kEmptyObject: Object.freeze({}),
    once(callback) {
      let called = false;
      return function(...args) {
        if (called) {
          return;
        }
        called = true;
        callback.apply(this, args);
      };
    },
    createDeferredPromise: function() {
      let resolve;
      let reject;
      const promise = new Promise((res, rej) => {
        resolve = res;
        reject = rej;
      });
      return {
        promise,
        resolve,
        reject
      };
    },
    promisify(fn) {
      return new Promise((resolve, reject) => {
        fn((err, ...args) => {
          if (err) {
            return reject(err);
          }
          return resolve(...args);
        });
      });
    },
    debuglog() {
      return function() {
      };
    },
    format(format, ...args) {
      return format.replace(/%([sdifj])/g, function(...[_unused, type]) {
        const replacement = args.shift();
        if (type === "f") {
          return replacement.toFixed(6);
        } else if (type === "j") {
          return JSON.stringify(replacement);
        } else if (type === "s" && typeof replacement === "object") {
          const ctor = replacement.constructor !== Object ? replacement.constructor.name : "";
          return `${ctor} {}`.trim();
        } else {
          return replacement.toString();
        }
      });
    },
    inspect(value) {
      switch (typeof value) {
        case "string":
          if (value.includes("'")) {
            if (!value.includes('"')) {
              return `"${value}"`;
            } else if (!value.includes("`") && !value.includes("${")) {
              return `\`${value}\``;
            }
          }
          return `'${value}'`;
        case "number":
          if (isNaN(value)) {
            return "NaN";
          } else if (Object.is(value, -0)) {
            return String(value);
          }
          return value;
        case "bigint":
          return `${String(value)}n`;
        case "boolean":
        case "undefined":
          return String(value);
        case "object":
          return "{}";
      }
    },
    types: {
      isAsyncFunction(fn) {
        return fn instanceof AsyncFunction;
      },
      isArrayBufferView(arr) {
        return ArrayBuffer.isView(arr);
      }
    },
    isBlob
  };
  module.exports.promisify.custom = Symbol.for("nodejs.util.promisify.custom");
});

// node_modules/event-target-shim/dist/event-target-shim.js
var require_event_target_shim = __commonJS((exports, module) => {
  var pd = function(event) {
    const retv = privateData.get(event);
    console.assert(retv != null, "'this' is expected an Event object, but got", event);
    return retv;
  };
  var setCancelFlag = function(data) {
    if (data.passiveListener != null) {
      if (typeof console !== "undefined" && typeof console.error === "function") {
        console.error("Unable to preventDefault inside passive event listener invocation.", data.passiveListener);
      }
      return;
    }
    if (!data.event.cancelable) {
      return;
    }
    data.canceled = true;
    if (typeof data.event.preventDefault === "function") {
      data.event.preventDefault();
    }
  };
  var Event = function(eventTarget, event) {
    privateData.set(this, {
      eventTarget,
      event,
      eventPhase: 2,
      currentTarget: eventTarget,
      canceled: false,
      stopped: false,
      immediateStopped: false,
      passiveListener: null,
      timeStamp: event.timeStamp || Date.now()
    });
    Object.defineProperty(this, "isTrusted", { value: false, enumerable: true });
    const keys = Object.keys(event);
    for (let i = 0;i < keys.length; ++i) {
      const key = keys[i];
      if (!(key in this)) {
        Object.defineProperty(this, key, defineRedirectDescriptor(key));
      }
    }
  };
  var defineRedirectDescriptor = function(key) {
    return {
      get() {
        return pd(this).event[key];
      },
      set(value) {
        pd(this).event[key] = value;
      },
      configurable: true,
      enumerable: true
    };
  };
  var defineCallDescriptor = function(key) {
    return {
      value() {
        const event = pd(this).event;
        return event[key].apply(event, arguments);
      },
      configurable: true,
      enumerable: true
    };
  };
  var defineWrapper = function(BaseEvent, proto) {
    const keys = Object.keys(proto);
    if (keys.length === 0) {
      return BaseEvent;
    }
    function CustomEvent(eventTarget, event) {
      BaseEvent.call(this, eventTarget, event);
    }
    CustomEvent.prototype = Object.create(BaseEvent.prototype, {
      constructor: { value: CustomEvent, configurable: true, writable: true }
    });
    for (let i = 0;i < keys.length; ++i) {
      const key = keys[i];
      if (!(key in BaseEvent.prototype)) {
        const descriptor = Object.getOwnPropertyDescriptor(proto, key);
        const isFunc = typeof descriptor.value === "function";
        Object.defineProperty(CustomEvent.prototype, key, isFunc ? defineCallDescriptor(key) : defineRedirectDescriptor(key));
      }
    }
    return CustomEvent;
  };
  var getWrapper = function(proto) {
    if (proto == null || proto === Object.prototype) {
      return Event;
    }
    let wrapper = wrappers.get(proto);
    if (wrapper == null) {
      wrapper = defineWrapper(getWrapper(Object.getPrototypeOf(proto)), proto);
      wrappers.set(proto, wrapper);
    }
    return wrapper;
  };
  var wrapEvent = function(eventTarget, event) {
    const Wrapper = getWrapper(Object.getPrototypeOf(event));
    return new Wrapper(eventTarget, event);
  };
  var isStopped = function(event) {
    return pd(event).immediateStopped;
  };
  var setEventPhase = function(event, eventPhase) {
    pd(event).eventPhase = eventPhase;
  };
  var setCurrentTarget = function(event, currentTarget) {
    pd(event).currentTarget = currentTarget;
  };
  var setPassiveListener = function(event, passiveListener) {
    pd(event).passiveListener = passiveListener;
  };
  var isObject = function(x) {
    return x !== null && typeof x === "object";
  };
  var getListeners = function(eventTarget) {
    const listeners = listenersMap.get(eventTarget);
    if (listeners == null) {
      throw new TypeError("'this' is expected an EventTarget object, but got another value.");
    }
    return listeners;
  };
  var defineEventAttributeDescriptor = function(eventName) {
    return {
      get() {
        const listeners = getListeners(this);
        let node = listeners.get(eventName);
        while (node != null) {
          if (node.listenerType === ATTRIBUTE) {
            return node.listener;
          }
          node = node.next;
        }
        return null;
      },
      set(listener) {
        if (typeof listener !== "function" && !isObject(listener)) {
          listener = null;
        }
        const listeners = getListeners(this);
        let prev = null;
        let node = listeners.get(eventName);
        while (node != null) {
          if (node.listenerType === ATTRIBUTE) {
            if (prev !== null) {
              prev.next = node.next;
            } else if (node.next !== null) {
              listeners.set(eventName, node.next);
            } else {
              listeners.delete(eventName);
            }
          } else {
            prev = node;
          }
          node = node.next;
        }
        if (listener !== null) {
          const newNode = {
            listener,
            listenerType: ATTRIBUTE,
            passive: false,
            once: false,
            next: null
          };
          if (prev === null) {
            listeners.set(eventName, newNode);
          } else {
            prev.next = newNode;
          }
        }
      },
      configurable: true,
      enumerable: true
    };
  };
  var defineEventAttribute = function(eventTargetPrototype, eventName) {
    Object.defineProperty(eventTargetPrototype, `on${eventName}`, defineEventAttributeDescriptor(eventName));
  };
  var defineCustomEventTarget = function(eventNames) {
    function CustomEventTarget() {
      EventTarget.call(this);
    }
    CustomEventTarget.prototype = Object.create(EventTarget.prototype, {
      constructor: {
        value: CustomEventTarget,
        configurable: true,
        writable: true
      }
    });
    for (let i = 0;i < eventNames.length; ++i) {
      defineEventAttribute(CustomEventTarget.prototype, eventNames[i]);
    }
    return CustomEventTarget;
  };
  var EventTarget = function() {
    if (this instanceof EventTarget) {
      listenersMap.set(this, new Map);
      return;
    }
    if (arguments.length === 1 && Array.isArray(arguments[0])) {
      return defineCustomEventTarget(arguments[0]);
    }
    if (arguments.length > 0) {
      const types = new Array(arguments.length);
      for (let i = 0;i < arguments.length; ++i) {
        types[i] = arguments[i];
      }
      return defineCustomEventTarget(types);
    }
    throw new TypeError("Cannot call a class as a function");
  };
  Object.defineProperty(exports, "__esModule", { value: true });
  var privateData = new WeakMap;
  var wrappers = new WeakMap;
  Event.prototype = {
    get type() {
      return pd(this).event.type;
    },
    get target() {
      return pd(this).eventTarget;
    },
    get currentTarget() {
      return pd(this).currentTarget;
    },
    composedPath() {
      const currentTarget = pd(this).currentTarget;
      if (currentTarget == null) {
        return [];
      }
      return [currentTarget];
    },
    get NONE() {
      return 0;
    },
    get CAPTURING_PHASE() {
      return 1;
    },
    get AT_TARGET() {
      return 2;
    },
    get BUBBLING_PHASE() {
      return 3;
    },
    get eventPhase() {
      return pd(this).eventPhase;
    },
    stopPropagation() {
      const data = pd(this);
      data.stopped = true;
      if (typeof data.event.stopPropagation === "function") {
        data.event.stopPropagation();
      }
    },
    stopImmediatePropagation() {
      const data = pd(this);
      data.stopped = true;
      data.immediateStopped = true;
      if (typeof data.event.stopImmediatePropagation === "function") {
        data.event.stopImmediatePropagation();
      }
    },
    get bubbles() {
      return Boolean(pd(this).event.bubbles);
    },
    get cancelable() {
      return Boolean(pd(this).event.cancelable);
    },
    preventDefault() {
      setCancelFlag(pd(this));
    },
    get defaultPrevented() {
      return pd(this).canceled;
    },
    get composed() {
      return Boolean(pd(this).event.composed);
    },
    get timeStamp() {
      return pd(this).timeStamp;
    },
    get srcElement() {
      return pd(this).eventTarget;
    },
    get cancelBubble() {
      return pd(this).stopped;
    },
    set cancelBubble(value) {
      if (!value) {
        return;
      }
      const data = pd(this);
      data.stopped = true;
      if (typeof data.event.cancelBubble === "boolean") {
        data.event.cancelBubble = true;
      }
    },
    get returnValue() {
      return !pd(this).canceled;
    },
    set returnValue(value) {
      if (!value) {
        setCancelFlag(pd(this));
      }
    },
    initEvent() {
    }
  };
  Object.defineProperty(Event.prototype, "constructor", {
    value: Event,
    configurable: true,
    writable: true
  });
  if (typeof window !== "undefined" && typeof window.Event !== "undefined") {
    Object.setPrototypeOf(Event.prototype, window.Event.prototype);
    wrappers.set(window.Event.prototype, Event);
  }
  var listenersMap = new WeakMap;
  var CAPTURE = 1;
  var BUBBLE = 2;
  var ATTRIBUTE = 3;
  EventTarget.prototype = {
    addEventListener(eventName, listener, options) {
      if (listener == null) {
        return;
      }
      if (typeof listener !== "function" && !isObject(listener)) {
        throw new TypeError("'listener' should be a function or an object.");
      }
      const listeners = getListeners(this);
      const optionsIsObj = isObject(options);
      const capture = optionsIsObj ? Boolean(options.capture) : Boolean(options);
      const listenerType = capture ? CAPTURE : BUBBLE;
      const newNode = {
        listener,
        listenerType,
        passive: optionsIsObj && Boolean(options.passive),
        once: optionsIsObj && Boolean(options.once),
        next: null
      };
      let node = listeners.get(eventName);
      if (node === undefined) {
        listeners.set(eventName, newNode);
        return;
      }
      let prev = null;
      while (node != null) {
        if (node.listener === listener && node.listenerType === listenerType) {
          return;
        }
        prev = node;
        node = node.next;
      }
      prev.next = newNode;
    },
    removeEventListener(eventName, listener, options) {
      if (listener == null) {
        return;
      }
      const listeners = getListeners(this);
      const capture = isObject(options) ? Boolean(options.capture) : Boolean(options);
      const listenerType = capture ? CAPTURE : BUBBLE;
      let prev = null;
      let node = listeners.get(eventName);
      while (node != null) {
        if (node.listener === listener && node.listenerType === listenerType) {
          if (prev !== null) {
            prev.next = node.next;
          } else if (node.next !== null) {
            listeners.set(eventName, node.next);
          } else {
            listeners.delete(eventName);
          }
          return;
        }
        prev = node;
        node = node.next;
      }
    },
    dispatchEvent(event) {
      if (event == null || typeof event.type !== "string") {
        throw new TypeError('"event.type" should be a string.');
      }
      const listeners = getListeners(this);
      const eventName = event.type;
      let node = listeners.get(eventName);
      if (node == null) {
        return true;
      }
      const wrappedEvent = wrapEvent(this, event);
      let prev = null;
      while (node != null) {
        if (node.once) {
          if (prev !== null) {
            prev.next = node.next;
          } else if (node.next !== null) {
            listeners.set(eventName, node.next);
          } else {
            listeners.delete(eventName);
          }
        } else {
          prev = node;
        }
        setPassiveListener(wrappedEvent, node.passive ? node.listener : null);
        if (typeof node.listener === "function") {
          try {
            node.listener.call(this, wrappedEvent);
          } catch (err) {
            if (typeof console !== "undefined" && typeof console.error === "function") {
              console.error(err);
            }
          }
        } else if (node.listenerType !== ATTRIBUTE && typeof node.listener.handleEvent === "function") {
          node.listener.handleEvent(wrappedEvent);
        }
        if (isStopped(wrappedEvent)) {
          break;
        }
        node = node.next;
      }
      setPassiveListener(wrappedEvent, null);
      setEventPhase(wrappedEvent, 0);
      setCurrentTarget(wrappedEvent, null);
      return !wrappedEvent.defaultPrevented;
    }
  };
  Object.defineProperty(EventTarget.prototype, "constructor", {
    value: EventTarget,
    configurable: true,
    writable: true
  });
  if (typeof window !== "undefined" && typeof window.EventTarget !== "undefined") {
    Object.setPrototypeOf(EventTarget.prototype, window.EventTarget.prototype);
  }
  exports.defineEventAttribute = defineEventAttribute;
  exports.EventTarget = EventTarget;
  exports.default = EventTarget;
  module.exports = EventTarget;
  module.exports.EventTarget = module.exports["default"] = EventTarget;
  module.exports.defineEventAttribute = defineEventAttribute;
});

// node_modules/abort-controller/dist/abort-controller.js
var require_abort_controller = __commonJS((exports, module) => {
  var createAbortSignal = function() {
    const signal = Object.create(AbortSignal.prototype);
    eventTargetShim.EventTarget.call(signal);
    abortedFlags.set(signal, false);
    return signal;
  };
  var abortSignal = function(signal) {
    if (abortedFlags.get(signal) !== false) {
      return;
    }
    abortedFlags.set(signal, true);
    signal.dispatchEvent({ type: "abort" });
  };
  var getSignal = function(controller) {
    const signal = signals.get(controller);
    if (signal == null) {
      throw new TypeError(`Expected 'this' to be an 'AbortController' object, but got ${controller === null ? "null" : typeof controller}`);
    }
    return signal;
  };
  Object.defineProperty(exports, "__esModule", { value: true });
  var eventTargetShim = require_event_target_shim();

  class AbortSignal extends eventTargetShim.EventTarget {
    constructor() {
      super();
      throw new TypeError("AbortSignal cannot be constructed directly");
    }
    get aborted() {
      const aborted = abortedFlags.get(this);
      if (typeof aborted !== "boolean") {
        throw new TypeError(`Expected 'this' to be an 'AbortSignal' object, but got ${this === null ? "null" : typeof this}`);
      }
      return aborted;
    }
  }
  eventTargetShim.defineEventAttribute(AbortSignal.prototype, "abort");
  var abortedFlags = new WeakMap;
  Object.defineProperties(AbortSignal.prototype, {
    aborted: { enumerable: true }
  });
  if (typeof Symbol === "function" && typeof Symbol.toStringTag === "symbol") {
    Object.defineProperty(AbortSignal.prototype, Symbol.toStringTag, {
      configurable: true,
      value: "AbortSignal"
    });
  }

  class AbortController {
    constructor() {
      signals.set(this, createAbortSignal());
    }
    get signal() {
      return getSignal(this);
    }
    abort() {
      abortSignal(getSignal(this));
    }
  }
  var signals = new WeakMap;
  Object.defineProperties(AbortController.prototype, {
    signal: { enumerable: true },
    abort: { enumerable: true }
  });
  if (typeof Symbol === "function" && typeof Symbol.toStringTag === "symbol") {
    Object.defineProperty(AbortController.prototype, Symbol.toStringTag, {
      configurable: true,
      value: "AbortController"
    });
  }
  exports.AbortController = AbortController;
  exports.AbortSignal = AbortSignal;
  exports.default = AbortController;
  module.exports = AbortController;
  module.exports.AbortController = module.exports["default"] = AbortController;
  module.exports.AbortSignal = AbortSignal;
});

// node_modules/readable-stream/lib/ours/errors.js
var require_errors = __commonJS((exports, module) => {
  var assert = function(value, message) {
    if (!value) {
      throw new codes.ERR_INTERNAL_ASSERTION(message);
    }
  };
  var addNumericalSeparator = function(val) {
    let res = "";
    let i = val.length;
    const start = val[0] === "-" ? 1 : 0;
    for (;i >= start + 4; i -= 3) {
      res = `_${val.slice(i - 3, i)}${res}`;
    }
    return `${val.slice(0, i)}${res}`;
  };
  var getMessage = function(key, msg, args) {
    if (typeof msg === "function") {
      assert(msg.length <= args.length, `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${msg.length}).`);
      return msg(...args);
    }
    const expectedLength = (msg.match(/%[dfijoOs]/g) || []).length;
    assert(expectedLength === args.length, `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${expectedLength}).`);
    if (args.length === 0) {
      return msg;
    }
    return format(msg, ...args);
  };
  var E = function(code, message, Base) {
    if (!Base) {
      Base = Error;
    }

    class NodeError extends Base {
      constructor(...args) {
        super(getMessage(code, message, args));
      }
      toString() {
        return `${this.name} [${code}]: ${this.message}`;
      }
    }
    Object.defineProperties(NodeError.prototype, {
      name: {
        value: Base.name,
        writable: true,
        enumerable: false,
        configurable: true
      },
      toString: {
        value() {
          return `${this.name} [${code}]: ${this.message}`;
        },
        writable: true,
        enumerable: false,
        configurable: true
      }
    });
    NodeError.prototype.code = code;
    NodeError.prototype[kIsNodeError] = true;
    codes[code] = NodeError;
  };
  var hideStackFrames = function(fn) {
    const hidden = nodeInternalPrefix + fn.name;
    Object.defineProperty(fn, "name", {
      value: hidden
    });
    return fn;
  };
  var aggregateTwoErrors = function(innerError, outerError) {
    if (innerError && outerError && innerError !== outerError) {
      if (Array.isArray(outerError.errors)) {
        outerError.errors.push(innerError);
        return outerError;
      }
      const err = new AggregateError([outerError, innerError], outerError.message);
      err.code = outerError.code;
      return err;
    }
    return innerError || outerError;
  };
  var { format, inspect, AggregateError: CustomAggregateError } = require_util();
  var AggregateError = globalThis.AggregateError || CustomAggregateError;
  var kIsNodeError = Symbol("kIsNodeError");
  var kTypes = [
    "string",
    "function",
    "number",
    "object",
    "Function",
    "Object",
    "boolean",
    "bigint",
    "symbol"
  ];
  var classRegExp = /^([A-Z][a-z0-9]*)+$/;
  var nodeInternalPrefix = "__node_internal_";
  var codes = {};

  class AbortError extends Error {
    constructor(message = "The operation was aborted", options = undefined) {
      if (options !== undefined && typeof options !== "object") {
        throw new codes.ERR_INVALID_ARG_TYPE("options", "Object", options);
      }
      super(message, options);
      this.code = "ABORT_ERR";
      this.name = "AbortError";
    }
  }
  E("ERR_ASSERTION", "%s", Error);
  E("ERR_INVALID_ARG_TYPE", (name, expected, actual) => {
    assert(typeof name === "string", "'name' must be a string");
    if (!Array.isArray(expected)) {
      expected = [expected];
    }
    let msg = "The ";
    if (name.endsWith(" argument")) {
      msg += `${name} `;
    } else {
      msg += `"${name}" ${name.includes(".") ? "property" : "argument"} `;
    }
    msg += "must be ";
    const types = [];
    const instances = [];
    const other = [];
    for (const value of expected) {
      assert(typeof value === "string", "All expected entries have to be of type string");
      if (kTypes.includes(value)) {
        types.push(value.toLowerCase());
      } else if (classRegExp.test(value)) {
        instances.push(value);
      } else {
        assert(value !== "object", 'The value "object" should be written as "Object"');
        other.push(value);
      }
    }
    if (instances.length > 0) {
      const pos = types.indexOf("object");
      if (pos !== -1) {
        types.splice(types, pos, 1);
        instances.push("Object");
      }
    }
    if (types.length > 0) {
      switch (types.length) {
        case 1:
          msg += `of type ${types[0]}`;
          break;
        case 2:
          msg += `one of type ${types[0]} or ${types[1]}`;
          break;
        default: {
          const last = types.pop();
          msg += `one of type ${types.join(", ")}, or ${last}`;
        }
      }
      if (instances.length > 0 || other.length > 0) {
        msg += " or ";
      }
    }
    if (instances.length > 0) {
      switch (instances.length) {
        case 1:
          msg += `an instance of ${instances[0]}`;
          break;
        case 2:
          msg += `an instance of ${instances[0]} or ${instances[1]}`;
          break;
        default: {
          const last = instances.pop();
          msg += `an instance of ${instances.join(", ")}, or ${last}`;
        }
      }
      if (other.length > 0) {
        msg += " or ";
      }
    }
    switch (other.length) {
      case 0:
        break;
      case 1:
        if (other[0].toLowerCase() !== other[0]) {
          msg += "an ";
        }
        msg += `${other[0]}`;
        break;
      case 2:
        msg += `one of ${other[0]} or ${other[1]}`;
        break;
      default: {
        const last = other.pop();
        msg += `one of ${other.join(", ")}, or ${last}`;
      }
    }
    if (actual == null) {
      msg += `. Received ${actual}`;
    } else if (typeof actual === "function" && actual.name) {
      msg += `. Received function ${actual.name}`;
    } else if (typeof actual === "object") {
      var _actual$constructor;
      if ((_actual$constructor = actual.constructor) !== null && _actual$constructor !== undefined && _actual$constructor.name) {
        msg += `. Received an instance of ${actual.constructor.name}`;
      } else {
        const inspected = inspect(actual, {
          depth: -1
        });
        msg += `. Received ${inspected}`;
      }
    } else {
      let inspected = inspect(actual, {
        colors: false
      });
      if (inspected.length > 25) {
        inspected = `${inspected.slice(0, 25)}...`;
      }
      msg += `. Received type ${typeof actual} (${inspected})`;
    }
    return msg;
  }, TypeError);
  E("ERR_INVALID_ARG_VALUE", (name, value, reason = "is invalid") => {
    let inspected = inspect(value);
    if (inspected.length > 128) {
      inspected = inspected.slice(0, 128) + "...";
    }
    const type = name.includes(".") ? "property" : "argument";
    return `The ${type} '${name}' ${reason}. Received ${inspected}`;
  }, TypeError);
  E("ERR_INVALID_RETURN_VALUE", (input, name, value) => {
    var _value$constructor;
    const type = value !== null && value !== undefined && (_value$constructor = value.constructor) !== null && _value$constructor !== undefined && _value$constructor.name ? `instance of ${value.constructor.name}` : `type ${typeof value}`;
    return `Expected ${input} to be returned from the "${name}"` + ` function but got ${type}.`;
  }, TypeError);
  E("ERR_MISSING_ARGS", (...args) => {
    assert(args.length > 0, "At least one arg needs to be specified");
    let msg;
    const len = args.length;
    args = (Array.isArray(args) ? args : [args]).map((a) => `"${a}"`).join(" or ");
    switch (len) {
      case 1:
        msg += `The ${args[0]} argument`;
        break;
      case 2:
        msg += `The ${args[0]} and ${args[1]} arguments`;
        break;
      default:
        {
          const last = args.pop();
          msg += `The ${args.join(", ")}, and ${last} arguments`;
        }
        break;
    }
    return `${msg} must be specified`;
  }, TypeError);
  E("ERR_OUT_OF_RANGE", (str, range, input) => {
    assert(range, 'Missing "range" argument');
    let received;
    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {
      received = addNumericalSeparator(String(input));
    } else if (typeof input === "bigint") {
      received = String(input);
      if (input > 2n ** 32n || input < -(2n ** 32n)) {
        received = addNumericalSeparator(received);
      }
      received += "n";
    } else {
      received = inspect(input);
    }
    return `The value of "${str}" is out of range. It must be ${range}. Received ${received}`;
  }, RangeError);
  E("ERR_MULTIPLE_CALLBACK", "Callback called multiple times", Error);
  E("ERR_METHOD_NOT_IMPLEMENTED", "The %s method is not implemented", Error);
  E("ERR_STREAM_ALREADY_FINISHED", "Cannot call %s after a stream was finished", Error);
  E("ERR_STREAM_CANNOT_PIPE", "Cannot pipe, not readable", Error);
  E("ERR_STREAM_DESTROYED", "Cannot call %s after a stream was destroyed", Error);
  E("ERR_STREAM_NULL_VALUES", "May not write null values to stream", TypeError);
  E("ERR_STREAM_PREMATURE_CLOSE", "Premature close", Error);
  E("ERR_STREAM_PUSH_AFTER_EOF", "stream.push() after EOF", Error);
  E("ERR_STREAM_UNSHIFT_AFTER_END_EVENT", "stream.unshift() after end event", Error);
  E("ERR_STREAM_WRITE_AFTER_END", "write after end", Error);
  E("ERR_UNKNOWN_ENCODING", "Unknown encoding: %s", TypeError);
  module.exports = {
    AbortError,
    aggregateTwoErrors: hideStackFrames(aggregateTwoErrors),
    hideStackFrames,
    codes
  };
});

// node_modules/readable-stream/lib/internal/validators.js
var require_validators = __commonJS((exports, module) => {
  var isInt32 = function(value) {
    return value === (value | 0);
  };
  var isUint32 = function(value) {
    return value === value >>> 0;
  };
  var parseFileMode = function(value, name, def) {
    if (typeof value === "undefined") {
      value = def;
    }
    if (typeof value === "string") {
      if (RegExpPrototypeExec(octalReg, value) === null) {
        throw new ERR_INVALID_ARG_VALUE(name, value, modeDesc);
      }
      value = NumberParseInt(value, 8);
    }
    validateUint32(value, name);
    return value;
  };
  var validateString = function(value, name) {
    if (typeof value !== "string")
      throw new ERR_INVALID_ARG_TYPE(name, "string", value);
  };
  var validateNumber = function(value, name, min = undefined, max) {
    if (typeof value !== "number")
      throw new ERR_INVALID_ARG_TYPE(name, "number", value);
    if (min != null && value < min || max != null && value > max || (min != null || max != null) && NumberIsNaN(value)) {
      throw new ERR_OUT_OF_RANGE(name, `${min != null ? `>= ${min}` : ""}${min != null && max != null ? " && " : ""}${max != null ? `<= ${max}` : ""}`, value);
    }
  };
  var validateBoolean = function(value, name) {
    if (typeof value !== "boolean")
      throw new ERR_INVALID_ARG_TYPE(name, "boolean", value);
  };
  var getOwnPropertyValueOrDefault = function(options, key, defaultValue) {
    return options == null || !ObjectPrototypeHasOwnProperty(options, key) ? defaultValue : options[key];
  };
  var validateStringArray = function(value, name) {
    validateArray(value, name);
    for (let i = 0;i < value.length; i++) {
      validateString(value[i], `${name}[${i}]`);
    }
  };
  var validateBooleanArray = function(value, name) {
    validateArray(value, name);
    for (let i = 0;i < value.length; i++) {
      validateBoolean(value[i], `${name}[${i}]`);
    }
  };
  var validateSignalName = function(signal, name = "signal") {
    validateString(signal, name);
    if (signals[signal] === undefined) {
      if (signals[StringPrototypeToUpperCase(signal)] !== undefined) {
        throw new ERR_UNKNOWN_SIGNAL(signal + " (signals must use all capital letters)");
      }
      throw new ERR_UNKNOWN_SIGNAL(signal);
    }
  };
  var validateEncoding = function(data, encoding) {
    const normalizedEncoding = normalizeEncoding(encoding);
    const length = data.length;
    if (normalizedEncoding === "hex" && length % 2 !== 0) {
      throw new ERR_INVALID_ARG_VALUE("encoding", encoding, `is invalid for data of length ${length}`);
    }
  };
  var validatePort = function(port, name = "Port", allowZero = true) {
    if (typeof port !== "number" && typeof port !== "string" || typeof port === "string" && StringPrototypeTrim(port).length === 0 || +port !== +port >>> 0 || port > 65535 || port === 0 && !allowZero) {
      throw new ERR_SOCKET_BAD_PORT(name, port, allowZero);
    }
    return port | 0;
  };
  var validateUnion = function(value, name, union) {
    if (!ArrayPrototypeIncludes(union, value)) {
      throw new ERR_INVALID_ARG_TYPE(name, `('${ArrayPrototypeJoin(union, "|")}')`, value);
    }
  };
  var validateLinkHeaderFormat = function(value, name) {
    if (typeof value === "undefined" || !RegExpPrototypeExec(linkValueRegExp, value)) {
      throw new ERR_INVALID_ARG_VALUE(name, value, 'must be an array or string of format "</styles.css>; rel=preload; as=style"');
    }
  };
  var validateLinkHeaderValue = function(hints) {
    if (typeof hints === "string") {
      validateLinkHeaderFormat(hints, "hints");
      return hints;
    } else if (ArrayIsArray(hints)) {
      const hintsLength = hints.length;
      let result = "";
      if (hintsLength === 0) {
        return result;
      }
      for (let i = 0;i < hintsLength; i++) {
        const link = hints[i];
        validateLinkHeaderFormat(link, "hints");
        result += link;
        if (i !== hintsLength - 1) {
          result += ", ";
        }
      }
      return result;
    }
    throw new ERR_INVALID_ARG_VALUE("hints", hints, 'must be an array or string of format "</styles.css>; rel=preload; as=style"');
  };
  var {
    ArrayIsArray,
    ArrayPrototypeIncludes,
    ArrayPrototypeJoin,
    ArrayPrototypeMap,
    NumberIsInteger,
    NumberIsNaN,
    NumberMAX_SAFE_INTEGER,
    NumberMIN_SAFE_INTEGER,
    NumberParseInt,
    ObjectPrototypeHasOwnProperty,
    RegExpPrototypeExec,
    String: String2,
    StringPrototypeToUpperCase,
    StringPrototypeTrim
  } = require_primordials();
  var {
    hideStackFrames,
    codes: { ERR_SOCKET_BAD_PORT, ERR_INVALID_ARG_TYPE, ERR_INVALID_ARG_VALUE, ERR_OUT_OF_RANGE, ERR_UNKNOWN_SIGNAL }
  } = require_errors();
  var { normalizeEncoding } = require_util();
  var { isAsyncFunction, isArrayBufferView } = require_util().types;
  var signals = {};
  var octalReg = /^[0-7]+$/;
  var modeDesc = "must be a 32-bit unsigned integer or an octal string";
  var validateInteger = hideStackFrames((value, name, min = NumberMIN_SAFE_INTEGER, max = NumberMAX_SAFE_INTEGER) => {
    if (typeof value !== "number")
      throw new ERR_INVALID_ARG_TYPE(name, "number", value);
    if (!NumberIsInteger(value))
      throw new ERR_OUT_OF_RANGE(name, "an integer", value);
    if (value < min || value > max)
      throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value);
  });
  var validateInt32 = hideStackFrames((value, name, min = -2147483648, max = 2147483647) => {
    if (typeof value !== "number") {
      throw new ERR_INVALID_ARG_TYPE(name, "number", value);
    }
    if (!NumberIsInteger(value)) {
      throw new ERR_OUT_OF_RANGE(name, "an integer", value);
    }
    if (value < min || value > max) {
      throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value);
    }
  });
  var validateUint32 = hideStackFrames((value, name, positive = false) => {
    if (typeof value !== "number") {
      throw new ERR_INVALID_ARG_TYPE(name, "number", value);
    }
    if (!NumberIsInteger(value)) {
      throw new ERR_OUT_OF_RANGE(name, "an integer", value);
    }
    const min = positive ? 1 : 0;
    const max = 4294967295;
    if (value < min || value > max) {
      throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value);
    }
  });
  var validateOneOf = hideStackFrames((value, name, oneOf) => {
    if (!ArrayPrototypeIncludes(oneOf, value)) {
      const allowed = ArrayPrototypeJoin(ArrayPrototypeMap(oneOf, (v) => typeof v === "string" ? `'${v}'` : String2(v)), ", ");
      const reason = "must be one of: " + allowed;
      throw new ERR_INVALID_ARG_VALUE(name, value, reason);
    }
  });
  var validateObject = hideStackFrames((value, name, options = null) => {
    const allowArray = getOwnPropertyValueOrDefault(options, "allowArray", false);
    const allowFunction = getOwnPropertyValueOrDefault(options, "allowFunction", false);
    const nullable = getOwnPropertyValueOrDefault(options, "nullable", false);
    if (!nullable && value === null || !allowArray && ArrayIsArray(value) || typeof value !== "object" && (!allowFunction || typeof value !== "function")) {
      throw new ERR_INVALID_ARG_TYPE(name, "Object", value);
    }
  });
  var validateDictionary = hideStackFrames((value, name) => {
    if (value != null && typeof value !== "object" && typeof value !== "function") {
      throw new ERR_INVALID_ARG_TYPE(name, "a dictionary", value);
    }
  });
  var validateArray = hideStackFrames((value, name, minLength = 0) => {
    if (!ArrayIsArray(value)) {
      throw new ERR_INVALID_ARG_TYPE(name, "Array", value);
    }
    if (value.length < minLength) {
      const reason = `must be longer than ${minLength}`;
      throw new ERR_INVALID_ARG_VALUE(name, value, reason);
    }
  });
  var validateBuffer = hideStackFrames((buffer, name = "buffer") => {
    if (!isArrayBufferView(buffer)) {
      throw new ERR_INVALID_ARG_TYPE(name, ["Buffer", "TypedArray", "DataView"], buffer);
    }
  });
  var validateAbortSignal = hideStackFrames((signal, name) => {
    if (signal !== undefined && (signal === null || typeof signal !== "object" || !("aborted" in signal))) {
      throw new ERR_INVALID_ARG_TYPE(name, "AbortSignal", signal);
    }
  });
  var validateFunction = hideStackFrames((value, name) => {
    if (typeof value !== "function")
      throw new ERR_INVALID_ARG_TYPE(name, "Function", value);
  });
  var validatePlainFunction = hideStackFrames((value, name) => {
    if (typeof value !== "function" || isAsyncFunction(value))
      throw new ERR_INVALID_ARG_TYPE(name, "Function", value);
  });
  var validateUndefined = hideStackFrames((value, name) => {
    if (value !== undefined)
      throw new ERR_INVALID_ARG_TYPE(name, "undefined", value);
  });
  var linkValueRegExp = /^(?:<[^>]*>)(?:\s*;\s*[^;"\s]+(?:=(")?[^;"\s]*\1)?)*$/;
  module.exports = {
    isInt32,
    isUint32,
    parseFileMode,
    validateArray,
    validateStringArray,
    validateBooleanArray,
    validateBoolean,
    validateBuffer,
    validateDictionary,
    validateEncoding,
    validateFunction,
    validateInt32,
    validateInteger,
    validateNumber,
    validateObject,
    validateOneOf,
    validatePlainFunction,
    validatePort,
    validateSignalName,
    validateString,
    validateUint32,
    validateUndefined,
    validateUnion,
    validateAbortSignal,
    validateLinkHeaderValue
  };
});

// node_modules/readable-stream/lib/internal/streams/utils.js
var require_utils = __commonJS((exports, module) => {
  var isReadableNodeStream = function(obj, strict = false) {
    var _obj$_readableState;
    return !!(obj && typeof obj.pipe === "function" && typeof obj.on === "function" && (!strict || typeof obj.pause === "function" && typeof obj.resume === "function") && (!obj._writableState || ((_obj$_readableState = obj._readableState) === null || _obj$_readableState === undefined ? undefined : _obj$_readableState.readable) !== false) && (!obj._writableState || obj._readableState));
  };
  var isWritableNodeStream = function(obj) {
    var _obj$_writableState;
    return !!(obj && typeof obj.write === "function" && typeof obj.on === "function" && (!obj._readableState || ((_obj$_writableState = obj._writableState) === null || _obj$_writableState === undefined ? undefined : _obj$_writableState.writable) !== false));
  };
  var isDuplexNodeStream = function(obj) {
    return !!(obj && typeof obj.pipe === "function" && obj._readableState && typeof obj.on === "function" && typeof obj.write === "function");
  };
  var isNodeStream = function(obj) {
    return obj && (obj._readableState || obj._writableState || typeof obj.write === "function" && typeof obj.on === "function" || typeof obj.pipe === "function" && typeof obj.on === "function");
  };
  var isReadableStream = function(obj) {
    return !!(obj && !isNodeStream(obj) && typeof obj.pipeThrough === "function" && typeof obj.getReader === "function" && typeof obj.cancel === "function");
  };
  var isWritableStream = function(obj) {
    return !!(obj && !isNodeStream(obj) && typeof obj.getWriter === "function" && typeof obj.abort === "function");
  };
  var isTransformStream = function(obj) {
    return !!(obj && !isNodeStream(obj) && typeof obj.readable === "object" && typeof obj.writable === "object");
  };
  var isWebStream = function(obj) {
    return isReadableStream(obj) || isWritableStream(obj) || isTransformStream(obj);
  };
  var isIterable = function(obj, isAsync) {
    if (obj == null)
      return false;
    if (isAsync === true)
      return typeof obj[SymbolAsyncIterator] === "function";
    if (isAsync === false)
      return typeof obj[SymbolIterator] === "function";
    return typeof obj[SymbolAsyncIterator] === "function" || typeof obj[SymbolIterator] === "function";
  };
  var isDestroyed = function(stream) {
    if (!isNodeStream(stream))
      return null;
    const wState = stream._writableState;
    const rState = stream._readableState;
    const state = wState || rState;
    return !!(stream.destroyed || stream[kDestroyed] || state !== null && state !== undefined && state.destroyed);
  };
  var isWritableEnded = function(stream) {
    if (!isWritableNodeStream(stream))
      return null;
    if (stream.writableEnded === true)
      return true;
    const wState = stream._writableState;
    if (wState !== null && wState !== undefined && wState.errored)
      return false;
    if (typeof (wState === null || wState === undefined ? undefined : wState.ended) !== "boolean")
      return null;
    return wState.ended;
  };
  var isWritableFinished = function(stream, strict) {
    if (!isWritableNodeStream(stream))
      return null;
    if (stream.writableFinished === true)
      return true;
    const wState = stream._writableState;
    if (wState !== null && wState !== undefined && wState.errored)
      return false;
    if (typeof (wState === null || wState === undefined ? undefined : wState.finished) !== "boolean")
      return null;
    return !!(wState.finished || strict === false && wState.ended === true && wState.length === 0);
  };
  var isReadableEnded = function(stream) {
    if (!isReadableNodeStream(stream))
      return null;
    if (stream.readableEnded === true)
      return true;
    const rState = stream._readableState;
    if (!rState || rState.errored)
      return false;
    if (typeof (rState === null || rState === undefined ? undefined : rState.ended) !== "boolean")
      return null;
    return rState.ended;
  };
  var isReadableFinished = function(stream, strict) {
    if (!isReadableNodeStream(stream))
      return null;
    const rState = stream._readableState;
    if (rState !== null && rState !== undefined && rState.errored)
      return false;
    if (typeof (rState === null || rState === undefined ? undefined : rState.endEmitted) !== "boolean")
      return null;
    return !!(rState.endEmitted || strict === false && rState.ended === true && rState.length === 0);
  };
  var isReadable = function(stream) {
    if (stream && stream[kIsReadable] != null)
      return stream[kIsReadable];
    if (typeof (stream === null || stream === undefined ? undefined : stream.readable) !== "boolean")
      return null;
    if (isDestroyed(stream))
      return false;
    return isReadableNodeStream(stream) && stream.readable && !isReadableFinished(stream);
  };
  var isWritable = function(stream) {
    if (typeof (stream === null || stream === undefined ? undefined : stream.writable) !== "boolean")
      return null;
    if (isDestroyed(stream))
      return false;
    return isWritableNodeStream(stream) && stream.writable && !isWritableEnded(stream);
  };
  var isFinished = function(stream, opts) {
    if (!isNodeStream(stream)) {
      return null;
    }
    if (isDestroyed(stream)) {
      return true;
    }
    if ((opts === null || opts === undefined ? undefined : opts.readable) !== false && isReadable(stream)) {
      return false;
    }
    if ((opts === null || opts === undefined ? undefined : opts.writable) !== false && isWritable(stream)) {
      return false;
    }
    return true;
  };
  var isWritableErrored = function(stream) {
    var _stream$_writableStat, _stream$_writableStat2;
    if (!isNodeStream(stream)) {
      return null;
    }
    if (stream.writableErrored) {
      return stream.writableErrored;
    }
    return (_stream$_writableStat = (_stream$_writableStat2 = stream._writableState) === null || _stream$_writableStat2 === undefined ? undefined : _stream$_writableStat2.errored) !== null && _stream$_writableStat !== undefined ? _stream$_writableStat : null;
  };
  var isReadableErrored = function(stream) {
    var _stream$_readableStat, _stream$_readableStat2;
    if (!isNodeStream(stream)) {
      return null;
    }
    if (stream.readableErrored) {
      return stream.readableErrored;
    }
    return (_stream$_readableStat = (_stream$_readableStat2 = stream._readableState) === null || _stream$_readableStat2 === undefined ? undefined : _stream$_readableStat2.errored) !== null && _stream$_readableStat !== undefined ? _stream$_readableStat : null;
  };
  var isClosed = function(stream) {
    if (!isNodeStream(stream)) {
      return null;
    }
    if (typeof stream.closed === "boolean") {
      return stream.closed;
    }
    const wState = stream._writableState;
    const rState = stream._readableState;
    if (typeof (wState === null || wState === undefined ? undefined : wState.closed) === "boolean" || typeof (rState === null || rState === undefined ? undefined : rState.closed) === "boolean") {
      return (wState === null || wState === undefined ? undefined : wState.closed) || (rState === null || rState === undefined ? undefined : rState.closed);
    }
    if (typeof stream._closed === "boolean" && isOutgoingMessage(stream)) {
      return stream._closed;
    }
    return null;
  };
  var isOutgoingMessage = function(stream) {
    return typeof stream._closed === "boolean" && typeof stream._defaultKeepAlive === "boolean" && typeof stream._removedConnection === "boolean" && typeof stream._removedContLen === "boolean";
  };
  var isServerResponse = function(stream) {
    return typeof stream._sent100 === "boolean" && isOutgoingMessage(stream);
  };
  var isServerRequest = function(stream) {
    var _stream$req;
    return typeof stream._consuming === "boolean" && typeof stream._dumped === "boolean" && ((_stream$req = stream.req) === null || _stream$req === undefined ? undefined : _stream$req.upgradeOrConnect) === undefined;
  };
  var willEmitClose = function(stream) {
    if (!isNodeStream(stream))
      return null;
    const wState = stream._writableState;
    const rState = stream._readableState;
    const state = wState || rState;
    return !state && isServerResponse(stream) || !!(state && state.autoDestroy && state.emitClose && state.closed === false);
  };
  var isDisturbed = function(stream) {
    var _stream$kIsDisturbed;
    return !!(stream && ((_stream$kIsDisturbed = stream[kIsDisturbed]) !== null && _stream$kIsDisturbed !== undefined ? _stream$kIsDisturbed : stream.readableDidRead || stream.readableAborted));
  };
  var isErrored = function(stream) {
    var _ref, _ref2, _ref3, _ref4, _ref5, _stream$kIsErrored, _stream$_readableStat3, _stream$_writableStat3, _stream$_readableStat4, _stream$_writableStat4;
    return !!(stream && ((_ref = (_ref2 = (_ref3 = (_ref4 = (_ref5 = (_stream$kIsErrored = stream[kIsErrored]) !== null && _stream$kIsErrored !== undefined ? _stream$kIsErrored : stream.readableErrored) !== null && _ref5 !== undefined ? _ref5 : stream.writableErrored) !== null && _ref4 !== undefined ? _ref4 : (_stream$_readableStat3 = stream._readableState) === null || _stream$_readableStat3 === undefined ? undefined : _stream$_readableStat3.errorEmitted) !== null && _ref3 !== undefined ? _ref3 : (_stream$_writableStat3 = stream._writableState) === null || _stream$_writableStat3 === undefined ? undefined : _stream$_writableStat3.errorEmitted) !== null && _ref2 !== undefined ? _ref2 : (_stream$_readableStat4 = stream._readableState) === null || _stream$_readableStat4 === undefined ? undefined : _stream$_readableStat4.errored) !== null && _ref !== undefined ? _ref : (_stream$_writableStat4 = stream._writableState) === null || _stream$_writableStat4 === undefined ? undefined : _stream$_writableStat4.errored));
  };
  var { Symbol: Symbol2, SymbolAsyncIterator, SymbolIterator, SymbolFor } = require_primordials();
  var kDestroyed = Symbol2("kDestroyed");
  var kIsErrored = Symbol2("kIsErrored");
  var kIsReadable = Symbol2("kIsReadable");
  var kIsDisturbed = Symbol2("kIsDisturbed");
  var kIsClosedPromise = SymbolFor("nodejs.webstream.isClosedPromise");
  var kControllerErrorFunction = SymbolFor("nodejs.webstream.controllerErrorFunction");
  module.exports = {
    kDestroyed,
    isDisturbed,
    kIsDisturbed,
    isErrored,
    kIsErrored,
    isReadable,
    kIsReadable,
    kIsClosedPromise,
    kControllerErrorFunction,
    isClosed,
    isDestroyed,
    isDuplexNodeStream,
    isFinished,
    isIterable,
    isReadableNodeStream,
    isReadableStream,
    isReadableEnded,
    isReadableFinished,
    isReadableErrored,
    isNodeStream,
    isWebStream,
    isWritable,
    isWritableNodeStream,
    isWritableStream,
    isWritableEnded,
    isWritableFinished,
    isWritableErrored,
    isServerRequest,
    isServerResponse,
    willEmitClose,
    isTransformStream
  };
});

// node_modules/readable-stream/lib/internal/streams/end-of-stream.js
var require_end_of_stream = __commonJS((exports, module) => {
  var isRequest = function(stream) {
    return stream.setHeader && typeof stream.abort === "function";
  };
  var eos = function(stream, options, callback) {
    var _options$readable, _options$writable;
    if (arguments.length === 2) {
      callback = options;
      options = kEmptyObject;
    } else if (options == null) {
      options = kEmptyObject;
    } else {
      validateObject(options, "options");
    }
    validateFunction(callback, "callback");
    validateAbortSignal(options.signal, "options.signal");
    callback = once(callback);
    if (isReadableStream(stream) || isWritableStream(stream)) {
      return eosWeb(stream, options, callback);
    }
    if (!isNodeStream(stream)) {
      throw new ERR_INVALID_ARG_TYPE("stream", ["ReadableStream", "WritableStream", "Stream"], stream);
    }
    const readable = (_options$readable = options.readable) !== null && _options$readable !== undefined ? _options$readable : isReadableNodeStream(stream);
    const writable = (_options$writable = options.writable) !== null && _options$writable !== undefined ? _options$writable : isWritableNodeStream(stream);
    const wState = stream._writableState;
    const rState = stream._readableState;
    const onlegacyfinish = () => {
      if (!stream.writable) {
        onfinish();
      }
    };
    let willEmitClose = _willEmitClose(stream) && isReadableNodeStream(stream) === readable && isWritableNodeStream(stream) === writable;
    let writableFinished = isWritableFinished(stream, false);
    const onfinish = () => {
      writableFinished = true;
      if (stream.destroyed) {
        willEmitClose = false;
      }
      if (willEmitClose && (!stream.readable || readable)) {
        return;
      }
      if (!readable || readableFinished) {
        callback.call(stream);
      }
    };
    let readableFinished = isReadableFinished(stream, false);
    const onend = () => {
      readableFinished = true;
      if (stream.destroyed) {
        willEmitClose = false;
      }
      if (willEmitClose && (!stream.writable || writable)) {
        return;
      }
      if (!writable || writableFinished) {
        callback.call(stream);
      }
    };
    const onerror = (err) => {
      callback.call(stream, err);
    };
    let closed = isClosed(stream);
    const onclose = () => {
      closed = true;
      const errored = isWritableErrored(stream) || isReadableErrored(stream);
      if (errored && typeof errored !== "boolean") {
        return callback.call(stream, errored);
      }
      if (readable && !readableFinished && isReadableNodeStream(stream, true)) {
        if (!isReadableFinished(stream, false))
          return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE);
      }
      if (writable && !writableFinished) {
        if (!isWritableFinished(stream, false))
          return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE);
      }
      callback.call(stream);
    };
    const onclosed = () => {
      closed = true;
      const errored = isWritableErrored(stream) || isReadableErrored(stream);
      if (errored && typeof errored !== "boolean") {
        return callback.call(stream, errored);
      }
      callback.call(stream);
    };
    const onrequest = () => {
      stream.req.on("finish", onfinish);
    };
    if (isRequest(stream)) {
      stream.on("complete", onfinish);
      if (!willEmitClose) {
        stream.on("abort", onclose);
      }
      if (stream.req) {
        onrequest();
      } else {
        stream.on("request", onrequest);
      }
    } else if (writable && !wState) {
      stream.on("end", onlegacyfinish);
      stream.on("close", onlegacyfinish);
    }
    if (!willEmitClose && typeof stream.aborted === "boolean") {
      stream.on("aborted", onclose);
    }
    stream.on("end", onend);
    stream.on("finish", onfinish);
    if (options.error !== false) {
      stream.on("error", onerror);
    }
    stream.on("close", onclose);
    if (closed) {
      process2.nextTick(onclose);
    } else if (wState !== null && wState !== undefined && wState.errorEmitted || rState !== null && rState !== undefined && rState.errorEmitted) {
      if (!willEmitClose) {
        process2.nextTick(onclosed);
      }
    } else if (!readable && (!willEmitClose || isReadable(stream)) && (writableFinished || isWritable(stream) === false)) {
      process2.nextTick(onclosed);
    } else if (!writable && (!willEmitClose || isWritable(stream)) && (readableFinished || isReadable(stream) === false)) {
      process2.nextTick(onclosed);
    } else if (rState && stream.req && stream.aborted) {
      process2.nextTick(onclosed);
    }
    const cleanup = () => {
      callback = nop;
      stream.removeListener("aborted", onclose);
      stream.removeListener("complete", onfinish);
      stream.removeListener("abort", onclose);
      stream.removeListener("request", onrequest);
      if (stream.req)
        stream.req.removeListener("finish", onfinish);
      stream.removeListener("end", onlegacyfinish);
      stream.removeListener("close", onlegacyfinish);
      stream.removeListener("finish", onfinish);
      stream.removeListener("end", onend);
      stream.removeListener("error", onerror);
      stream.removeListener("close", onclose);
    };
    if (options.signal && !closed) {
      const abort = () => {
        const endCallback = callback;
        cleanup();
        endCallback.call(stream, new AbortError(undefined, {
          cause: options.signal.reason
        }));
      };
      if (options.signal.aborted) {
        process2.nextTick(abort);
      } else {
        const originalCallback = callback;
        callback = once((...args) => {
          options.signal.removeEventListener("abort", abort);
          originalCallback.apply(stream, args);
        });
        options.signal.addEventListener("abort", abort);
      }
    }
    return cleanup;
  };
  var eosWeb = function(stream, options, callback) {
    let isAborted = false;
    let abort = nop;
    if (options.signal) {
      abort = () => {
        isAborted = true;
        callback.call(stream, new AbortError(undefined, {
          cause: options.signal.reason
        }));
      };
      if (options.signal.aborted) {
        process2.nextTick(abort);
      } else {
        const originalCallback = callback;
        callback = once((...args) => {
          options.signal.removeEventListener("abort", abort);
          originalCallback.apply(stream, args);
        });
        options.signal.addEventListener("abort", abort);
      }
    }
    const resolverFn = (...args) => {
      if (!isAborted) {
        process2.nextTick(() => callback.apply(stream, args));
      }
    };
    PromisePrototypeThen(stream[kIsClosedPromise].promise, resolverFn, resolverFn);
    return nop;
  };
  var finished = function(stream, opts) {
    var _opts;
    let autoCleanup = false;
    if (opts === null) {
      opts = kEmptyObject;
    }
    if ((_opts = opts) !== null && _opts !== undefined && _opts.cleanup) {
      validateBoolean(opts.cleanup, "cleanup");
      autoCleanup = opts.cleanup;
    }
    return new Promise2((resolve, reject) => {
      const cleanup = eos(stream, opts, (err) => {
        if (autoCleanup) {
          cleanup();
        }
        if (err) {
          reject(err);
        } else {
          resolve();
        }
      });
    });
  };
  var process2 = __require("process/");
  var { AbortError, codes } = require_errors();
  var { ERR_INVALID_ARG_TYPE, ERR_STREAM_PREMATURE_CLOSE } = codes;
  var { kEmptyObject, once } = require_util();
  var { validateAbortSignal, validateFunction, validateObject, validateBoolean } = require_validators();
  var { Promise: Promise2, PromisePrototypeThen } = require_primordials();
  var {
    isClosed,
    isReadable,
    isReadableNodeStream,
    isReadableStream,
    isReadableFinished,
    isReadableErrored,
    isWritable,
    isWritableNodeStream,
    isWritableStream,
    isWritableFinished,
    isWritableErrored,
    isNodeStream,
    willEmitClose: _willEmitClose,
    kIsClosedPromise
  } = require_utils();
  var nop = () => {
  };
  module.exports = eos;
  module.exports.finished = finished;
});

// node_modules/readable-stream/lib/internal/streams/legacy.js
var require_legacy = __commonJS((exports, module) => {
  var Stream = function(opts) {
    EE.call(this, opts);
  };
  var prependListener = function(emitter, event, fn) {
    if (typeof emitter.prependListener === "function")
      return emitter.prependListener(event, fn);
    if (!emitter._events || !emitter._events[event])
      emitter.on(event, fn);
    else if (ArrayIsArray(emitter._events[event]))
      emitter._events[event].unshift(fn);
    else
      emitter._events[event] = [fn, emitter._events[event]];
  };
  var { ArrayIsArray, ObjectSetPrototypeOf } = require_primordials();
  var { EventEmitter: EE } = __require("events");
  ObjectSetPrototypeOf(Stream.prototype, EE.prototype);
  ObjectSetPrototypeOf(Stream, EE);
  Stream.prototype.pipe = function(dest, options) {
    const source = this;
    function ondata(chunk) {
      if (dest.writable && dest.write(chunk) === false && source.pause) {
        source.pause();
      }
    }
    source.on("data", ondata);
    function ondrain() {
      if (source.readable && source.resume) {
        source.resume();
      }
    }
    dest.on("drain", ondrain);
    if (!dest._isStdio && (!options || options.end !== false)) {
      source.on("end", onend);
      source.on("close", onclose);
    }
    let didOnEnd = false;
    function onend() {
      if (didOnEnd)
        return;
      didOnEnd = true;
      dest.end();
    }
    function onclose() {
      if (didOnEnd)
        return;
      didOnEnd = true;
      if (typeof dest.destroy === "function")
        dest.destroy();
    }
    function onerror(er) {
      cleanup();
      if (EE.listenerCount(this, "error") === 0) {
        this.emit("error", er);
      }
    }
    prependListener(source, "error", onerror);
    prependListener(dest, "error", onerror);
    function cleanup() {
      source.removeListener("data", ondata);
      dest.removeListener("drain", ondrain);
      source.removeListener("end", onend);
      source.removeListener("close", onclose);
      source.removeListener("error", onerror);
      dest.removeListener("error", onerror);
      source.removeListener("end", cleanup);
      source.removeListener("close", cleanup);
      dest.removeListener("close", cleanup);
    }
    source.on("end", cleanup);
    source.on("close", cleanup);
    dest.on("close", cleanup);
    dest.emit("pipe", source);
    return dest;
  };
  module.exports = {
    Stream,
    prependListener
  };
});

// node_modules/readable-stream/lib/internal/streams/destroy.js
var require_destroy = __commonJS((exports, module) => {
  var checkError = function(err, w, r) {
    if (err) {
      err.stack;
      if (w && !w.errored) {
        w.errored = err;
      }
      if (r && !r.errored) {
        r.errored = err;
      }
    }
  };
  var destroy = function(err, cb) {
    const r = this._readableState;
    const w = this._writableState;
    const s = w || r;
    if (w !== null && w !== undefined && w.destroyed || r !== null && r !== undefined && r.destroyed) {
      if (typeof cb === "function") {
        cb();
      }
      return this;
    }
    checkError(err, w, r);
    if (w) {
      w.destroyed = true;
    }
    if (r) {
      r.destroyed = true;
    }
    if (!s.constructed) {
      this.once(kDestroy, function(er) {
        _destroy(this, aggregateTwoErrors(er, err), cb);
      });
    } else {
      _destroy(this, err, cb);
    }
    return this;
  };
  var _destroy = function(self2, err, cb) {
    let called = false;
    function onDestroy(err2) {
      if (called) {
        return;
      }
      called = true;
      const r = self2._readableState;
      const w = self2._writableState;
      checkError(err2, w, r);
      if (w) {
        w.closed = true;
      }
      if (r) {
        r.closed = true;
      }
      if (typeof cb === "function") {
        cb(err2);
      }
      if (err2) {
        process2.nextTick(emitErrorCloseNT, self2, err2);
      } else {
        process2.nextTick(emitCloseNT, self2);
      }
    }
    try {
      self2._destroy(err || null, onDestroy);
    } catch (err2) {
      onDestroy(err2);
    }
  };
  var emitErrorCloseNT = function(self2, err) {
    emitErrorNT(self2, err);
    emitCloseNT(self2);
  };
  var emitCloseNT = function(self2) {
    const r = self2._readableState;
    const w = self2._writableState;
    if (w) {
      w.closeEmitted = true;
    }
    if (r) {
      r.closeEmitted = true;
    }
    if (w !== null && w !== undefined && w.emitClose || r !== null && r !== undefined && r.emitClose) {
      self2.emit("close");
    }
  };
  var emitErrorNT = function(self2, err) {
    const r = self2._readableState;
    const w = self2._writableState;
    if (w !== null && w !== undefined && w.errorEmitted || r !== null && r !== undefined && r.errorEmitted) {
      return;
    }
    if (w) {
      w.errorEmitted = true;
    }
    if (r) {
      r.errorEmitted = true;
    }
    self2.emit("error", err);
  };
  var undestroy = function() {
    const r = this._readableState;
    const w = this._writableState;
    if (r) {
      r.constructed = true;
      r.closed = false;
      r.closeEmitted = false;
      r.destroyed = false;
      r.errored = null;
      r.errorEmitted = false;
      r.reading = false;
      r.ended = r.readable === false;
      r.endEmitted = r.readable === false;
    }
    if (w) {
      w.constructed = true;
      w.destroyed = false;
      w.closed = false;
      w.closeEmitted = false;
      w.errored = null;
      w.errorEmitted = false;
      w.finalCalled = false;
      w.prefinished = false;
      w.ended = w.writable === false;
      w.ending = w.writable === false;
      w.finished = w.writable === false;
    }
  };
  var errorOrDestroy = function(stream, err, sync) {
    const r = stream._readableState;
    const w = stream._writableState;
    if (w !== null && w !== undefined && w.destroyed || r !== null && r !== undefined && r.destroyed) {
      return this;
    }
    if (r !== null && r !== undefined && r.autoDestroy || w !== null && w !== undefined && w.autoDestroy)
      stream.destroy(err);
    else if (err) {
      err.stack;
      if (w && !w.errored) {
        w.errored = err;
      }
      if (r && !r.errored) {
        r.errored = err;
      }
      if (sync) {
        process2.nextTick(emitErrorNT, stream, err);
      } else {
        emitErrorNT(stream, err);
      }
    }
  };
  var construct = function(stream, cb) {
    if (typeof stream._construct !== "function") {
      return;
    }
    const r = stream._readableState;
    const w = stream._writableState;
    if (r) {
      r.constructed = false;
    }
    if (w) {
      w.constructed = false;
    }
    stream.once(kConstruct, cb);
    if (stream.listenerCount(kConstruct) > 1) {
      return;
    }
    process2.nextTick(constructNT, stream);
  };
  var constructNT = function(stream) {
    let called = false;
    function onConstruct(err) {
      if (called) {
        errorOrDestroy(stream, err !== null && err !== undefined ? err : new ERR_MULTIPLE_CALLBACK);
        return;
      }
      called = true;
      const r = stream._readableState;
      const w = stream._writableState;
      const s = w || r;
      if (r) {
        r.constructed = true;
      }
      if (w) {
        w.constructed = true;
      }
      if (s.destroyed) {
        stream.emit(kDestroy, err);
      } else if (err) {
        errorOrDestroy(stream, err, true);
      } else {
        process2.nextTick(emitConstructNT, stream);
      }
    }
    try {
      stream._construct((err) => {
        process2.nextTick(onConstruct, err);
      });
    } catch (err) {
      process2.nextTick(onConstruct, err);
    }
  };
  var emitConstructNT = function(stream) {
    stream.emit(kConstruct);
  };
  var isRequest = function(stream) {
    return (stream === null || stream === undefined ? undefined : stream.setHeader) && typeof stream.abort === "function";
  };
  var emitCloseLegacy = function(stream) {
    stream.emit("close");
  };
  var emitErrorCloseLegacy = function(stream, err) {
    stream.emit("error", err);
    process2.nextTick(emitCloseLegacy, stream);
  };
  var destroyer = function(stream, err) {
    if (!stream || isDestroyed(stream)) {
      return;
    }
    if (!err && !isFinished(stream)) {
      err = new AbortError;
    }
    if (isServerRequest(stream)) {
      stream.socket = null;
      stream.destroy(err);
    } else if (isRequest(stream)) {
      stream.abort();
    } else if (isRequest(stream.req)) {
      stream.req.abort();
    } else if (typeof stream.destroy === "function") {
      stream.destroy(err);
    } else if (typeof stream.close === "function") {
      stream.close();
    } else if (err) {
      process2.nextTick(emitErrorCloseLegacy, stream, err);
    } else {
      process2.nextTick(emitCloseLegacy, stream);
    }
    if (!stream.destroyed) {
      stream[kDestroyed] = true;
    }
  };
  var process2 = __require("process/");
  var {
    aggregateTwoErrors,
    codes: { ERR_MULTIPLE_CALLBACK },
    AbortError
  } = require_errors();
  var { Symbol: Symbol2 } = require_primordials();
  var { kDestroyed, isDestroyed, isFinished, isServerRequest } = require_utils();
  var kDestroy = Symbol2("kDestroy");
  var kConstruct = Symbol2("kConstruct");
  module.exports = {
    construct,
    destroyer,
    destroy,
    undestroy,
    errorOrDestroy
  };
});

// node_modules/readable-stream/lib/internal/streams/add-abort-signal.js
var require_add_abort_signal = __commonJS((exports, module) => {
  var { AbortError, codes } = require_errors();
  var { isNodeStream, isWebStream, kControllerErrorFunction } = require_utils();
  var eos = require_end_of_stream();
  var { ERR_INVALID_ARG_TYPE } = codes;
  var validateAbortSignal = (signal, name) => {
    if (typeof signal !== "object" || !("aborted" in signal)) {
      throw new ERR_INVALID_ARG_TYPE(name, "AbortSignal", signal);
    }
  };
  exports.addAbortSignal = function addAbortSignal(signal, stream) {
    validateAbortSignal(signal, "signal");
    if (!isNodeStream(stream) && !isWebStream(stream)) {
      throw new ERR_INVALID_ARG_TYPE("stream", ["ReadableStream", "WritableStream", "Stream"], stream);
    }
    return exports.addAbortSignalNoValidate(signal, stream);
  };
  exports.addAbortSignalNoValidate = function(signal, stream) {
    if (typeof signal !== "object" || !("aborted" in signal)) {
      return stream;
    }
    const onAbort = isNodeStream(stream) ? () => {
      stream.destroy(new AbortError(undefined, {
        cause: signal.reason
      }));
    } : () => {
      stream[kControllerErrorFunction](new AbortError(undefined, {
        cause: signal.reason
      }));
    };
    if (signal.aborted) {
      onAbort();
    } else {
      signal.addEventListener("abort", onAbort);
      eos(stream, () => signal.removeEventListener("abort", onAbort));
    }
    return stream;
  };
});

// node_modules/readable-stream/lib/internal/streams/state.js
var require_state = __commonJS((exports, module) => {
  var highWaterMarkFrom = function(options, isDuplex, duplexKey) {
    return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;
  };
  var getDefaultHighWaterMark = function(objectMode) {
    return objectMode ? 16 : 16 * 1024;
  };
  var getHighWaterMark = function(state, options, duplexKey, isDuplex) {
    const hwm = highWaterMarkFrom(options, isDuplex, duplexKey);
    if (hwm != null) {
      if (!NumberIsInteger(hwm) || hwm < 0) {
        const name = isDuplex ? `options.${duplexKey}` : "options.highWaterMark";
        throw new ERR_INVALID_ARG_VALUE(name, hwm);
      }
      return MathFloor(hwm);
    }
    return getDefaultHighWaterMark(state.objectMode);
  };
  var { MathFloor, NumberIsInteger } = require_primordials();
  var { ERR_INVALID_ARG_VALUE } = require_errors().codes;
  module.exports = {
    getHighWaterMark,
    getDefaultHighWaterMark
  };
});

// node_modules/readable-stream/lib/internal/streams/writable.js
var require_writable = __commonJS((exports, module) => {
  var nop = function() {
  };
  var WritableState = function(options, stream, isDuplex) {
    if (typeof isDuplex !== "boolean")
      isDuplex = stream instanceof require_duplex();
    this.objectMode = !!(options && options.objectMode);
    if (isDuplex)
      this.objectMode = this.objectMode || !!(options && options.writableObjectMode);
    this.highWaterMark = options ? getHighWaterMark(this, options, "writableHighWaterMark", isDuplex) : getDefaultHighWaterMark(false);
    this.finalCalled = false;
    this.needDrain = false;
    this.ending = false;
    this.ended = false;
    this.finished = false;
    this.destroyed = false;
    const noDecode = !!(options && options.decodeStrings === false);
    this.decodeStrings = !noDecode;
    this.defaultEncoding = options && options.defaultEncoding || "utf8";
    this.length = 0;
    this.writing = false;
    this.corked = 0;
    this.sync = true;
    this.bufferProcessing = false;
    this.onwrite = onwrite.bind(undefined, stream);
    this.writecb = null;
    this.writelen = 0;
    this.afterWriteTickInfo = null;
    resetBuffer(this);
    this.pendingcb = 0;
    this.constructed = true;
    this.prefinished = false;
    this.errorEmitted = false;
    this.emitClose = !options || options.emitClose !== false;
    this.autoDestroy = !options || options.autoDestroy !== false;
    this.errored = null;
    this.closed = false;
    this.closeEmitted = false;
    this[kOnFinished] = [];
  };
  var resetBuffer = function(state) {
    state.buffered = [];
    state.bufferedIndex = 0;
    state.allBuffers = true;
    state.allNoop = true;
  };
  var Writable = function(options) {
    const isDuplex = this instanceof require_duplex();
    if (!isDuplex && !FunctionPrototypeSymbolHasInstance(Writable, this))
      return new Writable(options);
    this._writableState = new WritableState(options, this, isDuplex);
    if (options) {
      if (typeof options.write === "function")
        this._write = options.write;
      if (typeof options.writev === "function")
        this._writev = options.writev;
      if (typeof options.destroy === "function")
        this._destroy = options.destroy;
      if (typeof options.final === "function")
        this._final = options.final;
      if (typeof options.construct === "function")
        this._construct = options.construct;
      if (options.signal)
        addAbortSignal(options.signal, this);
    }
    Stream.call(this, options);
    destroyImpl.construct(this, () => {
      const state = this._writableState;
      if (!state.writing) {
        clearBuffer(this, state);
      }
      finishMaybe(this, state);
    });
  };
  var _write = function(stream, chunk, encoding, cb) {
    const state = stream._writableState;
    if (typeof encoding === "function") {
      cb = encoding;
      encoding = state.defaultEncoding;
    } else {
      if (!encoding)
        encoding = state.defaultEncoding;
      else if (encoding !== "buffer" && !Buffer2.isEncoding(encoding))
        throw new ERR_UNKNOWN_ENCODING(encoding);
      if (typeof cb !== "function")
        cb = nop;
    }
    if (chunk === null) {
      throw new ERR_STREAM_NULL_VALUES;
    } else if (!state.objectMode) {
      if (typeof chunk === "string") {
        if (state.decodeStrings !== false) {
          chunk = Buffer2.from(chunk, encoding);
          encoding = "buffer";
        }
      } else if (chunk instanceof Buffer2) {
        encoding = "buffer";
      } else if (Stream._isUint8Array(chunk)) {
        chunk = Stream._uint8ArrayToBuffer(chunk);
        encoding = "buffer";
      } else {
        throw new ERR_INVALID_ARG_TYPE("chunk", ["string", "Buffer", "Uint8Array"], chunk);
      }
    }
    let err;
    if (state.ending) {
      err = new ERR_STREAM_WRITE_AFTER_END;
    } else if (state.destroyed) {
      err = new ERR_STREAM_DESTROYED("write");
    }
    if (err) {
      process2.nextTick(cb, err);
      errorOrDestroy(stream, err, true);
      return err;
    }
    state.pendingcb++;
    return writeOrBuffer(stream, state, chunk, encoding, cb);
  };
  var writeOrBuffer = function(stream, state, chunk, encoding, callback) {
    const len = state.objectMode ? 1 : chunk.length;
    state.length += len;
    const ret = state.length < state.highWaterMark;
    if (!ret)
      state.needDrain = true;
    if (state.writing || state.corked || state.errored || !state.constructed) {
      state.buffered.push({
        chunk,
        encoding,
        callback
      });
      if (state.allBuffers && encoding !== "buffer") {
        state.allBuffers = false;
      }
      if (state.allNoop && callback !== nop) {
        state.allNoop = false;
      }
    } else {
      state.writelen = len;
      state.writecb = callback;
      state.writing = true;
      state.sync = true;
      stream._write(chunk, encoding, state.onwrite);
      state.sync = false;
    }
    return ret && !state.errored && !state.destroyed;
  };
  var doWrite = function(stream, state, writev, len, chunk, encoding, cb) {
    state.writelen = len;
    state.writecb = cb;
    state.writing = true;
    state.sync = true;
    if (state.destroyed)
      state.onwrite(new ERR_STREAM_DESTROYED("write"));
    else if (writev)
      stream._writev(chunk, state.onwrite);
    else
      stream._write(chunk, encoding, state.onwrite);
    state.sync = false;
  };
  var onwriteError = function(stream, state, er, cb) {
    --state.pendingcb;
    cb(er);
    errorBuffer(state);
    errorOrDestroy(stream, er);
  };
  var onwrite = function(stream, er) {
    const state = stream._writableState;
    const sync = state.sync;
    const cb = state.writecb;
    if (typeof cb !== "function") {
      errorOrDestroy(stream, new ERR_MULTIPLE_CALLBACK);
      return;
    }
    state.writing = false;
    state.writecb = null;
    state.length -= state.writelen;
    state.writelen = 0;
    if (er) {
      er.stack;
      if (!state.errored) {
        state.errored = er;
      }
      if (stream._readableState && !stream._readableState.errored) {
        stream._readableState.errored = er;
      }
      if (sync) {
        process2.nextTick(onwriteError, stream, state, er, cb);
      } else {
        onwriteError(stream, state, er, cb);
      }
    } else {
      if (state.buffered.length > state.bufferedIndex) {
        clearBuffer(stream, state);
      }
      if (sync) {
        if (state.afterWriteTickInfo !== null && state.afterWriteTickInfo.cb === cb) {
          state.afterWriteTickInfo.count++;
        } else {
          state.afterWriteTickInfo = {
            count: 1,
            cb,
            stream,
            state
          };
          process2.nextTick(afterWriteTick, state.afterWriteTickInfo);
        }
      } else {
        afterWrite(stream, state, 1, cb);
      }
    }
  };
  var afterWriteTick = function({ stream, state, count, cb }) {
    state.afterWriteTickInfo = null;
    return afterWrite(stream, state, count, cb);
  };
  var afterWrite = function(stream, state, count, cb) {
    const needDrain = !state.ending && !stream.destroyed && state.length === 0 && state.needDrain;
    if (needDrain) {
      state.needDrain = false;
      stream.emit("drain");
    }
    while (count-- > 0) {
      state.pendingcb--;
      cb();
    }
    if (state.destroyed) {
      errorBuffer(state);
    }
    finishMaybe(stream, state);
  };
  var errorBuffer = function(state) {
    if (state.writing) {
      return;
    }
    for (let n = state.bufferedIndex;n < state.buffered.length; ++n) {
      var _state$errored;
      const { chunk, callback } = state.buffered[n];
      const len = state.objectMode ? 1 : chunk.length;
      state.length -= len;
      callback((_state$errored = state.errored) !== null && _state$errored !== undefined ? _state$errored : new ERR_STREAM_DESTROYED("write"));
    }
    const onfinishCallbacks = state[kOnFinished].splice(0);
    for (let i = 0;i < onfinishCallbacks.length; i++) {
      var _state$errored2;
      onfinishCallbacks[i]((_state$errored2 = state.errored) !== null && _state$errored2 !== undefined ? _state$errored2 : new ERR_STREAM_DESTROYED("end"));
    }
    resetBuffer(state);
  };
  var clearBuffer = function(stream, state) {
    if (state.corked || state.bufferProcessing || state.destroyed || !state.constructed) {
      return;
    }
    const { buffered, bufferedIndex, objectMode } = state;
    const bufferedLength = buffered.length - bufferedIndex;
    if (!bufferedLength) {
      return;
    }
    let i = bufferedIndex;
    state.bufferProcessing = true;
    if (bufferedLength > 1 && stream._writev) {
      state.pendingcb -= bufferedLength - 1;
      const callback = state.allNoop ? nop : (err) => {
        for (let n = i;n < buffered.length; ++n) {
          buffered[n].callback(err);
        }
      };
      const chunks = state.allNoop && i === 0 ? buffered : ArrayPrototypeSlice(buffered, i);
      chunks.allBuffers = state.allBuffers;
      doWrite(stream, state, true, state.length, chunks, "", callback);
      resetBuffer(state);
    } else {
      do {
        const { chunk, encoding, callback } = buffered[i];
        buffered[i++] = null;
        const len = objectMode ? 1 : chunk.length;
        doWrite(stream, state, false, len, chunk, encoding, callback);
      } while (i < buffered.length && !state.writing);
      if (i === buffered.length) {
        resetBuffer(state);
      } else if (i > 256) {
        buffered.splice(0, i);
        state.bufferedIndex = 0;
      } else {
        state.bufferedIndex = i;
      }
    }
    state.bufferProcessing = false;
  };
  var needFinish = function(state) {
    return state.ending && !state.destroyed && state.constructed && state.length === 0 && !state.errored && state.buffered.length === 0 && !state.finished && !state.writing && !state.errorEmitted && !state.closeEmitted;
  };
  var callFinal = function(stream, state) {
    let called = false;
    function onFinish(err) {
      if (called) {
        errorOrDestroy(stream, err !== null && err !== undefined ? err : ERR_MULTIPLE_CALLBACK());
        return;
      }
      called = true;
      state.pendingcb--;
      if (err) {
        const onfinishCallbacks = state[kOnFinished].splice(0);
        for (let i = 0;i < onfinishCallbacks.length; i++) {
          onfinishCallbacks[i](err);
        }
        errorOrDestroy(stream, err, state.sync);
      } else if (needFinish(state)) {
        state.prefinished = true;
        stream.emit("prefinish");
        state.pendingcb++;
        process2.nextTick(finish, stream, state);
      }
    }
    state.sync = true;
    state.pendingcb++;
    try {
      stream._final(onFinish);
    } catch (err) {
      onFinish(err);
    }
    state.sync = false;
  };
  var prefinish = function(stream, state) {
    if (!state.prefinished && !state.finalCalled) {
      if (typeof stream._final === "function" && !state.destroyed) {
        state.finalCalled = true;
        callFinal(stream, state);
      } else {
        state.prefinished = true;
        stream.emit("prefinish");
      }
    }
  };
  var finishMaybe = function(stream, state, sync) {
    if (needFinish(state)) {
      prefinish(stream, state);
      if (state.pendingcb === 0) {
        if (sync) {
          state.pendingcb++;
          process2.nextTick((stream2, state2) => {
            if (needFinish(state2)) {
              finish(stream2, state2);
            } else {
              state2.pendingcb--;
            }
          }, stream, state);
        } else if (needFinish(state)) {
          state.pendingcb++;
          finish(stream, state);
        }
      }
    }
  };
  var finish = function(stream, state) {
    state.pendingcb--;
    state.finished = true;
    const onfinishCallbacks = state[kOnFinished].splice(0);
    for (let i = 0;i < onfinishCallbacks.length; i++) {
      onfinishCallbacks[i]();
    }
    stream.emit("finish");
    if (state.autoDestroy) {
      const rState = stream._readableState;
      const autoDestroy = !rState || rState.autoDestroy && (rState.endEmitted || rState.readable === false);
      if (autoDestroy) {
        stream.destroy();
      }
    }
  };
  var lazyWebStreams = function() {
    if (webStreamsAdapters === undefined)
      webStreamsAdapters = {};
    return webStreamsAdapters;
  };
  var process2 = __require("process/");
  var {
    ArrayPrototypeSlice,
    Error: Error2,
    FunctionPrototypeSymbolHasInstance,
    ObjectDefineProperty,
    ObjectDefineProperties,
    ObjectSetPrototypeOf,
    StringPrototypeToLowerCase,
    Symbol: Symbol2,
    SymbolHasInstance
  } = require_primordials();
  module.exports = Writable;
  Writable.WritableState = WritableState;
  var { EventEmitter: EE } = __require("events");
  var Stream = require_legacy().Stream;
  var { Buffer: Buffer2 } = __require("buffer");
  var destroyImpl = require_destroy();
  var { addAbortSignal } = require_add_abort_signal();
  var { getHighWaterMark, getDefaultHighWaterMark } = require_state();
  var {
    ERR_INVALID_ARG_TYPE,
    ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK,
    ERR_STREAM_CANNOT_PIPE,
    ERR_STREAM_DESTROYED,
    ERR_STREAM_ALREADY_FINISHED,
    ERR_STREAM_NULL_VALUES,
    ERR_STREAM_WRITE_AFTER_END,
    ERR_UNKNOWN_ENCODING
  } = require_errors().codes;
  var { errorOrDestroy } = destroyImpl;
  ObjectSetPrototypeOf(Writable.prototype, Stream.prototype);
  ObjectSetPrototypeOf(Writable, Stream);
  var kOnFinished = Symbol2("kOnFinished");
  WritableState.prototype.getBuffer = function getBuffer() {
    return ArrayPrototypeSlice(this.buffered, this.bufferedIndex);
  };
  ObjectDefineProperty(WritableState.prototype, "bufferedRequestCount", {
    __proto__: null,
    get() {
      return this.buffered.length - this.bufferedIndex;
    }
  });
  ObjectDefineProperty(Writable, SymbolHasInstance, {
    __proto__: null,
    value: function(object) {
      if (FunctionPrototypeSymbolHasInstance(this, object))
        return true;
      if (this !== Writable)
        return false;
      return object && object._writableState instanceof WritableState;
    }
  });
  Writable.prototype.pipe = function() {
    errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE);
  };
  Writable.prototype.write = function(chunk, encoding, cb) {
    return _write(this, chunk, encoding, cb) === true;
  };
  Writable.prototype.cork = function() {
    this._writableState.corked++;
  };
  Writable.prototype.uncork = function() {
    const state = this._writableState;
    if (state.corked) {
      state.corked--;
      if (!state.writing)
        clearBuffer(this, state);
    }
  };
  Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {
    if (typeof encoding === "string")
      encoding = StringPrototypeToLowerCase(encoding);
    if (!Buffer2.isEncoding(encoding))
      throw new ERR_UNKNOWN_ENCODING(encoding);
    this._writableState.defaultEncoding = encoding;
    return this;
  };
  Writable.prototype._write = function(chunk, encoding, cb) {
    if (this._writev) {
      this._writev([
        {
          chunk,
          encoding
        }
      ], cb);
    } else {
      throw new ERR_METHOD_NOT_IMPLEMENTED("_write()");
    }
  };
  Writable.prototype._writev = null;
  Writable.prototype.end = function(chunk, encoding, cb) {
    const state = this._writableState;
    if (typeof chunk === "function") {
      cb = chunk;
      chunk = null;
      encoding = null;
    } else if (typeof encoding === "function") {
      cb = encoding;
      encoding = null;
    }
    let err;
    if (chunk !== null && chunk !== undefined) {
      const ret = _write(this, chunk, encoding);
      if (ret instanceof Error2) {
        err = ret;
      }
    }
    if (state.corked) {
      state.corked = 1;
      this.uncork();
    }
    if (err) {
    } else if (!state.errored && !state.ending) {
      state.ending = true;
      finishMaybe(this, state, true);
      state.ended = true;
    } else if (state.finished) {
      err = new ERR_STREAM_ALREADY_FINISHED("end");
    } else if (state.destroyed) {
      err = new ERR_STREAM_DESTROYED("end");
    }
    if (typeof cb === "function") {
      if (err || state.finished) {
        process2.nextTick(cb, err);
      } else {
        state[kOnFinished].push(cb);
      }
    }
    return this;
  };
  ObjectDefineProperties(Writable.prototype, {
    closed: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.closed : false;
      }
    },
    destroyed: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.destroyed : false;
      },
      set(value) {
        if (this._writableState) {
          this._writableState.destroyed = value;
        }
      }
    },
    writable: {
      __proto__: null,
      get() {
        const w = this._writableState;
        return !!w && w.writable !== false && !w.destroyed && !w.errored && !w.ending && !w.ended;
      },
      set(val) {
        if (this._writableState) {
          this._writableState.writable = !!val;
        }
      }
    },
    writableFinished: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.finished : false;
      }
    },
    writableObjectMode: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.objectMode : false;
      }
    },
    writableBuffer: {
      __proto__: null,
      get() {
        return this._writableState && this._writableState.getBuffer();
      }
    },
    writableEnded: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.ending : false;
      }
    },
    writableNeedDrain: {
      __proto__: null,
      get() {
        const wState = this._writableState;
        if (!wState)
          return false;
        return !wState.destroyed && !wState.ending && wState.needDrain;
      }
    },
    writableHighWaterMark: {
      __proto__: null,
      get() {
        return this._writableState && this._writableState.highWaterMark;
      }
    },
    writableCorked: {
      __proto__: null,
      get() {
        return this._writableState ? this._writableState.corked : 0;
      }
    },
    writableLength: {
      __proto__: null,
      get() {
        return this._writableState && this._writableState.length;
      }
    },
    errored: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._writableState ? this._writableState.errored : null;
      }
    },
    writableAborted: {
      __proto__: null,
      enumerable: false,
      get: function() {
        return !!(this._writableState.writable !== false && (this._writableState.destroyed || this._writableState.errored) && !this._writableState.finished);
      }
    }
  });
  var destroy = destroyImpl.destroy;
  Writable.prototype.destroy = function(err, cb) {
    const state = this._writableState;
    if (!state.destroyed && (state.bufferedIndex < state.buffered.length || state[kOnFinished].length)) {
      process2.nextTick(errorBuffer, state);
    }
    destroy.call(this, err, cb);
    return this;
  };
  Writable.prototype._undestroy = destroyImpl.undestroy;
  Writable.prototype._destroy = function(err, cb) {
    cb(err);
  };
  Writable.prototype[EE.captureRejectionSymbol] = function(err) {
    this.destroy(err);
  };
  var webStreamsAdapters;
  Writable.fromWeb = function(writableStream, options) {
    return lazyWebStreams().newStreamWritableFromWritableStream(writableStream, options);
  };
  Writable.toWeb = function(streamWritable) {
    return lazyWebStreams().newWritableStreamFromStreamWritable(streamWritable);
  };
});

// node_modules/readable-stream/lib/internal/streams/from.js
var require_from = __commonJS((exports, module) => {
  var from = function(Readable, iterable, opts) {
    let iterator;
    if (typeof iterable === "string" || iterable instanceof Buffer2) {
      return new Readable({
        objectMode: true,
        ...opts,
        read() {
          this.push(iterable);
          this.push(null);
        }
      });
    }
    let isAsync;
    if (iterable && iterable[SymbolAsyncIterator]) {
      isAsync = true;
      iterator = iterable[SymbolAsyncIterator]();
    } else if (iterable && iterable[SymbolIterator]) {
      isAsync = false;
      iterator = iterable[SymbolIterator]();
    } else {
      throw new ERR_INVALID_ARG_TYPE("iterable", ["Iterable"], iterable);
    }
    const readable = new Readable({
      objectMode: true,
      highWaterMark: 1,
      ...opts
    });
    let reading = false;
    readable._read = function() {
      if (!reading) {
        reading = true;
        next();
      }
    };
    readable._destroy = function(error, cb) {
      PromisePrototypeThen(close(error), () => process2.nextTick(cb, error), (e) => process2.nextTick(cb, e || error));
    };
    async function close(error) {
      const hadError = error !== undefined && error !== null;
      const hasThrow = typeof iterator.throw === "function";
      if (hadError && hasThrow) {
        const { value, done } = await iterator.throw(error);
        await value;
        if (done) {
          return;
        }
      }
      if (typeof iterator.return === "function") {
        const { value } = await iterator.return();
        await value;
      }
    }
    async function next() {
      for (;; ) {
        try {
          const { value, done } = isAsync ? await iterator.next() : iterator.next();
          if (done) {
            readable.push(null);
          } else {
            const res = value && typeof value.then === "function" ? await value : value;
            if (res === null) {
              reading = false;
              throw new ERR_STREAM_NULL_VALUES;
            } else if (readable.push(res)) {
              continue;
            } else {
              reading = false;
            }
          }
        } catch (err) {
          readable.destroy(err);
        }
        break;
      }
    }
    return readable;
  };
  var process2 = __require("process/");
  var { PromisePrototypeThen, SymbolAsyncIterator, SymbolIterator } = require_primordials();
  var { Buffer: Buffer2 } = __require("buffer");
  var { ERR_INVALID_ARG_TYPE, ERR_STREAM_NULL_VALUES } = require_errors().codes;
  module.exports = from;
});

// node_modules/readable-stream/lib/internal/streams/duplexify.js
var require_duplexify = __commonJS((exports, module) => {
  var fromAsyncGen = function(fn) {
    let { promise, resolve } = createDeferredPromise();
    const ac = new AbortController;
    const signal = ac.signal;
    const value = fn(async function* () {
      while (true) {
        const _promise = promise;
        promise = null;
        const { chunk, done, cb } = await _promise;
        process2.nextTick(cb);
        if (done)
          return;
        if (signal.aborted)
          throw new AbortError(undefined, {
            cause: signal.reason
          });
        ({ promise, resolve } = createDeferredPromise());
        yield chunk;
      }
    }(), {
      signal
    });
    return {
      value,
      write(chunk, encoding, cb) {
        const _resolve = resolve;
        resolve = null;
        _resolve({
          chunk,
          done: false,
          cb
        });
      },
      final(cb) {
        const _resolve = resolve;
        resolve = null;
        _resolve({
          done: true,
          cb
        });
      },
      destroy(err, cb) {
        ac.abort();
        cb(err);
      }
    };
  };
  var _duplexify = function(pair) {
    const r = pair.readable && typeof pair.readable.read !== "function" ? Readable.wrap(pair.readable) : pair.readable;
    const w = pair.writable;
    let readable = !!isReadable(r);
    let writable = !!isWritable(w);
    let ondrain;
    let onfinish;
    let onreadable;
    let onclose;
    let d;
    function onfinished(err) {
      const cb = onclose;
      onclose = null;
      if (cb) {
        cb(err);
      } else if (err) {
        d.destroy(err);
      }
    }
    d = new Duplexify({
      readableObjectMode: !!(r !== null && r !== undefined && r.readableObjectMode),
      writableObjectMode: !!(w !== null && w !== undefined && w.writableObjectMode),
      readable,
      writable
    });
    if (writable) {
      eos(w, (err) => {
        writable = false;
        if (err) {
          destroyer(r, err);
        }
        onfinished(err);
      });
      d._write = function(chunk, encoding, callback) {
        if (w.write(chunk, encoding)) {
          callback();
        } else {
          ondrain = callback;
        }
      };
      d._final = function(callback) {
        w.end();
        onfinish = callback;
      };
      w.on("drain", function() {
        if (ondrain) {
          const cb = ondrain;
          ondrain = null;
          cb();
        }
      });
      w.on("finish", function() {
        if (onfinish) {
          const cb = onfinish;
          onfinish = null;
          cb();
        }
      });
    }
    if (readable) {
      eos(r, (err) => {
        readable = false;
        if (err) {
          destroyer(r, err);
        }
        onfinished(err);
      });
      r.on("readable", function() {
        if (onreadable) {
          const cb = onreadable;
          onreadable = null;
          cb();
        }
      });
      r.on("end", function() {
        d.push(null);
      });
      d._read = function() {
        while (true) {
          const buf = r.read();
          if (buf === null) {
            onreadable = d._read;
            return;
          }
          if (!d.push(buf)) {
            return;
          }
        }
      };
    }
    d._destroy = function(err, callback) {
      if (!err && onclose !== null) {
        err = new AbortError;
      }
      onreadable = null;
      ondrain = null;
      onfinish = null;
      if (onclose === null) {
        callback(err);
      } else {
        onclose = callback;
        destroyer(w, err);
        destroyer(r, err);
      }
    };
    return d;
  };
  var process2 = __require("process/");
  var bufferModule = __require("buffer");
  var {
    isReadable,
    isWritable,
    isIterable,
    isNodeStream,
    isReadableNodeStream,
    isWritableNodeStream,
    isDuplexNodeStream
  } = require_utils();
  var eos = require_end_of_stream();
  var {
    AbortError,
    codes: { ERR_INVALID_ARG_TYPE, ERR_INVALID_RETURN_VALUE }
  } = require_errors();
  var { destroyer } = require_destroy();
  var Duplex = require_duplex();
  var Readable = require_readable();
  var { createDeferredPromise } = require_util();
  var from = require_from();
  var Blob = globalThis.Blob || bufferModule.Blob;
  var isBlob = typeof Blob !== "undefined" ? function isBlob(b) {
    return b instanceof Blob;
  } : function isBlob(b) {
    return false;
  };
  var AbortController = globalThis.AbortController || require_abort_controller().AbortController;
  var { FunctionPrototypeCall } = require_primordials();

  class Duplexify extends Duplex {
    constructor(options) {
      super(options);
      if ((options === null || options === undefined ? undefined : options.readable) === false) {
        this._readableState.readable = false;
        this._readableState.ended = true;
        this._readableState.endEmitted = true;
      }
      if ((options === null || options === undefined ? undefined : options.writable) === false) {
        this._writableState.writable = false;
        this._writableState.ending = true;
        this._writableState.ended = true;
        this._writableState.finished = true;
      }
    }
  }
  module.exports = function duplexify(body, name) {
    if (isDuplexNodeStream(body)) {
      return body;
    }
    if (isReadableNodeStream(body)) {
      return _duplexify({
        readable: body
      });
    }
    if (isWritableNodeStream(body)) {
      return _duplexify({
        writable: body
      });
    }
    if (isNodeStream(body)) {
      return _duplexify({
        writable: false,
        readable: false
      });
    }
    if (typeof body === "function") {
      const { value, write, final, destroy } = fromAsyncGen(body);
      if (isIterable(value)) {
        return from(Duplexify, value, {
          objectMode: true,
          write,
          final,
          destroy
        });
      }
      const then2 = value === null || value === undefined ? undefined : value.then;
      if (typeof then2 === "function") {
        let d;
        const promise = FunctionPrototypeCall(then2, value, (val) => {
          if (val != null) {
            throw new ERR_INVALID_RETURN_VALUE("nully", "body", val);
          }
        }, (err) => {
          destroyer(d, err);
        });
        return d = new Duplexify({
          objectMode: true,
          readable: false,
          write,
          final(cb) {
            final(async () => {
              try {
                await promise;
                process2.nextTick(cb, null);
              } catch (err) {
                process2.nextTick(cb, err);
              }
            });
          },
          destroy
        });
      }
      throw new ERR_INVALID_RETURN_VALUE("Iterable, AsyncIterable or AsyncFunction", name, value);
    }
    if (isBlob(body)) {
      return duplexify(body.arrayBuffer());
    }
    if (isIterable(body)) {
      return from(Duplexify, body, {
        objectMode: true,
        writable: false
      });
    }
    if (typeof (body === null || body === undefined ? undefined : body.writable) === "object" || typeof (body === null || body === undefined ? undefined : body.readable) === "object") {
      const readable = body !== null && body !== undefined && body.readable ? isReadableNodeStream(body === null || body === undefined ? undefined : body.readable) ? body === null || body === undefined ? undefined : body.readable : duplexify(body.readable) : undefined;
      const writable = body !== null && body !== undefined && body.writable ? isWritableNodeStream(body === null || body === undefined ? undefined : body.writable) ? body === null || body === undefined ? undefined : body.writable : duplexify(body.writable) : undefined;
      return _duplexify({
        readable,
        writable
      });
    }
    const then = body === null || body === undefined ? undefined : body.then;
    if (typeof then === "function") {
      let d;
      FunctionPrototypeCall(then, body, (val) => {
        if (val != null) {
          d.push(val);
        }
        d.push(null);
      }, (err) => {
        destroyer(d, err);
      });
      return d = new Duplexify({
        objectMode: true,
        writable: false,
        read() {
        }
      });
    }
    throw new ERR_INVALID_ARG_TYPE(name, [
      "Blob",
      "ReadableStream",
      "WritableStream",
      "Stream",
      "Iterable",
      "AsyncIterable",
      "Function",
      "{ readable, writable } pair",
      "Promise"
    ], body);
  };
});

// node_modules/readable-stream/lib/internal/streams/duplex.js
var require_duplex = __commonJS((exports, module) => {
  var Duplex = function(options) {
    if (!(this instanceof Duplex))
      return new Duplex(options);
    Readable.call(this, options);
    Writable.call(this, options);
    if (options) {
      this.allowHalfOpen = options.allowHalfOpen !== false;
      if (options.readable === false) {
        this._readableState.readable = false;
        this._readableState.ended = true;
        this._readableState.endEmitted = true;
      }
      if (options.writable === false) {
        this._writableState.writable = false;
        this._writableState.ending = true;
        this._writableState.ended = true;
        this._writableState.finished = true;
      }
    } else {
      this.allowHalfOpen = true;
    }
  };
  var lazyWebStreams = function() {
    if (webStreamsAdapters === undefined)
      webStreamsAdapters = {};
    return webStreamsAdapters;
  };
  var {
    ObjectDefineProperties,
    ObjectGetOwnPropertyDescriptor,
    ObjectKeys,
    ObjectSetPrototypeOf
  } = require_primordials();
  module.exports = Duplex;
  var Readable = require_readable();
  var Writable = require_writable();
  ObjectSetPrototypeOf(Duplex.prototype, Readable.prototype);
  ObjectSetPrototypeOf(Duplex, Readable);
  {
    const keys = ObjectKeys(Writable.prototype);
    for (let i = 0;i < keys.length; i++) {
      const method = keys[i];
      if (!Duplex.prototype[method])
        Duplex.prototype[method] = Writable.prototype[method];
    }
  }
  ObjectDefineProperties(Duplex.prototype, {
    writable: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writable")
    },
    writableHighWaterMark: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableHighWaterMark")
    },
    writableObjectMode: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableObjectMode")
    },
    writableBuffer: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableBuffer")
    },
    writableLength: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableLength")
    },
    writableFinished: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableFinished")
    },
    writableCorked: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableCorked")
    },
    writableEnded: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableEnded")
    },
    writableNeedDrain: {
      __proto__: null,
      ...ObjectGetOwnPropertyDescriptor(Writable.prototype, "writableNeedDrain")
    },
    destroyed: {
      __proto__: null,
      get() {
        if (this._readableState === undefined || this._writableState === undefined) {
          return false;
        }
        return this._readableState.destroyed && this._writableState.destroyed;
      },
      set(value) {
        if (this._readableState && this._writableState) {
          this._readableState.destroyed = value;
          this._writableState.destroyed = value;
        }
      }
    }
  });
  var webStreamsAdapters;
  Duplex.fromWeb = function(pair, options) {
    return lazyWebStreams().newStreamDuplexFromReadableWritablePair(pair, options);
  };
  Duplex.toWeb = function(duplex) {
    return lazyWebStreams().newReadableWritablePairFromDuplex(duplex);
  };
  var duplexify;
  Duplex.from = function(body) {
    if (!duplexify) {
      duplexify = require_duplexify();
    }
    return duplexify(body, "body");
  };
});

// node_modules/readable-stream/lib/internal/streams/buffer_list.js
var require_buffer_list = __commonJS((exports, module) => {
  var { StringPrototypeSlice, SymbolIterator, TypedArrayPrototypeSet, Uint8Array: Uint8Array2 } = require_primordials();
  var { Buffer: Buffer2 } = __require("buffer");
  var { inspect } = require_util();
  module.exports = class BufferList {
    constructor() {
      this.head = null;
      this.tail = null;
      this.length = 0;
    }
    push(v) {
      const entry = {
        data: v,
        next: null
      };
      if (this.length > 0)
        this.tail.next = entry;
      else
        this.head = entry;
      this.tail = entry;
      ++this.length;
    }
    unshift(v) {
      const entry = {
        data: v,
        next: this.head
      };
      if (this.length === 0)
        this.tail = entry;
      this.head = entry;
      ++this.length;
    }
    shift() {
      if (this.length === 0)
        return;
      const ret = this.head.data;
      if (this.length === 1)
        this.head = this.tail = null;
      else
        this.head = this.head.next;
      --this.length;
      return ret;
    }
    clear() {
      this.head = this.tail = null;
      this.length = 0;
    }
    join(s) {
      if (this.length === 0)
        return "";
      let p = this.head;
      let ret = "" + p.data;
      while ((p = p.next) !== null)
        ret += s + p.data;
      return ret;
    }
    concat(n) {
      if (this.length === 0)
        return Buffer2.alloc(0);
      const ret = Buffer2.allocUnsafe(n >>> 0);
      let p = this.head;
      let i = 0;
      while (p) {
        TypedArrayPrototypeSet(ret, p.data, i);
        i += p.data.length;
        p = p.next;
      }
      return ret;
    }
    consume(n, hasStrings) {
      const data = this.head.data;
      if (n < data.length) {
        const slice = data.slice(0, n);
        this.head.data = data.slice(n);
        return slice;
      }
      if (n === data.length) {
        return this.shift();
      }
      return hasStrings ? this._getString(n) : this._getBuffer(n);
    }
    first() {
      return this.head.data;
    }
    *[SymbolIterator]() {
      for (let p = this.head;p; p = p.next) {
        yield p.data;
      }
    }
    _getString(n) {
      let ret = "";
      let p = this.head;
      let c = 0;
      do {
        const str = p.data;
        if (n > str.length) {
          ret += str;
          n -= str.length;
        } else {
          if (n === str.length) {
            ret += str;
            ++c;
            if (p.next)
              this.head = p.next;
            else
              this.head = this.tail = null;
          } else {
            ret += StringPrototypeSlice(str, 0, n);
            this.head = p;
            p.data = StringPrototypeSlice(str, n);
          }
          break;
        }
        ++c;
      } while ((p = p.next) !== null);
      this.length -= c;
      return ret;
    }
    _getBuffer(n) {
      const ret = Buffer2.allocUnsafe(n);
      const retLen = n;
      let p = this.head;
      let c = 0;
      do {
        const buf = p.data;
        if (n > buf.length) {
          TypedArrayPrototypeSet(ret, buf, retLen - n);
          n -= buf.length;
        } else {
          if (n === buf.length) {
            TypedArrayPrototypeSet(ret, buf, retLen - n);
            ++c;
            if (p.next)
              this.head = p.next;
            else
              this.head = this.tail = null;
          } else {
            TypedArrayPrototypeSet(ret, new Uint8Array2(buf.buffer, buf.byteOffset, n), retLen - n);
            this.head = p;
            p.data = buf.slice(n);
          }
          break;
        }
        ++c;
      } while ((p = p.next) !== null);
      this.length -= c;
      return ret;
    }
    [Symbol.for("nodejs.util.inspect.custom")](_, options) {
      return inspect(this, {
        ...options,
        depth: 0,
        customInspect: false
      });
    }
  };
});

// node_modules/readable-stream/lib/internal/streams/readable.js
var require_readable = __commonJS((exports, module) => {
  var ReadableState = function(options, stream, isDuplex) {
    if (typeof isDuplex !== "boolean")
      isDuplex = stream instanceof require_duplex();
    this.objectMode = !!(options && options.objectMode);
    if (isDuplex)
      this.objectMode = this.objectMode || !!(options && options.readableObjectMode);
    this.highWaterMark = options ? getHighWaterMark(this, options, "readableHighWaterMark", isDuplex) : getDefaultHighWaterMark(false);
    this.buffer = new BufferList;
    this.length = 0;
    this.pipes = [];
    this.flowing = null;
    this.ended = false;
    this.endEmitted = false;
    this.reading = false;
    this.constructed = true;
    this.sync = true;
    this.needReadable = false;
    this.emittedReadable = false;
    this.readableListening = false;
    this.resumeScheduled = false;
    this[kPaused] = null;
    this.errorEmitted = false;
    this.emitClose = !options || options.emitClose !== false;
    this.autoDestroy = !options || options.autoDestroy !== false;
    this.destroyed = false;
    this.errored = null;
    this.closed = false;
    this.closeEmitted = false;
    this.defaultEncoding = options && options.defaultEncoding || "utf8";
    this.awaitDrainWriters = null;
    this.multiAwaitDrain = false;
    this.readingMore = false;
    this.dataEmitted = false;
    this.decoder = null;
    this.encoding = null;
    if (options && options.encoding) {
      this.decoder = new StringDecoder(options.encoding);
      this.encoding = options.encoding;
    }
  };
  var Readable = function(options) {
    if (!(this instanceof Readable))
      return new Readable(options);
    const isDuplex = this instanceof require_duplex();
    this._readableState = new ReadableState(options, this, isDuplex);
    if (options) {
      if (typeof options.read === "function")
        this._read = options.read;
      if (typeof options.destroy === "function")
        this._destroy = options.destroy;
      if (typeof options.construct === "function")
        this._construct = options.construct;
      if (options.signal && !isDuplex)
        addAbortSignal(options.signal, this);
    }
    Stream.call(this, options);
    destroyImpl.construct(this, () => {
      if (this._readableState.needReadable) {
        maybeReadMore(this, this._readableState);
      }
    });
  };
  var readableAddChunk = function(stream, chunk, encoding, addToFront) {
    debug("readableAddChunk", chunk);
    const state = stream._readableState;
    let err;
    if (!state.objectMode) {
      if (typeof chunk === "string") {
        encoding = encoding || state.defaultEncoding;
        if (state.encoding !== encoding) {
          if (addToFront && state.encoding) {
            chunk = Buffer2.from(chunk, encoding).toString(state.encoding);
          } else {
            chunk = Buffer2.from(chunk, encoding);
            encoding = "";
          }
        }
      } else if (chunk instanceof Buffer2) {
        encoding = "";
      } else if (Stream._isUint8Array(chunk)) {
        chunk = Stream._uint8ArrayToBuffer(chunk);
        encoding = "";
      } else if (chunk != null) {
        err = new ERR_INVALID_ARG_TYPE("chunk", ["string", "Buffer", "Uint8Array"], chunk);
      }
    }
    if (err) {
      errorOrDestroy(stream, err);
    } else if (chunk === null) {
      state.reading = false;
      onEofChunk(stream, state);
    } else if (state.objectMode || chunk && chunk.length > 0) {
      if (addToFront) {
        if (state.endEmitted)
          errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT);
        else if (state.destroyed || state.errored)
          return false;
        else
          addChunk(stream, state, chunk, true);
      } else if (state.ended) {
        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF);
      } else if (state.destroyed || state.errored) {
        return false;
      } else {
        state.reading = false;
        if (state.decoder && !encoding) {
          chunk = state.decoder.write(chunk);
          if (state.objectMode || chunk.length !== 0)
            addChunk(stream, state, chunk, false);
          else
            maybeReadMore(stream, state);
        } else {
          addChunk(stream, state, chunk, false);
        }
      }
    } else if (!addToFront) {
      state.reading = false;
      maybeReadMore(stream, state);
    }
    return !state.ended && (state.length < state.highWaterMark || state.length === 0);
  };
  var addChunk = function(stream, state, chunk, addToFront) {
    if (state.flowing && state.length === 0 && !state.sync && stream.listenerCount("data") > 0) {
      if (state.multiAwaitDrain) {
        state.awaitDrainWriters.clear();
      } else {
        state.awaitDrainWriters = null;
      }
      state.dataEmitted = true;
      stream.emit("data", chunk);
    } else {
      state.length += state.objectMode ? 1 : chunk.length;
      if (addToFront)
        state.buffer.unshift(chunk);
      else
        state.buffer.push(chunk);
      if (state.needReadable)
        emitReadable(stream);
    }
    maybeReadMore(stream, state);
  };
  var computeNewHighWaterMark = function(n) {
    if (n > MAX_HWM) {
      throw new ERR_OUT_OF_RANGE("size", "<= 1GiB", n);
    } else {
      n--;
      n |= n >>> 1;
      n |= n >>> 2;
      n |= n >>> 4;
      n |= n >>> 8;
      n |= n >>> 16;
      n++;
    }
    return n;
  };
  var howMuchToRead = function(n, state) {
    if (n <= 0 || state.length === 0 && state.ended)
      return 0;
    if (state.objectMode)
      return 1;
    if (NumberIsNaN(n)) {
      if (state.flowing && state.length)
        return state.buffer.first().length;
      return state.length;
    }
    if (n <= state.length)
      return n;
    return state.ended ? state.length : 0;
  };
  var onEofChunk = function(stream, state) {
    debug("onEofChunk");
    if (state.ended)
      return;
    if (state.decoder) {
      const chunk = state.decoder.end();
      if (chunk && chunk.length) {
        state.buffer.push(chunk);
        state.length += state.objectMode ? 1 : chunk.length;
      }
    }
    state.ended = true;
    if (state.sync) {
      emitReadable(stream);
    } else {
      state.needReadable = false;
      state.emittedReadable = true;
      emitReadable_(stream);
    }
  };
  var emitReadable = function(stream) {
    const state = stream._readableState;
    debug("emitReadable", state.needReadable, state.emittedReadable);
    state.needReadable = false;
    if (!state.emittedReadable) {
      debug("emitReadable", state.flowing);
      state.emittedReadable = true;
      process2.nextTick(emitReadable_, stream);
    }
  };
  var emitReadable_ = function(stream) {
    const state = stream._readableState;
    debug("emitReadable_", state.destroyed, state.length, state.ended);
    if (!state.destroyed && !state.errored && (state.length || state.ended)) {
      stream.emit("readable");
      state.emittedReadable = false;
    }
    state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;
    flow(stream);
  };
  var maybeReadMore = function(stream, state) {
    if (!state.readingMore && state.constructed) {
      state.readingMore = true;
      process2.nextTick(maybeReadMore_, stream, state);
    }
  };
  var maybeReadMore_ = function(stream, state) {
    while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {
      const len = state.length;
      debug("maybeReadMore read 0");
      stream.read(0);
      if (len === state.length)
        break;
    }
    state.readingMore = false;
  };
  var pipeOnDrain = function(src, dest) {
    return function pipeOnDrainFunctionResult() {
      const state = src._readableState;
      if (state.awaitDrainWriters === dest) {
        debug("pipeOnDrain", 1);
        state.awaitDrainWriters = null;
      } else if (state.multiAwaitDrain) {
        debug("pipeOnDrain", state.awaitDrainWriters.size);
        state.awaitDrainWriters.delete(dest);
      }
      if ((!state.awaitDrainWriters || state.awaitDrainWriters.size === 0) && src.listenerCount("data")) {
        src.resume();
      }
    };
  };
  var updateReadableListening = function(self2) {
    const state = self2._readableState;
    state.readableListening = self2.listenerCount("readable") > 0;
    if (state.resumeScheduled && state[kPaused] === false) {
      state.flowing = true;
    } else if (self2.listenerCount("data") > 0) {
      self2.resume();
    } else if (!state.readableListening) {
      state.flowing = null;
    }
  };
  var nReadingNextTick = function(self2) {
    debug("readable nexttick read 0");
    self2.read(0);
  };
  var resume = function(stream, state) {
    if (!state.resumeScheduled) {
      state.resumeScheduled = true;
      process2.nextTick(resume_, stream, state);
    }
  };
  var resume_ = function(stream, state) {
    debug("resume", state.reading);
    if (!state.reading) {
      stream.read(0);
    }
    state.resumeScheduled = false;
    stream.emit("resume");
    flow(stream);
    if (state.flowing && !state.reading)
      stream.read(0);
  };
  var flow = function(stream) {
    const state = stream._readableState;
    debug("flow", state.flowing);
    while (state.flowing && stream.read() !== null)
      ;
  };
  var streamToAsyncIterator = function(stream, options) {
    if (typeof stream.read !== "function") {
      stream = Readable.wrap(stream, {
        objectMode: true
      });
    }
    const iter = createAsyncIterator(stream, options);
    iter.stream = stream;
    return iter;
  };
  async function* createAsyncIterator(stream, options) {
    let callback = nop;
    function next(resolve) {
      if (this === stream) {
        callback();
        callback = nop;
      } else {
        callback = resolve;
      }
    }
    stream.on("readable", next);
    let error;
    const cleanup = eos(stream, {
      writable: false
    }, (err) => {
      error = err ? aggregateTwoErrors(error, err) : null;
      callback();
      callback = nop;
    });
    try {
      while (true) {
        const chunk = stream.destroyed ? null : stream.read();
        if (chunk !== null) {
          yield chunk;
        } else if (error) {
          throw error;
        } else if (error === null) {
          return;
        } else {
          await new Promise2(next);
        }
      }
    } catch (err) {
      error = aggregateTwoErrors(error, err);
      throw error;
    } finally {
      if ((error || (options === null || options === undefined ? undefined : options.destroyOnReturn) !== false) && (error === undefined || stream._readableState.autoDestroy)) {
        destroyImpl.destroyer(stream, null);
      } else {
        stream.off("readable", next);
        cleanup();
      }
    }
  }
  var fromList = function(n, state) {
    if (state.length === 0)
      return null;
    let ret;
    if (state.objectMode)
      ret = state.buffer.shift();
    else if (!n || n >= state.length) {
      if (state.decoder)
        ret = state.buffer.join("");
      else if (state.buffer.length === 1)
        ret = state.buffer.first();
      else
        ret = state.buffer.concat(state.length);
      state.buffer.clear();
    } else {
      ret = state.buffer.consume(n, state.decoder);
    }
    return ret;
  };
  var endReadable = function(stream) {
    const state = stream._readableState;
    debug("endReadable", state.endEmitted);
    if (!state.endEmitted) {
      state.ended = true;
      process2.nextTick(endReadableNT, state, stream);
    }
  };
  var endReadableNT = function(state, stream) {
    debug("endReadableNT", state.endEmitted, state.length);
    if (!state.errored && !state.closeEmitted && !state.endEmitted && state.length === 0) {
      state.endEmitted = true;
      stream.emit("end");
      if (stream.writable && stream.allowHalfOpen === false) {
        process2.nextTick(endWritableNT, stream);
      } else if (state.autoDestroy) {
        const wState = stream._writableState;
        const autoDestroy = !wState || wState.autoDestroy && (wState.finished || wState.writable === false);
        if (autoDestroy) {
          stream.destroy();
        }
      }
    }
  };
  var endWritableNT = function(stream) {
    const writable = stream.writable && !stream.writableEnded && !stream.destroyed;
    if (writable) {
      stream.end();
    }
  };
  var lazyWebStreams = function() {
    if (webStreamsAdapters === undefined)
      webStreamsAdapters = {};
    return webStreamsAdapters;
  };
  var process2 = __require("process/");
  var {
    ArrayPrototypeIndexOf,
    NumberIsInteger,
    NumberIsNaN,
    NumberParseInt,
    ObjectDefineProperties,
    ObjectKeys,
    ObjectSetPrototypeOf,
    Promise: Promise2,
    SafeSet,
    SymbolAsyncIterator,
    Symbol: Symbol2
  } = require_primordials();
  module.exports = Readable;
  Readable.ReadableState = ReadableState;
  var { EventEmitter: EE } = __require("events");
  var { Stream, prependListener } = require_legacy();
  var { Buffer: Buffer2 } = __require("buffer");
  var { addAbortSignal } = require_add_abort_signal();
  var eos = require_end_of_stream();
  var debug = require_util().debuglog("stream", (fn) => {
    debug = fn;
  });
  var BufferList = require_buffer_list();
  var destroyImpl = require_destroy();
  var { getHighWaterMark, getDefaultHighWaterMark } = require_state();
  var {
    aggregateTwoErrors,
    codes: {
      ERR_INVALID_ARG_TYPE,
      ERR_METHOD_NOT_IMPLEMENTED,
      ERR_OUT_OF_RANGE,
      ERR_STREAM_PUSH_AFTER_EOF,
      ERR_STREAM_UNSHIFT_AFTER_END_EVENT
    }
  } = require_errors();
  var { validateObject } = require_validators();
  var kPaused = Symbol2("kPaused");
  var { StringDecoder } = __require("string_decoder");
  var from = require_from();
  ObjectSetPrototypeOf(Readable.prototype, Stream.prototype);
  ObjectSetPrototypeOf(Readable, Stream);
  var nop = () => {
  };
  var { errorOrDestroy } = destroyImpl;
  Readable.prototype.destroy = destroyImpl.destroy;
  Readable.prototype._undestroy = destroyImpl.undestroy;
  Readable.prototype._destroy = function(err, cb) {
    cb(err);
  };
  Readable.prototype[EE.captureRejectionSymbol] = function(err) {
    this.destroy(err);
  };
  Readable.prototype.push = function(chunk, encoding) {
    return readableAddChunk(this, chunk, encoding, false);
  };
  Readable.prototype.unshift = function(chunk, encoding) {
    return readableAddChunk(this, chunk, encoding, true);
  };
  Readable.prototype.isPaused = function() {
    const state = this._readableState;
    return state[kPaused] === true || state.flowing === false;
  };
  Readable.prototype.setEncoding = function(enc) {
    const decoder = new StringDecoder(enc);
    this._readableState.decoder = decoder;
    this._readableState.encoding = this._readableState.decoder.encoding;
    const buffer = this._readableState.buffer;
    let content = "";
    for (const data of buffer) {
      content += decoder.write(data);
    }
    buffer.clear();
    if (content !== "")
      buffer.push(content);
    this._readableState.length = content.length;
    return this;
  };
  var MAX_HWM = 1073741824;
  Readable.prototype.read = function(n) {
    debug("read", n);
    if (n === undefined) {
      n = NaN;
    } else if (!NumberIsInteger(n)) {
      n = NumberParseInt(n, 10);
    }
    const state = this._readableState;
    const nOrig = n;
    if (n > state.highWaterMark)
      state.highWaterMark = computeNewHighWaterMark(n);
    if (n !== 0)
      state.emittedReadable = false;
    if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {
      debug("read: emitReadable", state.length, state.ended);
      if (state.length === 0 && state.ended)
        endReadable(this);
      else
        emitReadable(this);
      return null;
    }
    n = howMuchToRead(n, state);
    if (n === 0 && state.ended) {
      if (state.length === 0)
        endReadable(this);
      return null;
    }
    let doRead = state.needReadable;
    debug("need readable", doRead);
    if (state.length === 0 || state.length - n < state.highWaterMark) {
      doRead = true;
      debug("length less than watermark", doRead);
    }
    if (state.ended || state.reading || state.destroyed || state.errored || !state.constructed) {
      doRead = false;
      debug("reading, ended or constructing", doRead);
    } else if (doRead) {
      debug("do read");
      state.reading = true;
      state.sync = true;
      if (state.length === 0)
        state.needReadable = true;
      try {
        this._read(state.highWaterMark);
      } catch (err) {
        errorOrDestroy(this, err);
      }
      state.sync = false;
      if (!state.reading)
        n = howMuchToRead(nOrig, state);
    }
    let ret;
    if (n > 0)
      ret = fromList(n, state);
    else
      ret = null;
    if (ret === null) {
      state.needReadable = state.length <= state.highWaterMark;
      n = 0;
    } else {
      state.length -= n;
      if (state.multiAwaitDrain) {
        state.awaitDrainWriters.clear();
      } else {
        state.awaitDrainWriters = null;
      }
    }
    if (state.length === 0) {
      if (!state.ended)
        state.needReadable = true;
      if (nOrig !== n && state.ended)
        endReadable(this);
    }
    if (ret !== null && !state.errorEmitted && !state.closeEmitted) {
      state.dataEmitted = true;
      this.emit("data", ret);
    }
    return ret;
  };
  Readable.prototype._read = function(n) {
    throw new ERR_METHOD_NOT_IMPLEMENTED("_read()");
  };
  Readable.prototype.pipe = function(dest, pipeOpts) {
    const src = this;
    const state = this._readableState;
    if (state.pipes.length === 1) {
      if (!state.multiAwaitDrain) {
        state.multiAwaitDrain = true;
        state.awaitDrainWriters = new SafeSet(state.awaitDrainWriters ? [state.awaitDrainWriters] : []);
      }
    }
    state.pipes.push(dest);
    debug("pipe count=%d opts=%j", state.pipes.length, pipeOpts);
    const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process2.stdout && dest !== process2.stderr;
    const endFn = doEnd ? onend : unpipe;
    if (state.endEmitted)
      process2.nextTick(endFn);
    else
      src.once("end", endFn);
    dest.on("unpipe", onunpipe);
    function onunpipe(readable, unpipeInfo) {
      debug("onunpipe");
      if (readable === src) {
        if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
          unpipeInfo.hasUnpiped = true;
          cleanup();
        }
      }
    }
    function onend() {
      debug("onend");
      dest.end();
    }
    let ondrain;
    let cleanedUp = false;
    function cleanup() {
      debug("cleanup");
      dest.removeListener("close", onclose);
      dest.removeListener("finish", onfinish);
      if (ondrain) {
        dest.removeListener("drain", ondrain);
      }
      dest.removeListener("error", onerror);
      dest.removeListener("unpipe", onunpipe);
      src.removeListener("end", onend);
      src.removeListener("end", unpipe);
      src.removeListener("data", ondata);
      cleanedUp = true;
      if (ondrain && state.awaitDrainWriters && (!dest._writableState || dest._writableState.needDrain))
        ondrain();
    }
    function pause() {
      if (!cleanedUp) {
        if (state.pipes.length === 1 && state.pipes[0] === dest) {
          debug("false write response, pause", 0);
          state.awaitDrainWriters = dest;
          state.multiAwaitDrain = false;
        } else if (state.pipes.length > 1 && state.pipes.includes(dest)) {
          debug("false write response, pause", state.awaitDrainWriters.size);
          state.awaitDrainWriters.add(dest);
        }
        src.pause();
      }
      if (!ondrain) {
        ondrain = pipeOnDrain(src, dest);
        dest.on("drain", ondrain);
      }
    }
    src.on("data", ondata);
    function ondata(chunk) {
      debug("ondata");
      const ret = dest.write(chunk);
      debug("dest.write", ret);
      if (ret === false) {
        pause();
      }
    }
    function onerror(er) {
      debug("onerror", er);
      unpipe();
      dest.removeListener("error", onerror);
      if (dest.listenerCount("error") === 0) {
        const s = dest._writableState || dest._readableState;
        if (s && !s.errorEmitted) {
          errorOrDestroy(dest, er);
        } else {
          dest.emit("error", er);
        }
      }
    }
    prependListener(dest, "error", onerror);
    function onclose() {
      dest.removeListener("finish", onfinish);
      unpipe();
    }
    dest.once("close", onclose);
    function onfinish() {
      debug("onfinish");
      dest.removeListener("close", onclose);
      unpipe();
    }
    dest.once("finish", onfinish);
    function unpipe() {
      debug("unpipe");
      src.unpipe(dest);
    }
    dest.emit("pipe", src);
    if (dest.writableNeedDrain === true) {
      if (state.flowing) {
        pause();
      }
    } else if (!state.flowing) {
      debug("pipe resume");
      src.resume();
    }
    return dest;
  };
  Readable.prototype.unpipe = function(dest) {
    const state = this._readableState;
    const unpipeInfo = {
      hasUnpiped: false
    };
    if (state.pipes.length === 0)
      return this;
    if (!dest) {
      const dests = state.pipes;
      state.pipes = [];
      this.pause();
      for (let i = 0;i < dests.length; i++)
        dests[i].emit("unpipe", this, {
          hasUnpiped: false
        });
      return this;
    }
    const index = ArrayPrototypeIndexOf(state.pipes, dest);
    if (index === -1)
      return this;
    state.pipes.splice(index, 1);
    if (state.pipes.length === 0)
      this.pause();
    dest.emit("unpipe", this, unpipeInfo);
    return this;
  };
  Readable.prototype.on = function(ev, fn) {
    const res = Stream.prototype.on.call(this, ev, fn);
    const state = this._readableState;
    if (ev === "data") {
      state.readableListening = this.listenerCount("readable") > 0;
      if (state.flowing !== false)
        this.resume();
    } else if (ev === "readable") {
      if (!state.endEmitted && !state.readableListening) {
        state.readableListening = state.needReadable = true;
        state.flowing = false;
        state.emittedReadable = false;
        debug("on readable", state.length, state.reading);
        if (state.length) {
          emitReadable(this);
        } else if (!state.reading) {
          process2.nextTick(nReadingNextTick, this);
        }
      }
    }
    return res;
  };
  Readable.prototype.addListener = Readable.prototype.on;
  Readable.prototype.removeListener = function(ev, fn) {
    const res = Stream.prototype.removeListener.call(this, ev, fn);
    if (ev === "readable") {
      process2.nextTick(updateReadableListening, this);
    }
    return res;
  };
  Readable.prototype.off = Readable.prototype.removeListener;
  Readable.prototype.removeAllListeners = function(ev) {
    const res = Stream.prototype.removeAllListeners.apply(this, arguments);
    if (ev === "readable" || ev === undefined) {
      process2.nextTick(updateReadableListening, this);
    }
    return res;
  };
  Readable.prototype.resume = function() {
    const state = this._readableState;
    if (!state.flowing) {
      debug("resume");
      state.flowing = !state.readableListening;
      resume(this, state);
    }
    state[kPaused] = false;
    return this;
  };
  Readable.prototype.pause = function() {
    debug("call pause flowing=%j", this._readableState.flowing);
    if (this._readableState.flowing !== false) {
      debug("pause");
      this._readableState.flowing = false;
      this.emit("pause");
    }
    this._readableState[kPaused] = true;
    return this;
  };
  Readable.prototype.wrap = function(stream) {
    let paused = false;
    stream.on("data", (chunk) => {
      if (!this.push(chunk) && stream.pause) {
        paused = true;
        stream.pause();
      }
    });
    stream.on("end", () => {
      this.push(null);
    });
    stream.on("error", (err) => {
      errorOrDestroy(this, err);
    });
    stream.on("close", () => {
      this.destroy();
    });
    stream.on("destroy", () => {
      this.destroy();
    });
    this._read = () => {
      if (paused && stream.resume) {
        paused = false;
        stream.resume();
      }
    };
    const streamKeys = ObjectKeys(stream);
    for (let j = 1;j < streamKeys.length; j++) {
      const i = streamKeys[j];
      if (this[i] === undefined && typeof stream[i] === "function") {
        this[i] = stream[i].bind(stream);
      }
    }
    return this;
  };
  Readable.prototype[SymbolAsyncIterator] = function() {
    return streamToAsyncIterator(this);
  };
  Readable.prototype.iterator = function(options) {
    if (options !== undefined) {
      validateObject(options, "options");
    }
    return streamToAsyncIterator(this, options);
  };
  ObjectDefineProperties(Readable.prototype, {
    readable: {
      __proto__: null,
      get() {
        const r = this._readableState;
        return !!r && r.readable !== false && !r.destroyed && !r.errorEmitted && !r.endEmitted;
      },
      set(val) {
        if (this._readableState) {
          this._readableState.readable = !!val;
        }
      }
    },
    readableDidRead: {
      __proto__: null,
      enumerable: false,
      get: function() {
        return this._readableState.dataEmitted;
      }
    },
    readableAborted: {
      __proto__: null,
      enumerable: false,
      get: function() {
        return !!(this._readableState.readable !== false && (this._readableState.destroyed || this._readableState.errored) && !this._readableState.endEmitted);
      }
    },
    readableHighWaterMark: {
      __proto__: null,
      enumerable: false,
      get: function() {
        return this._readableState.highWaterMark;
      }
    },
    readableBuffer: {
      __proto__: null,
      enumerable: false,
      get: function() {
        return this._readableState && this._readableState.buffer;
      }
    },
    readableFlowing: {
      __proto__: null,
      enumerable: false,
      get: function() {
        return this._readableState.flowing;
      },
      set: function(state) {
        if (this._readableState) {
          this._readableState.flowing = state;
        }
      }
    },
    readableLength: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState.length;
      }
    },
    readableObjectMode: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.objectMode : false;
      }
    },
    readableEncoding: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.encoding : null;
      }
    },
    errored: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.errored : null;
      }
    },
    closed: {
      __proto__: null,
      get() {
        return this._readableState ? this._readableState.closed : false;
      }
    },
    destroyed: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.destroyed : false;
      },
      set(value) {
        if (!this._readableState) {
          return;
        }
        this._readableState.destroyed = value;
      }
    },
    readableEnded: {
      __proto__: null,
      enumerable: false,
      get() {
        return this._readableState ? this._readableState.endEmitted : false;
      }
    }
  });
  ObjectDefineProperties(ReadableState.prototype, {
    pipesCount: {
      __proto__: null,
      get() {
        return this.pipes.length;
      }
    },
    paused: {
      __proto__: null,
      get() {
        return this[kPaused] !== false;
      },
      set(value) {
        this[kPaused] = !!value;
      }
    }
  });
  Readable._fromList = fromList;
  Readable.from = function(iterable, opts) {
    return from(Readable, iterable, opts);
  };
  var webStreamsAdapters;
  Readable.fromWeb = function(readableStream, options) {
    return lazyWebStreams().newStreamReadableFromReadableStream(readableStream, options);
  };
  Readable.toWeb = function(streamReadable, options) {
    return lazyWebStreams().newReadableStreamFromStreamReadable(streamReadable, options);
  };
  Readable.wrap = function(src, options) {
    var _ref, _src$readableObjectMo;
    return new Readable({
      objectMode: (_ref = (_src$readableObjectMo = src.readableObjectMode) !== null && _src$readableObjectMo !== undefined ? _src$readableObjectMo : src.objectMode) !== null && _ref !== undefined ? _ref : true,
      ...options,
      destroy(err, callback) {
        destroyImpl.destroyer(src, err);
        callback(err);
      }
    }).wrap(src);
  };
});

// node_modules/readable-stream/lib/internal/streams/transform.js
var require_transform = __commonJS((exports, module) => {
  var Transform = function(options) {
    if (!(this instanceof Transform))
      return new Transform(options);
    const readableHighWaterMark = options ? getHighWaterMark(this, options, "readableHighWaterMark", true) : null;
    if (readableHighWaterMark === 0) {
      options = {
        ...options,
        highWaterMark: null,
        readableHighWaterMark,
        writableHighWaterMark: options.writableHighWaterMark || 0
      };
    }
    Duplex.call(this, options);
    this._readableState.sync = false;
    this[kCallback] = null;
    if (options) {
      if (typeof options.transform === "function")
        this._transform = options.transform;
      if (typeof options.flush === "function")
        this._flush = options.flush;
    }
    this.on("prefinish", prefinish);
  };
  var final = function(cb) {
    if (typeof this._flush === "function" && !this.destroyed) {
      this._flush((er, data) => {
        if (er) {
          if (cb) {
            cb(er);
          } else {
            this.destroy(er);
          }
          return;
        }
        if (data != null) {
          this.push(data);
        }
        this.push(null);
        if (cb) {
          cb();
        }
      });
    } else {
      this.push(null);
      if (cb) {
        cb();
      }
    }
  };
  var prefinish = function() {
    if (this._final !== final) {
      final.call(this);
    }
  };
  var { ObjectSetPrototypeOf, Symbol: Symbol2 } = require_primordials();
  module.exports = Transform;
  var { ERR_METHOD_NOT_IMPLEMENTED } = require_errors().codes;
  var Duplex = require_duplex();
  var { getHighWaterMark } = require_state();
  ObjectSetPrototypeOf(Transform.prototype, Duplex.prototype);
  ObjectSetPrototypeOf(Transform, Duplex);
  var kCallback = Symbol2("kCallback");
  Transform.prototype._final = final;
  Transform.prototype._transform = function(chunk, encoding, callback) {
    throw new ERR_METHOD_NOT_IMPLEMENTED("_transform()");
  };
  Transform.prototype._write = function(chunk, encoding, callback) {
    const rState = this._readableState;
    const wState = this._writableState;
    const length = rState.length;
    this._transform(chunk, encoding, (err, val) => {
      if (err) {
        callback(err);
        return;
      }
      if (val != null) {
        this.push(val);
      }
      if (wState.ended || length === rState.length || rState.length < rState.highWaterMark) {
        callback();
      } else {
        this[kCallback] = callback;
      }
    });
  };
  Transform.prototype._read = function() {
    if (this[kCallback]) {
      const callback = this[kCallback];
      this[kCallback] = null;
      callback();
    }
  };
});

// node_modules/readable-stream/lib/internal/streams/passthrough.js
var require_passthrough = __commonJS((exports, module) => {
  var PassThrough = function(options) {
    if (!(this instanceof PassThrough))
      return new PassThrough(options);
    Transform.call(this, options);
  };
  var { ObjectSetPrototypeOf } = require_primordials();
  module.exports = PassThrough;
  var Transform = require_transform();
  ObjectSetPrototypeOf(PassThrough.prototype, Transform.prototype);
  ObjectSetPrototypeOf(PassThrough, Transform);
  PassThrough.prototype._transform = function(chunk, encoding, cb) {
    cb(null, chunk);
  };
});

// node_modules/readable-stream/lib/internal/streams/pipeline.js
var require_pipeline = __commonJS((exports, module) => {
  var destroyer = function(stream, reading, writing) {
    let finished = false;
    stream.on("close", () => {
      finished = true;
    });
    const cleanup = eos(stream, {
      readable: reading,
      writable: writing
    }, (err) => {
      finished = !err;
    });
    return {
      destroy: (err) => {
        if (finished)
          return;
        finished = true;
        destroyImpl.destroyer(stream, err || new ERR_STREAM_DESTROYED("pipe"));
      },
      cleanup
    };
  };
  var popCallback = function(streams) {
    validateFunction(streams[streams.length - 1], "streams[stream.length - 1]");
    return streams.pop();
  };
  var makeAsyncIterable = function(val) {
    if (isIterable(val)) {
      return val;
    } else if (isReadableNodeStream(val)) {
      return fromReadable(val);
    }
    throw new ERR_INVALID_ARG_TYPE("val", ["Readable", "Iterable", "AsyncIterable"], val);
  };
  async function* fromReadable(val) {
    if (!Readable) {
      Readable = require_readable();
    }
    yield* Readable.prototype[SymbolAsyncIterator].call(val);
  }
  async function pumpToNode(iterable, writable, finish, { end }) {
    let error;
    let onresolve = null;
    const resume = (err) => {
      if (err) {
        error = err;
      }
      if (onresolve) {
        const callback = onresolve;
        onresolve = null;
        callback();
      }
    };
    const wait = () => new Promise2((resolve, reject) => {
      if (error) {
        reject(error);
      } else {
        onresolve = () => {
          if (error) {
            reject(error);
          } else {
            resolve();
          }
        };
      }
    });
    writable.on("drain", resume);
    const cleanup = eos(writable, {
      readable: false
    }, resume);
    try {
      if (writable.writableNeedDrain) {
        await wait();
      }
      for await (const chunk of iterable) {
        if (!writable.write(chunk)) {
          await wait();
        }
      }
      if (end) {
        writable.end();
      }
      await wait();
      finish();
    } catch (err) {
      finish(error !== err ? aggregateTwoErrors(error, err) : err);
    } finally {
      cleanup();
      writable.off("drain", resume);
    }
  }
  async function pumpToWeb(readable, writable, finish, { end }) {
    if (isTransformStream(writable)) {
      writable = writable.writable;
    }
    const writer = writable.getWriter();
    try {
      for await (const chunk of readable) {
        await writer.ready;
        writer.write(chunk).catch(() => {
        });
      }
      await writer.ready;
      if (end) {
        await writer.close();
      }
      finish();
    } catch (err) {
      try {
        await writer.abort(err);
        finish(err);
      } catch (err2) {
        finish(err2);
      }
    }
  }
  var pipeline = function(...streams) {
    return pipelineImpl(streams, once(popCallback(streams)));
  };
  var pipelineImpl = function(streams, callback, opts) {
    if (streams.length === 1 && ArrayIsArray(streams[0])) {
      streams = streams[0];
    }
    if (streams.length < 2) {
      throw new ERR_MISSING_ARGS("streams");
    }
    const ac = new AbortController;
    const signal = ac.signal;
    const outerSignal = opts === null || opts === undefined ? undefined : opts.signal;
    const lastStreamCleanup = [];
    validateAbortSignal(outerSignal, "options.signal");
    function abort() {
      finishImpl(new AbortError);
    }
    outerSignal === null || outerSignal === undefined || outerSignal.addEventListener("abort", abort);
    let error;
    let value;
    const destroys = [];
    let finishCount = 0;
    function finish(err) {
      finishImpl(err, --finishCount === 0);
    }
    function finishImpl(err, final) {
      if (err && (!error || error.code === "ERR_STREAM_PREMATURE_CLOSE")) {
        error = err;
      }
      if (!error && !final) {
        return;
      }
      while (destroys.length) {
        destroys.shift()(error);
      }
      outerSignal === null || outerSignal === undefined || outerSignal.removeEventListener("abort", abort);
      ac.abort();
      if (final) {
        if (!error) {
          lastStreamCleanup.forEach((fn) => fn());
        }
        process2.nextTick(callback, error, value);
      }
    }
    let ret;
    for (let i = 0;i < streams.length; i++) {
      const stream = streams[i];
      const reading = i < streams.length - 1;
      const writing = i > 0;
      const end = reading || (opts === null || opts === undefined ? undefined : opts.end) !== false;
      const isLastStream = i === streams.length - 1;
      if (isNodeStream(stream)) {
        let onError2 = function(err) {
          if (err && err.name !== "AbortError" && err.code !== "ERR_STREAM_PREMATURE_CLOSE") {
            finish(err);
          }
        };
        var onError = onError2;
        if (end) {
          const { destroy, cleanup } = destroyer(stream, reading, writing);
          destroys.push(destroy);
          if (isReadable(stream) && isLastStream) {
            lastStreamCleanup.push(cleanup);
          }
        }
        stream.on("error", onError2);
        if (isReadable(stream) && isLastStream) {
          lastStreamCleanup.push(() => {
            stream.removeListener("error", onError2);
          });
        }
      }
      if (i === 0) {
        if (typeof stream === "function") {
          ret = stream({
            signal
          });
          if (!isIterable(ret)) {
            throw new ERR_INVALID_RETURN_VALUE("Iterable, AsyncIterable or Stream", "source", ret);
          }
        } else if (isIterable(stream) || isReadableNodeStream(stream) || isTransformStream(stream)) {
          ret = stream;
        } else {
          ret = Duplex.from(stream);
        }
      } else if (typeof stream === "function") {
        if (isTransformStream(ret)) {
          var _ret;
          ret = makeAsyncIterable((_ret = ret) === null || _ret === undefined ? undefined : _ret.readable);
        } else {
          ret = makeAsyncIterable(ret);
        }
        ret = stream(ret, {
          signal
        });
        if (reading) {
          if (!isIterable(ret, true)) {
            throw new ERR_INVALID_RETURN_VALUE("AsyncIterable", `transform[${i - 1}]`, ret);
          }
        } else {
          var _ret2;
          if (!PassThrough) {
            PassThrough = require_passthrough();
          }
          const pt = new PassThrough({
            objectMode: true
          });
          const then = (_ret2 = ret) === null || _ret2 === undefined ? undefined : _ret2.then;
          if (typeof then === "function") {
            finishCount++;
            then.call(ret, (val) => {
              value = val;
              if (val != null) {
                pt.write(val);
              }
              if (end) {
                pt.end();
              }
              process2.nextTick(finish);
            }, (err) => {
              pt.destroy(err);
              process2.nextTick(finish, err);
            });
          } else if (isIterable(ret, true)) {
            finishCount++;
            pumpToNode(ret, pt, finish, {
              end
            });
          } else if (isReadableStream(ret) || isTransformStream(ret)) {
            const toRead = ret.readable || ret;
            finishCount++;
            pumpToNode(toRead, pt, finish, {
              end
            });
          } else {
            throw new ERR_INVALID_RETURN_VALUE("AsyncIterable or Promise", "destination", ret);
          }
          ret = pt;
          const { destroy, cleanup } = destroyer(ret, false, true);
          destroys.push(destroy);
          if (isLastStream) {
            lastStreamCleanup.push(cleanup);
          }
        }
      } else if (isNodeStream(stream)) {
        if (isReadableNodeStream(ret)) {
          finishCount += 2;
          const cleanup = pipe(ret, stream, finish, {
            end
          });
          if (isReadable(stream) && isLastStream) {
            lastStreamCleanup.push(cleanup);
          }
        } else if (isTransformStream(ret) || isReadableStream(ret)) {
          const toRead = ret.readable || ret;
          finishCount++;
          pumpToNode(toRead, stream, finish, {
            end
          });
        } else if (isIterable(ret)) {
          finishCount++;
          pumpToNode(ret, stream, finish, {
            end
          });
        } else {
          throw new ERR_INVALID_ARG_TYPE("val", ["Readable", "Iterable", "AsyncIterable", "ReadableStream", "TransformStream"], ret);
        }
        ret = stream;
      } else if (isWebStream(stream)) {
        if (isReadableNodeStream(ret)) {
          finishCount++;
          pumpToWeb(makeAsyncIterable(ret), stream, finish, {
            end
          });
        } else if (isReadableStream(ret) || isIterable(ret)) {
          finishCount++;
          pumpToWeb(ret, stream, finish, {
            end
          });
        } else if (isTransformStream(ret)) {
          finishCount++;
          pumpToWeb(ret.readable, stream, finish, {
            end
          });
        } else {
          throw new ERR_INVALID_ARG_TYPE("val", ["Readable", "Iterable", "AsyncIterable", "ReadableStream", "TransformStream"], ret);
        }
        ret = stream;
      } else {
        ret = Duplex.from(stream);
      }
    }
    if (signal !== null && signal !== undefined && signal.aborted || outerSignal !== null && outerSignal !== undefined && outerSignal.aborted) {
      process2.nextTick(abort);
    }
    return ret;
  };
  var pipe = function(src, dst, finish, { end }) {
    let ended = false;
    dst.on("close", () => {
      if (!ended) {
        finish(new ERR_STREAM_PREMATURE_CLOSE);
      }
    });
    src.pipe(dst, {
      end: false
    });
    if (end) {
      let endFn2 = function() {
        ended = true;
        dst.end();
      };
      var endFn = endFn2;
      if (isReadableEnded(src)) {
        process2.nextTick(endFn2);
      } else {
        src.once("end", endFn2);
      }
    } else {
      finish();
    }
    eos(src, {
      readable: true,
      writable: false
    }, (err) => {
      const rState = src._readableState;
      if (err && err.code === "ERR_STREAM_PREMATURE_CLOSE" && rState && rState.ended && !rState.errored && !rState.errorEmitted) {
        src.once("end", finish).once("error", finish);
      } else {
        finish(err);
      }
    });
    return eos(dst, {
      readable: false,
      writable: true
    }, finish);
  };
  var process2 = __require("process/");
  var { ArrayIsArray, Promise: Promise2, SymbolAsyncIterator } = require_primordials();
  var eos = require_end_of_stream();
  var { once } = require_util();
  var destroyImpl = require_destroy();
  var Duplex = require_duplex();
  var {
    aggregateTwoErrors,
    codes: {
      ERR_INVALID_ARG_TYPE,
      ERR_INVALID_RETURN_VALUE,
      ERR_MISSING_ARGS,
      ERR_STREAM_DESTROYED,
      ERR_STREAM_PREMATURE_CLOSE
    },
    AbortError
  } = require_errors();
  var { validateFunction, validateAbortSignal } = require_validators();
  var {
    isIterable,
    isReadable,
    isReadableNodeStream,
    isNodeStream,
    isTransformStream,
    isWebStream,
    isReadableStream,
    isReadableEnded
  } = require_utils();
  var AbortController = globalThis.AbortController || require_abort_controller().AbortController;
  var PassThrough;
  var Readable;
  module.exports = {
    pipelineImpl,
    pipeline
  };
});

// node_modules/readable-stream/lib/internal/streams/compose.js
var require_compose = __commonJS((exports, module) => {
  var { pipeline } = require_pipeline();
  var Duplex = require_duplex();
  var { destroyer } = require_destroy();
  var {
    isNodeStream,
    isReadable,
    isWritable,
    isWebStream,
    isTransformStream,
    isWritableStream,
    isReadableStream
  } = require_utils();
  var {
    AbortError,
    codes: { ERR_INVALID_ARG_VALUE, ERR_MISSING_ARGS }
  } = require_errors();
  var eos = require_end_of_stream();
  module.exports = function compose(...streams) {
    if (streams.length === 0) {
      throw new ERR_MISSING_ARGS("streams");
    }
    if (streams.length === 1) {
      return Duplex.from(streams[0]);
    }
    const orgStreams = [...streams];
    if (typeof streams[0] === "function") {
      streams[0] = Duplex.from(streams[0]);
    }
    if (typeof streams[streams.length - 1] === "function") {
      const idx = streams.length - 1;
      streams[idx] = Duplex.from(streams[idx]);
    }
    for (let n = 0;n < streams.length; ++n) {
      if (!isNodeStream(streams[n]) && !isWebStream(streams[n])) {
        continue;
      }
      if (n < streams.length - 1 && !(isReadable(streams[n]) || isReadableStream(streams[n]) || isTransformStream(streams[n]))) {
        throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], "must be readable");
      }
      if (n > 0 && !(isWritable(streams[n]) || isWritableStream(streams[n]) || isTransformStream(streams[n]))) {
        throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], "must be writable");
      }
    }
    let ondrain;
    let onfinish;
    let onreadable;
    let onclose;
    let d;
    function onfinished(err) {
      const cb = onclose;
      onclose = null;
      if (cb) {
        cb(err);
      } else if (err) {
        d.destroy(err);
      } else if (!readable && !writable) {
        d.destroy();
      }
    }
    const head = streams[0];
    const tail = pipeline(streams, onfinished);
    const writable = !!(isWritable(head) || isWritableStream(head) || isTransformStream(head));
    const readable = !!(isReadable(tail) || isReadableStream(tail) || isTransformStream(tail));
    d = new Duplex({
      writableObjectMode: !!(head !== null && head !== undefined && head.writableObjectMode),
      readableObjectMode: !!(tail !== null && tail !== undefined && tail.writableObjectMode),
      writable,
      readable
    });
    if (writable) {
      if (isNodeStream(head)) {
        d._write = function(chunk, encoding, callback) {
          if (head.write(chunk, encoding)) {
            callback();
          } else {
            ondrain = callback;
          }
        };
        d._final = function(callback) {
          head.end();
          onfinish = callback;
        };
        head.on("drain", function() {
          if (ondrain) {
            const cb = ondrain;
            ondrain = null;
            cb();
          }
        });
      } else if (isWebStream(head)) {
        const writable2 = isTransformStream(head) ? head.writable : head;
        const writer = writable2.getWriter();
        d._write = async function(chunk, encoding, callback) {
          try {
            await writer.ready;
            writer.write(chunk).catch(() => {
            });
            callback();
          } catch (err) {
            callback(err);
          }
        };
        d._final = async function(callback) {
          try {
            await writer.ready;
            writer.close().catch(() => {
            });
            onfinish = callback;
          } catch (err) {
            callback(err);
          }
        };
      }
      const toRead = isTransformStream(tail) ? tail.readable : tail;
      eos(toRead, () => {
        if (onfinish) {
          const cb = onfinish;
          onfinish = null;
          cb();
        }
      });
    }
    if (readable) {
      if (isNodeStream(tail)) {
        tail.on("readable", function() {
          if (onreadable) {
            const cb = onreadable;
            onreadable = null;
            cb();
          }
        });
        tail.on("end", function() {
          d.push(null);
        });
        d._read = function() {
          while (true) {
            const buf = tail.read();
            if (buf === null) {
              onreadable = d._read;
              return;
            }
            if (!d.push(buf)) {
              return;
            }
          }
        };
      } else if (isWebStream(tail)) {
        const readable2 = isTransformStream(tail) ? tail.readable : tail;
        const reader = readable2.getReader();
        d._read = async function() {
          while (true) {
            try {
              const { value, done } = await reader.read();
              if (!d.push(value)) {
                return;
              }
              if (done) {
                d.push(null);
                return;
              }
            } catch {
              return;
            }
          }
        };
      }
    }
    d._destroy = function(err, callback) {
      if (!err && onclose !== null) {
        err = new AbortError;
      }
      onreadable = null;
      ondrain = null;
      onfinish = null;
      if (onclose === null) {
        callback(err);
      } else {
        onclose = callback;
        if (isNodeStream(tail)) {
          destroyer(tail, err);
        }
      }
    };
    return d;
  };
});

// node_modules/readable-stream/lib/internal/streams/operators.js
var require_operators = __commonJS((exports, module) => {
  var compose = function(stream, options) {
    if (options != null) {
      validateObject(options, "options");
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, "options.signal");
    }
    if (isNodeStream(stream) && !isWritable(stream)) {
      throw new ERR_INVALID_ARG_VALUE("stream", stream, "must be writable");
    }
    const composedStream = staticCompose(this, stream);
    if (options !== null && options !== undefined && options.signal) {
      addAbortSignalNoValidate(options.signal, composedStream);
    }
    return composedStream;
  };
  var map = function(fn, options) {
    if (typeof fn !== "function") {
      throw new ERR_INVALID_ARG_TYPE("fn", ["Function", "AsyncFunction"], fn);
    }
    if (options != null) {
      validateObject(options, "options");
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, "options.signal");
    }
    let concurrency = 1;
    if ((options === null || options === undefined ? undefined : options.concurrency) != null) {
      concurrency = MathFloor(options.concurrency);
    }
    validateInteger(concurrency, "concurrency", 1);
    return async function* map() {
      var _options$signal, _options$signal2;
      const ac = new AbortController;
      const stream = this;
      const queue = [];
      const signal = ac.signal;
      const signalOpt = {
        signal
      };
      const abort = () => ac.abort();
      if (options !== null && options !== undefined && (_options$signal = options.signal) !== null && _options$signal !== undefined && _options$signal.aborted) {
        abort();
      }
      options === null || options === undefined || (_options$signal2 = options.signal) === null || _options$signal2 === undefined || _options$signal2.addEventListener("abort", abort);
      let next;
      let resume;
      let done = false;
      function onDone() {
        done = true;
      }
      async function pump() {
        try {
          for await (let val of stream) {
            var _val;
            if (done) {
              return;
            }
            if (signal.aborted) {
              throw new AbortError;
            }
            try {
              val = fn(val, signalOpt);
            } catch (err) {
              val = PromiseReject(err);
            }
            if (val === kEmpty) {
              continue;
            }
            if (typeof ((_val = val) === null || _val === undefined ? undefined : _val.catch) === "function") {
              val.catch(onDone);
            }
            queue.push(val);
            if (next) {
              next();
              next = null;
            }
            if (!done && queue.length && queue.length >= concurrency) {
              await new Promise2((resolve) => {
                resume = resolve;
              });
            }
          }
          queue.push(kEof);
        } catch (err) {
          const val = PromiseReject(err);
          PromisePrototypeThen(val, undefined, onDone);
          queue.push(val);
        } finally {
          var _options$signal3;
          done = true;
          if (next) {
            next();
            next = null;
          }
          options === null || options === undefined || (_options$signal3 = options.signal) === null || _options$signal3 === undefined || _options$signal3.removeEventListener("abort", abort);
        }
      }
      pump();
      try {
        while (true) {
          while (queue.length > 0) {
            const val = await queue[0];
            if (val === kEof) {
              return;
            }
            if (signal.aborted) {
              throw new AbortError;
            }
            if (val !== kEmpty) {
              yield val;
            }
            queue.shift();
            if (resume) {
              resume();
              resume = null;
            }
          }
          await new Promise2((resolve) => {
            next = resolve;
          });
        }
      } finally {
        ac.abort();
        done = true;
        if (resume) {
          resume();
          resume = null;
        }
      }
    }.call(this);
  };
  var asIndexedPairs = function(options = undefined) {
    if (options != null) {
      validateObject(options, "options");
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, "options.signal");
    }
    return async function* asIndexedPairs() {
      let index = 0;
      for await (const val of this) {
        var _options$signal4;
        if (options !== null && options !== undefined && (_options$signal4 = options.signal) !== null && _options$signal4 !== undefined && _options$signal4.aborted) {
          throw new AbortError({
            cause: options.signal.reason
          });
        }
        yield [index++, val];
      }
    }.call(this);
  };
  async function some(fn, options = undefined) {
    for await (const unused of filter.call(this, fn, options)) {
      return true;
    }
    return false;
  }
  async function every(fn, options = undefined) {
    if (typeof fn !== "function") {
      throw new ERR_INVALID_ARG_TYPE("fn", ["Function", "AsyncFunction"], fn);
    }
    return !await some.call(this, async (...args) => {
      return !await fn(...args);
    }, options);
  }
  async function find(fn, options) {
    for await (const result of filter.call(this, fn, options)) {
      return result;
    }
    return;
  }
  async function forEach(fn, options) {
    if (typeof fn !== "function") {
      throw new ERR_INVALID_ARG_TYPE("fn", ["Function", "AsyncFunction"], fn);
    }
    async function forEachFn(value, options2) {
      await fn(value, options2);
      return kEmpty;
    }
    for await (const unused of map.call(this, forEachFn, options))
      ;
  }
  var filter = function(fn, options) {
    if (typeof fn !== "function") {
      throw new ERR_INVALID_ARG_TYPE("fn", ["Function", "AsyncFunction"], fn);
    }
    async function filterFn(value, options2) {
      if (await fn(value, options2)) {
        return value;
      }
      return kEmpty;
    }
    return map.call(this, filterFn, options);
  };
  async function reduce(reducer, initialValue, options) {
    var _options$signal5;
    if (typeof reducer !== "function") {
      throw new ERR_INVALID_ARG_TYPE("reducer", ["Function", "AsyncFunction"], reducer);
    }
    if (options != null) {
      validateObject(options, "options");
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, "options.signal");
    }
    let hasInitialValue = arguments.length > 1;
    if (options !== null && options !== undefined && (_options$signal5 = options.signal) !== null && _options$signal5 !== undefined && _options$signal5.aborted) {
      const err = new AbortError(undefined, {
        cause: options.signal.reason
      });
      this.once("error", () => {
      });
      await finished(this.destroy(err));
      throw err;
    }
    const ac = new AbortController;
    const signal = ac.signal;
    if (options !== null && options !== undefined && options.signal) {
      const opts = {
        once: true,
        [kWeakHandler]: this
      };
      options.signal.addEventListener("abort", () => ac.abort(), opts);
    }
    let gotAnyItemFromStream = false;
    try {
      for await (const value of this) {
        var _options$signal6;
        gotAnyItemFromStream = true;
        if (options !== null && options !== undefined && (_options$signal6 = options.signal) !== null && _options$signal6 !== undefined && _options$signal6.aborted) {
          throw new AbortError;
        }
        if (!hasInitialValue) {
          initialValue = value;
          hasInitialValue = true;
        } else {
          initialValue = await reducer(initialValue, value, {
            signal
          });
        }
      }
      if (!gotAnyItemFromStream && !hasInitialValue) {
        throw new ReduceAwareErrMissingArgs;
      }
    } finally {
      ac.abort();
    }
    return initialValue;
  }
  async function toArray(options) {
    if (options != null) {
      validateObject(options, "options");
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, "options.signal");
    }
    const result = [];
    for await (const val of this) {
      var _options$signal7;
      if (options !== null && options !== undefined && (_options$signal7 = options.signal) !== null && _options$signal7 !== undefined && _options$signal7.aborted) {
        throw new AbortError(undefined, {
          cause: options.signal.reason
        });
      }
      ArrayPrototypePush(result, val);
    }
    return result;
  }
  var flatMap = function(fn, options) {
    const values = map.call(this, fn, options);
    return async function* flatMap() {
      for await (const val of values) {
        yield* val;
      }
    }.call(this);
  };
  var toIntegerOrInfinity = function(number) {
    number = Number2(number);
    if (NumberIsNaN(number)) {
      return 0;
    }
    if (number < 0) {
      throw new ERR_OUT_OF_RANGE("number", ">= 0", number);
    }
    return number;
  };
  var drop = function(number, options = undefined) {
    if (options != null) {
      validateObject(options, "options");
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, "options.signal");
    }
    number = toIntegerOrInfinity(number);
    return async function* drop() {
      var _options$signal8;
      if (options !== null && options !== undefined && (_options$signal8 = options.signal) !== null && _options$signal8 !== undefined && _options$signal8.aborted) {
        throw new AbortError;
      }
      for await (const val of this) {
        var _options$signal9;
        if (options !== null && options !== undefined && (_options$signal9 = options.signal) !== null && _options$signal9 !== undefined && _options$signal9.aborted) {
          throw new AbortError;
        }
        if (number-- <= 0) {
          yield val;
        }
      }
    }.call(this);
  };
  var take = function(number, options = undefined) {
    if (options != null) {
      validateObject(options, "options");
    }
    if ((options === null || options === undefined ? undefined : options.signal) != null) {
      validateAbortSignal(options.signal, "options.signal");
    }
    number = toIntegerOrInfinity(number);
    return async function* take() {
      var _options$signal10;
      if (options !== null && options !== undefined && (_options$signal10 = options.signal) !== null && _options$signal10 !== undefined && _options$signal10.aborted) {
        throw new AbortError;
      }
      for await (const val of this) {
        var _options$signal11;
        if (options !== null && options !== undefined && (_options$signal11 = options.signal) !== null && _options$signal11 !== undefined && _options$signal11.aborted) {
          throw new AbortError;
        }
        if (number-- > 0) {
          yield val;
        } else {
          return;
        }
      }
    }.call(this);
  };
  var AbortController = globalThis.AbortController || require_abort_controller().AbortController;
  var {
    codes: { ERR_INVALID_ARG_VALUE, ERR_INVALID_ARG_TYPE, ERR_MISSING_ARGS, ERR_OUT_OF_RANGE },
    AbortError
  } = require_errors();
  var { validateAbortSignal, validateInteger, validateObject } = require_validators();
  var kWeakHandler = require_primordials().Symbol("kWeak");
  var { finished } = require_end_of_stream();
  var staticCompose = require_compose();
  var { addAbortSignalNoValidate } = require_add_abort_signal();
  var { isWritable, isNodeStream } = require_utils();
  var {
    ArrayPrototypePush,
    MathFloor,
    Number: Number2,
    NumberIsNaN,
    Promise: Promise2,
    PromiseReject,
    PromisePrototypeThen,
    Symbol: Symbol2
  } = require_primordials();
  var kEmpty = Symbol2("kEmpty");
  var kEof = Symbol2("kEof");

  class ReduceAwareErrMissingArgs extends ERR_MISSING_ARGS {
    constructor() {
      super("reduce");
      this.message = "Reduce of an empty stream requires an initial value";
    }
  }
  exports.streamReturningOperators = {
    asIndexedPairs,
    drop,
    filter,
    flatMap,
    map,
    take,
    compose
  };
  exports.promiseReturningOperators = {
    every,
    forEach,
    reduce,
    toArray,
    some,
    find
  };
});

// node_modules/readable-stream/lib/stream/promises.js
var require_promises = __commonJS((exports, module) => {
  var pipeline = function(...streams) {
    return new Promise2((resolve, reject) => {
      let signal;
      let end;
      const lastArg = streams[streams.length - 1];
      if (lastArg && typeof lastArg === "object" && !isNodeStream(lastArg) && !isIterable(lastArg) && !isWebStream(lastArg)) {
        const options = ArrayPrototypePop(streams);
        signal = options.signal;
        end = options.end;
      }
      pl(streams, (err, value) => {
        if (err) {
          reject(err);
        } else {
          resolve(value);
        }
      }, {
        signal,
        end
      });
    });
  };
  var { ArrayPrototypePop, Promise: Promise2 } = require_primordials();
  var { isIterable, isNodeStream, isWebStream } = require_utils();
  var { pipelineImpl: pl } = require_pipeline();
  var { finished } = require_end_of_stream();
  require_stream();
  module.exports = {
    finished,
    pipeline
  };
});

// node_modules/readable-stream/lib/stream.js
var require_stream = __commonJS((exports, module) => {
  var { Buffer: Buffer2 } = __require("buffer");
  var { ObjectDefineProperty, ObjectKeys, ReflectApply } = require_primordials();
  var {
    promisify: { custom: customPromisify }
  } = require_util();
  var { streamReturningOperators, promiseReturningOperators } = require_operators();
  var {
    codes: { ERR_ILLEGAL_CONSTRUCTOR }
  } = require_errors();
  var compose = require_compose();
  var { pipeline } = require_pipeline();
  var { destroyer } = require_destroy();
  var eos = require_end_of_stream();
  var promises = require_promises();
  var utils = require_utils();
  var Stream = module.exports = require_legacy().Stream;
  Stream.isDisturbed = utils.isDisturbed;
  Stream.isErrored = utils.isErrored;
  Stream.isReadable = utils.isReadable;
  Stream.Readable = require_readable();
  for (const key of ObjectKeys(streamReturningOperators)) {
    let fn2 = function(...args) {
      if (new.target) {
        throw ERR_ILLEGAL_CONSTRUCTOR();
      }
      return Stream.Readable.from(ReflectApply(op, this, args));
    };
    fn = fn2;
    const op = streamReturningOperators[key];
    ObjectDefineProperty(fn2, "name", {
      __proto__: null,
      value: op.name
    });
    ObjectDefineProperty(fn2, "length", {
      __proto__: null,
      value: op.length
    });
    ObjectDefineProperty(Stream.Readable.prototype, key, {
      __proto__: null,
      value: fn2,
      enumerable: false,
      configurable: true,
      writable: true
    });
  }
  var fn;
  for (const key of ObjectKeys(promiseReturningOperators)) {
    let fn2 = function(...args) {
      if (new.target) {
        throw ERR_ILLEGAL_CONSTRUCTOR();
      }
      return ReflectApply(op, this, args);
    };
    fn = fn2;
    const op = promiseReturningOperators[key];
    ObjectDefineProperty(fn2, "name", {
      __proto__: null,
      value: op.name
    });
    ObjectDefineProperty(fn2, "length", {
      __proto__: null,
      value: op.length
    });
    ObjectDefineProperty(Stream.Readable.prototype, key, {
      __proto__: null,
      value: fn2,
      enumerable: false,
      configurable: true,
      writable: true
    });
  }
  var fn;
  Stream.Writable = require_writable();
  Stream.Duplex = require_duplex();
  Stream.Transform = require_transform();
  Stream.PassThrough = require_passthrough();
  Stream.pipeline = pipeline;
  var { addAbortSignal } = require_add_abort_signal();
  Stream.addAbortSignal = addAbortSignal;
  Stream.finished = eos;
  Stream.destroy = destroyer;
  Stream.compose = compose;
  ObjectDefineProperty(Stream, "promises", {
    __proto__: null,
    configurable: true,
    enumerable: true,
    get() {
      return promises;
    }
  });
  ObjectDefineProperty(pipeline, customPromisify, {
    __proto__: null,
    enumerable: true,
    get() {
      return promises.pipeline;
    }
  });
  ObjectDefineProperty(eos, customPromisify, {
    __proto__: null,
    enumerable: true,
    get() {
      return promises.finished;
    }
  });
  Stream.Stream = Stream;
  Stream._isUint8Array = function isUint8Array(value) {
    return value instanceof Uint8Array;
  };
  Stream._uint8ArrayToBuffer = function _uint8ArrayToBuffer(chunk) {
    return Buffer2.from(chunk.buffer, chunk.byteOffset, chunk.byteLength);
  };
});

// node_modules/readable-stream/lib/ours/index.js
var require_ours = __commonJS((exports, module) => {
  var Stream = __require("stream");
  if (Stream && process.env.READABLE_STREAM === "disable") {
    const promises = Stream.promises;
    exports._uint8ArrayToBuffer = Stream._uint8ArrayToBuffer;
    exports._isUint8Array = Stream._isUint8Array;
    exports.isDisturbed = Stream.isDisturbed;
    exports.isErrored = Stream.isErrored;
    exports.isReadable = Stream.isReadable;
    exports.Readable = Stream.Readable;
    exports.Writable = Stream.Writable;
    exports.Duplex = Stream.Duplex;
    exports.Transform = Stream.Transform;
    exports.PassThrough = Stream.PassThrough;
    exports.addAbortSignal = Stream.addAbortSignal;
    exports.finished = Stream.finished;
    exports.destroy = Stream.destroy;
    exports.pipeline = Stream.pipeline;
    exports.compose = Stream.compose;
    Object.defineProperty(Stream, "promises", {
      configurable: true,
      enumerable: true,
      get() {
        return promises;
      }
    });
    exports.Stream = Stream.Stream;
  } else {
    const CustomStream = require_stream();
    const promises = require_promises();
    const originalDestroy = CustomStream.Readable.destroy;
    module.exports = CustomStream.Readable;
    module.exports._uint8ArrayToBuffer = CustomStream._uint8ArrayToBuffer;
    module.exports._isUint8Array = CustomStream._isUint8Array;
    module.exports.isDisturbed = CustomStream.isDisturbed;
    module.exports.isErrored = CustomStream.isErrored;
    module.exports.isReadable = CustomStream.isReadable;
    module.exports.Readable = CustomStream.Readable;
    module.exports.Writable = CustomStream.Writable;
    module.exports.Duplex = CustomStream.Duplex;
    module.exports.Transform = CustomStream.Transform;
    module.exports.PassThrough = CustomStream.PassThrough;
    module.exports.addAbortSignal = CustomStream.addAbortSignal;
    module.exports.finished = CustomStream.finished;
    module.exports.destroy = CustomStream.destroy;
    module.exports.destroy = originalDestroy;
    module.exports.pipeline = CustomStream.pipeline;
    module.exports.compose = CustomStream.compose;
    Object.defineProperty(CustomStream, "promises", {
      configurable: true,
      enumerable: true,
      get() {
        return promises;
      }
    });
    module.exports.Stream = CustomStream.Stream;
  }
  module.exports.default = module.exports;
});

// node_modules/n3/lib/N3Store.js
var require_N3Store = __commonJS((exports) => {
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  var _getRequireWildcardCache = function(nodeInterop) {
    if (typeof WeakMap !== "function")
      return null;
    var cacheBabelInterop = new WeakMap;
    var cacheNodeInterop = new WeakMap;
    return (_getRequireWildcardCache = function(nodeInterop2) {
      return nodeInterop2 ? cacheNodeInterop : cacheBabelInterop;
    })(nodeInterop);
  };
  var _interopRequireWildcard = function(obj, nodeInterop) {
    if (!nodeInterop && obj && obj.__esModule) {
      return obj;
    }
    if (obj === null || typeof obj !== "object" && typeof obj !== "function") {
      return { default: obj };
    }
    var cache = _getRequireWildcardCache(nodeInterop);
    if (cache && cache.has(obj)) {
      return cache.get(obj);
    }
    var newObj = {};
    var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor;
    for (var key in obj) {
      if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) {
        var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null;
        if (desc && (desc.get || desc.set)) {
          Object.defineProperty(newObj, key, desc);
        } else {
          newObj[key] = obj[key];
        }
      }
    }
    newObj.default = obj;
    if (cache) {
      cache.set(obj, newObj);
    }
    return newObj;
  };
  var isString = function(s) {
    return typeof s === "string" || s instanceof String;
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = undefined;
  var _N3DataFactory = _interopRequireWildcard(require_N3DataFactory());
  var _readableStream = require_ours();
  var _IRIs = _interopRequireDefault(require_IRIs());

  class N3Store {
    constructor(quads, options) {
      this._size = 0;
      this._graphs = Object.create(null);
      this._id = 0;
      this._ids = Object.create(null);
      this._ids["><"] = 0;
      this._entities = Object.create(null);
      this._blankNodeIndex = 0;
      if (!options && quads && !quads[0])
        options = quads, quads = null;
      options = options || {};
      this._factory = options.factory || _N3DataFactory.default;
      if (quads)
        this.addQuads(quads);
    }
    get size() {
      let size = this._size;
      if (size !== null)
        return size;
      size = 0;
      const graphs = this._graphs;
      let subjects, subject;
      for (const graphKey in graphs)
        for (const subjectKey in subjects = graphs[graphKey].subjects)
          for (const predicateKey in subject = subjects[subjectKey])
            size += Object.keys(subject[predicateKey]).length;
      return this._size = size;
    }
    _addToIndex(index0, key0, key1, key2) {
      const index1 = index0[key0] || (index0[key0] = {});
      const index2 = index1[key1] || (index1[key1] = {});
      const existed = key2 in index2;
      if (!existed)
        index2[key2] = null;
      return !existed;
    }
    _removeFromIndex(index0, key0, key1, key2) {
      const index1 = index0[key0], index2 = index1[key1];
      delete index2[key2];
      for (const key in index2)
        return;
      delete index1[key1];
      for (const key in index1)
        return;
      delete index0[key0];
    }
    *_findInIndex(index0, key0, key1, key2, name0, name1, name2, graphId) {
      let tmp, index1, index2;
      const entityKeys = this._entities;
      const graph = (0, _N3DataFactory.termFromId)(graphId, this._factory);
      const parts = {
        subject: null,
        predicate: null,
        object: null
      };
      if (key0)
        (tmp = index0, index0 = {})[key0] = tmp[key0];
      for (const value0 in index0) {
        if (index1 = index0[value0]) {
          parts[name0] = (0, _N3DataFactory.termFromId)(entityKeys[value0], this._factory);
          if (key1)
            (tmp = index1, index1 = {})[key1] = tmp[key1];
          for (const value1 in index1) {
            if (index2 = index1[value1]) {
              parts[name1] = (0, _N3DataFactory.termFromId)(entityKeys[value1], this._factory);
              const values = key2 ? key2 in index2 ? [key2] : [] : Object.keys(index2);
              for (let l = 0;l < values.length; l++) {
                parts[name2] = (0, _N3DataFactory.termFromId)(entityKeys[values[l]], this._factory);
                yield this._factory.quad(parts.subject, parts.predicate, parts.object, graph);
              }
            }
          }
        }
      }
    }
    _loop(index0, callback) {
      for (const key0 in index0)
        callback(key0);
    }
    _loopByKey0(index0, key0, callback) {
      let index1, key1;
      if (index1 = index0[key0]) {
        for (key1 in index1)
          callback(key1);
      }
    }
    _loopByKey1(index0, key1, callback) {
      let key0, index1;
      for (key0 in index0) {
        index1 = index0[key0];
        if (index1[key1])
          callback(key0);
      }
    }
    _loopBy2Keys(index0, key0, key1, callback) {
      let index1, index2, key2;
      if ((index1 = index0[key0]) && (index2 = index1[key1])) {
        for (key2 in index2)
          callback(key2);
      }
    }
    _countInIndex(index0, key0, key1, key2) {
      let count = 0, tmp, index1, index2;
      if (key0)
        (tmp = index0, index0 = {})[key0] = tmp[key0];
      for (const value0 in index0) {
        if (index1 = index0[value0]) {
          if (key1)
            (tmp = index1, index1 = {})[key1] = tmp[key1];
          for (const value1 in index1) {
            if (index2 = index1[value1]) {
              if (key2)
                (key2 in index2) && count++;
              else
                count += Object.keys(index2).length;
            }
          }
        }
      }
      return count;
    }
    _getGraphs(graph) {
      if (!isString(graph))
        return this._graphs;
      const graphs = {};
      graphs[graph] = this._graphs[graph];
      return graphs;
    }
    _uniqueEntities(callback) {
      const uniqueIds = Object.create(null);
      return (id) => {
        if (!(id in uniqueIds)) {
          uniqueIds[id] = true;
          callback((0, _N3DataFactory.termFromId)(this._entities[id], this._factory));
        }
      };
    }
    add(quad) {
      this.addQuad(quad);
      return this;
    }
    addQuad(subject, predicate, object, graph) {
      if (!predicate)
        graph = subject.graph, object = subject.object, predicate = subject.predicate, subject = subject.subject;
      subject = (0, _N3DataFactory.termToId)(subject);
      predicate = (0, _N3DataFactory.termToId)(predicate);
      object = (0, _N3DataFactory.termToId)(object);
      graph = (0, _N3DataFactory.termToId)(graph);
      let graphItem = this._graphs[graph];
      if (!graphItem) {
        graphItem = this._graphs[graph] = {
          subjects: {},
          predicates: {},
          objects: {}
        };
        Object.freeze(graphItem);
      }
      const ids = this._ids;
      const entities = this._entities;
      subject = ids[subject] || (ids[entities[++this._id] = subject] = this._id);
      predicate = ids[predicate] || (ids[entities[++this._id] = predicate] = this._id);
      object = ids[object] || (ids[entities[++this._id] = object] = this._id);
      const changed = this._addToIndex(graphItem.subjects, subject, predicate, object);
      this._addToIndex(graphItem.predicates, predicate, object, subject);
      this._addToIndex(graphItem.objects, object, subject, predicate);
      this._size = null;
      return changed;
    }
    addQuads(quads) {
      for (let i = 0;i < quads.length; i++)
        this.addQuad(quads[i]);
    }
    delete(quad) {
      this.removeQuad(quad);
      return this;
    }
    has(subjectOrQuad, predicate, object, graph) {
      if (subjectOrQuad && subjectOrQuad.subject)
        ({
          subject: subjectOrQuad,
          predicate,
          object,
          graph
        } = subjectOrQuad);
      return !this.readQuads(subjectOrQuad, predicate, object, graph).next().done;
    }
    import(stream) {
      stream.on("data", (quad) => {
        this.addQuad(quad);
      });
      return stream;
    }
    removeQuad(subject, predicate, object, graph) {
      if (!predicate)
        graph = subject.graph, object = subject.object, predicate = subject.predicate, subject = subject.subject;
      subject = (0, _N3DataFactory.termToId)(subject);
      predicate = (0, _N3DataFactory.termToId)(predicate);
      object = (0, _N3DataFactory.termToId)(object);
      graph = (0, _N3DataFactory.termToId)(graph);
      const ids = this._ids, graphs = this._graphs;
      let graphItem, subjects, predicates;
      if (!(subject = ids[subject]) || !(predicate = ids[predicate]) || !(object = ids[object]) || !(graphItem = graphs[graph]) || !(subjects = graphItem.subjects[subject]) || !(predicates = subjects[predicate]) || !(object in predicates))
        return false;
      this._removeFromIndex(graphItem.subjects, subject, predicate, object);
      this._removeFromIndex(graphItem.predicates, predicate, object, subject);
      this._removeFromIndex(graphItem.objects, object, subject, predicate);
      if (this._size !== null)
        this._size--;
      for (subject in graphItem.subjects)
        return true;
      delete graphs[graph];
      return true;
    }
    removeQuads(quads) {
      for (let i = 0;i < quads.length; i++)
        this.removeQuad(quads[i]);
    }
    remove(stream) {
      stream.on("data", (quad) => {
        this.removeQuad(quad);
      });
      return stream;
    }
    removeMatches(subject, predicate, object, graph) {
      const stream = new _readableStream.Readable({
        objectMode: true
      });
      stream._read = () => {
        for (const quad of this.readQuads(subject, predicate, object, graph))
          stream.push(quad);
        stream.push(null);
      };
      return this.remove(stream);
    }
    deleteGraph(graph) {
      return this.removeMatches(null, null, null, graph);
    }
    getQuads(subject, predicate, object, graph) {
      return [...this.readQuads(subject, predicate, object, graph)];
    }
    *readQuads(subject, predicate, object, graph) {
      subject = subject && (0, _N3DataFactory.termToId)(subject);
      predicate = predicate && (0, _N3DataFactory.termToId)(predicate);
      object = object && (0, _N3DataFactory.termToId)(object);
      graph = graph && (0, _N3DataFactory.termToId)(graph);
      const graphs = this._getGraphs(graph), ids = this._ids;
      let content, subjectId, predicateId, objectId;
      if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object]))
        return;
      for (const graphId in graphs) {
        if (content = graphs[graphId]) {
          if (subjectId) {
            if (objectId)
              yield* this._findInIndex(content.objects, objectId, subjectId, predicateId, "object", "subject", "predicate", graphId);
            else
              yield* this._findInIndex(content.subjects, subjectId, predicateId, null, "subject", "predicate", "object", graphId);
          } else if (predicateId)
            yield* this._findInIndex(content.predicates, predicateId, objectId, null, "predicate", "object", "subject", graphId);
          else if (objectId)
            yield* this._findInIndex(content.objects, objectId, null, null, "object", "subject", "predicate", graphId);
          else
            yield* this._findInIndex(content.subjects, null, null, null, "subject", "predicate", "object", graphId);
        }
      }
    }
    match(subject, predicate, object, graph) {
      return new DatasetCoreAndReadableStream(this, subject, predicate, object, graph);
    }
    countQuads(subject, predicate, object, graph) {
      subject = subject && (0, _N3DataFactory.termToId)(subject);
      predicate = predicate && (0, _N3DataFactory.termToId)(predicate);
      object = object && (0, _N3DataFactory.termToId)(object);
      graph = graph && (0, _N3DataFactory.termToId)(graph);
      const graphs = this._getGraphs(graph), ids = this._ids;
      let count = 0, content, subjectId, predicateId, objectId;
      if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object]))
        return 0;
      for (const graphId in graphs) {
        if (content = graphs[graphId]) {
          if (subject) {
            if (object)
              count += this._countInIndex(content.objects, objectId, subjectId, predicateId);
            else
              count += this._countInIndex(content.subjects, subjectId, predicateId, objectId);
          } else if (predicate) {
            count += this._countInIndex(content.predicates, predicateId, objectId, subjectId);
          } else {
            count += this._countInIndex(content.objects, objectId, subjectId, predicateId);
          }
        }
      }
      return count;
    }
    forEach(callback, subject, predicate, object, graph) {
      this.some((quad) => {
        callback(quad);
        return false;
      }, subject, predicate, object, graph);
    }
    every(callback, subject, predicate, object, graph) {
      let some = false;
      const every = !this.some((quad) => {
        some = true;
        return !callback(quad);
      }, subject, predicate, object, graph);
      return some && every;
    }
    some(callback, subject, predicate, object, graph) {
      for (const quad of this.readQuads(subject, predicate, object, graph))
        if (callback(quad))
          return true;
      return false;
    }
    getSubjects(predicate, object, graph) {
      const results = [];
      this.forSubjects((s) => {
        results.push(s);
      }, predicate, object, graph);
      return results;
    }
    forSubjects(callback, predicate, object, graph) {
      predicate = predicate && (0, _N3DataFactory.termToId)(predicate);
      object = object && (0, _N3DataFactory.termToId)(object);
      graph = graph && (0, _N3DataFactory.termToId)(graph);
      const ids = this._ids, graphs = this._getGraphs(graph);
      let content, predicateId, objectId;
      callback = this._uniqueEntities(callback);
      if (isString(predicate) && !(predicateId = ids[predicate]) || isString(object) && !(objectId = ids[object]))
        return;
      for (graph in graphs) {
        if (content = graphs[graph]) {
          if (predicateId) {
            if (objectId)
              this._loopBy2Keys(content.predicates, predicateId, objectId, callback);
            else
              this._loopByKey1(content.subjects, predicateId, callback);
          } else if (objectId)
            this._loopByKey0(content.objects, objectId, callback);
          else
            this._loop(content.subjects, callback);
        }
      }
    }
    getPredicates(subject, object, graph) {
      const results = [];
      this.forPredicates((p) => {
        results.push(p);
      }, subject, object, graph);
      return results;
    }
    forPredicates(callback, subject, object, graph) {
      subject = subject && (0, _N3DataFactory.termToId)(subject);
      object = object && (0, _N3DataFactory.termToId)(object);
      graph = graph && (0, _N3DataFactory.termToId)(graph);
      const ids = this._ids, graphs = this._getGraphs(graph);
      let content, subjectId, objectId;
      callback = this._uniqueEntities(callback);
      if (isString(subject) && !(subjectId = ids[subject]) || isString(object) && !(objectId = ids[object]))
        return;
      for (graph in graphs) {
        if (content = graphs[graph]) {
          if (subjectId) {
            if (objectId)
              this._loopBy2Keys(content.objects, objectId, subjectId, callback);
            else
              this._loopByKey0(content.subjects, subjectId, callback);
          } else if (objectId)
            this._loopByKey1(content.predicates, objectId, callback);
          else
            this._loop(content.predicates, callback);
        }
      }
    }
    getObjects(subject, predicate, graph) {
      const results = [];
      this.forObjects((o) => {
        results.push(o);
      }, subject, predicate, graph);
      return results;
    }
    forObjects(callback, subject, predicate, graph) {
      subject = subject && (0, _N3DataFactory.termToId)(subject);
      predicate = predicate && (0, _N3DataFactory.termToId)(predicate);
      graph = graph && (0, _N3DataFactory.termToId)(graph);
      const ids = this._ids, graphs = this._getGraphs(graph);
      let content, subjectId, predicateId;
      callback = this._uniqueEntities(callback);
      if (isString(subject) && !(subjectId = ids[subject]) || isString(predicate) && !(predicateId = ids[predicate]))
        return;
      for (graph in graphs) {
        if (content = graphs[graph]) {
          if (subjectId) {
            if (predicateId)
              this._loopBy2Keys(content.subjects, subjectId, predicateId, callback);
            else
              this._loopByKey1(content.objects, subjectId, callback);
          } else if (predicateId)
            this._loopByKey0(content.predicates, predicateId, callback);
          else
            this._loop(content.objects, callback);
        }
      }
    }
    getGraphs(subject, predicate, object) {
      const results = [];
      this.forGraphs((g) => {
        results.push(g);
      }, subject, predicate, object);
      return results;
    }
    forGraphs(callback, subject, predicate, object) {
      for (const graph in this._graphs) {
        this.some((quad) => {
          callback(quad.graph);
          return true;
        }, subject, predicate, object, graph);
      }
    }
    createBlankNode(suggestedName) {
      let name, index;
      if (suggestedName) {
        name = suggestedName = `_:${suggestedName}`, index = 1;
        while (this._ids[name])
          name = suggestedName + index++;
      } else {
        do {
          name = `_:b${this._blankNodeIndex++}`;
        } while (this._ids[name]);
      }
      this._ids[name] = ++this._id;
      this._entities[this._id] = name;
      return this._factory.blankNode(name.substr(2));
    }
    extractLists({
      remove = false,
      ignoreErrors = false
    } = {}) {
      const lists = {};
      const onError = ignoreErrors ? () => true : (node, message) => {
        throw new Error(`${node.value} ${message}`);
      };
      const tails = this.getQuads(null, _IRIs.default.rdf.rest, _IRIs.default.rdf.nil, null);
      const toRemove = remove ? [...tails] : [];
      tails.forEach((tailQuad) => {
        const items = [];
        let malformed = false;
        let head;
        let headPos;
        const graph = tailQuad.graph;
        let current = tailQuad.subject;
        while (current && !malformed) {
          const objectQuads = this.getQuads(null, null, current, null);
          const subjectQuads = this.getQuads(current, null, null, null);
          let quad, first = null, rest = null, parent = null;
          for (let i = 0;i < subjectQuads.length && !malformed; i++) {
            quad = subjectQuads[i];
            if (!quad.graph.equals(graph))
              malformed = onError(current, "not confined to single graph");
            else if (head)
              malformed = onError(current, "has non-list arcs out");
            else if (quad.predicate.value === _IRIs.default.rdf.first) {
              if (first)
                malformed = onError(current, "has multiple rdf:first arcs");
              else
                toRemove.push(first = quad);
            } else if (quad.predicate.value === _IRIs.default.rdf.rest) {
              if (rest)
                malformed = onError(current, "has multiple rdf:rest arcs");
              else
                toRemove.push(rest = quad);
            } else if (objectQuads.length)
              malformed = onError(current, "can\'t be subject and object");
            else {
              head = quad;
              headPos = "subject";
            }
          }
          for (let i = 0;i < objectQuads.length && !malformed; ++i) {
            quad = objectQuads[i];
            if (head)
              malformed = onError(current, "can\'t have coreferences");
            else if (quad.predicate.value === _IRIs.default.rdf.rest) {
              if (parent)
                malformed = onError(current, "has incoming rdf:rest arcs");
              else
                parent = quad;
            } else {
              head = quad;
              headPos = "object";
            }
          }
          if (!first)
            malformed = onError(current, "has no list head");
          else
            items.unshift(first.object);
          current = parent && parent.subject;
        }
        if (malformed)
          remove = false;
        else if (head)
          lists[head[headPos].value] = items;
      });
      if (remove)
        this.removeQuads(toRemove);
      return lists;
    }
    *[Symbol.iterator]() {
      yield* this.readQuads();
    }
  }
  exports.default = N3Store;

  class DatasetCoreAndReadableStream extends _readableStream.Readable {
    constructor(n3Store, subject, predicate, object, graph) {
      super({
        objectMode: true
      });
      Object.assign(this, {
        n3Store,
        subject,
        predicate,
        object,
        graph
      });
    }
    get filtered() {
      if (!this._filtered) {
        const {
          n3Store,
          graph,
          object,
          predicate,
          subject
        } = this;
        const newStore = this._filtered = new N3Store({
          factory: n3Store._factory
        });
        for (const quad of n3Store.readQuads(subject, predicate, object, graph))
          newStore.addQuad(quad);
      }
      return this._filtered;
    }
    get size() {
      return this.filtered.size;
    }
    _read() {
      for (const quad of this)
        this.push(quad);
      this.push(null);
    }
    add(quad) {
      return this.filtered.add(quad);
    }
    delete(quad) {
      return this.filtered.delete(quad);
    }
    has(quad) {
      return this.filtered.has(quad);
    }
    match(subject, predicate, object, graph) {
      return new DatasetCoreAndReadableStream(this.filtered, subject, predicate, object, graph);
    }
    *[Symbol.iterator]() {
      yield* this._filtered || this.n3Store.readQuads(this.subject, this.predicate, this.object, this.graph);
    }
  }
});

// node_modules/n3/lib/N3StreamParser.js
var require_N3StreamParser = __commonJS((exports) => {
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = undefined;
  var _N3Parser = _interopRequireDefault(require_N3Parser());
  var _readableStream = require_ours();

  class N3StreamParser extends _readableStream.Transform {
    constructor(options) {
      super({
        decodeStrings: true
      });
      this._readableState.objectMode = true;
      const parser = new _N3Parser.default(options);
      let onData, onEnd;
      parser.parse({
        on: (event, callback) => {
          switch (event) {
            case "data":
              onData = callback;
              break;
            case "end":
              onEnd = callback;
              break;
          }
        }
      }, (error, quad) => {
        error && this.emit("error", error) || quad && this.push(quad);
      }, (prefix, uri) => {
        this.emit("prefix", prefix, uri);
      });
      this._transform = (chunk, encoding, done) => {
        onData(chunk);
        done();
      };
      this._flush = (done) => {
        onEnd();
        done();
      };
    }
    import(stream) {
      stream.on("data", (chunk) => {
        this.write(chunk);
      });
      stream.on("end", () => {
        this.end();
      });
      stream.on("error", (error) => {
        this.emit("error", error);
      });
      return this;
    }
  }
  exports.default = N3StreamParser;
});

// node_modules/n3/lib/N3StreamWriter.js
var require_N3StreamWriter = __commonJS((exports) => {
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  exports.default = undefined;
  var _readableStream = require_ours();
  var _N3Writer = _interopRequireDefault(require_N3Writer());

  class N3StreamWriter extends _readableStream.Transform {
    constructor(options) {
      super({
        encoding: "utf8",
        writableObjectMode: true
      });
      const writer = this._writer = new _N3Writer.default({
        write: (quad, encoding, callback) => {
          this.push(quad);
          callback && callback();
        },
        end: (callback) => {
          this.push(null);
          callback && callback();
        }
      }, options);
      this._transform = (quad, encoding, done) => {
        writer.addQuad(quad, done);
      };
      this._flush = (done) => {
        writer.end(done);
      };
    }
    import(stream) {
      stream.on("data", (quad) => {
        this.write(quad);
      });
      stream.on("end", () => {
        this.end();
      });
      stream.on("error", (error) => {
        this.emit("error", error);
      });
      stream.on("prefix", (prefix, iri) => {
        this._writer.addPrefix(prefix, iri);
      });
      return this;
    }
  }
  exports.default = N3StreamWriter;
});

// node_modules/n3/lib/index.js
var require_lib = __commonJS((exports) => {
  var _getRequireWildcardCache = function(nodeInterop) {
    if (typeof WeakMap !== "function")
      return null;
    var cacheBabelInterop = new WeakMap;
    var cacheNodeInterop = new WeakMap;
    return (_getRequireWildcardCache = function(nodeInterop2) {
      return nodeInterop2 ? cacheNodeInterop : cacheBabelInterop;
    })(nodeInterop);
  };
  var _interopRequireWildcard = function(obj, nodeInterop) {
    if (!nodeInterop && obj && obj.__esModule) {
      return obj;
    }
    if (obj === null || typeof obj !== "object" && typeof obj !== "function") {
      return { default: obj };
    }
    var cache = _getRequireWildcardCache(nodeInterop);
    if (cache && cache.has(obj)) {
      return cache.get(obj);
    }
    var newObj = {};
    var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor;
    for (var key in obj) {
      if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) {
        var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null;
        if (desc && (desc.get || desc.set)) {
          Object.defineProperty(newObj, key, desc);
        } else {
          newObj[key] = obj[key];
        }
      }
    }
    newObj.default = obj;
    if (cache) {
      cache.set(obj, newObj);
    }
    return newObj;
  };
  var _interopRequireDefault = function(obj) {
    return obj && obj.__esModule ? obj : { default: obj };
  };
  Object.defineProperty(exports, "__esModule", {
    value: true
  });
  Object.defineProperty(exports, "BlankNode", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.BlankNode;
    }
  });
  Object.defineProperty(exports, "DataFactory", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.default;
    }
  });
  Object.defineProperty(exports, "DefaultGraph", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.DefaultGraph;
    }
  });
  Object.defineProperty(exports, "Lexer", {
    enumerable: true,
    get: function() {
      return _N3Lexer.default;
    }
  });
  Object.defineProperty(exports, "Literal", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.Literal;
    }
  });
  Object.defineProperty(exports, "NamedNode", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.NamedNode;
    }
  });
  Object.defineProperty(exports, "Parser", {
    enumerable: true,
    get: function() {
      return _N3Parser.default;
    }
  });
  Object.defineProperty(exports, "Quad", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.Quad;
    }
  });
  Object.defineProperty(exports, "Store", {
    enumerable: true,
    get: function() {
      return _N3Store.default;
    }
  });
  Object.defineProperty(exports, "StreamParser", {
    enumerable: true,
    get: function() {
      return _N3StreamParser.default;
    }
  });
  Object.defineProperty(exports, "StreamWriter", {
    enumerable: true,
    get: function() {
      return _N3StreamWriter.default;
    }
  });
  Object.defineProperty(exports, "Term", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.Term;
    }
  });
  Object.defineProperty(exports, "Triple", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.Triple;
    }
  });
  exports.Util = undefined;
  Object.defineProperty(exports, "Variable", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.Variable;
    }
  });
  Object.defineProperty(exports, "Writer", {
    enumerable: true,
    get: function() {
      return _N3Writer.default;
    }
  });
  exports.default = undefined;
  Object.defineProperty(exports, "termFromId", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.termFromId;
    }
  });
  Object.defineProperty(exports, "termToId", {
    enumerable: true,
    get: function() {
      return _N3DataFactory.termToId;
    }
  });
  var _N3Lexer = _interopRequireDefault(require_N3Lexer());
  var _N3Parser = _interopRequireDefault(require_N3Parser());
  var _N3Writer = _interopRequireDefault(require_N3Writer());
  var _N3Store = _interopRequireDefault(require_N3Store());
  var _N3StreamParser = _interopRequireDefault(require_N3StreamParser());
  var _N3StreamWriter = _interopRequireDefault(require_N3StreamWriter());
  var Util = _interopRequireWildcard(require_N3Util());
  exports.Util = Util;
  var _N3DataFactory = _interopRequireWildcard(require_N3DataFactory());
  var _default = {
    Lexer: _N3Lexer.default,
    Parser: _N3Parser.default,
    Writer: _N3Writer.default,
    Store: _N3Store.default,
    StreamParser: _N3StreamParser.default,
    StreamWriter: _N3StreamWriter.default,
    Util,
    DataFactory: _N3DataFactory.default,
    Term: _N3DataFactory.Term,
    NamedNode: _N3DataFactory.NamedNode,
    Literal: _N3DataFactory.Literal,
    BlankNode: _N3DataFactory.BlankNode,
    Variable: _N3DataFactory.Variable,
    DefaultGraph: _N3DataFactory.DefaultGraph,
    Quad: _N3DataFactory.Quad,
    Triple: _N3DataFactory.Triple,
    termFromId: _N3DataFactory.termFromId,
    termToId: _N3DataFactory.termToId
  };
  exports.default = _default;
});

// node_modules/lodash.camelcase/index.js
var require_lodash = __commonJS((exports, module) => {
  var arrayReduce = function(array, iteratee, accumulator, initAccum) {
    var index = -1, length = array ? array.length : 0;
    if (initAccum && length) {
      accumulator = array[++index];
    }
    while (++index < length) {
      accumulator = iteratee(accumulator, array[index], index, array);
    }
    return accumulator;
  };
  var asciiToArray = function(string) {
    return string.split("");
  };
  var asciiWords = function(string) {
    return string.match(reAsciiWord) || [];
  };
  var basePropertyOf = function(object) {
    return function(key) {
      return object == null ? undefined : object[key];
    };
  };
  var hasUnicode = function(string) {
    return reHasUnicode.test(string);
  };
  var hasUnicodeWord = function(string) {
    return reHasUnicodeWord.test(string);
  };
  var stringToArray = function(string) {
    return hasUnicode(string) ? unicodeToArray(string) : asciiToArray(string);
  };
  var unicodeToArray = function(string) {
    return string.match(reUnicode) || [];
  };
  var unicodeWords = function(string) {
    return string.match(reUnicodeWord) || [];
  };
  var baseSlice = function(array, start, end) {
    var index = -1, length = array.length;
    if (start < 0) {
      start = -start > length ? 0 : length + start;
    }
    end = end > length ? length : end;
    if (end < 0) {
      end += length;
    }
    length = start > end ? 0 : end - start >>> 0;
    start >>>= 0;
    var result = Array(length);
    while (++index < length) {
      result[index] = array[index + start];
    }
    return result;
  };
  var baseToString = function(value) {
    if (typeof value == "string") {
      return value;
    }
    if (isSymbol(value)) {
      return symbolToString ? symbolToString.call(value) : "";
    }
    var result = value + "";
    return result == "0" && 1 / value == -INFINITY ? "-0" : result;
  };
  var castSlice = function(array, start, end) {
    var length = array.length;
    end = end === undefined ? length : end;
    return !start && end >= length ? array : baseSlice(array, start, end);
  };
  var createCaseFirst = function(methodName) {
    return function(string) {
      string = toString(string);
      var strSymbols = hasUnicode(string) ? stringToArray(string) : undefined;
      var chr = strSymbols ? strSymbols[0] : string.charAt(0);
      var trailing = strSymbols ? castSlice(strSymbols, 1).join("") : string.slice(1);
      return chr[methodName]() + trailing;
    };
  };
  var createCompounder = function(callback) {
    return function(string) {
      return arrayReduce(words(deburr(string).replace(reApos, "")), callback, "");
    };
  };
  var isObjectLike = function(value) {
    return !!value && typeof value == "object";
  };
  var isSymbol = function(value) {
    return typeof value == "symbol" || isObjectLike(value) && objectToString.call(value) == symbolTag;
  };
  var toString = function(value) {
    return value == null ? "" : baseToString(value);
  };
  var capitalize = function(string) {
    return upperFirst(toString(string).toLowerCase());
  };
  var deburr = function(string) {
    string = toString(string);
    return string && string.replace(reLatin, deburrLetter).replace(reComboMark, "");
  };
  var words = function(string, pattern, guard) {
    string = toString(string);
    pattern = guard ? undefined : pattern;
    if (pattern === undefined) {
      return hasUnicodeWord(string) ? unicodeWords(string) : asciiWords(string);
    }
    return string.match(pattern) || [];
  };
  var INFINITY = 1 / 0;
  var symbolTag = "[object Symbol]";
  var reAsciiWord = /[^\x00-\x2f\x3a-\x40\x5b-\x60\x7b-\x7f]+/g;
  var reLatin = /[\xc0-\xd6\xd8-\xf6\xf8-\xff\u0100-\u017f]/g;
  var rsAstralRange = "\\ud800-\\udfff";
  var rsComboMarksRange = "\\u0300-\\u036f\\ufe20-\\ufe23";
  var rsComboSymbolsRange = "\\u20d0-\\u20f0";
  var rsDingbatRange = "\\u2700-\\u27bf";
  var rsLowerRange = "a-z\\xdf-\\xf6\\xf8-\\xff";
  var rsMathOpRange = "\\xac\\xb1\\xd7\\xf7";
  var rsNonCharRange = "\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\xbf";
  var rsPunctuationRange = "\\u2000-\\u206f";
  var rsSpaceRange = " \\t\\x0b\\f\\xa0\\ufeff\\n\\r\\u2028\\u2029\\u1680\\u180e\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200a\\u202f\\u205f\\u3000";
  var rsUpperRange = "A-Z\\xc0-\\xd6\\xd8-\\xde";
  var rsVarRange = "\\ufe0e\\ufe0f";
  var rsBreakRange = rsMathOpRange + rsNonCharRange + rsPunctuationRange + rsSpaceRange;
  var rsApos = "['\u2019]";
  var rsAstral = "[" + rsAstralRange + "]";
  var rsBreak = "[" + rsBreakRange + "]";
  var rsCombo = "[" + rsComboMarksRange + rsComboSymbolsRange + "]";
  var rsDigits = "\\d+";
  var rsDingbat = "[" + rsDingbatRange + "]";
  var rsLower = "[" + rsLowerRange + "]";
  var rsMisc = "[^" + rsAstralRange + rsBreakRange + rsDigits + rsDingbatRange + rsLowerRange + rsUpperRange + "]";
  var rsFitz = "\\ud83c[\\udffb-\\udfff]";
  var rsModifier = "(?:" + rsCombo + "|" + rsFitz + ")";
  var rsNonAstral = "[^" + rsAstralRange + "]";
  var rsRegional = "(?:\\ud83c[\\udde6-\\uddff]){2}";
  var rsSurrPair = "[\\ud800-\\udbff][\\udc00-\\udfff]";
  var rsUpper = "[" + rsUpperRange + "]";
  var rsZWJ = "\\u200d";
  var rsLowerMisc = "(?:" + rsLower + "|" + rsMisc + ")";
  var rsUpperMisc = "(?:" + rsUpper + "|" + rsMisc + ")";
  var rsOptLowerContr = "(?:" + rsApos + "(?:d|ll|m|re|s|t|ve))?";
  var rsOptUpperContr = "(?:" + rsApos + "(?:D|LL|M|RE|S|T|VE))?";
  var reOptMod = rsModifier + "?";
  var rsOptVar = "[" + rsVarRange + "]?";
  var rsOptJoin = "(?:" + rsZWJ + "(?:" + [rsNonAstral, rsRegional, rsSurrPair].join("|") + ")" + rsOptVar + reOptMod + ")*";
  var rsSeq = rsOptVar + reOptMod + rsOptJoin;
  var rsEmoji = "(?:" + [rsDingbat, rsRegional, rsSurrPair].join("|") + ")" + rsSeq;
  var rsSymbol = "(?:" + [rsNonAstral + rsCombo + "?", rsCombo, rsRegional, rsSurrPair, rsAstral].join("|") + ")";
  var reApos = RegExp(rsApos, "g");
  var reComboMark = RegExp(rsCombo, "g");
  var reUnicode = RegExp(rsFitz + "(?=" + rsFitz + ")|" + rsSymbol + rsSeq, "g");
  var reUnicodeWord = RegExp([
    rsUpper + "?" + rsLower + "+" + rsOptLowerContr + "(?=" + [rsBreak, rsUpper, "$"].join("|") + ")",
    rsUpperMisc + "+" + rsOptUpperContr + "(?=" + [rsBreak, rsUpper + rsLowerMisc, "$"].join("|") + ")",
    rsUpper + "?" + rsLowerMisc + "+" + rsOptLowerContr,
    rsUpper + "+" + rsOptUpperContr,
    rsDigits,
    rsEmoji
  ].join("|"), "g");
  var reHasUnicode = RegExp("[" + rsZWJ + rsAstralRange + rsComboMarksRange + rsComboSymbolsRange + rsVarRange + "]");
  var reHasUnicodeWord = /[a-z][A-Z]|[A-Z]{2,}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/;
  var deburredLetters = {
    "\xC0": "A",
    "\xC1": "A",
    "\xC2": "A",
    "\xC3": "A",
    "\xC4": "A",
    "\xC5": "A",
    "\xE0": "a",
    "\xE1": "a",
    "\xE2": "a",
    "\xE3": "a",
    "\xE4": "a",
    "\xE5": "a",
    "\xC7": "C",
    "\xE7": "c",
    "\xD0": "D",
    "\xF0": "d",
    "\xC8": "E",
    "\xC9": "E",
    "\xCA": "E",
    "\xCB": "E",
    "\xE8": "e",
    "\xE9": "e",
    "\xEA": "e",
    "\xEB": "e",
    "\xCC": "I",
    "\xCD": "I",
    "\xCE": "I",
    "\xCF": "I",
    "\xEC": "i",
    "\xED": "i",
    "\xEE": "i",
    "\xEF": "i",
    "\xD1": "N",
    "\xF1": "n",
    "\xD2": "O",
    "\xD3": "O",
    "\xD4": "O",
    "\xD5": "O",
    "\xD6": "O",
    "\xD8": "O",
    "\xF2": "o",
    "\xF3": "o",
    "\xF4": "o",
    "\xF5": "o",
    "\xF6": "o",
    "\xF8": "o",
    "\xD9": "U",
    "\xDA": "U",
    "\xDB": "U",
    "\xDC": "U",
    "\xF9": "u",
    "\xFA": "u",
    "\xFB": "u",
    "\xFC": "u",
    "\xDD": "Y",
    "\xFD": "y",
    "\xFF": "y",
    "\xC6": "Ae",
    "\xE6": "ae",
    "\xDE": "Th",
    "\xFE": "th",
    "\xDF": "ss",
    "\u0100": "A",
    "\u0102": "A",
    "\u0104": "A",
    "\u0101": "a",
    "\u0103": "a",
    "\u0105": "a",
    "\u0106": "C",
    "\u0108": "C",
    "\u010A": "C",
    "\u010C": "C",
    "\u0107": "c",
    "\u0109": "c",
    "\u010B": "c",
    "\u010D": "c",
    "\u010E": "D",
    "\u0110": "D",
    "\u010F": "d",
    "\u0111": "d",
    "\u0112": "E",
    "\u0114": "E",
    "\u0116": "E",
    "\u0118": "E",
    "\u011A": "E",
    "\u0113": "e",
    "\u0115": "e",
    "\u0117": "e",
    "\u0119": "e",
    "\u011B": "e",
    "\u011C": "G",
    "\u011E": "G",
    "\u0120": "G",
    "\u0122": "G",
    "\u011D": "g",
    "\u011F": "g",
    "\u0121": "g",
    "\u0123": "g",
    "\u0124": "H",
    "\u0126": "H",
    "\u0125": "h",
    "\u0127": "h",
    "\u0128": "I",
    "\u012A": "I",
    "\u012C": "I",
    "\u012E": "I",
    "\u0130": "I",
    "\u0129": "i",
    "\u012B": "i",
    "\u012D": "i",
    "\u012F": "i",
    "\u0131": "i",
    "\u0134": "J",
    "\u0135": "j",
    "\u0136": "K",
    "\u0137": "k",
    "\u0138": "k",
    "\u0139": "L",
    "\u013B": "L",
    "\u013D": "L",
    "\u013F": "L",
    "\u0141": "L",
    "\u013A": "l",
    "\u013C": "l",
    "\u013E": "l",
    "\u0140": "l",
    "\u0142": "l",
    "\u0143": "N",
    "\u0145": "N",
    "\u0147": "N",
    "\u014A": "N",
    "\u0144": "n",
    "\u0146": "n",
    "\u0148": "n",
    "\u014B": "n",
    "\u014C": "O",
    "\u014E": "O",
    "\u0150": "O",
    "\u014D": "o",
    "\u014F": "o",
    "\u0151": "o",
    "\u0154": "R",
    "\u0156": "R",
    "\u0158": "R",
    "\u0155": "r",
    "\u0157": "r",
    "\u0159": "r",
    "\u015A": "S",
    "\u015C": "S",
    "\u015E": "S",
    "\u0160": "S",
    "\u015B": "s",
    "\u015D": "s",
    "\u015F": "s",
    "\u0161": "s",
    "\u0162": "T",
    "\u0164": "T",
    "\u0166": "T",
    "\u0163": "t",
    "\u0165": "t",
    "\u0167": "t",
    "\u0168": "U",
    "\u016A": "U",
    "\u016C": "U",
    "\u016E": "U",
    "\u0170": "U",
    "\u0172": "U",
    "\u0169": "u",
    "\u016B": "u",
    "\u016D": "u",
    "\u016F": "u",
    "\u0171": "u",
    "\u0173": "u",
    "\u0174": "W",
    "\u0175": "w",
    "\u0176": "Y",
    "\u0177": "y",
    "\u0178": "Y",
    "\u0179": "Z",
    "\u017B": "Z",
    "\u017D": "Z",
    "\u017A": "z",
    "\u017C": "z",
    "\u017E": "z",
    "\u0132": "IJ",
    "\u0133": "ij",
    "\u0152": "Oe",
    "\u0153": "oe",
    "\u0149": "'n",
    "\u017F": "ss"
  };
  var freeGlobal = typeof global == "object" && global && global.Object === Object && global;
  var freeSelf = typeof self == "object" && self && self.Object === Object && self;
  var root = freeGlobal || freeSelf || Function("return this")();
  var deburrLetter = basePropertyOf(deburredLetters);
  var objectProto = Object.prototype;
  var objectToString = objectProto.toString;
  var Symbol2 = root.Symbol;
  var symbolProto = Symbol2 ? Symbol2.prototype : undefined;
  var symbolToString = symbolProto ? symbolProto.toString : undefined;
  var camelCase = createCompounder(function(result, word, index) {
    word = word.toLowerCase();
    return result + (index ? capitalize(word) : word);
  });
  var upperFirst = createCaseFirst("toUpperCase");
  module.exports = camelCase;
});

// node_modules/command-line-args/dist/index.js
var require_dist = __commonJS((exports, module) => {
  var _interopDefault = function(ex) {
    return ex && typeof ex === "object" && ("default" in ex) ? ex["default"] : ex;
  };
  var isObject = function(input) {
    return typeof input === "object" && input !== null;
  };
  var isArrayLike = function(input) {
    return isObject(input) && typeof input.length === "number";
  };
  var arrayify = function(input) {
    if (Array.isArray(input)) {
      return input;
    }
    if (input === undefined) {
      return [];
    }
    if (isArrayLike(input) || input instanceof Set) {
      return Array.from(input);
    }
    return [input];
  };
  var isObject$1 = function(input) {
    return typeof input === "object" && input !== null;
  };
  var isArrayLike$1 = function(input) {
    return isObject$1(input) && typeof input.length === "number";
  };
  var arrayify$1 = function(input) {
    if (Array.isArray(input)) {
      return input;
    } else {
      if (input === undefined) {
        return [];
      } else if (isArrayLike$1(input)) {
        return Array.prototype.slice.call(input);
      } else {
        return [input];
      }
    }
  };
  var findReplace = function(array, testFn) {
    const found = [];
    const replaceWiths = arrayify$1(arguments);
    replaceWiths.splice(0, 2);
    arrayify$1(array).forEach((value, index) => {
      let expanded = [];
      replaceWiths.forEach((replaceWith) => {
        if (typeof replaceWith === "function") {
          expanded = expanded.concat(replaceWith(value));
        } else {
          expanded.push(replaceWith);
        }
      });
      if (testFn(value)) {
        found.push({
          index,
          replaceWithValue: expanded
        });
      }
    });
    found.reverse().forEach((item) => {
      const spliceArgs = [item.index, 1].concat(item.replaceWithValue);
      array.splice.apply(array, spliceArgs);
    });
    return array;
  };
  var expandCombinedShortArg = function(arg) {
    arg = arg.slice(1);
    return arg.split("").map((letter) => "-" + letter);
  };
  var isOptionEqualsNotation = function(arg) {
    return re.optEquals.test(arg);
  };
  var isOption = function(arg) {
    return (re.short.test(arg) || re.long.test(arg)) && !re.optEquals.test(arg);
  };
  var isLongOption = function(arg) {
    return re.long.test(arg) && !isOptionEqualsNotation(arg);
  };
  var getOptionName = function(arg) {
    if (re.short.test(arg)) {
      return arg.match(re.short)[1];
    } else if (isLongOption(arg)) {
      return arg.match(re.long)[1];
    } else if (isOptionEqualsNotation(arg)) {
      return arg.match(re.optEquals)[1].replace(/^--/, "");
    } else {
      return null;
    }
  };
  var isValue = function(arg) {
    return !(isOption(arg) || re.combinedShort.test(arg) || re.optEquals.test(arg));
  };
  var isExecArg = function(arg) {
    return ["--eval", "-e"].indexOf(arg) > -1 || arg.startsWith("--eval=");
  };
  var isNumber = function(n) {
    return !isNaN(parseFloat(n)) && isFinite(n);
  };
  var isPlainObject = function(input) {
    return input !== null && typeof input === "object" && input.constructor === Object;
  };
  var isArrayLike$2 = function(input) {
    return isObject$2(input) && typeof input.length === "number";
  };
  var isObject$2 = function(input) {
    return typeof input === "object" && input !== null;
  };
  var isDefined = function(input) {
    return typeof input !== "undefined";
  };
  var isString = function(input) {
    return typeof input === "string";
  };
  var isBoolean = function(input) {
    return typeof input === "boolean";
  };
  var isFunction = function(input) {
    return typeof input === "function";
  };
  var isClass = function(input) {
    if (isFunction(input)) {
      return /^class /.test(Function.prototype.toString.call(input));
    } else {
      return false;
    }
  };
  var isPrimitive = function(input) {
    if (input === null)
      return true;
    switch (typeof input) {
      case "string":
      case "number":
      case "symbol":
      case "undefined":
      case "boolean":
        return true;
      default:
        return false;
    }
  };
  var isPromise = function(input) {
    if (input) {
      const isPromise2 = isDefined(Promise) && input instanceof Promise;
      const isThenable = input.then && typeof input.then === "function";
      return !!(isPromise2 || isThenable);
    } else {
      return false;
    }
  };
  var isIterable = function(input) {
    if (input === null || !isDefined(input)) {
      return false;
    } else {
      return typeof input[Symbol.iterator] === "function" || typeof input[Symbol.asyncIterator] === "function";
    }
  };
  var halt = function(name, message) {
    const err = new Error(message);
    err.name = name;
    throw err;
  };
  var containsValidGroup = function(def) {
    return arrayify(def.group).some((group) => group);
  };
  var hasDuplicates = function(array) {
    const items = {};
    for (let i = 0;i < array.length; i++) {
      const value = array[i];
      if (items[value]) {
        return true;
      } else {
        if (t.isDefined(value))
          items[value] = true;
      }
    }
  };
  var commandLineArgs = function(optionDefinitions, options) {
    options = options || {};
    if (options.stopAtFirstUnknown)
      options.partial = true;
    optionDefinitions = Definitions.from(optionDefinitions, options.caseInsensitive);
    const parser = new ArgvParser(optionDefinitions, {
      argv: options.argv,
      stopAtFirstUnknown: options.stopAtFirstUnknown,
      caseInsensitive: options.caseInsensitive
    });
    const OutputClass = optionDefinitions.isGrouped() ? GroupedOutput : Output;
    const output = new OutputClass(optionDefinitions);
    for (const argInfo of parser) {
      const arg = argInfo.subArg || argInfo.arg;
      if (!options.partial) {
        if (argInfo.event === "unknown_value") {
          const err = new Error(`Unknown value: ${arg}`);
          err.name = "UNKNOWN_VALUE";
          err.value = arg;
          throw err;
        } else if (argInfo.event === "unknown_option") {
          const err = new Error(`Unknown option: ${arg}`);
          err.name = "UNKNOWN_OPTION";
          err.optionName = arg;
          throw err;
        }
      }
      let option;
      if (output.has(argInfo.name)) {
        option = output.get(argInfo.name);
      } else {
        option = Option.create(argInfo.def);
        output.set(argInfo.name, option);
      }
      if (argInfo.name === "_unknown") {
        option.set(arg);
      } else {
        option.set(argInfo.value);
      }
    }
    return output.toObject({ skipUnknown: !options.partial, camelCase: options.camelCase });
  };
  var camelCase = _interopDefault(require_lodash());
  var re = {
    short: /^-([^\d-])$/,
    long: /^--(\S+)/,
    combinedShort: /^-[^\d-]{2,}$/,
    optEquals: /^(--\S+?)=(.*)/
  };

  class ArgvArray extends Array {
    load(argv) {
      this.clear();
      if (argv && argv !== process.argv) {
        argv = arrayify(argv);
      } else {
        argv = process.argv.slice(0);
        const deleteCount = process.execArgv.some(isExecArg) ? 1 : 2;
        argv.splice(0, deleteCount);
      }
      argv.forEach((arg) => this.push(String(arg)));
    }
    clear() {
      this.length = 0;
    }
    expandOptionEqualsNotation() {
      if (this.some((arg) => re.optEquals.test(arg))) {
        const expandedArgs = [];
        this.forEach((arg) => {
          const matches = arg.match(re.optEquals);
          if (matches) {
            expandedArgs.push(matches[1], matches[2]);
          } else {
            expandedArgs.push(arg);
          }
        });
        this.clear();
        this.load(expandedArgs);
      }
    }
    expandGetoptNotation() {
      if (this.hasCombinedShortOptions()) {
        findReplace(this, re.combinedShort, expandCombinedShortArg);
      }
    }
    hasCombinedShortOptions() {
      return this.some((arg) => re.combinedShort.test(arg));
    }
    static from(argv) {
      const result = new this;
      result.load(argv);
      return result;
    }
  }
  var t = {
    isNumber,
    isString,
    isBoolean,
    isPlainObject,
    isArrayLike: isArrayLike$2,
    isObject: isObject$2,
    isDefined,
    isFunction,
    isClass,
    isPrimitive,
    isPromise,
    isIterable
  };

  class OptionDefinition {
    constructor(definition) {
      this.name = definition.name;
      this.type = definition.type || String;
      this.alias = definition.alias;
      this.multiple = definition.multiple;
      this.lazyMultiple = definition.lazyMultiple;
      this.defaultOption = definition.defaultOption;
      this.defaultValue = definition.defaultValue;
      this.group = definition.group;
      for (const prop in definition) {
        if (!this[prop])
          this[prop] = definition[prop];
      }
    }
    isBoolean() {
      return this.type === Boolean || t.isFunction(this.type) && this.type.name === "Boolean";
    }
    isMultiple() {
      return this.multiple || this.lazyMultiple;
    }
    static create(def) {
      const result = new this(def);
      return result;
    }
  }

  class Definitions extends Array {
    validate(caseInsensitive) {
      const someHaveNoName = this.some((def) => !def.name);
      if (someHaveNoName) {
        halt("INVALID_DEFINITIONS", "Invalid option definitions: the `name` property is required on each definition");
      }
      const someDontHaveFunctionType = this.some((def) => def.type && typeof def.type !== "function");
      if (someDontHaveFunctionType) {
        halt("INVALID_DEFINITIONS", "Invalid option definitions: the `type` property must be a setter fuction (default: `Boolean`)");
      }
      let invalidOption;
      const numericAlias = this.some((def) => {
        invalidOption = def;
        return t.isDefined(def.alias) && t.isNumber(def.alias);
      });
      if (numericAlias) {
        halt("INVALID_DEFINITIONS", "Invalid option definition: to avoid ambiguity an alias cannot be numeric [--" + invalidOption.name + " alias is -" + invalidOption.alias + "]");
      }
      const multiCharacterAlias = this.some((def) => {
        invalidOption = def;
        return t.isDefined(def.alias) && def.alias.length !== 1;
      });
      if (multiCharacterAlias) {
        halt("INVALID_DEFINITIONS", "Invalid option definition: an alias must be a single character");
      }
      const hypenAlias = this.some((def) => {
        invalidOption = def;
        return def.alias === "-";
      });
      if (hypenAlias) {
        halt("INVALID_DEFINITIONS", 'Invalid option definition: an alias cannot be "-"');
      }
      const duplicateName = hasDuplicates(this.map((def) => caseInsensitive ? def.name.toLowerCase() : def.name));
      if (duplicateName) {
        halt("INVALID_DEFINITIONS", "Two or more option definitions have the same name");
      }
      const duplicateAlias = hasDuplicates(this.map((def) => caseInsensitive && t.isDefined(def.alias) ? def.alias.toLowerCase() : def.alias));
      if (duplicateAlias) {
        halt("INVALID_DEFINITIONS", "Two or more option definitions have the same alias");
      }
      const duplicateDefaultOption = this.filter((def) => def.defaultOption === true).length > 1;
      if (duplicateDefaultOption) {
        halt("INVALID_DEFINITIONS", "Only one option definition can be the defaultOption");
      }
      const defaultBoolean = this.some((def) => {
        invalidOption = def;
        return def.isBoolean() && def.defaultOption;
      });
      if (defaultBoolean) {
        halt("INVALID_DEFINITIONS", `A boolean option ["${invalidOption.name}"] can not also be the defaultOption.`);
      }
    }
    get(arg, caseInsensitive) {
      if (isOption(arg)) {
        if (re.short.test(arg)) {
          const shortOptionName = getOptionName(arg);
          if (caseInsensitive) {
            const lowercaseShortOptionName = shortOptionName.toLowerCase();
            return this.find((def) => t.isDefined(def.alias) && def.alias.toLowerCase() === lowercaseShortOptionName);
          } else {
            return this.find((def) => def.alias === shortOptionName);
          }
        } else {
          const optionName = getOptionName(arg);
          if (caseInsensitive) {
            const lowercaseOptionName = optionName.toLowerCase();
            return this.find((def) => def.name.toLowerCase() === lowercaseOptionName);
          } else {
            return this.find((def) => def.name === optionName);
          }
        }
      } else {
        return this.find((def) => def.name === arg);
      }
    }
    getDefault() {
      return this.find((def) => def.defaultOption === true);
    }
    isGrouped() {
      return this.some((def) => def.group);
    }
    whereGrouped() {
      return this.filter(containsValidGroup);
    }
    whereNotGrouped() {
      return this.filter((def) => !containsValidGroup(def));
    }
    whereDefaultValueSet() {
      return this.filter((def) => t.isDefined(def.defaultValue));
    }
    static from(definitions, caseInsensitive) {
      if (definitions instanceof this)
        return definitions;
      const result = super.from(arrayify(definitions), (def) => OptionDefinition.create(def));
      result.validate(caseInsensitive);
      return result;
    }
  }

  class ArgvParser {
    constructor(definitions, options) {
      this.options = Object.assign({}, options);
      this.definitions = Definitions.from(definitions, this.options.caseInsensitive);
      this.argv = ArgvArray.from(this.options.argv);
      if (this.argv.hasCombinedShortOptions()) {
        findReplace(this.argv, re.combinedShort.test.bind(re.combinedShort), (arg) => {
          arg = arg.slice(1);
          return arg.split("").map((letter) => ({ origArg: `-${arg}`, arg: "-" + letter }));
        });
      }
    }
    *[Symbol.iterator]() {
      const definitions = this.definitions;
      let def;
      let value;
      let name;
      let event;
      let singularDefaultSet = false;
      let unknownFound = false;
      let origArg;
      for (let arg of this.argv) {
        if (t.isPlainObject(arg)) {
          origArg = arg.origArg;
          arg = arg.arg;
        }
        if (unknownFound && this.options.stopAtFirstUnknown) {
          yield { event: "unknown_value", arg, name: "_unknown", value: undefined };
          continue;
        }
        if (isOption(arg)) {
          def = definitions.get(arg, this.options.caseInsensitive);
          value = undefined;
          if (def) {
            value = def.isBoolean() ? true : null;
            event = "set";
          } else {
            event = "unknown_option";
          }
        } else if (isOptionEqualsNotation(arg)) {
          const matches = arg.match(re.optEquals);
          def = definitions.get(matches[1], this.options.caseInsensitive);
          if (def) {
            if (def.isBoolean()) {
              yield { event: "unknown_value", arg, name: "_unknown", value, def };
              event = "set";
              value = true;
            } else {
              event = "set";
              value = matches[2];
            }
          } else {
            event = "unknown_option";
          }
        } else if (isValue(arg)) {
          if (def) {
            value = arg;
            event = "set";
          } else {
            def = this.definitions.getDefault();
            if (def && !singularDefaultSet) {
              value = arg;
              event = "set";
            } else {
              event = "unknown_value";
              def = undefined;
            }
          }
        }
        name = def ? def.name : "_unknown";
        const argInfo = { event, arg, name, value, def };
        if (origArg) {
          argInfo.subArg = arg;
          argInfo.arg = origArg;
        }
        yield argInfo;
        if (name === "_unknown")
          unknownFound = true;
        if (def && def.defaultOption && !def.isMultiple() && event === "set")
          singularDefaultSet = true;
        if (def && def.isBoolean())
          def = undefined;
        if (def && !def.multiple && t.isDefined(value) && value !== null) {
          def = undefined;
        }
        value = undefined;
        event = undefined;
        name = undefined;
        origArg = undefined;
      }
    }
  }
  var _value = new WeakMap;

  class Option {
    constructor(definition) {
      this.definition = new OptionDefinition(definition);
      this.state = null;
      this.resetToDefault();
    }
    get() {
      return _value.get(this);
    }
    set(val) {
      this._set(val, "set");
    }
    _set(val, state) {
      const def = this.definition;
      if (def.isMultiple()) {
        if (val !== null && val !== undefined) {
          const arr = this.get();
          if (this.state === "default")
            arr.length = 0;
          arr.push(def.type(val));
          this.state = state;
        }
      } else {
        if (!def.isMultiple() && this.state === "set") {
          const err = new Error(`Singular option already set [${this.definition.name}=${this.get()}]`);
          err.name = "ALREADY_SET";
          err.value = val;
          err.optionName = def.name;
          throw err;
        } else if (val === null || val === undefined) {
          _value.set(this, val);
        } else {
          _value.set(this, def.type(val));
          this.state = state;
        }
      }
    }
    resetToDefault() {
      if (t.isDefined(this.definition.defaultValue)) {
        if (this.definition.isMultiple()) {
          _value.set(this, arrayify(this.definition.defaultValue).slice());
        } else {
          _value.set(this, this.definition.defaultValue);
        }
      } else {
        if (this.definition.isMultiple()) {
          _value.set(this, []);
        } else {
          _value.set(this, null);
        }
      }
      this.state = "default";
    }
    static create(definition) {
      definition = new OptionDefinition(definition);
      if (definition.isBoolean()) {
        return FlagOption.create(definition);
      } else {
        return new this(definition);
      }
    }
  }

  class FlagOption extends Option {
    set(val) {
      super.set(true);
    }
    static create(def) {
      return new this(def);
    }
  }

  class Output extends Map {
    constructor(definitions) {
      super();
      this.definitions = Definitions.from(definitions);
      this.set("_unknown", Option.create({ name: "_unknown", multiple: true }));
      for (const def of this.definitions.whereDefaultValueSet()) {
        this.set(def.name, Option.create(def));
      }
    }
    toObject(options) {
      options = options || {};
      const output = {};
      for (const item of this) {
        const name = options.camelCase && item[0] !== "_unknown" ? camelCase(item[0]) : item[0];
        const option = item[1];
        if (name === "_unknown" && !option.get().length)
          continue;
        output[name] = option.get();
      }
      if (options.skipUnknown)
        delete output._unknown;
      return output;
    }
  }

  class GroupedOutput extends Output {
    toObject(options) {
      const superOutputNoCamel = super.toObject({ skipUnknown: options.skipUnknown });
      const superOutput = super.toObject(options);
      const unknown = superOutput._unknown;
      delete superOutput._unknown;
      const grouped = {
        _all: superOutput
      };
      if (unknown && unknown.length)
        grouped._unknown = unknown;
      this.definitions.whereGrouped().forEach((def) => {
        const name = options.camelCase ? camelCase(def.name) : def.name;
        const outputValue = superOutputNoCamel[def.name];
        for (const groupName of arrayify(def.group)) {
          grouped[groupName] = grouped[groupName] || {};
          if (t.isDefined(outputValue)) {
            grouped[groupName][name] = outputValue;
          }
        }
      });
      this.definitions.whereNotGrouped().forEach((def) => {
        const name = options.camelCase ? camelCase(def.name) : def.name;
        const outputValue = superOutputNoCamel[def.name];
        if (t.isDefined(outputValue)) {
          if (!grouped._none)
            grouped._none = {};
          grouped._none[name] = outputValue;
        }
      });
      return grouped;
    }
  }
  module.exports = commandLineArgs;
});

// node_modules/command-line-usage/node_modules/array-back/dist/index.js
var require_dist2 = __commonJS((exports, module) => {
  (function(global2, factory) {
    typeof exports === "object" && typeof module !== "undefined" ? module.exports = factory() : typeof define === "function" && define.amd ? define(factory) : (global2 = global2 || self, global2.arrayBack = factory());
  })(exports, function() {
    function isObject(input) {
      return typeof input === "object" && input !== null;
    }
    function isArrayLike(input) {
      return isObject(input) && typeof input.length === "number";
    }
    function arrayify(input) {
      if (Array.isArray(input)) {
        return input;
      }
      if (input === undefined) {
        return [];
      }
      if (isArrayLike(input) || input instanceof Set) {
        return Array.from(input);
      }
      return [input];
    }
    return arrayify;
  });
});

// node_modules/escape-string-regexp/index.js
var require_escape_string_regexp = __commonJS((exports, module) => {
  var matchOperatorsRe = /[|\\{}()[\]^$+*?.]/g;
  module.exports = function(str) {
    if (typeof str !== "string") {
      throw new TypeError("Expected a string");
    }
    return str.replace(matchOperatorsRe, "\\$&");
  };
});

// node_modules/color-name/index.js
var require_color_name = __commonJS((exports, module) => {
  module.exports = {
    aliceblue: [240, 248, 255],
    antiquewhite: [250, 235, 215],
    aqua: [0, 255, 255],
    aquamarine: [127, 255, 212],
    azure: [240, 255, 255],
    beige: [245, 245, 220],
    bisque: [255, 228, 196],
    black: [0, 0, 0],
    blanchedalmond: [255, 235, 205],
    blue: [0, 0, 255],
    blueviolet: [138, 43, 226],
    brown: [165, 42, 42],
    burlywood: [222, 184, 135],
    cadetblue: [95, 158, 160],
    chartreuse: [127, 255, 0],
    chocolate: [210, 105, 30],
    coral: [255, 127, 80],
    cornflowerblue: [100, 149, 237],
    cornsilk: [255, 248, 220],
    crimson: [220, 20, 60],
    cyan: [0, 255, 255],
    darkblue: [0, 0, 139],
    darkcyan: [0, 139, 139],
    darkgoldenrod: [184, 134, 11],
    darkgray: [169, 169, 169],
    darkgreen: [0, 100, 0],
    darkgrey: [169, 169, 169],
    darkkhaki: [189, 183, 107],
    darkmagenta: [139, 0, 139],
    darkolivegreen: [85, 107, 47],
    darkorange: [255, 140, 0],
    darkorchid: [153, 50, 204],
    darkred: [139, 0, 0],
    darksalmon: [233, 150, 122],
    darkseagreen: [143, 188, 143],
    darkslateblue: [72, 61, 139],
    darkslategray: [47, 79, 79],
    darkslategrey: [47, 79, 79],
    darkturquoise: [0, 206, 209],
    darkviolet: [148, 0, 211],
    deeppink: [255, 20, 147],
    deepskyblue: [0, 191, 255],
    dimgray: [105, 105, 105],
    dimgrey: [105, 105, 105],
    dodgerblue: [30, 144, 255],
    firebrick: [178, 34, 34],
    floralwhite: [255, 250, 240],
    forestgreen: [34, 139, 34],
    fuchsia: [255, 0, 255],
    gainsboro: [220, 220, 220],
    ghostwhite: [248, 248, 255],
    gold: [255, 215, 0],
    goldenrod: [218, 165, 32],
    gray: [128, 128, 128],
    green: [0, 128, 0],
    greenyellow: [173, 255, 47],
    grey: [128, 128, 128],
    honeydew: [240, 255, 240],
    hotpink: [255, 105, 180],
    indianred: [205, 92, 92],
    indigo: [75, 0, 130],
    ivory: [255, 255, 240],
    khaki: [240, 230, 140],
    lavender: [230, 230, 250],
    lavenderblush: [255, 240, 245],
    lawngreen: [124, 252, 0],
    lemonchiffon: [255, 250, 205],
    lightblue: [173, 216, 230],
    lightcoral: [240, 128, 128],
    lightcyan: [224, 255, 255],
    lightgoldenrodyellow: [250, 250, 210],
    lightgray: [211, 211, 211],
    lightgreen: [144, 238, 144],
    lightgrey: [211, 211, 211],
    lightpink: [255, 182, 193],
    lightsalmon: [255, 160, 122],
    lightseagreen: [32, 178, 170],
    lightskyblue: [135, 206, 250],
    lightslategray: [119, 136, 153],
    lightslategrey: [119, 136, 153],
    lightsteelblue: [176, 196, 222],
    lightyellow: [255, 255, 224],
    lime: [0, 255, 0],
    limegreen: [50, 205, 50],
    linen: [250, 240, 230],
    magenta: [255, 0, 255],
    maroon: [128, 0, 0],
    mediumaquamarine: [102, 205, 170],
    mediumblue: [0, 0, 205],
    mediumorchid: [186, 85, 211],
    mediumpurple: [147, 112, 219],
    mediumseagreen: [60, 179, 113],
    mediumslateblue: [123, 104, 238],
    mediumspringgreen: [0, 250, 154],
    mediumturquoise: [72, 209, 204],
    mediumvioletred: [199, 21, 133],
    midnightblue: [25, 25, 112],
    mintcream: [245, 255, 250],
    mistyrose: [255, 228, 225],
    moccasin: [255, 228, 181],
    navajowhite: [255, 222, 173],
    navy: [0, 0, 128],
    oldlace: [253, 245, 230],
    olive: [128, 128, 0],
    olivedrab: [107, 142, 35],
    orange: [255, 165, 0],
    orangered: [255, 69, 0],
    orchid: [218, 112, 214],
    palegoldenrod: [238, 232, 170],
    palegreen: [152, 251, 152],
    paleturquoise: [175, 238, 238],
    palevioletred: [219, 112, 147],
    papayawhip: [255, 239, 213],
    peachpuff: [255, 218, 185],
    peru: [205, 133, 63],
    pink: [255, 192, 203],
    plum: [221, 160, 221],
    powderblue: [176, 224, 230],
    purple: [128, 0, 128],
    rebeccapurple: [102, 51, 153],
    red: [255, 0, 0],
    rosybrown: [188, 143, 143],
    royalblue: [65, 105, 225],
    saddlebrown: [139, 69, 19],
    salmon: [250, 128, 114],
    sandybrown: [244, 164, 96],
    seagreen: [46, 139, 87],
    seashell: [255, 245, 238],
    sienna: [160, 82, 45],
    silver: [192, 192, 192],
    skyblue: [135, 206, 235],
    slateblue: [106, 90, 205],
    slategray: [112, 128, 144],
    slategrey: [112, 128, 144],
    snow: [255, 250, 250],
    springgreen: [0, 255, 127],
    steelblue: [70, 130, 180],
    tan: [210, 180, 140],
    teal: [0, 128, 128],
    thistle: [216, 191, 216],
    tomato: [255, 99, 71],
    turquoise: [64, 224, 208],
    violet: [238, 130, 238],
    wheat: [245, 222, 179],
    white: [255, 255, 255],
    whitesmoke: [245, 245, 245],
    yellow: [255, 255, 0],
    yellowgreen: [154, 205, 50]
  };
});

// node_modules/color-convert/conversions.js
var require_conversions = __commonJS((exports, module) => {
  var comparativeDistance = function(x, y) {
    return Math.pow(x[0] - y[0], 2) + Math.pow(x[1] - y[1], 2) + Math.pow(x[2] - y[2], 2);
  };
  var cssKeywords = require_color_name();
  var reverseKeywords = {};
  for (key in cssKeywords) {
    if (cssKeywords.hasOwnProperty(key)) {
      reverseKeywords[cssKeywords[key]] = key;
    }
  }
  var key;
  var convert = module.exports = {
    rgb: { channels: 3, labels: "rgb" },
    hsl: { channels: 3, labels: "hsl" },
    hsv: { channels: 3, labels: "hsv" },
    hwb: { channels: 3, labels: "hwb" },
    cmyk: { channels: 4, labels: "cmyk" },
    xyz: { channels: 3, labels: "xyz" },
    lab: { channels: 3, labels: "lab" },
    lch: { channels: 3, labels: "lch" },
    hex: { channels: 1, labels: ["hex"] },
    keyword: { channels: 1, labels: ["keyword"] },
    ansi16: { channels: 1, labels: ["ansi16"] },
    ansi256: { channels: 1, labels: ["ansi256"] },
    hcg: { channels: 3, labels: ["h", "c", "g"] },
    apple: { channels: 3, labels: ["r16", "g16", "b16"] },
    gray: { channels: 1, labels: ["gray"] }
  };
  for (model in convert) {
    if (convert.hasOwnProperty(model)) {
      if (!("channels" in convert[model])) {
        throw new Error("missing channels property: " + model);
      }
      if (!("labels" in convert[model])) {
        throw new Error("missing channel labels property: " + model);
      }
      if (convert[model].labels.length !== convert[model].channels) {
        throw new Error("channel and label counts mismatch: " + model);
      }
      channels = convert[model].channels;
      labels = convert[model].labels;
      delete convert[model].channels;
      delete convert[model].labels;
      Object.defineProperty(convert[model], "channels", { value: channels });
      Object.defineProperty(convert[model], "labels", { value: labels });
    }
  }
  var channels;
  var labels;
  var model;
  convert.rgb.hsl = function(rgb) {
    var r = rgb[0] / 255;
    var g = rgb[1] / 255;
    var b = rgb[2] / 255;
    var min = Math.min(r, g, b);
    var max = Math.max(r, g, b);
    var delta = max - min;
    var h;
    var s;
    var l;
    if (max === min) {
      h = 0;
    } else if (r === max) {
      h = (g - b) / delta;
    } else if (g === max) {
      h = 2 + (b - r) / delta;
    } else if (b === max) {
      h = 4 + (r - g) / delta;
    }
    h = Math.min(h * 60, 360);
    if (h < 0) {
      h += 360;
    }
    l = (min + max) / 2;
    if (max === min) {
      s = 0;
    } else if (l <= 0.5) {
      s = delta / (max + min);
    } else {
      s = delta / (2 - max - min);
    }
    return [h, s * 100, l * 100];
  };
  convert.rgb.hsv = function(rgb) {
    var rdif;
    var gdif;
    var bdif;
    var h;
    var s;
    var r = rgb[0] / 255;
    var g = rgb[1] / 255;
    var b = rgb[2] / 255;
    var v = Math.max(r, g, b);
    var diff = v - Math.min(r, g, b);
    var diffc = function(c) {
      return (v - c) / 6 / diff + 1 / 2;
    };
    if (diff === 0) {
      h = s = 0;
    } else {
      s = diff / v;
      rdif = diffc(r);
      gdif = diffc(g);
      bdif = diffc(b);
      if (r === v) {
        h = bdif - gdif;
      } else if (g === v) {
        h = 1 / 3 + rdif - bdif;
      } else if (b === v) {
        h = 2 / 3 + gdif - rdif;
      }
      if (h < 0) {
        h += 1;
      } else if (h > 1) {
        h -= 1;
      }
    }
    return [
      h * 360,
      s * 100,
      v * 100
    ];
  };
  convert.rgb.hwb = function(rgb) {
    var r = rgb[0];
    var g = rgb[1];
    var b = rgb[2];
    var h = convert.rgb.hsl(rgb)[0];
    var w = 1 / 255 * Math.min(r, Math.min(g, b));
    b = 1 - 1 / 255 * Math.max(r, Math.max(g, b));
    return [h, w * 100, b * 100];
  };
  convert.rgb.cmyk = function(rgb) {
    var r = rgb[0] / 255;
    var g = rgb[1] / 255;
    var b = rgb[2] / 255;
    var c;
    var m;
    var y;
    var k;
    k = Math.min(1 - r, 1 - g, 1 - b);
    c = (1 - r - k) / (1 - k) || 0;
    m = (1 - g - k) / (1 - k) || 0;
    y = (1 - b - k) / (1 - k) || 0;
    return [c * 100, m * 100, y * 100, k * 100];
  };
  convert.rgb.keyword = function(rgb) {
    var reversed = reverseKeywords[rgb];
    if (reversed) {
      return reversed;
    }
    var currentClosestDistance = Infinity;
    var currentClosestKeyword;
    for (var keyword in cssKeywords) {
      if (cssKeywords.hasOwnProperty(keyword)) {
        var value = cssKeywords[keyword];
        var distance = comparativeDistance(rgb, value);
        if (distance < currentClosestDistance) {
          currentClosestDistance = distance;
          currentClosestKeyword = keyword;
        }
      }
    }
    return currentClosestKeyword;
  };
  convert.keyword.rgb = function(keyword) {
    return cssKeywords[keyword];
  };
  convert.rgb.xyz = function(rgb) {
    var r = rgb[0] / 255;
    var g = rgb[1] / 255;
    var b = rgb[2] / 255;
    r = r > 0.04045 ? Math.pow((r + 0.055) / 1.055, 2.4) : r / 12.92;
    g = g > 0.04045 ? Math.pow((g + 0.055) / 1.055, 2.4) : g / 12.92;
    b = b > 0.04045 ? Math.pow((b + 0.055) / 1.055, 2.4) : b / 12.92;
    var x = r * 0.4124 + g * 0.3576 + b * 0.1805;
    var y = r * 0.2126 + g * 0.7152 + b * 0.0722;
    var z = r * 0.0193 + g * 0.1192 + b * 0.9505;
    return [x * 100, y * 100, z * 100];
  };
  convert.rgb.lab = function(rgb) {
    var xyz = convert.rgb.xyz(rgb);
    var x = xyz[0];
    var y = xyz[1];
    var z = xyz[2];
    var l;
    var a;
    var b;
    x /= 95.047;
    y /= 100;
    z /= 108.883;
    x = x > 0.008856 ? Math.pow(x, 1 / 3) : 7.787 * x + 16 / 116;
    y = y > 0.008856 ? Math.pow(y, 1 / 3) : 7.787 * y + 16 / 116;
    z = z > 0.008856 ? Math.pow(z, 1 / 3) : 7.787 * z + 16 / 116;
    l = 116 * y - 16;
    a = 500 * (x - y);
    b = 200 * (y - z);
    return [l, a, b];
  };
  convert.hsl.rgb = function(hsl) {
    var h = hsl[0] / 360;
    var s = hsl[1] / 100;
    var l = hsl[2] / 100;
    var t1;
    var t2;
    var t3;
    var rgb;
    var val;
    if (s === 0) {
      val = l * 255;
      return [val, val, val];
    }
    if (l < 0.5) {
      t2 = l * (1 + s);
    } else {
      t2 = l + s - l * s;
    }
    t1 = 2 * l - t2;
    rgb = [0, 0, 0];
    for (var i = 0;i < 3; i++) {
      t3 = h + 1 / 3 * -(i - 1);
      if (t3 < 0) {
        t3++;
      }
      if (t3 > 1) {
        t3--;
      }
      if (6 * t3 < 1) {
        val = t1 + (t2 - t1) * 6 * t3;
      } else if (2 * t3 < 1) {
        val = t2;
      } else if (3 * t3 < 2) {
        val = t1 + (t2 - t1) * (2 / 3 - t3) * 6;
      } else {
        val = t1;
      }
      rgb[i] = val * 255;
    }
    return rgb;
  };
  convert.hsl.hsv = function(hsl) {
    var h = hsl[0];
    var s = hsl[1] / 100;
    var l = hsl[2] / 100;
    var smin = s;
    var lmin = Math.max(l, 0.01);
    var sv;
    var v;
    l *= 2;
    s *= l <= 1 ? l : 2 - l;
    smin *= lmin <= 1 ? lmin : 2 - lmin;
    v = (l + s) / 2;
    sv = l === 0 ? 2 * smin / (lmin + smin) : 2 * s / (l + s);
    return [h, sv * 100, v * 100];
  };
  convert.hsv.rgb = function(hsv) {
    var h = hsv[0] / 60;
    var s = hsv[1] / 100;
    var v = hsv[2] / 100;
    var hi = Math.floor(h) % 6;
    var f = h - Math.floor(h);
    var p = 255 * v * (1 - s);
    var q = 255 * v * (1 - s * f);
    var t = 255 * v * (1 - s * (1 - f));
    v *= 255;
    switch (hi) {
      case 0:
        return [v, t, p];
      case 1:
        return [q, v, p];
      case 2:
        return [p, v, t];
      case 3:
        return [p, q, v];
      case 4:
        return [t, p, v];
      case 5:
        return [v, p, q];
    }
  };
  convert.hsv.hsl = function(hsv) {
    var h = hsv[0];
    var s = hsv[1] / 100;
    var v = hsv[2] / 100;
    var vmin = Math.max(v, 0.01);
    var lmin;
    var sl;
    var l;
    l = (2 - s) * v;
    lmin = (2 - s) * vmin;
    sl = s * vmin;
    sl /= lmin <= 1 ? lmin : 2 - lmin;
    sl = sl || 0;
    l /= 2;
    return [h, sl * 100, l * 100];
  };
  convert.hwb.rgb = function(hwb) {
    var h = hwb[0] / 360;
    var wh = hwb[1] / 100;
    var bl = hwb[2] / 100;
    var ratio = wh + bl;
    var i;
    var v;
    var f;
    var n;
    if (ratio > 1) {
      wh /= ratio;
      bl /= ratio;
    }
    i = Math.floor(6 * h);
    v = 1 - bl;
    f = 6 * h - i;
    if ((i & 1) !== 0) {
      f = 1 - f;
    }
    n = wh + f * (v - wh);
    var r;
    var g;
    var b;
    switch (i) {
      default:
      case 6:
      case 0:
        r = v;
        g = n;
        b = wh;
        break;
      case 1:
        r = n;
        g = v;
        b = wh;
        break;
      case 2:
        r = wh;
        g = v;
        b = n;
        break;
      case 3:
        r = wh;
        g = n;
        b = v;
        break;
      case 4:
        r = n;
        g = wh;
        b = v;
        break;
      case 5:
        r = v;
        g = wh;
        b = n;
        break;
    }
    return [r * 255, g * 255, b * 255];
  };
  convert.cmyk.rgb = function(cmyk) {
    var c = cmyk[0] / 100;
    var m = cmyk[1] / 100;
    var y = cmyk[2] / 100;
    var k = cmyk[3] / 100;
    var r;
    var g;
    var b;
    r = 1 - Math.min(1, c * (1 - k) + k);
    g = 1 - Math.min(1, m * (1 - k) + k);
    b = 1 - Math.min(1, y * (1 - k) + k);
    return [r * 255, g * 255, b * 255];
  };
  convert.xyz.rgb = function(xyz) {
    var x = xyz[0] / 100;
    var y = xyz[1] / 100;
    var z = xyz[2] / 100;
    var r;
    var g;
    var b;
    r = x * 3.2406 + y * -1.5372 + z * -0.4986;
    g = x * -0.9689 + y * 1.8758 + z * 0.0415;
    b = x * 0.0557 + y * -0.204 + z * 1.057;
    r = r > 0.0031308 ? 1.055 * Math.pow(r, 1 / 2.4) - 0.055 : r * 12.92;
    g = g > 0.0031308 ? 1.055 * Math.pow(g, 1 / 2.4) - 0.055 : g * 12.92;
    b = b > 0.0031308 ? 1.055 * Math.pow(b, 1 / 2.4) - 0.055 : b * 12.92;
    r = Math.min(Math.max(0, r), 1);
    g = Math.min(Math.max(0, g), 1);
    b = Math.min(Math.max(0, b), 1);
    return [r * 255, g * 255, b * 255];
  };
  convert.xyz.lab = function(xyz) {
    var x = xyz[0];
    var y = xyz[1];
    var z = xyz[2];
    var l;
    var a;
    var b;
    x /= 95.047;
    y /= 100;
    z /= 108.883;
    x = x > 0.008856 ? Math.pow(x, 1 / 3) : 7.787 * x + 16 / 116;
    y = y > 0.008856 ? Math.pow(y, 1 / 3) : 7.787 * y + 16 / 116;
    z = z > 0.008856 ? Math.pow(z, 1 / 3) : 7.787 * z + 16 / 116;
    l = 116 * y - 16;
    a = 500 * (x - y);
    b = 200 * (y - z);
    return [l, a, b];
  };
  convert.lab.xyz = function(lab) {
    var l = lab[0];
    var a = lab[1];
    var b = lab[2];
    var x;
    var y;
    var z;
    y = (l + 16) / 116;
    x = a / 500 + y;
    z = y - b / 200;
    var y2 = Math.pow(y, 3);
    var x2 = Math.pow(x, 3);
    var z2 = Math.pow(z, 3);
    y = y2 > 0.008856 ? y2 : (y - 16 / 116) / 7.787;
    x = x2 > 0.008856 ? x2 : (x - 16 / 116) / 7.787;
    z = z2 > 0.008856 ? z2 : (z - 16 / 116) / 7.787;
    x *= 95.047;
    y *= 100;
    z *= 108.883;
    return [x, y, z];
  };
  convert.lab.lch = function(lab) {
    var l = lab[0];
    var a = lab[1];
    var b = lab[2];
    var hr;
    var h;
    var c;
    hr = Math.atan2(b, a);
    h = hr * 360 / 2 / Math.PI;
    if (h < 0) {
      h += 360;
    }
    c = Math.sqrt(a * a + b * b);
    return [l, c, h];
  };
  convert.lch.lab = function(lch) {
    var l = lch[0];
    var c = lch[1];
    var h = lch[2];
    var a;
    var b;
    var hr;
    hr = h / 360 * 2 * Math.PI;
    a = c * Math.cos(hr);
    b = c * Math.sin(hr);
    return [l, a, b];
  };
  convert.rgb.ansi16 = function(args) {
    var r = args[0];
    var g = args[1];
    var b = args[2];
    var value = 1 in arguments ? arguments[1] : convert.rgb.hsv(args)[2];
    value = Math.round(value / 50);
    if (value === 0) {
      return 30;
    }
    var ansi = 30 + (Math.round(b / 255) << 2 | Math.round(g / 255) << 1 | Math.round(r / 255));
    if (value === 2) {
      ansi += 60;
    }
    return ansi;
  };
  convert.hsv.ansi16 = function(args) {
    return convert.rgb.ansi16(convert.hsv.rgb(args), args[2]);
  };
  convert.rgb.ansi256 = function(args) {
    var r = args[0];
    var g = args[1];
    var b = args[2];
    if (r === g && g === b) {
      if (r < 8) {
        return 16;
      }
      if (r > 248) {
        return 231;
      }
      return Math.round((r - 8) / 247 * 24) + 232;
    }
    var ansi = 16 + 36 * Math.round(r / 255 * 5) + 6 * Math.round(g / 255 * 5) + Math.round(b / 255 * 5);
    return ansi;
  };
  convert.ansi16.rgb = function(args) {
    var color = args % 10;
    if (color === 0 || color === 7) {
      if (args > 50) {
        color += 3.5;
      }
      color = color / 10.5 * 255;
      return [color, color, color];
    }
    var mult = (~~(args > 50) + 1) * 0.5;
    var r = (color & 1) * mult * 255;
    var g = (color >> 1 & 1) * mult * 255;
    var b = (color >> 2 & 1) * mult * 255;
    return [r, g, b];
  };
  convert.ansi256.rgb = function(args) {
    if (args >= 232) {
      var c = (args - 232) * 10 + 8;
      return [c, c, c];
    }
    args -= 16;
    var rem;
    var r = Math.floor(args / 36) / 5 * 255;
    var g = Math.floor((rem = args % 36) / 6) / 5 * 255;
    var b = rem % 6 / 5 * 255;
    return [r, g, b];
  };
  convert.rgb.hex = function(args) {
    var integer = ((Math.round(args[0]) & 255) << 16) + ((Math.round(args[1]) & 255) << 8) + (Math.round(args[2]) & 255);
    var string = integer.toString(16).toUpperCase();
    return "000000".substring(string.length) + string;
  };
  convert.hex.rgb = function(args) {
    var match = args.toString(16).match(/[a-f0-9]{6}|[a-f0-9]{3}/i);
    if (!match) {
      return [0, 0, 0];
    }
    var colorString = match[0];
    if (match[0].length === 3) {
      colorString = colorString.split("").map(function(char) {
        return char + char;
      }).join("");
    }
    var integer = parseInt(colorString, 16);
    var r = integer >> 16 & 255;
    var g = integer >> 8 & 255;
    var b = integer & 255;
    return [r, g, b];
  };
  convert.rgb.hcg = function(rgb) {
    var r = rgb[0] / 255;
    var g = rgb[1] / 255;
    var b = rgb[2] / 255;
    var max = Math.max(Math.max(r, g), b);
    var min = Math.min(Math.min(r, g), b);
    var chroma = max - min;
    var grayscale;
    var hue;
    if (chroma < 1) {
      grayscale = min / (1 - chroma);
    } else {
      grayscale = 0;
    }
    if (chroma <= 0) {
      hue = 0;
    } else if (max === r) {
      hue = (g - b) / chroma % 6;
    } else if (max === g) {
      hue = 2 + (b - r) / chroma;
    } else {
      hue = 4 + (r - g) / chroma + 4;
    }
    hue /= 6;
    hue %= 1;
    return [hue * 360, chroma * 100, grayscale * 100];
  };
  convert.hsl.hcg = function(hsl) {
    var s = hsl[1] / 100;
    var l = hsl[2] / 100;
    var c = 1;
    var f = 0;
    if (l < 0.5) {
      c = 2 * s * l;
    } else {
      c = 2 * s * (1 - l);
    }
    if (c < 1) {
      f = (l - 0.5 * c) / (1 - c);
    }
    return [hsl[0], c * 100, f * 100];
  };
  convert.hsv.hcg = function(hsv) {
    var s = hsv[1] / 100;
    var v = hsv[2] / 100;
    var c = s * v;
    var f = 0;
    if (c < 1) {
      f = (v - c) / (1 - c);
    }
    return [hsv[0], c * 100, f * 100];
  };
  convert.hcg.rgb = function(hcg) {
    var h = hcg[0] / 360;
    var c = hcg[1] / 100;
    var g = hcg[2] / 100;
    if (c === 0) {
      return [g * 255, g * 255, g * 255];
    }
    var pure = [0, 0, 0];
    var hi = h % 1 * 6;
    var v = hi % 1;
    var w = 1 - v;
    var mg = 0;
    switch (Math.floor(hi)) {
      case 0:
        pure[0] = 1;
        pure[1] = v;
        pure[2] = 0;
        break;
      case 1:
        pure[0] = w;
        pure[1] = 1;
        pure[2] = 0;
        break;
      case 2:
        pure[0] = 0;
        pure[1] = 1;
        pure[2] = v;
        break;
      case 3:
        pure[0] = 0;
        pure[1] = w;
        pure[2] = 1;
        break;
      case 4:
        pure[0] = v;
        pure[1] = 0;
        pure[2] = 1;
        break;
      default:
        pure[0] = 1;
        pure[1] = 0;
        pure[2] = w;
    }
    mg = (1 - c) * g;
    return [
      (c * pure[0] + mg) * 255,
      (c * pure[1] + mg) * 255,
      (c * pure[2] + mg) * 255
    ];
  };
  convert.hcg.hsv = function(hcg) {
    var c = hcg[1] / 100;
    var g = hcg[2] / 100;
    var v = c + g * (1 - c);
    var f = 0;
    if (v > 0) {
      f = c / v;
    }
    return [hcg[0], f * 100, v * 100];
  };
  convert.hcg.hsl = function(hcg) {
    var c = hcg[1] / 100;
    var g = hcg[2] / 100;
    var l = g * (1 - c) + 0.5 * c;
    var s = 0;
    if (l > 0 && l < 0.5) {
      s = c / (2 * l);
    } else if (l >= 0.5 && l < 1) {
      s = c / (2 * (1 - l));
    }
    return [hcg[0], s * 100, l * 100];
  };
  convert.hcg.hwb = function(hcg) {
    var c = hcg[1] / 100;
    var g = hcg[2] / 100;
    var v = c + g * (1 - c);
    return [hcg[0], (v - c) * 100, (1 - v) * 100];
  };
  convert.hwb.hcg = function(hwb) {
    var w = hwb[1] / 100;
    var b = hwb[2] / 100;
    var v = 1 - b;
    var c = v - w;
    var g = 0;
    if (c < 1) {
      g = (v - c) / (1 - c);
    }
    return [hwb[0], c * 100, g * 100];
  };
  convert.apple.rgb = function(apple) {
    return [apple[0] / 65535 * 255, apple[1] / 65535 * 255, apple[2] / 65535 * 255];
  };
  convert.rgb.apple = function(rgb) {
    return [rgb[0] / 255 * 65535, rgb[1] / 255 * 65535, rgb[2] / 255 * 65535];
  };
  convert.gray.rgb = function(args) {
    return [args[0] / 100 * 255, args[0] / 100 * 255, args[0] / 100 * 255];
  };
  convert.gray.hsl = convert.gray.hsv = function(args) {
    return [0, 0, args[0]];
  };
  convert.gray.hwb = function(gray) {
    return [0, 100, gray[0]];
  };
  convert.gray.cmyk = function(gray) {
    return [0, 0, 0, gray[0]];
  };
  convert.gray.lab = function(gray) {
    return [gray[0], 0, 0];
  };
  convert.gray.hex = function(gray) {
    var val = Math.round(gray[0] / 100 * 255) & 255;
    var integer = (val << 16) + (val << 8) + val;
    var string = integer.toString(16).toUpperCase();
    return "000000".substring(string.length) + string;
  };
  convert.rgb.gray = function(rgb) {
    var val = (rgb[0] + rgb[1] + rgb[2]) / 3;
    return [val / 255 * 100];
  };
});

// node_modules/color-convert/route.js
var require_route = __commonJS((exports, module) => {
  var buildGraph = function() {
    var graph = {};
    var models = Object.keys(conversions);
    for (var len = models.length, i = 0;i < len; i++) {
      graph[models[i]] = {
        distance: -1,
        parent: null
      };
    }
    return graph;
  };
  var deriveBFS = function(fromModel) {
    var graph = buildGraph();
    var queue = [fromModel];
    graph[fromModel].distance = 0;
    while (queue.length) {
      var current = queue.pop();
      var adjacents = Object.keys(conversions[current]);
      for (var len = adjacents.length, i = 0;i < len; i++) {
        var adjacent = adjacents[i];
        var node = graph[adjacent];
        if (node.distance === -1) {
          node.distance = graph[current].distance + 1;
          node.parent = current;
          queue.unshift(adjacent);
        }
      }
    }
    return graph;
  };
  var link = function(from, to) {
    return function(args) {
      return to(from(args));
    };
  };
  var wrapConversion = function(toModel, graph) {
    var path = [graph[toModel].parent, toModel];
    var fn = conversions[graph[toModel].parent][toModel];
    var cur = graph[toModel].parent;
    while (graph[cur].parent) {
      path.unshift(graph[cur].parent);
      fn = link(conversions[graph[cur].parent][cur], fn);
      cur = graph[cur].parent;
    }
    fn.conversion = path;
    return fn;
  };
  var conversions = require_conversions();
  module.exports = function(fromModel) {
    var graph = deriveBFS(fromModel);
    var conversion = {};
    var models = Object.keys(graph);
    for (var len = models.length, i = 0;i < len; i++) {
      var toModel = models[i];
      var node = graph[toModel];
      if (node.parent === null) {
        continue;
      }
      conversion[toModel] = wrapConversion(toModel, graph);
    }
    return conversion;
  };
});

// node_modules/color-convert/index.js
var require_color_convert = __commonJS((exports, module) => {
  var wrapRaw = function(fn) {
    var wrappedFn = function(args) {
      if (args === undefined || args === null) {
        return args;
      }
      if (arguments.length > 1) {
        args = Array.prototype.slice.call(arguments);
      }
      return fn(args);
    };
    if ("conversion" in fn) {
      wrappedFn.conversion = fn.conversion;
    }
    return wrappedFn;
  };
  var wrapRounded = function(fn) {
    var wrappedFn = function(args) {
      if (args === undefined || args === null) {
        return args;
      }
      if (arguments.length > 1) {
        args = Array.prototype.slice.call(arguments);
      }
      var result = fn(args);
      if (typeof result === "object") {
        for (var len = result.length, i = 0;i < len; i++) {
          result[i] = Math.round(result[i]);
        }
      }
      return result;
    };
    if ("conversion" in fn) {
      wrappedFn.conversion = fn.conversion;
    }
    return wrappedFn;
  };
  var conversions = require_conversions();
  var route = require_route();
  var convert = {};
  var models = Object.keys(conversions);
  models.forEach(function(fromModel) {
    convert[fromModel] = {};
    Object.defineProperty(convert[fromModel], "channels", { value: conversions[fromModel].channels });
    Object.defineProperty(convert[fromModel], "labels", { value: conversions[fromModel].labels });
    var routes = route(fromModel);
    var routeModels = Object.keys(routes);
    routeModels.forEach(function(toModel) {
      var fn = routes[toModel];
      convert[fromModel][toModel] = wrapRounded(fn);
      convert[fromModel][toModel].raw = wrapRaw(fn);
    });
  });
  module.exports = convert;
});

// node_modules/ansi-styles/index.js
var require_ansi_styles = __commonJS((exports, module) => {
  var assembleStyles = function() {
    const codes = new Map;
    const styles = {
      modifier: {
        reset: [0, 0],
        bold: [1, 22],
        dim: [2, 22],
        italic: [3, 23],
        underline: [4, 24],
        inverse: [7, 27],
        hidden: [8, 28],
        strikethrough: [9, 29]
      },
      color: {
        black: [30, 39],
        red: [31, 39],
        green: [32, 39],
        yellow: [33, 39],
        blue: [34, 39],
        magenta: [35, 39],
        cyan: [36, 39],
        white: [37, 39],
        gray: [90, 39],
        redBright: [91, 39],
        greenBright: [92, 39],
        yellowBright: [93, 39],
        blueBright: [94, 39],
        magentaBright: [95, 39],
        cyanBright: [96, 39],
        whiteBright: [97, 39]
      },
      bgColor: {
        bgBlack: [40, 49],
        bgRed: [41, 49],
        bgGreen: [42, 49],
        bgYellow: [43, 49],
        bgBlue: [44, 49],
        bgMagenta: [45, 49],
        bgCyan: [46, 49],
        bgWhite: [47, 49],
        bgBlackBright: [100, 49],
        bgRedBright: [101, 49],
        bgGreenBright: [102, 49],
        bgYellowBright: [103, 49],
        bgBlueBright: [104, 49],
        bgMagentaBright: [105, 49],
        bgCyanBright: [106, 49],
        bgWhiteBright: [107, 49]
      }
    };
    styles.color.grey = styles.color.gray;
    for (const groupName of Object.keys(styles)) {
      const group = styles[groupName];
      for (const styleName of Object.keys(group)) {
        const style = group[styleName];
        styles[styleName] = {
          open: `\x1B[${style[0]}m`,
          close: `\x1B[${style[1]}m`
        };
        group[styleName] = styles[styleName];
        codes.set(style[0], style[1]);
      }
      Object.defineProperty(styles, groupName, {
        value: group,
        enumerable: false
      });
      Object.defineProperty(styles, "codes", {
        value: codes,
        enumerable: false
      });
    }
    const ansi2ansi = (n) => n;
    const rgb2rgb = (r, g, b) => [r, g, b];
    styles.color.close = "\x1B[39m";
    styles.bgColor.close = "\x1B[49m";
    styles.color.ansi = {
      ansi: wrapAnsi16(ansi2ansi, 0)
    };
    styles.color.ansi256 = {
      ansi256: wrapAnsi256(ansi2ansi, 0)
    };
    styles.color.ansi16m = {
      rgb: wrapAnsi16m(rgb2rgb, 0)
    };
    styles.bgColor.ansi = {
      ansi: wrapAnsi16(ansi2ansi, 10)
    };
    styles.bgColor.ansi256 = {
      ansi256: wrapAnsi256(ansi2ansi, 10)
    };
    styles.bgColor.ansi16m = {
      rgb: wrapAnsi16m(rgb2rgb, 10)
    };
    for (let key of Object.keys(colorConvert)) {
      if (typeof colorConvert[key] !== "object") {
        continue;
      }
      const suite = colorConvert[key];
      if (key === "ansi16") {
        key = "ansi";
      }
      if ("ansi16" in suite) {
        styles.color.ansi[key] = wrapAnsi16(suite.ansi16, 0);
        styles.bgColor.ansi[key] = wrapAnsi16(suite.ansi16, 10);
      }
      if ("ansi256" in suite) {
        styles.color.ansi256[key] = wrapAnsi256(suite.ansi256, 0);
        styles.bgColor.ansi256[key] = wrapAnsi256(suite.ansi256, 10);
      }
      if ("rgb" in suite) {
        styles.color.ansi16m[key] = wrapAnsi16m(suite.rgb, 0);
        styles.bgColor.ansi16m[key] = wrapAnsi16m(suite.rgb, 10);
      }
    }
    return styles;
  };
  var colorConvert = require_color_convert();
  var wrapAnsi16 = (fn, offset) => function() {
    const code = fn.apply(colorConvert, arguments);
    return `\x1B[${code + offset}m`;
  };
  var wrapAnsi256 = (fn, offset) => function() {
    const code = fn.apply(colorConvert, arguments);
    return `\x1B[${38 + offset};5;${code}m`;
  };
  var wrapAnsi16m = (fn, offset) => function() {
    const rgb = fn.apply(colorConvert, arguments);
    return `\x1B[${38 + offset};2;${rgb[0]};${rgb[1]};${rgb[2]}m`;
  };
  Object.defineProperty(module, "exports", {
    enumerable: true,
    get: assembleStyles
  });
});

// node_modules/has-flag/index.js
var require_has_flag = __commonJS((exports, module) => {
  module.exports = (flag, argv) => {
    argv = argv || process.argv;
    const prefix = flag.startsWith("-") ? "" : flag.length === 1 ? "-" : "--";
    const pos = argv.indexOf(prefix + flag);
    const terminatorPos = argv.indexOf("--");
    return pos !== -1 && (terminatorPos === -1 ? true : pos < terminatorPos);
  };
});

// node_modules/supports-color/index.js
var require_supports_color = __commonJS((exports, module) => {
  var translateLevel = function(level) {
    if (level === 0) {
      return false;
    }
    return {
      level,
      hasBasic: true,
      has256: level >= 2,
      has16m: level >= 3
    };
  };
  var supportsColor = function(stream) {
    if (forceColor === false) {
      return 0;
    }
    if (hasFlag("color=16m") || hasFlag("color=full") || hasFlag("color=truecolor")) {
      return 3;
    }
    if (hasFlag("color=256")) {
      return 2;
    }
    if (stream && !stream.isTTY && forceColor !== true) {
      return 0;
    }
    const min = forceColor ? 1 : 0;
    if (process.platform === "win32") {
      const osRelease = os.release().split(".");
      if (Number(process.versions.node.split(".")[0]) >= 8 && Number(osRelease[0]) >= 10 && Number(osRelease[2]) >= 10586) {
        return Number(osRelease[2]) >= 14931 ? 3 : 2;
      }
      return 1;
    }
    if ("CI" in env) {
      if (["TRAVIS", "CIRCLECI", "APPVEYOR", "GITLAB_CI"].some((sign) => (sign in env)) || env.CI_NAME === "codeship") {
        return 1;
      }
      return min;
    }
    if ("TEAMCITY_VERSION" in env) {
      return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0;
    }
    if (env.COLORTERM === "truecolor") {
      return 3;
    }
    if ("TERM_PROGRAM" in env) {
      const version = parseInt((env.TERM_PROGRAM_VERSION || "").split(".")[0], 10);
      switch (env.TERM_PROGRAM) {
        case "iTerm.app":
          return version >= 3 ? 3 : 2;
        case "Apple_Terminal":
          return 2;
      }
    }
    if (/-256(color)?$/i.test(env.TERM)) {
      return 2;
    }
    if (/^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(env.TERM)) {
      return 1;
    }
    if ("COLORTERM" in env) {
      return 1;
    }
    if (env.TERM === "dumb") {
      return min;
    }
    return min;
  };
  var getSupportLevel = function(stream) {
    const level = supportsColor(stream);
    return translateLevel(level);
  };
  var os = __require("os");
  var hasFlag = require_has_flag();
  var env = process.env;
  var forceColor;
  if (hasFlag("no-color") || hasFlag("no-colors") || hasFlag("color=false")) {
    forceColor = false;
  } else if (hasFlag("color") || hasFlag("colors") || hasFlag("color=true") || hasFlag("color=always")) {
    forceColor = true;
  }
  if ("FORCE_COLOR" in env) {
    forceColor = env.FORCE_COLOR.length === 0 || parseInt(env.FORCE_COLOR, 10) !== 0;
  }
  module.exports = {
    supportsColor: getSupportLevel,
    stdout: getSupportLevel(process.stdout),
    stderr: getSupportLevel(process.stderr)
  };
});

// node_modules/chalk/templates.js
var require_templates = __commonJS((exports, module) => {
  var unescape = function(c) {
    if (c[0] === "u" && c.length === 5 || c[0] === "x" && c.length === 3) {
      return String.fromCharCode(parseInt(c.slice(1), 16));
    }
    return ESCAPES.get(c) || c;
  };
  var parseArguments = function(name, args) {
    const results = [];
    const chunks = args.trim().split(/\s*,\s*/g);
    let matches;
    for (const chunk of chunks) {
      if (!isNaN(chunk)) {
        results.push(Number(chunk));
      } else if (matches = chunk.match(STRING_REGEX)) {
        results.push(matches[2].replace(ESCAPE_REGEX, (m, escape, chr) => escape ? unescape(escape) : chr));
      } else {
        throw new Error(`Invalid Chalk template style argument: ${chunk} (in style '${name}')`);
      }
    }
    return results;
  };
  var parseStyle = function(style) {
    STYLE_REGEX.lastIndex = 0;
    const results = [];
    let matches;
    while ((matches = STYLE_REGEX.exec(style)) !== null) {
      const name = matches[1];
      if (matches[2]) {
        const args = parseArguments(name, matches[2]);
        results.push([name].concat(args));
      } else {
        results.push([name]);
      }
    }
    return results;
  };
  var buildStyle = function(chalk, styles) {
    const enabled = {};
    for (const layer of styles) {
      for (const style of layer.styles) {
        enabled[style[0]] = layer.inverse ? null : style.slice(1);
      }
    }
    let current = chalk;
    for (const styleName of Object.keys(enabled)) {
      if (Array.isArray(enabled[styleName])) {
        if (!(styleName in current)) {
          throw new Error(`Unknown Chalk style: ${styleName}`);
        }
        if (enabled[styleName].length > 0) {
          current = current[styleName].apply(current, enabled[styleName]);
        } else {
          current = current[styleName];
        }
      }
    }
    return current;
  };
  var TEMPLATE_REGEX = /(?:\\(u[a-f\d]{4}|x[a-f\d]{2}|.))|(?:\{(~)?(\w+(?:\([^)]*\))?(?:\.\w+(?:\([^)]*\))?)*)(?:[ \t]|(?=\r?\n)))|(\})|((?:.|[\r\n\f])+?)/gi;
  var STYLE_REGEX = /(?:^|\.)(\w+)(?:\(([^)]*)\))?/g;
  var STRING_REGEX = /^(['"])((?:\\.|(?!\1)[^\\])*)\1$/;
  var ESCAPE_REGEX = /\\(u[a-f\d]{4}|x[a-f\d]{2}|.)|([^\\])/gi;
  var ESCAPES = new Map([
    ["n", "\n"],
    ["r", "\r"],
    ["t", "\t"],
    ["b", "\b"],
    ["f", "\f"],
    ["v", "\v"],
    ["0", "\0"],
    ["\\", "\\"],
    ["e", "\x1B"],
    ["a", "\x07"]
  ]);
  module.exports = (chalk, tmp) => {
    const styles = [];
    const chunks = [];
    let chunk = [];
    tmp.replace(TEMPLATE_REGEX, (m, escapeChar, inverse, style, close, chr) => {
      if (escapeChar) {
        chunk.push(unescape(escapeChar));
      } else if (style) {
        const str = chunk.join("");
        chunk = [];
        chunks.push(styles.length === 0 ? str : buildStyle(chalk, styles)(str));
        styles.push({ inverse, styles: parseStyle(style) });
      } else if (close) {
        if (styles.length === 0) {
          throw new Error("Found extraneous } in Chalk template literal");
        }
        chunks.push(buildStyle(chalk, styles)(chunk.join("")));
        chunk = [];
        styles.pop();
      } else {
        chunk.push(chr);
      }
    });
    chunks.push(chunk.join(""));
    if (styles.length > 0) {
      const errMsg = `Chalk template literal is missing ${styles.length} closing bracket${styles.length === 1 ? "" : "s"} (\`}\`)`;
      throw new Error(errMsg);
    }
    return chunks.join("");
  };
});

// node_modules/chalk/index.js
var require_chalk = __commonJS((exports, module) => {
  var applyOptions = function(obj, options) {
    options = options || {};
    const scLevel = stdoutColor ? stdoutColor.level : 0;
    obj.level = options.level === undefined ? scLevel : options.level;
    obj.enabled = ("enabled" in options) ? options.enabled : obj.level > 0;
  };
  var Chalk = function(options) {
    if (!this || !(this instanceof Chalk) || this.template) {
      const chalk = {};
      applyOptions(chalk, options);
      chalk.template = function() {
        const args = [].slice.call(arguments);
        return chalkTag.apply(null, [chalk.template].concat(args));
      };
      Object.setPrototypeOf(chalk, Chalk.prototype);
      Object.setPrototypeOf(chalk.template, chalk);
      chalk.template.constructor = Chalk;
      return chalk.template;
    }
    applyOptions(this, options);
  };
  var build = function(_styles, _empty, key) {
    const builder = function() {
      return applyStyle.apply(builder, arguments);
    };
    builder._styles = _styles;
    builder._empty = _empty;
    const self2 = this;
    Object.defineProperty(builder, "level", {
      enumerable: true,
      get() {
        return self2.level;
      },
      set(level) {
        self2.level = level;
      }
    });
    Object.defineProperty(builder, "enabled", {
      enumerable: true,
      get() {
        return self2.enabled;
      },
      set(enabled) {
        self2.enabled = enabled;
      }
    });
    builder.hasGrey = this.hasGrey || key === "gray" || key === "grey";
    builder.__proto__ = proto;
    return builder;
  };
  var applyStyle = function() {
    const args = arguments;
    const argsLen = args.length;
    let str = String(arguments[0]);
    if (argsLen === 0) {
      return "";
    }
    if (argsLen > 1) {
      for (let a = 1;a < argsLen; a++) {
        str += " " + args[a];
      }
    }
    if (!this.enabled || this.level <= 0 || !str) {
      return this._empty ? "" : str;
    }
    const originalDim = ansiStyles.dim.open;
    if (isSimpleWindowsTerm && this.hasGrey) {
      ansiStyles.dim.open = "";
    }
    for (const code of this._styles.slice().reverse()) {
      str = code.open + str.replace(code.closeRe, code.open) + code.close;
      str = str.replace(/\r?\n/g, `${code.close}\$&${code.open}`);
    }
    ansiStyles.dim.open = originalDim;
    return str;
  };
  var chalkTag = function(chalk, strings) {
    if (!Array.isArray(strings)) {
      return [].slice.call(arguments, 1).join(" ");
    }
    const args = [].slice.call(arguments, 2);
    const parts = [strings.raw[0]];
    for (let i = 1;i < strings.length; i++) {
      parts.push(String(args[i - 1]).replace(/[{}\\]/g, "\\$&"));
      parts.push(String(strings.raw[i]));
    }
    return template(chalk, parts.join(""));
  };
  var escapeStringRegexp = require_escape_string_regexp();
  var ansiStyles = require_ansi_styles();
  var stdoutColor = require_supports_color().stdout;
  var template = require_templates();
  var isSimpleWindowsTerm = process.platform === "win32" && !(process.env.TERM || "").toLowerCase().startsWith("xterm");
  var levelMapping = ["ansi", "ansi", "ansi256", "ansi16m"];
  var skipModels = new Set(["gray"]);
  var styles = Object.create(null);
  if (isSimpleWindowsTerm) {
    ansiStyles.blue.open = "\x1B[94m";
  }
  for (const key of Object.keys(ansiStyles)) {
    ansiStyles[key].closeRe = new RegExp(escapeStringRegexp(ansiStyles[key].close), "g");
    styles[key] = {
      get() {
        const codes = ansiStyles[key];
        return build.call(this, this._styles ? this._styles.concat(codes) : [codes], this._empty, key);
      }
    };
  }
  styles.visible = {
    get() {
      return build.call(this, this._styles || [], true, "visible");
    }
  };
  ansiStyles.color.closeRe = new RegExp(escapeStringRegexp(ansiStyles.color.close), "g");
  for (const model of Object.keys(ansiStyles.color.ansi)) {
    if (skipModels.has(model)) {
      continue;
    }
    styles[model] = {
      get() {
        const level = this.level;
        return function() {
          const open = ansiStyles.color[levelMapping[level]][model].apply(null, arguments);
          const codes = {
            open,
            close: ansiStyles.color.close,
            closeRe: ansiStyles.color.closeRe
          };
          return build.call(this, this._styles ? this._styles.concat(codes) : [codes], this._empty, model);
        };
      }
    };
  }
  ansiStyles.bgColor.closeRe = new RegExp(escapeStringRegexp(ansiStyles.bgColor.close), "g");
  for (const model of Object.keys(ansiStyles.bgColor.ansi)) {
    if (skipModels.has(model)) {
      continue;
    }
    const bgModel = "bg" + model[0].toUpperCase() + model.slice(1);
    styles[bgModel] = {
      get() {
        const level = this.level;
        return function() {
          const open = ansiStyles.bgColor[levelMapping[level]][model].apply(null, arguments);
          const codes = {
            open,
            close: ansiStyles.bgColor.close,
            closeRe: ansiStyles.bgColor.closeRe
          };
          return build.call(this, this._styles ? this._styles.concat(codes) : [codes], this._empty, model);
        };
      }
    };
  }
  var proto = Object.defineProperties(() => {
  }, styles);
  Object.defineProperties(Chalk.prototype, styles);
  module.exports = Chalk();
  module.exports.supportsColor = stdoutColor;
  module.exports.default = module.exports;
});

// node_modules/command-line-usage/lib/section.js
var require_section = __commonJS((exports, module) => {
  class Section {
    constructor() {
      this.lines = [];
    }
    add(lines) {
      if (lines) {
        const arrayify = require_dist2();
        arrayify(lines).forEach((line) => this.lines.push(line));
      } else {
        this.lines.push("");
      }
    }
    toString() {
      const os = __require("os");
      return this.lines.join(os.EOL);
    }
    header(text) {
      const chalk = require_chalk();
      if (text) {
        this.add(chalk.underline.bold(text));
        this.add();
      }
    }
  }
  module.exports = Section;
});

// node_modules/table-layout/lib/ansi.js
var require_ansi = __commonJS((exports) => {
  var remove = function(input) {
    return input.replace(ansiEscapeSequence, "");
  };
  var has = function(input) {
    return ansiEscapeSequence.test(input);
  };
  var ansiEscapeSequence = /\u001b.*?m/g;
  exports.remove = remove;
  exports.has = has;
});

// node_modules/deep-extend/lib/deep-extend.js
var require_deep_extend = __commonJS((exports, module) => {
  var isSpecificValue = function(val) {
    return val instanceof Buffer || val instanceof Date || val instanceof RegExp ? true : false;
  };
  var cloneSpecificValue = function(val) {
    if (val instanceof Buffer) {
      var x = Buffer.alloc ? Buffer.alloc(val.length) : new Buffer(val.length);
      val.copy(x);
      return x;
    } else if (val instanceof Date) {
      return new Date(val.getTime());
    } else if (val instanceof RegExp) {
      return new RegExp(val);
    } else {
      throw new Error("Unexpected situation");
    }
  };
  var deepCloneArray = function(arr) {
    var clone = [];
    arr.forEach(function(item, index) {
      if (typeof item === "object" && item !== null) {
        if (Array.isArray(item)) {
          clone[index] = deepCloneArray(item);
        } else if (isSpecificValue(item)) {
          clone[index] = cloneSpecificValue(item);
        } else {
          clone[index] = deepExtend({}, item);
        }
      } else {
        clone[index] = item;
      }
    });
    return clone;
  };
  var safeGetProperty = function(object, property) {
    return property === "__proto__" ? undefined : object[property];
  };
  /*!
   * @description Recursive object extending
   * @author Viacheslav Lotsmanov <lotsmanov89@gmail.com>
   * @license MIT
   *
   * The MIT License (MIT)
   *
   * Copyright (c) 2013-2018 Viacheslav Lotsmanov
   *
   * Permission is hereby granted, free of charge, to any person obtaining a copy of
   * this software and associated documentation files (the "Software"), to deal in
   * the Software without restriction, including without limitation the rights to
   * use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
   * the Software, and to permit persons to whom the Software is furnished to do so,
   * subject to the following conditions:
   *
   * The above copyright notice and this permission notice shall be included in all
   * copies or substantial portions of the Software.
   *
   * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
   * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
   * FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
   * COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
   * IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
   * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
   */
  var deepExtend = module.exports = function() {
    if (arguments.length < 1 || typeof arguments[0] !== "object") {
      return false;
    }
    if (arguments.length < 2) {
      return arguments[0];
    }
    var target = arguments[0];
    var args = Array.prototype.slice.call(arguments, 1);
    var val, src, clone;
    args.forEach(function(obj) {
      if (typeof obj !== "object" || obj === null || Array.isArray(obj)) {
        return;
      }
      Object.keys(obj).forEach(function(key) {
        src = safeGetProperty(target, key);
        val = safeGetProperty(obj, key);
        if (val === target) {
          return;
        } else if (typeof val !== "object" || val === null) {
          target[key] = val;
          return;
        } else if (Array.isArray(val)) {
          target[key] = deepCloneArray(val);
          return;
        } else if (isSpecificValue(val)) {
          target[key] = cloneSpecificValue(val);
          return;
        } else if (typeof src !== "object" || src === null || Array.isArray(src)) {
          target[key] = deepExtend({}, val);
          return;
        } else {
          target[key] = deepExtend(src, val);
          return;
        }
      });
    });
    return target;
  };
});

// node_modules/table-layout/node_modules/array-back/dist/index.js
var require_dist3 = __commonJS((exports, module) => {
  (function(global2, factory) {
    typeof exports === "object" && typeof module !== "undefined" ? module.exports = factory() : typeof define === "function" && define.amd ? define(factory) : (global2 = global2 || self, global2.arrayBack = factory());
  })(exports, function() {
    function isObject(input) {
      return typeof input === "object" && input !== null;
    }
    function isArrayLike(input) {
      return isObject(input) && typeof input.length === "number";
    }
    function arrayify(input) {
      if (Array.isArray(input)) {
        return input;
      }
      if (input === undefined) {
        return [];
      }
      if (isArrayLike(input) || input instanceof Set) {
        return Array.from(input);
      }
      return [input];
    }
    return arrayify;
  });
});

// node_modules/table-layout/node_modules/typical/dist/index.js
var require_dist4 = __commonJS((exports, module) => {
  (function(global2, factory) {
    typeof exports === "object" && typeof module !== "undefined" ? factory(exports) : typeof define === "function" && define.amd ? define(["exports"], factory) : (global2 = global2 || self, factory(global2.typical = {}));
  })(exports, function(exports2) {
    function isNumber(n) {
      return !isNaN(parseFloat(n)) && isFinite(n);
    }
    function isPlainObject(input) {
      return input !== null && typeof input === "object" && input.constructor === Object;
    }
    function isArrayLike(input) {
      return isObject(input) && typeof input.length === "number";
    }
    function isObject(input) {
      return typeof input === "object" && input !== null;
    }
    function isDefined(input) {
      return typeof input !== "undefined";
    }
    function isUndefined(input) {
      return !isDefined(input);
    }
    function isNull(input) {
      return input === null;
    }
    function isDefinedValue(input) {
      return isDefined(input) && !isNull(input) && !Number.isNaN(input);
    }
    function isClass(input) {
      if (typeof input === "function") {
        return /^class /.test(Function.prototype.toString.call(input));
      } else {
        return false;
      }
    }
    function isPrimitive(input) {
      if (input === null)
        return true;
      switch (typeof input) {
        case "string":
        case "number":
        case "symbol":
        case "undefined":
        case "boolean":
          return true;
        default:
          return false;
      }
    }
    function isPromise(input) {
      if (input) {
        const isPromise2 = isDefined(Promise) && input instanceof Promise;
        const isThenable = input.then && typeof input.then === "function";
        return !!(isPromise2 || isThenable);
      } else {
        return false;
      }
    }
    function isIterable(input) {
      if (input === null || !isDefined(input)) {
        return false;
      } else {
        return typeof input[Symbol.iterator] === "function" || typeof input[Symbol.asyncIterator] === "function";
      }
    }
    function isString(input) {
      return typeof input === "string";
    }
    function isFunction(input) {
      return typeof input === "function";
    }
    var index = {
      isNumber,
      isPlainObject,
      isArrayLike,
      isObject,
      isDefined,
      isUndefined,
      isNull,
      isDefinedValue,
      isClass,
      isPrimitive,
      isPromise,
      isIterable,
      isString,
      isFunction
    };
    exports2.default = index;
    exports2.isArrayLike = isArrayLike;
    exports2.isClass = isClass;
    exports2.isDefined = isDefined;
    exports2.isDefinedValue = isDefinedValue;
    exports2.isFunction = isFunction;
    exports2.isIterable = isIterable;
    exports2.isNull = isNull;
    exports2.isNumber = isNumber;
    exports2.isObject = isObject;
    exports2.isPlainObject = isPlainObject;
    exports2.isPrimitive = isPrimitive;
    exports2.isPromise = isPromise;
    exports2.isString = isString;
    exports2.isUndefined = isUndefined;
    Object.defineProperty(exports2, "__esModule", { value: true });
  });
});

// node_modules/table-layout/lib/cell.js
var require_cell = __commonJS((exports, module) => {
  var t = require_dist4();
  var _value = new WeakMap;
  var _column = new WeakMap;

  class Cell {
    constructor(value, column) {
      this.value = value;
      _column.set(this, column);
    }
    set value(val) {
      _value.set(this, val);
    }
    get value() {
      let cellValue = _value.get(this);
      if (typeof cellValue === "function")
        cellValue = cellValue.call(_column.get(this));
      if (cellValue === undefined) {
        cellValue = "";
      } else {
        cellValue = String(cellValue);
      }
      return cellValue;
    }
  }
  module.exports = Cell;
});

// node_modules/table-layout/lib/rows.js
var require_rows = __commonJS((exports, module) => {
  var objectToIterable = function(row, columns) {
    return columns.list.map((column) => {
      return [column, new Cell(row[column.name], column)];
    });
  };
  var arrayify = require_dist3();
  var Cell = require_cell();
  var t = require_dist4();

  class Rows {
    constructor(rows, columns) {
      this.list = [];
      this.load(rows, columns);
    }
    load(rows, columns) {
      arrayify(rows).forEach((row) => {
        this.list.push(new Map(objectToIterable(row, columns)));
      });
    }
    static removeEmptyColumns(data) {
      const distinctColumnNames = data.reduce((columnNames, row) => {
        Object.keys(row).forEach((key) => {
          if (columnNames.indexOf(key) === -1)
            columnNames.push(key);
        });
        return columnNames;
      }, []);
      const emptyColumns = distinctColumnNames.filter((columnName) => {
        const hasValue = data.some((row) => {
          const value = row[columnName];
          return t.isDefined(value) && typeof value !== "string" || typeof value === "string" && /\S+/.test(value);
        });
        return !hasValue;
      });
      return data.map((row) => {
        emptyColumns.forEach((emptyCol) => delete row[emptyCol]);
        return row;
      });
    }
  }
  module.exports = Rows;
});

// node_modules/table-layout/lib/padding.js
var require_padding = __commonJS((exports, module) => {
  class Padding {
    constructor(padding) {
      this.left = padding.left;
      this.right = padding.right;
    }
    length() {
      return this.left.length + this.right.length;
    }
  }
  module.exports = Padding;
});

// node_modules/table-layout/lib/column.js
var require_column = __commonJS((exports, module) => {
  var t = require_dist4();
  var Padding = require_padding();
  var _padding = new WeakMap;

  class Column {
    constructor(column) {
      if (t.isDefined(column.name))
        this.name = column.name;
      if (t.isDefined(column.width))
        this.width = column.width;
      if (t.isDefined(column.maxWidth))
        this.maxWidth = column.maxWidth;
      if (t.isDefined(column.minWidth))
        this.minWidth = column.minWidth;
      if (t.isDefined(column.noWrap))
        this.noWrap = column.noWrap;
      if (t.isDefined(column.break))
        this.break = column.break;
      if (t.isDefined(column.contentWrappable))
        this.contentWrappable = column.contentWrappable;
      if (t.isDefined(column.contentWidth))
        this.contentWidth = column.contentWidth;
      if (t.isDefined(column.minContentWidth))
        this.minContentWidth = column.minContentWidth;
      this.padding = column.padding || { left: " ", right: " " };
      this.generatedWidth = null;
    }
    set padding(padding) {
      _padding.set(this, new Padding(padding));
    }
    get padding() {
      return _padding.get(this);
    }
    get wrappedContentWidth() {
      return Math.max(this.generatedWidth - this.padding.length(), 0);
    }
    isResizable() {
      return !this.isFixed();
    }
    isFixed() {
      return t.isDefined(this.width) || this.noWrap || !this.contentWrappable;
    }
    generateWidth() {
      this.generatedWidth = this.width || this.contentWidth + this.padding.length();
    }
    generateMinWidth() {
      this.minWidth = this.minContentWidth + this.padding.length();
    }
  }
  module.exports = Column;
});

// node_modules/wordwrapjs/node_modules/typical/dist/index.js
var require_dist5 = __commonJS((exports, module) => {
  (function(global2, factory) {
    typeof exports === "object" && typeof module !== "undefined" ? factory(exports) : typeof define === "function" && define.amd ? define(["exports"], factory) : (global2 = global2 || self, factory(global2.typical = {}));
  })(exports, function(exports2) {
    function isNumber(n) {
      return !isNaN(parseFloat(n)) && isFinite(n);
    }
    function isPlainObject(input) {
      return input !== null && typeof input === "object" && input.constructor === Object;
    }
    function isArrayLike(input) {
      return isObject(input) && typeof input.length === "number";
    }
    function isObject(input) {
      return typeof input === "object" && input !== null;
    }
    function isDefined(input) {
      return typeof input !== "undefined";
    }
    function isUndefined(input) {
      return !isDefined(input);
    }
    function isNull(input) {
      return input === null;
    }
    function isDefinedValue(input) {
      return isDefined(input) && !isNull(input) && !Number.isNaN(input);
    }
    function isClass(input) {
      if (typeof input === "function") {
        return /^class /.test(Function.prototype.toString.call(input));
      } else {
        return false;
      }
    }
    function isPrimitive(input) {
      if (input === null)
        return true;
      switch (typeof input) {
        case "string":
        case "number":
        case "symbol":
        case "undefined":
        case "boolean":
          return true;
        default:
          return false;
      }
    }
    function isPromise(input) {
      if (input) {
        const isPromise2 = isDefined(Promise) && input instanceof Promise;
        const isThenable = input.then && typeof input.then === "function";
        return !!(isPromise2 || isThenable);
      } else {
        return false;
      }
    }
    function isIterable(input) {
      if (input === null || !isDefined(input)) {
        return false;
      } else {
        return typeof input[Symbol.iterator] === "function" || typeof input[Symbol.asyncIterator] === "function";
      }
    }
    function isString(input) {
      return typeof input === "string";
    }
    function isFunction(input) {
      return typeof input === "function";
    }
    var index = {
      isNumber,
      isPlainObject,
      isArrayLike,
      isObject,
      isDefined,
      isUndefined,
      isNull,
      isDefinedValue,
      isClass,
      isPrimitive,
      isPromise,
      isIterable,
      isString,
      isFunction
    };
    exports2.default = index;
    exports2.isArrayLike = isArrayLike;
    exports2.isClass = isClass;
    exports2.isDefined = isDefined;
    exports2.isDefinedValue = isDefinedValue;
    exports2.isFunction = isFunction;
    exports2.isIterable = isIterable;
    exports2.isNull = isNull;
    exports2.isNumber = isNumber;
    exports2.isObject = isObject;
    exports2.isPlainObject = isPlainObject;
    exports2.isPrimitive = isPrimitive;
    exports2.isPromise = isPromise;
    exports2.isString = isString;
    exports2.isUndefined = isUndefined;
    Object.defineProperty(exports2, "__esModule", { value: true });
  });
});

// node_modules/reduce-flatten/index.js
var require_reduce_flatten = __commonJS((exports, module) => {
  var flatten = function(prev, curr) {
    return prev.concat(curr);
  };
  module.exports = flatten;
});

// node_modules/wordwrapjs/index.js
var require_wordwrapjs = __commonJS((exports, module) => {
  var trimLine = function(line) {
    return this.options.noTrim ? line : line.trim();
  };
  var replaceAnsi = function(string) {
    return string.replace(re.ansiEscapeSequence, "");
  };
  var breakWord = function(word) {
    if (replaceAnsi(word).length > this.options.width) {
      const letters = word.split("");
      let piece;
      const pieces = [];
      while ((piece = letters.splice(0, this.options.width)).length) {
        pieces.push(piece.join(""));
      }
      return pieces;
    } else {
      return word;
    }
  };
  var os = __require("os");
  var t = require_dist5();
  var re = {
    chunk: /[^\s-]+?-\b|\S+|\s+|\r\n?|\n/g,
    ansiEscapeSequence: /\u001b.*?m/g
  };

  class WordWrap {
    constructor(text, options) {
      options = options || {};
      if (!t.isDefined(text))
        text = "";
      this._lines = String(text).split(/\r\n|\n/g);
      this.options = options;
      this.options.width = options.width === undefined ? 30 : options.width;
    }
    lines() {
      const flatten = require_reduce_flatten();
      return this._lines.map(trimLine.bind(this)).map((line) => line.match(re.chunk) || ["~~empty~~"]).map((lineWords) => {
        if (this.options.break) {
          return lineWords.map(breakWord.bind(this));
        } else {
          return lineWords;
        }
      }).map((lineWords) => lineWords.reduce(flatten, [])).map((lineWords) => {
        return lineWords.reduce((lines, word) => {
          let currentLine = lines[lines.length - 1];
          if (replaceAnsi(word).length + replaceAnsi(currentLine).length > this.options.width) {
            lines.push(word);
          } else {
            lines[lines.length - 1] += word;
          }
          return lines;
        }, [""]);
      }).reduce(flatten, []).map(trimLine.bind(this)).filter((line) => line.trim()).map((line) => line.replace("~~empty~~", ""));
    }
    wrap() {
      return this.lines().join(os.EOL);
    }
    toString() {
      return this.wrap();
    }
    static wrap(text, options) {
      const block = new this(text, options);
      return block.wrap();
    }
    static lines(text, options) {
      const block = new this(text, options);
      return block.lines();
    }
    static isWrappable(text) {
      if (t.isDefined(text)) {
        text = String(text);
        var matches = text.match(re.chunk);
        return matches ? matches.length > 1 : false;
      }
    }
    static getChunks(text) {
      return text.match(re.chunk) || [];
    }
  }
  module.exports = WordWrap;
});

// node_modules/table-layout/lib/columns.js
var require_columns = __commonJS((exports, module) => {
  var getLongestWord = function(line) {
    const words = wrap.getChunks(line);
    return words.reduce((max, word) => {
      return Math.max(word.length, max);
    }, 0);
  };
  var t = require_dist4();
  var arrayify = require_dist3();
  var Column = require_column();
  var wrap = require_wordwrapjs();
  var Cell = require_cell();
  var ansi = require_ansi();
  var _maxWidth = new WeakMap;

  class Columns {
    constructor(columns) {
      this.list = [];
      arrayify(columns).forEach(this.add.bind(this));
    }
    totalWidth() {
      return this.list.length ? this.list.map((col) => col.generatedWidth).reduce((a, b) => a + b) : 0;
    }
    totalFixedWidth() {
      return this.getFixed().map((col) => col.generatedWidth).reduce((a, b) => a + b, 0);
    }
    get(columnName) {
      return this.list.find((column) => column.name === columnName);
    }
    getResizable() {
      return this.list.filter((column) => column.isResizable());
    }
    getFixed() {
      return this.list.filter((column) => column.isFixed());
    }
    add(column) {
      const col = column instanceof Column ? column : new Column(column);
      this.list.push(col);
      return col;
    }
    set maxWidth(val) {
      _maxWidth.set(this, val);
    }
    autoSize() {
      const maxWidth = _maxWidth.get(this);
      this.list.forEach((column) => {
        column.generateWidth();
        column.generateMinWidth();
      });
      this.list.forEach((column) => {
        if (t.isDefined(column.maxWidth) && column.generatedWidth > column.maxWidth) {
          column.generatedWidth = column.maxWidth;
        }
        if (t.isDefined(column.minWidth) && column.generatedWidth < column.minWidth) {
          column.generatedWidth = column.minWidth;
        }
      });
      const width = {
        total: this.totalWidth(),
        view: maxWidth,
        diff: this.totalWidth() - maxWidth,
        totalFixed: this.totalFixedWidth(),
        totalResizable: Math.max(maxWidth - this.totalFixedWidth(), 0)
      };
      if (width.diff > 0) {
        let resizableColumns = this.getResizable();
        resizableColumns.forEach((column) => {
          column.generatedWidth = Math.floor(width.totalResizable / resizableColumns.length);
        });
        const grownColumns = this.list.filter((column) => column.generatedWidth > column.contentWidth);
        const shrunkenColumns = this.list.filter((column) => column.generatedWidth < column.contentWidth);
        let salvagedSpace = 0;
        grownColumns.forEach((column) => {
          const currentGeneratedWidth = column.generatedWidth;
          column.generateWidth();
          salvagedSpace += currentGeneratedWidth - column.generatedWidth;
        });
        shrunkenColumns.forEach((column) => {
          column.generatedWidth += Math.floor(salvagedSpace / shrunkenColumns.length);
        });
      }
      return this;
    }
    static getColumns(rows) {
      var columns = new Columns;
      arrayify(rows).forEach((row) => {
        for (let columnName in row) {
          let column = columns.get(columnName);
          if (!column) {
            column = columns.add({ name: columnName, contentWidth: 0, minContentWidth: 0 });
          }
          let cell = new Cell(row[columnName], column);
          let cellValue = cell.value;
          if (ansi.has(cellValue)) {
            cellValue = ansi.remove(cellValue);
          }
          if (cellValue.length > column.contentWidth)
            column.contentWidth = cellValue.length;
          let longestWord = getLongestWord(cellValue);
          if (longestWord > column.minContentWidth) {
            column.minContentWidth = longestWord;
          }
          if (!column.contentWrappable)
            column.contentWrappable = wrap.isWrappable(cellValue);
        }
      });
      return columns;
    }
  }
  module.exports = Columns;
});

// node_modules/table-layout/index.js
var require_table_layout = __commonJS((exports, module) => {
  var getLongestArray = function(arrays) {
    var lengths = arrays.map((array) => array.length);
    return Math.max.apply(null, lengths);
  };
  var padCell = function(cellValue, padding, width) {
    const ansi = require_ansi();
    var ansiLength = cellValue.length - ansi.remove(cellValue).length;
    cellValue = cellValue || "";
    return (padding.left || "") + cellValue.padEnd(width - padding.length() + ansiLength) + (padding.right || "");
  };
  var os = __require("os");

  class Table {
    constructor(data, options) {
      let ttyWidth = process && (process.stdout.columns || process.stderr.columns) || 0;
      if (ttyWidth && os.platform() === "win32")
        ttyWidth--;
      let defaults = {
        padding: {
          left: " ",
          right: " "
        },
        maxWidth: ttyWidth || 80,
        columns: []
      };
      const extend = require_deep_extend();
      this.options = extend(defaults, options);
      this.load(data);
    }
    load(data) {
      const Rows = require_rows();
      const Columns = require_columns();
      let options = this.options;
      if (options.ignoreEmptyColumns) {
        data = Rows.removeEmptyColumns(data);
      }
      this.columns = Columns.getColumns(data);
      this.rows = new Rows(data, this.columns);
      this.columns.maxWidth = options.maxWidth;
      this.columns.list.forEach((column) => {
        if (options.padding)
          column.padding = options.padding;
        if (options.noWrap)
          column.noWrap = options.noWrap;
        if (options.break) {
          column.break = options.break;
          column.contentWrappable = true;
        }
      });
      options.columns.forEach((optionColumn) => {
        let column = this.columns.get(optionColumn.name);
        if (column) {
          if (optionColumn.padding) {
            column.padding.left = optionColumn.padding.left;
            column.padding.right = optionColumn.padding.right;
          }
          if (optionColumn.width)
            column.width = optionColumn.width;
          if (optionColumn.maxWidth)
            column.maxWidth = optionColumn.maxWidth;
          if (optionColumn.minWidth)
            column.minWidth = optionColumn.minWidth;
          if (optionColumn.noWrap)
            column.noWrap = optionColumn.noWrap;
          if (optionColumn.break) {
            column.break = optionColumn.break;
            column.contentWrappable = true;
          }
        }
      });
      this.columns.autoSize();
      return this;
    }
    getWrapped() {
      const wrap = require_wordwrapjs();
      this.columns.autoSize();
      return this.rows.list.map((row) => {
        let line = [];
        row.forEach((cell, column) => {
          if (column.noWrap) {
            line.push(cell.value.split(/\r\n?|\n/));
          } else {
            line.push(wrap.lines(cell.value, {
              width: column.wrappedContentWidth,
              break: column.break,
              noTrim: this.options.noTrim
            }));
          }
        });
        return line;
      });
    }
    getLines() {
      var wrappedLines = this.getWrapped();
      var lines = [];
      wrappedLines.forEach((wrapped) => {
        let mostLines = getLongestArray(wrapped);
        for (let i = 0;i < mostLines; i++) {
          let line = [];
          wrapped.forEach((cell) => {
            line.push(cell[i] || "");
          });
          lines.push(line);
        }
      });
      return lines;
    }
    renderLines() {
      var lines = this.getLines();
      return lines.map((line) => {
        return line.reduce((prev, cell, index) => {
          let column = this.columns.list[index];
          return prev + padCell(cell, column.padding, column.generatedWidth);
        }, "");
      });
    }
    toString() {
      return this.renderLines().join(os.EOL) + os.EOL;
    }
  }
  module.exports = Table;
});

// node_modules/command-line-usage/lib/chalk-format.js
var require_chalk_format = __commonJS((exports, module) => {
  var chalkFormat = function(str) {
    if (str) {
      str = str.replace(/`/g, "\\`");
      const chalk = require_chalk();
      return chalk(Object.assign([], { raw: [str] }));
    } else {
      return "";
    }
  };
  module.exports = chalkFormat;
});

// node_modules/command-line-usage/node_modules/typical/dist/index.js
var require_dist6 = __commonJS((exports, module) => {
  (function(global2, factory) {
    typeof exports === "object" && typeof module !== "undefined" ? factory(exports) : typeof define === "function" && define.amd ? define(["exports"], factory) : (global2 = global2 || self, factory(global2.typical = {}));
  })(exports, function(exports2) {
    function isNumber(n) {
      return !isNaN(parseFloat(n)) && isFinite(n);
    }
    function isPlainObject(input) {
      return input !== null && typeof input === "object" && input.constructor === Object;
    }
    function isArrayLike(input) {
      return isObject(input) && typeof input.length === "number";
    }
    function isObject(input) {
      return typeof input === "object" && input !== null;
    }
    function isDefined(input) {
      return typeof input !== "undefined";
    }
    function isUndefined(input) {
      return !isDefined(input);
    }
    function isNull(input) {
      return input === null;
    }
    function isDefinedValue(input) {
      return isDefined(input) && !isNull(input) && !Number.isNaN(input);
    }
    function isClass(input) {
      if (typeof input === "function") {
        return /^class /.test(Function.prototype.toString.call(input));
      } else {
        return false;
      }
    }
    function isPrimitive(input) {
      if (input === null)
        return true;
      switch (typeof input) {
        case "string":
        case "number":
        case "symbol":
        case "undefined":
        case "boolean":
          return true;
        default:
          return false;
      }
    }
    function isPromise(input) {
      if (input) {
        const isPromise2 = isDefined(Promise) && input instanceof Promise;
        const isThenable = input.then && typeof input.then === "function";
        return !!(isPromise2 || isThenable);
      } else {
        return false;
      }
    }
    function isIterable(input) {
      if (input === null || !isDefined(input)) {
        return false;
      } else {
        return typeof input[Symbol.iterator] === "function" || typeof input[Symbol.asyncIterator] === "function";
      }
    }
    function isString(input) {
      return typeof input === "string";
    }
    function isFunction(input) {
      return typeof input === "function";
    }
    var index = {
      isNumber,
      isPlainObject,
      isArrayLike,
      isObject,
      isDefined,
      isUndefined,
      isNull,
      isDefinedValue,
      isClass,
      isPrimitive,
      isPromise,
      isIterable,
      isString,
      isFunction
    };
    exports2.default = index;
    exports2.isArrayLike = isArrayLike;
    exports2.isClass = isClass;
    exports2.isDefined = isDefined;
    exports2.isDefinedValue = isDefinedValue;
    exports2.isFunction = isFunction;
    exports2.isIterable = isIterable;
    exports2.isNull = isNull;
    exports2.isNumber = isNumber;
    exports2.isObject = isObject;
    exports2.isPlainObject = isPlainObject;
    exports2.isPrimitive = isPrimitive;
    exports2.isPromise = isPromise;
    exports2.isString = isString;
    exports2.isUndefined = isUndefined;
    Object.defineProperty(exports2, "__esModule", { value: true });
  });
});

// node_modules/command-line-usage/lib/section/option-list.js
var require_option_list = __commonJS((exports, module) => {
  var getOptionNames = function(definition, reverseNameOrder) {
    let type = definition.type ? definition.type.name.toLowerCase() : "string";
    const multiple = definition.multiple || definition.lazyMultiple ? "[]" : "";
    if (type) {
      type = type === "boolean" ? "" : `{underline ${type}${multiple}}`;
    }
    type = chalk(definition.typeLabel || type);
    let result = "";
    if (definition.alias) {
      if (definition.name) {
        if (reverseNameOrder) {
          result = chalk(`{bold --${definition.name}}, {bold -${definition.alias}} ${type}`);
        } else {
          result = chalk(`{bold -${definition.alias}}, {bold --${definition.name}} ${type}`);
        }
      } else {
        if (reverseNameOrder) {
          result = chalk(`{bold -${definition.alias}} ${type}`);
        } else {
          result = chalk(`{bold -${definition.alias}} ${type}`);
        }
      }
    } else {
      result = chalk(`{bold --${definition.name}} ${type}`);
    }
    return result;
  };
  var intersect = function(arr1, arr2) {
    return arr1.some(function(item1) {
      return arr2.some(function(item2) {
        return item1 === item2;
      });
    });
  };
  var Section = require_section();
  var Table = require_table_layout();
  var chalk = require_chalk_format();
  var t = require_dist6();
  var arrayify = require_dist2();

  class OptionList extends Section {
    constructor(data) {
      super();
      let definitions = arrayify(data.optionList);
      const hide = arrayify(data.hide);
      const groups = arrayify(data.group);
      if (hide.length) {
        definitions = definitions.filter((definition) => {
          return hide.indexOf(definition.name) === -1;
        });
      }
      if (data.header)
        this.header(data.header);
      if (groups.length) {
        definitions = definitions.filter((def) => {
          const noGroupMatch = groups.indexOf("_none") > -1 && !t.isDefined(def.group);
          const groupMatch = intersect(arrayify(def.group), groups);
          if (noGroupMatch || groupMatch)
            return def;
        });
      }
      const rows = definitions.map((def) => {
        return {
          option: getOptionNames(def, data.reverseNameOrder),
          description: chalk(def.description)
        };
      });
      const tableOptions = data.tableOptions || {
        padding: { left: "  ", right: " " },
        columns: [
          { name: "option", noWrap: true },
          { name: "description", maxWidth: 80 }
        ]
      };
      const table = new Table(rows, tableOptions);
      this.add(table.renderLines());
      this.add();
    }
  }
  module.exports = OptionList;
});

// node_modules/command-line-usage/lib/section/content.js
var require_content = __commonJS((exports, module) => {
  var getContentLines = function(content) {
    const defaultPadding = { left: "  ", right: " " };
    if (content) {
      if (t.isString(content)) {
        const table = new Table({ column: chalkFormat(content) }, {
          padding: defaultPadding,
          maxWidth: 80
        });
        return table.renderLines();
      } else if (Array.isArray(content) && content.every(t.isString)) {
        const rows = content.map((string) => ({ column: chalkFormat(string) }));
        const table = new Table(rows, {
          padding: defaultPadding,
          maxWidth: 80
        });
        return table.renderLines();
      } else if (Array.isArray(content) && content.every(t.isPlainObject)) {
        const table = new Table(content.map((row) => ansiFormatRow(row)), {
          padding: defaultPadding
        });
        return table.renderLines();
      } else if (t.isPlainObject(content)) {
        if (!content.options || !content.data) {
          throw new Error('must have an "options" or "data" property\n' + JSON.stringify(content));
        }
        const options = Object.assign({ padding: defaultPadding }, content.options);
        if (options.columns) {
          options.columns = options.columns.map((column) => {
            if (column.nowrap) {
              column.noWrap = column.nowrap;
              delete column.nowrap;
            }
            return column;
          });
        }
        const table = new Table(content.data.map((row) => ansiFormatRow(row)), options);
        return table.renderLines();
      } else {
        const message = `invalid input - 'content' must be a string, array of strings, or array of plain objects:\n\n${JSON.stringify(content)}`;
        throw new Error(message);
      }
    }
  };
  var ansiFormatRow = function(row) {
    for (const key in row) {
      row[key] = chalkFormat(row[key]);
    }
    return row;
  };
  var Section = require_section();
  var t = require_dist6();
  var Table = require_table_layout();
  var chalkFormat = require_chalk_format();

  class ContentSection extends Section {
    constructor(section) {
      super();
      this.header(section.header);
      if (section.content) {
        if (section.raw) {
          const arrayify = require_dist2();
          const content = arrayify(section.content).map((line) => chalkFormat(line));
          this.add(content);
        } else {
          this.add(getContentLines(section.content));
        }
        this.add();
      }
    }
  }
  module.exports = ContentSection;
});

// node_modules/command-line-usage/index.js
var require_command_line_usage = __commonJS((exports, module) => {
  var commandLineUsage = function(sections) {
    const arrayify = require_dist2();
    sections = arrayify(sections);
    if (sections.length) {
      const OptionList = require_option_list();
      const ContentSection = require_content();
      const output = sections.map((section) => {
        if (section.optionList) {
          return new OptionList(section);
        } else {
          return new ContentSection(section);
        }
      });
      return "\n" + output.join("\n");
    } else {
      return "";
    }
  };
  module.exports = commandLineUsage;
});

// node_modules/@treecg/types/dist/lib/Bucketizer.js
var require_Bucketizer = __commonJS((exports) => {
  exports.__esModule = true;
});

// node_modules/@treecg/types/dist/lib/BucketizerOptions.js
var require_BucketizerOptions = __commonJS((exports) => {
  exports.__esModule = true;
});

// node_modules/@treecg/types/dist/lib/Fragment.js
var require_Fragment = __commonJS((exports) => {
  exports.__esModule = true;
});

// node_modules/@treecg/types/dist/lib/Member.js
var require_Member = __commonJS((exports) => {
  exports.__esModule = true;
});

// node_modules/@treecg/types/dist/lib/RelationParameters.js
var require_RelationParameters = __commonJS((exports) => {
  exports.__esModule = true;
  exports.RelationType = undefined;
  var RelationType;
  (function(RelationType2) {
    RelationType2["Relation"] = "https://w3id.org/tree#Relation";
    RelationType2["Substring"] = "https://w3id.org/tree#SubstringRelation";
    RelationType2["Prefix"] = "https://w3id.org/tree#PrefixRelation";
    RelationType2["Suffix"] = "https://w3id.org/tree#SuffixRelation";
    RelationType2["GreaterThan"] = "https://w3id.org/tree#GreaterThanRelation";
    RelationType2["GreaterThanOrEqualTo"] = "https://w3id.org/tree#GreaterThanOrEqualToRelation";
    RelationType2["LessThan"] = "https://w3id.org/tree#LessThanRelation";
    RelationType2["LessThanOrEqualTo"] = "https://w3id.org/tree#LessThanOrEqualToRelation";
    RelationType2["EqualThan"] = "https://w3id.org/tree#EqualThanRelation";
    RelationType2["GeospatiallyContains"] = "https://w3id.org/tree#GeospatiallyContainsRelation";
  })(RelationType = exports.RelationType || (exports.RelationType = {}));
});

// node_modules/loglevel/lib/loglevel.js
var require_loglevel = __commonJS((exports, module) => {
  (function(root, definition) {
    if (typeof define === "function" && define.amd) {
      define(definition);
    } else if (typeof module === "object" && exports) {
      module.exports = definition();
    } else {
      root.log = definition();
    }
  })(exports, function() {
    var noop = function() {
    };
    var undefinedType = "undefined";
    var isIE = typeof window !== undefinedType && typeof window.navigator !== undefinedType && /Trident\/|MSIE /.test(window.navigator.userAgent);
    var logMethods = [
      "trace",
      "debug",
      "info",
      "warn",
      "error"
    ];
    function bindMethod(obj, methodName) {
      var method = obj[methodName];
      if (typeof method.bind === "function") {
        return method.bind(obj);
      } else {
        try {
          return Function.prototype.bind.call(method, obj);
        } catch (e) {
          return function() {
            return Function.prototype.apply.apply(method, [obj, arguments]);
          };
        }
      }
    }
    function traceForIE() {
      if (console.log) {
        if (console.log.apply) {
          console.log.apply(console, arguments);
        } else {
          Function.prototype.apply.apply(console.log, [console, arguments]);
        }
      }
      if (console.trace)
        console.trace();
    }
    function realMethod(methodName) {
      if (methodName === "debug") {
        methodName = "log";
      }
      if (typeof console === undefinedType) {
        return false;
      } else if (methodName === "trace" && isIE) {
        return traceForIE;
      } else if (console[methodName] !== undefined) {
        return bindMethod(console, methodName);
      } else if (console.log !== undefined) {
        return bindMethod(console, "log");
      } else {
        return noop;
      }
    }
    function replaceLoggingMethods(level, loggerName) {
      for (var i = 0;i < logMethods.length; i++) {
        var methodName = logMethods[i];
        this[methodName] = i < level ? noop : this.methodFactory(methodName, level, loggerName);
      }
      this.log = this.debug;
    }
    function enableLoggingWhenConsoleArrives(methodName, level, loggerName) {
      return function() {
        if (typeof console !== undefinedType) {
          replaceLoggingMethods.call(this, level, loggerName);
          this[methodName].apply(this, arguments);
        }
      };
    }
    function defaultMethodFactory(methodName, level, loggerName) {
      return realMethod(methodName) || enableLoggingWhenConsoleArrives.apply(this, arguments);
    }
    function Logger(name, defaultLevel, factory) {
      var self2 = this;
      var currentLevel;
      defaultLevel = defaultLevel == null ? "WARN" : defaultLevel;
      var storageKey = "loglevel";
      if (typeof name === "string") {
        storageKey += ":" + name;
      } else if (typeof name === "symbol") {
        storageKey = undefined;
      }
      function persistLevelIfPossible(levelNum) {
        var levelName = (logMethods[levelNum] || "silent").toUpperCase();
        if (typeof window === undefinedType || !storageKey)
          return;
        try {
          window.localStorage[storageKey] = levelName;
          return;
        } catch (ignore) {
        }
        try {
          window.document.cookie = encodeURIComponent(storageKey) + "=" + levelName + ";";
        } catch (ignore) {
        }
      }
      function getPersistedLevel() {
        var storedLevel;
        if (typeof window === undefinedType || !storageKey)
          return;
        try {
          storedLevel = window.localStorage[storageKey];
        } catch (ignore) {
        }
        if (typeof storedLevel === undefinedType) {
          try {
            var cookie = window.document.cookie;
            var location = cookie.indexOf(encodeURIComponent(storageKey) + "=");
            if (location !== -1) {
              storedLevel = /^([^;]+)/.exec(cookie.slice(location))[1];
            }
          } catch (ignore) {
          }
        }
        if (self2.levels[storedLevel] === undefined) {
          storedLevel = undefined;
        }
        return storedLevel;
      }
      function clearPersistedLevel() {
        if (typeof window === undefinedType || !storageKey)
          return;
        try {
          window.localStorage.removeItem(storageKey);
          return;
        } catch (ignore) {
        }
        try {
          window.document.cookie = encodeURIComponent(storageKey) + "=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
        } catch (ignore) {
        }
      }
      self2.name = name;
      self2.levels = {
        TRACE: 0,
        DEBUG: 1,
        INFO: 2,
        WARN: 3,
        ERROR: 4,
        SILENT: 5
      };
      self2.methodFactory = factory || defaultMethodFactory;
      self2.getLevel = function() {
        return currentLevel;
      };
      self2.setLevel = function(level, persist) {
        if (typeof level === "string" && self2.levels[level.toUpperCase()] !== undefined) {
          level = self2.levels[level.toUpperCase()];
        }
        if (typeof level === "number" && level >= 0 && level <= self2.levels.SILENT) {
          currentLevel = level;
          if (persist !== false) {
            persistLevelIfPossible(level);
          }
          replaceLoggingMethods.call(self2, level, name);
          if (typeof console === undefinedType && level < self2.levels.SILENT) {
            return "No console available for logging";
          }
        } else {
          throw "log.setLevel() called with invalid level: " + level;
        }
      };
      self2.setDefaultLevel = function(level) {
        defaultLevel = level;
        if (!getPersistedLevel()) {
          self2.setLevel(level, false);
        }
      };
      self2.resetLevel = function() {
        self2.setLevel(defaultLevel, false);
        clearPersistedLevel();
      };
      self2.enableAll = function(persist) {
        self2.setLevel(self2.levels.TRACE, persist);
      };
      self2.disableAll = function(persist) {
        self2.setLevel(self2.levels.SILENT, persist);
      };
      var initialLevel = getPersistedLevel();
      if (initialLevel == null) {
        initialLevel = defaultLevel;
      }
      self2.setLevel(initialLevel, false);
    }
    var defaultLogger = new Logger;
    var _loggersByName = {};
    defaultLogger.getLogger = function getLogger(name) {
      if (typeof name !== "symbol" && typeof name !== "string" || name === "") {
        throw new TypeError("You must supply a name when creating a logger.");
      }
      var logger = _loggersByName[name];
      if (!logger) {
        logger = _loggersByName[name] = new Logger(name, defaultLogger.getLevel(), defaultLogger.methodFactory);
      }
      return logger;
    };
    var _log = typeof window !== undefinedType ? window.log : undefined;
    defaultLogger.noConflict = function() {
      if (typeof window !== undefinedType && window.log === defaultLogger) {
        window.log = _log;
      }
      return defaultLogger;
    };
    defaultLogger.getLoggers = function getLoggers() {
      return _loggersByName;
    };
    defaultLogger["default"] = defaultLogger;
    return defaultLogger;
  });
});

// node_modules/loglevel-plugin-prefix/lib/loglevel-plugin-prefix.js
var require_loglevel_plugin_prefix = __commonJS((exports, module) => {
  (function(root, factory) {
    if (typeof define === "function" && define.amd) {
      define(factory);
    } else if (typeof module === "object" && exports) {
      module.exports = factory();
    } else {
      root.prefix = factory(root);
    }
  })(exports, function(root) {
    var merge = function(target) {
      var i = 1;
      var length = arguments.length;
      var key;
      for (;i < length; i++) {
        for (key in arguments[i]) {
          if (Object.prototype.hasOwnProperty.call(arguments[i], key)) {
            target[key] = arguments[i][key];
          }
        }
      }
      return target;
    };
    var defaults = {
      template: "[%t] %l:",
      levelFormatter: function(level) {
        return level.toUpperCase();
      },
      nameFormatter: function(name) {
        return name || "root";
      },
      timestampFormatter: function(date) {
        return date.toTimeString().replace(/.*(\d{2}:\d{2}:\d{2}).*/, "$1");
      },
      format: undefined
    };
    var loglevel;
    var configs = {};
    var reg = function(rootLogger) {
      if (!rootLogger || !rootLogger.getLogger) {
        throw new TypeError("Argument is not a root logger");
      }
      loglevel = rootLogger;
    };
    var apply = function(logger, config) {
      if (!logger || !logger.setLevel) {
        throw new TypeError("Argument is not a logger");
      }
      var originalFactory = logger.methodFactory;
      var name = logger.name || "";
      var parent = configs[name] || configs[""] || defaults;
      function methodFactory(methodName, logLevel, loggerName) {
        var originalMethod = originalFactory(methodName, logLevel, loggerName);
        var options = configs[loggerName] || configs[""];
        var hasTimestamp = options.template.indexOf("%t") !== -1;
        var hasLevel = options.template.indexOf("%l") !== -1;
        var hasName = options.template.indexOf("%n") !== -1;
        return function() {
          var content = "";
          var length = arguments.length;
          var args = Array(length);
          var key = 0;
          for (;key < length; key++) {
            args[key] = arguments[key];
          }
          if (name || !configs[loggerName]) {
            var timestamp = options.timestampFormatter(new Date);
            var level = options.levelFormatter(methodName);
            var lname = options.nameFormatter(loggerName);
            if (options.format) {
              content += options.format(level, lname, timestamp);
            } else {
              content += options.template;
              if (hasTimestamp) {
                content = content.replace(/%t/, timestamp);
              }
              if (hasLevel)
                content = content.replace(/%l/, level);
              if (hasName)
                content = content.replace(/%n/, lname);
            }
            if (args.length && typeof args[0] === "string") {
              args[0] = content + " " + args[0];
            } else {
              args.unshift(content);
            }
          }
          originalMethod.apply(undefined, args);
        };
      }
      if (!configs[name]) {
        logger.methodFactory = methodFactory;
      }
      config = config || {};
      if (config.template)
        config.format = undefined;
      configs[name] = merge({}, parent, config);
      logger.setLevel(logger.getLevel());
      if (!loglevel) {
        logger.warn("It is necessary to call the function reg() of loglevel-plugin-prefix before calling apply. From the next release, it will throw an error. See more: https://github.com/kutuluk/loglevel-plugin-prefix/blob/master/README.md");
      }
      return logger;
    };
    var api = {
      reg,
      apply
    };
    var save;
    if (root) {
      save = root.prefix;
      api.noConflict = function() {
        if (root.prefix === api) {
          root.prefix = save;
        }
        return api;
      };
    }
    return api;
  });
});

// node_modules/@treecg/types/dist/lib/utils/Logger-Browser.js
var require_Logger_Browser = __commonJS((exports) => {
  var isLogLevel = function(value) {
    value = value.toUpperCase();
    return Object.keys(log.levels).includes(value);
  };
  exports.__esModule = true;
  exports.getLogger = exports.LoggerBrowser = undefined;
  var log = require_loglevel();
  var prefix = require_loglevel_plugin_prefix();
  var LoggerBrowser = function() {
    function LoggerBrowser2(loggable, level) {
      var label = typeof loggable === "string" ? loggable : loggable.constructor.name;
      level = level && isLogLevel(level) ? level : "info";
      log.setDefaultLevel("info");
      if (level && isLogLevel(level)) {
        log.setLevel(level);
      }
      prefix.reg(log);
      prefix.apply(log, {
        template: "%t [%n] %l:",
        levelFormatter: function(level2) {
          return level2;
        },
        nameFormatter: function(name) {
          return name || "global";
        },
        timestampFormatter: function(date) {
          return date.toISOString();
        }
      });
      this.logger = log.getLogger(label);
    }
    LoggerBrowser2.prototype.error = function(message) {
      this.logger.error(message);
    };
    LoggerBrowser2.prototype.warn = function(message) {
      this.logger.warn(message);
    };
    LoggerBrowser2.prototype.info = function(message) {
      this.logger.info(message);
    };
    LoggerBrowser2.prototype.debug = function(message) {
      this.logger.debug(message);
    };
    LoggerBrowser2.prototype.trace = function(message) {
      this.logger.trace(message);
    };
    return LoggerBrowser2;
  }();
  exports.LoggerBrowser = LoggerBrowser;
  var getLogger = function(name) {
    return new LoggerBrowser(name, "info");
  };
  exports.getLogger = getLogger;
});

// node_modules/rdf-data-factory/lib/BlankNode.js
var require_BlankNode = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.BlankNode = undefined;

  class BlankNode {
    constructor(value) {
      this.termType = "BlankNode";
      this.value = value;
    }
    equals(other) {
      return !!other && other.termType === "BlankNode" && other.value === this.value;
    }
  }
  exports.BlankNode = BlankNode;
});

// node_modules/rdf-data-factory/lib/DefaultGraph.js
var require_DefaultGraph = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.DefaultGraph = undefined;

  class DefaultGraph {
    constructor() {
      this.termType = "DefaultGraph";
      this.value = "";
    }
    equals(other) {
      return !!other && other.termType === "DefaultGraph";
    }
  }
  exports.DefaultGraph = DefaultGraph;
  DefaultGraph.INSTANCE = new DefaultGraph;
});

// node_modules/rdf-data-factory/lib/NamedNode.js
var require_NamedNode = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.NamedNode = undefined;

  class NamedNode {
    constructor(value) {
      this.termType = "NamedNode";
      this.value = value;
    }
    equals(other) {
      return !!other && other.termType === "NamedNode" && other.value === this.value;
    }
  }
  exports.NamedNode = NamedNode;
});

// node_modules/rdf-data-factory/lib/Literal.js
var require_Literal = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.Literal = undefined;
  var NamedNode_1 = require_NamedNode();

  class Literal {
    constructor(value, languageOrDatatype) {
      this.termType = "Literal";
      this.value = value;
      if (typeof languageOrDatatype === "string") {
        this.language = languageOrDatatype;
        this.datatype = Literal.RDF_LANGUAGE_STRING;
      } else if (languageOrDatatype) {
        this.language = "";
        this.datatype = languageOrDatatype;
      } else {
        this.language = "";
        this.datatype = Literal.XSD_STRING;
      }
    }
    equals(other) {
      return !!other && other.termType === "Literal" && other.value === this.value && other.language === this.language && this.datatype.equals(other.datatype);
    }
  }
  exports.Literal = Literal;
  Literal.RDF_LANGUAGE_STRING = new NamedNode_1.NamedNode("http://www.w3.org/1999/02/22-rdf-syntax-ns#langString");
  Literal.XSD_STRING = new NamedNode_1.NamedNode("http://www.w3.org/2001/XMLSchema#string");
});

// node_modules/rdf-data-factory/lib/Quad.js
var require_Quad = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.Quad = undefined;

  class Quad {
    constructor(subject, predicate, object, graph) {
      this.termType = "Quad";
      this.value = "";
      this.subject = subject;
      this.predicate = predicate;
      this.object = object;
      this.graph = graph;
    }
    equals(other) {
      return !!other && (other.termType === "Quad" || !other.termType) && this.subject.equals(other.subject) && this.predicate.equals(other.predicate) && this.object.equals(other.object) && this.graph.equals(other.graph);
    }
  }
  exports.Quad = Quad;
});

// node_modules/rdf-data-factory/lib/Variable.js
var require_Variable = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.Variable = undefined;

  class Variable {
    constructor(value) {
      this.termType = "Variable";
      this.value = value;
    }
    equals(other) {
      return !!other && other.termType === "Variable" && other.value === this.value;
    }
  }
  exports.Variable = Variable;
});

// node_modules/rdf-data-factory/lib/DataFactory.js
var require_DataFactory = __commonJS((exports) => {
  Object.defineProperty(exports, "__esModule", { value: true });
  exports.DataFactory = undefined;
  var BlankNode_1 = require_BlankNode();
  var DefaultGraph_1 = require_DefaultGraph();
  var Literal_1 = require_Literal();
  var NamedNode_1 = require_NamedNode();
  var Quad_1 = require_Quad();
  var Variable_1 = require_Variable();
  var dataFactoryCounter = 0;

  class DataFactory {
    constructor(options) {
      this.blankNodeCounter = 0;
      options = options || {};
      this.blankNodePrefix = options.blankNodePrefix || `df_${dataFactoryCounter++}_`;
    }
    namedNode(value) {
      return new NamedNode_1.NamedNode(value);
    }
    blankNode(value) {
      return new BlankNode_1.BlankNode(value || `${this.blankNodePrefix}${this.blankNodeCounter++}`);
    }
    literal(value, languageOrDatatype) {
      return new Literal_1.Literal(value, languageOrDatatype);
    }
    variable(value) {
      return new Variable_1.Variable(value);
    }
    defaultGraph() {
      return DefaultGraph_1.DefaultGraph.INSTANCE;
    }
    quad(subject, predicate, object, graph) {
      return new Quad_1.Quad(subject, predicate, object, graph || this.defaultGraph());
    }
    fromTerm(original) {
      switch (original.termType) {
        case "NamedNode":
          return this.namedNode(original.value);
        case "BlankNode":
          return this.blankNode(original.value);
        case "Literal":
          if (original.language) {
            return this.literal(original.value, original.language);
          }
          if (!original.datatype.equals(Literal_1.Literal.XSD_STRING)) {
            return this.literal(original.value, this.fromTerm(original.datatype));
          }
          return this.literal(original.value);
        case "Variable":
          return this.variable(original.value);
        case "DefaultGraph":
          return this.defaultGraph();
        case "Quad":
          return this.quad(this.fromTerm(original.subject), this.fromTerm(original.predicate), this.fromTerm(original.object), this.fromTerm(original.graph));
      }
    }
    fromQuad(original) {
      return this.fromTerm(original);
    }
    resetBlankNodeCounter() {
      this.blankNodeCounter = 0;
    }
  }
  exports.DataFactory = DataFactory;
});

// node_modules/rdf-data-factory/index.js
var require_rdf_data_factory = __commonJS((exports) => {
  var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
    if (k2 === undefined)
      k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() {
      return m[k];
    } });
  } : function(o, m, k, k2) {
    if (k2 === undefined)
      k2 = k;
    o[k2] = m[k];
  });
  var __exportStar = exports && exports.__exportStar || function(m, exports2) {
    for (var p in m)
      if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports2, p))
        __createBinding(exports2, m, p);
  };
  Object.defineProperty(exports, "__esModule", { value: true });
  __exportStar(require_BlankNode(), exports);
  __exportStar(require_DataFactory(), exports);
  __exportStar(require_DefaultGraph(), exports);
  __exportStar(require_Literal(), exports);
  __exportStar(require_NamedNode(), exports);
  __exportStar(require_Quad(), exports);
  __exportStar(require_Variable(), exports);
});

// node_modules/@treecg/types/dist/lib/Vocabularies.js
var require_Vocabularies = __commonJS((exports) => {
  var createNamespace = function(baseUri, toValue) {
    var localNames = [];
    for (var _i = 2;_i < arguments.length; _i++) {
      localNames[_i - 2] = arguments[_i];
    }
    var expanded = {};
    expanded.namespace = toValue(baseUri);
    expanded.custom = function(v) {
      return toValue(baseUri + v);
    };
    for (var _a = 0, localNames_1 = localNames;_a < localNames_1.length; _a++) {
      var localName = localNames_1[_a];
      expanded[localName] = toValue("".concat(baseUri).concat(localName));
    }
    return expanded;
  };
  var createUriNamespace = function(baseUri) {
    var localNames = [];
    for (var _i = 1;_i < arguments.length; _i++) {
      localNames[_i - 1] = arguments[_i];
    }
    return createNamespace.apply(undefined, __spreadArray([baseUri, function(expanded) {
      return expanded;
    }], localNames, false));
  };
  var createTermNamespace = function(baseUri) {
    var localNames = [];
    for (var _i = 1;_i < arguments.length; _i++) {
      localNames[_i - 1] = arguments[_i];
    }
    return createNamespace.apply(undefined, __spreadArray([baseUri, factory.namedNode], localNames, false));
  };
  var createUriAndTermNamespace = function(baseUri) {
    var localNames = [];
    for (var _i = 1;_i < arguments.length; _i++) {
      localNames[_i - 1] = arguments[_i];
    }
    return Object.assign(createUriNamespace.apply(undefined, __spreadArray([baseUri], localNames, false)), { terms: createTermNamespace.apply(undefined, __spreadArray([baseUri], localNames, false)) });
  };
  var __spreadArray = exports && exports.__spreadArray || function(to, from, pack) {
    if (pack || arguments.length === 2)
      for (var i = 0, l = from.length, ar;i < l; i++) {
        if (ar || !(i in from)) {
          if (!ar)
            ar = Array.prototype.slice.call(from, 0, i);
          ar[i] = from[i];
        }
      }
    return to.concat(ar || Array.prototype.slice.call(from));
  };
  exports.__esModule = true;
  exports.EX = exports.SHACL = exports.VOID = exports.PPLAN = exports.PROV = exports.SDS = exports.LDES = exports.TREE = exports.XSD = exports.RDFS = exports.RDF = exports.FOAF = exports.DC = exports.createUriAndTermNamespace = exports.createTermNamespace = exports.createUriNamespace = exports.createNamespace = undefined;
  var rdf_data_factory_1 = require_rdf_data_factory();
  var factory = new rdf_data_factory_1.DataFactory;
  exports.createNamespace = createNamespace;
  exports.createUriNamespace = createUriNamespace;
  exports.createTermNamespace = createTermNamespace;
  exports.createUriAndTermNamespace = createUriAndTermNamespace;
  exports.DC = createUriAndTermNamespace("http://purl.org/dc/terms/", "description", "modified", "title");
  exports.FOAF = createUriAndTermNamespace("http://xmlns.com/foaf/0.1/", "Agent");
  exports.RDF = createUriAndTermNamespace("http://www.w3.org/1999/02/22-rdf-syntax-ns#", "type", "Class", "Property", "nil", "rest", "first");
  exports.RDFS = createUriAndTermNamespace("http://www.w3.org/2000/01/rdf-schema#", "label", "comment", "domain", "range", "isDefinedBy", "Class", "subClassOf");
  exports.XSD = createUriAndTermNamespace("http://www.w3.org/2001/XMLSchema#", "dateTime", "integer", "string");
  exports.TREE = createUriAndTermNamespace("https://w3id.org/tree#", "Collection", "Relation", "Node", "Member", "member", "view", "value", "relation", "PrefixRelation", "SubstringRelation", "SuffixRelation", "GreaterThanRelation", "GreaterThanOrEqualRelation", "LessThanRelation", "LessThanOrEqualToRelation", "EqualToRelation", "GeospatiallyContainsRelation", "path", "node", "shape", "search", "ConditionalImport", "import", "importStream", "remainingItems", "zoom", "latitudeTile", "longitudeTile");
  exports.LDES = createUriAndTermNamespace("https://w3id.org/ldes#", "EventStream", "timestampPath", "versionOfPath", "DurationAgoPolicy", "Bucketization", "retentionPolicy", "amount", "bucket", "bucketProperty", "bucketType", "LatestVersionSubset", "BucketizeStrategy");
  exports.SDS = createUriAndTermNamespace("https://w3id.org/sds#", "Member", "Record", "ImmutableMember", "shape", "carries", "dataset", "Stream", "payload", "bucket", "relationType", "relationBucket", "relationValue", "relationPath", "stream", "relation");
  exports.PROV = createUriAndTermNamespace("http://www.w3.org/ns/prov#", "used", "startedAtTime", "wasGeneratedBy");
  exports.PPLAN = createUriAndTermNamespace("http://purl.org/net/p-plan#", "Activity");
  exports.VOID = createUriAndTermNamespace("http://rdfs.org/ns/void#", "Dataset", "DatasetDescription", "Linkset", "TechnicalFeature", "feature", "sparqlEndpoint", "dataDump", "rootResource", "exampleResource", "uriLookupEndpoint", "openSearchDescription", "uriSpace", "uriRegexPattern", "vocabulary", "subset", "propertyPartition", "triples", "entities", "class", "classes", "classPartition", "property", "properties", "distinctSubjects", "distinctObjects", "documents", "target", "subjectsTarget", "objectsTarget", "linkPredicate", "inDataset");
  exports.SHACL = createUriAndTermNamespace("http://www.w3.org/ns/shacl#", "NodeShape", "targetClass", "property", "path", "name", "alternativePath", "datatype", "nodeKind", "pattern", "flags", "minExclusive", "minInclusive", "maxExclusive", "maxInclusive", "not", "and", "or", "xone", "in", "hasValue", "defaultValue", "minCount", "maxCount");
  exports.EX = createUriAndTermNamespace("http://example.org/ns#");
});

// node_modules/@treecg/types/dist/index.js
var require_dist7 = __commonJS((exports) => {
  var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
    if (k2 === undefined)
      k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() {
      return m[k];
    } });
  } : function(o, m, k, k2) {
    if (k2 === undefined)
      k2 = k;
    o[k2] = m[k];
  });
  var __exportStar = exports && exports.__exportStar || function(m, exports2) {
    for (var p in m)
      if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports2, p))
        __createBinding(exports2, m, p);
  };
  exports.__esModule = true;
  exports.getLogger = exports.Logger = exports.LoggerBrowser = undefined;
  __exportStar(require_Bucketizer(), exports);
  __exportStar(require_BucketizerOptions(), exports);
  __exportStar(require_Fragment(), exports);
  __exportStar(require_Member(), exports);
  __exportStar(require_RelationParameters(), exports);
  var Logger_Browser_1 = require_Logger_Browser();
  __createBinding(exports, Logger_Browser_1, "LoggerBrowser");
  __createBinding(exports, Logger_Browser_1, "LoggerBrowser", "Logger");
  __createBinding(exports, Logger_Browser_1, "getLogger");
  __exportStar(require_Vocabularies(), exports);
});

// node_modules/ws/lib/stream.js
var require_stream2 = __commonJS((exports, module) => {
  var emitClose = function(stream) {
    stream.emit("close");
  };
  var duplexOnEnd = function() {
    if (!this.destroyed && this._writableState.finished) {
      this.destroy();
    }
  };
  var duplexOnError = function(err) {
    this.removeListener("error", duplexOnError);
    this.destroy();
    if (this.listenerCount("error") === 0) {
      this.emit("error", err);
    }
  };
  var createWebSocketStream = function(ws, options) {
    let terminateOnDestroy = true;
    const duplex = new Duplex({
      ...options,
      autoDestroy: false,
      emitClose: false,
      objectMode: false,
      writableObjectMode: false
    });
    ws.on("message", function message(msg, isBinary) {
      const data = !isBinary && duplex._readableState.objectMode ? msg.toString() : msg;
      if (!duplex.push(data))
        ws.pause();
    });
    ws.once("error", function error(err) {
      if (duplex.destroyed)
        return;
      terminateOnDestroy = false;
      duplex.destroy(err);
    });
    ws.once("close", function close() {
      if (duplex.destroyed)
        return;
      duplex.push(null);
    });
    duplex._destroy = function(err, callback) {
      if (ws.readyState === ws.CLOSED) {
        callback(err);
        process.nextTick(emitClose, duplex);
        return;
      }
      let called = false;
      ws.once("error", function error(err2) {
        called = true;
        callback(err2);
      });
      ws.once("close", function close() {
        if (!called)
          callback(err);
        process.nextTick(emitClose, duplex);
      });
      if (terminateOnDestroy)
        ws.terminate();
    };
    duplex._final = function(callback) {
      if (ws.readyState === ws.CONNECTING) {
        ws.once("open", function open() {
          duplex._final(callback);
        });
        return;
      }
      if (ws._socket === null)
        return;
      if (ws._socket._writableState.finished) {
        callback();
        if (duplex._readableState.endEmitted)
          duplex.destroy();
      } else {
        ws._socket.once("finish", function finish() {
          callback();
        });
        ws.close();
      }
    };
    duplex._read = function() {
      if (ws.isPaused)
        ws.resume();
    };
    duplex._write = function(chunk, encoding, callback) {
      if (ws.readyState === ws.CONNECTING) {
        ws.once("open", function open() {
          duplex._write(chunk, encoding, callback);
        });
        return;
      }
      ws.send(chunk, callback);
    };
    duplex.on("end", duplexOnEnd);
    duplex.on("error", duplexOnError);
    return duplex;
  };
  var { Duplex } = __require("stream");
  module.exports = createWebSocketStream;
});

// node_modules/ws/lib/constants.js
var require_constants = __commonJS((exports, module) => {
  module.exports = {
    BINARY_TYPES: ["nodebuffer", "arraybuffer", "fragments"],
    EMPTY_BUFFER: Buffer.alloc(0),
    GUID: "258EAFA5-E914-47DA-95CA-C5AB0DC85B11",
    kForOnEventAttribute: Symbol("kIsForOnEventAttribute"),
    kListener: Symbol("kListener"),
    kStatusCode: Symbol("status-code"),
    kWebSocket: Symbol("websocket"),
    NOOP: () => {
    }
  };
});

// node_modules/node-gyp-build/node-gyp-build.js
var require_node_gyp_build = __commonJS((exports, module) => {
  var load = function(dir) {
    return runtimeRequire(load.resolve(dir));
  };
  var readdirSync = function(dir) {
    try {
      return fs.readdirSync(dir);
    } catch (err) {
      return [];
    }
  };
  var getFirst = function(dir, filter) {
    var files = readdirSync(dir).filter(filter);
    return files[0] && path.join(dir, files[0]);
  };
  var matchBuild = function(name) {
    return /\.node$/.test(name);
  };
  var parseTuple = function(name) {
    var arr = name.split("-");
    if (arr.length !== 2)
      return;
    var platform2 = arr[0];
    var architectures = arr[1].split("+");
    if (!platform2)
      return;
    if (!architectures.length)
      return;
    if (!architectures.every(Boolean))
      return;
    return { name, platform: platform2, architectures };
  };
  var matchTuple = function(platform2, arch2) {
    return function(tuple) {
      if (tuple == null)
        return false;
      if (tuple.platform !== platform2)
        return false;
      return tuple.architectures.includes(arch2);
    };
  };
  var compareTuples = function(a, b) {
    return a.architectures.length - b.architectures.length;
  };
  var parseTags = function(file) {
    var arr = file.split(".");
    var extension = arr.pop();
    var tags = { file, specificity: 0 };
    if (extension !== "node")
      return;
    for (var i = 0;i < arr.length; i++) {
      var tag = arr[i];
      if (tag === "node" || tag === "electron" || tag === "node-webkit") {
        tags.runtime = tag;
      } else if (tag === "napi") {
        tags.napi = true;
      } else if (tag.slice(0, 3) === "abi") {
        tags.abi = tag.slice(3);
      } else if (tag.slice(0, 2) === "uv") {
        tags.uv = tag.slice(2);
      } else if (tag.slice(0, 4) === "armv") {
        tags.armv = tag.slice(4);
      } else if (tag === "glibc" || tag === "musl") {
        tags.libc = tag;
      } else {
        continue;
      }
      tags.specificity++;
    }
    return tags;
  };
  var matchTags = function(runtime2, abi2) {
    return function(tags) {
      if (tags == null)
        return false;
      if (tags.runtime !== runtime2 && !runtimeAgnostic(tags))
        return false;
      if (tags.abi !== abi2 && !tags.napi)
        return false;
      if (tags.uv && tags.uv !== uv)
        return false;
      if (tags.armv && tags.armv !== armv)
        return false;
      if (tags.libc && tags.libc !== libc)
        return false;
      return true;
    };
  };
  var runtimeAgnostic = function(tags) {
    return tags.runtime === "node" && tags.napi;
  };
  var compareTags = function(runtime2) {
    return function(a, b) {
      if (a.runtime !== b.runtime) {
        return a.runtime === runtime2 ? -1 : 1;
      } else if (a.abi !== b.abi) {
        return a.abi ? -1 : 1;
      } else if (a.specificity !== b.specificity) {
        return a.specificity > b.specificity ? -1 : 1;
      } else {
        return 0;
      }
    };
  };
  var isNwjs = function() {
    return !!(process.versions && process.versions.nw);
  };
  var isElectron = function() {
    if (process.versions && process.versions.electron)
      return true;
    if (process.env.ELECTRON_RUN_AS_NODE)
      return true;
    return typeof window !== "undefined" && window.process && window.process.type === "renderer";
  };
  var isAlpine = function(platform2) {
    return platform2 === "linux" && fs.existsSync("/etc/alpine-release");
  };
  var fs = __require("fs");
  var path = __require("path");
  var os = __require("os");
  var runtimeRequire = typeof __webpack_require__ === "function" ? __non_webpack_require__ : require;
  var vars = process.config && process.config.variables || {};
  var prebuildsOnly = !!process.env.PREBUILDS_ONLY;
  var abi = process.versions.modules;
  var runtime = isElectron() ? "electron" : isNwjs() ? "node-webkit" : "node";
  var arch = process.env.npm_config_arch || os.arch();
  var platform = process.env.npm_config_platform || os.platform();
  var libc = process.env.LIBC || (isAlpine(platform) ? "musl" : "glibc");
  var armv = process.env.ARM_VERSION || (arch === "arm64" ? "8" : vars.arm_version) || "";
  var uv = (process.versions.uv || "").split(".")[0];
  module.exports = load;
  load.resolve = load.path = function(dir) {
    dir = path.resolve(dir || ".");
    try {
      var name = runtimeRequire(path.join(dir, "package.json")).name.toUpperCase().replace(/-/g, "_");
      if (process.env[name + "_PREBUILD"])
        dir = process.env[name + "_PREBUILD"];
    } catch (err) {
    }
    if (!prebuildsOnly) {
      var release = getFirst(path.join(dir, "build/Release"), matchBuild);
      if (release)
        return release;
      var debug = getFirst(path.join(dir, "build/Debug"), matchBuild);
      if (debug)
        return debug;
    }
    var prebuild = resolve(dir);
    if (prebuild)
      return prebuild;
    var nearby = resolve(path.dirname(process.execPath));
    if (nearby)
      return nearby;
    var target = [
      "platform=" + platform,
      "arch=" + arch,
      "runtime=" + runtime,
      "abi=" + abi,
      "uv=" + uv,
      armv ? "armv=" + armv : "",
      "libc=" + libc,
      "node=" + process.versions.node,
      process.versions.electron ? "electron=" + process.versions.electron : "",
      typeof __webpack_require__ === "function" ? "webpack=true" : ""
    ].filter(Boolean).join(" ");
    throw new Error("No native build was found for " + target + "\n    loaded from: " + dir + "\n");
    function resolve(dir2) {
      var tuples = readdirSync(path.join(dir2, "prebuilds")).map(parseTuple);
      var tuple = tuples.filter(matchTuple(platform, arch)).sort(compareTuples)[0];
      if (!tuple)
        return;
      var prebuilds = path.join(dir2, "prebuilds", tuple.name);
      var parsed = readdirSync(prebuilds).map(parseTags);
      var candidates = parsed.filter(matchTags(runtime, abi));
      var winner = candidates.sort(compareTags(runtime))[0];
      if (winner)
        return path.join(prebuilds, winner.file);
    }
  };
  load.parseTags = parseTags;
  load.matchTags = matchTags;
  load.compareTags = compareTags;
  load.parseTuple = parseTuple;
  load.matchTuple = matchTuple;
  load.compareTuples = compareTuples;
});

// node_modules/node-gyp-build/index.js
var require_node_gyp_build2 = __commonJS((exports, module) => {
  if (typeof process.addon === "function") {
    module.exports = process.addon.bind(process);
  } else {
    module.exports = require_node_gyp_build();
  }
});

// node_modules/bufferutil/fallback.js
var require_fallback = __commonJS((exports, module) => {
  var mask = (source, mask2, output, offset, length) => {
    for (var i = 0;i < length; i++) {
      output[offset + i] = source[i] ^ mask2[i & 3];
    }
  };
  var unmask = (buffer, mask2) => {
    const length = buffer.length;
    for (var i = 0;i < length; i++) {
      buffer[i] ^= mask2[i & 3];
    }
  };
  module.exports = { mask, unmask };
});

// node_modules/bufferutil/index.js
var require_bufferutil = __commonJS((exports, module) => {
  var __dirname = "/home/julian/code/github/js-runner/node_modules/bufferutil";
  try {
    module.exports = require_node_gyp_build2()(__dirname);
  } catch (e) {
    module.exports = require_fallback();
  }
});

// node_modules/ws/lib/buffer-util.js
var require_buffer_util = __commonJS((exports, module) => {
  var concat = function(list, totalLength) {
    if (list.length === 0)
      return EMPTY_BUFFER;
    if (list.length === 1)
      return list[0];
    const target = Buffer.allocUnsafe(totalLength);
    let offset = 0;
    for (let i = 0;i < list.length; i++) {
      const buf = list[i];
      target.set(buf, offset);
      offset += buf.length;
    }
    if (offset < totalLength) {
      return new FastBuffer(target.buffer, target.byteOffset, offset);
    }
    return target;
  };
  var _mask = function(source, mask, output, offset, length) {
    for (let i = 0;i < length; i++) {
      output[offset + i] = source[i] ^ mask[i & 3];
    }
  };
  var _unmask = function(buffer, mask) {
    for (let i = 0;i < buffer.length; i++) {
      buffer[i] ^= mask[i & 3];
    }
  };
  var toArrayBuffer = function(buf) {
    if (buf.length === buf.buffer.byteLength) {
      return buf.buffer;
    }
    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.length);
  };
  var toBuffer = function(data) {
    toBuffer.readOnly = true;
    if (Buffer.isBuffer(data))
      return data;
    let buf;
    if (data instanceof ArrayBuffer) {
      buf = new FastBuffer(data);
    } else if (ArrayBuffer.isView(data)) {
      buf = new FastBuffer(data.buffer, data.byteOffset, data.byteLength);
    } else {
      buf = Buffer.from(data);
      toBuffer.readOnly = false;
    }
    return buf;
  };
  var { EMPTY_BUFFER } = require_constants();
  var FastBuffer = Buffer[Symbol.species];
  module.exports = {
    concat,
    mask: _mask,
    toArrayBuffer,
    toBuffer,
    unmask: _unmask
  };
  if (!process.env.WS_NO_BUFFER_UTIL) {
    try {
      const bufferUtil = require_bufferutil();
      module.exports.mask = function(source, mask, output, offset, length) {
        if (length < 48)
          _mask(source, mask, output, offset, length);
        else
          bufferUtil.mask(source, mask, output, offset, length);
      };
      module.exports.unmask = function(buffer, mask) {
        if (buffer.length < 32)
          _unmask(buffer, mask);
        else
          bufferUtil.unmask(buffer, mask);
      };
    } catch (e) {
    }
  }
});

// node_modules/ws/lib/limiter.js
var require_limiter = __commonJS((exports, module) => {
  var kDone = Symbol("kDone");
  var kRun = Symbol("kRun");

  class Limiter {
    constructor(concurrency) {
      this[kDone] = () => {
        this.pending--;
        this[kRun]();
      };
      this.concurrency = concurrency || Infinity;
      this.jobs = [];
      this.pending = 0;
    }
    add(job) {
      this.jobs.push(job);
      this[kRun]();
    }
    [kRun]() {
      if (this.pending === this.concurrency)
        return;
      if (this.jobs.length) {
        const job = this.jobs.shift();
        this.pending++;
        job(this[kDone]);
      }
    }
  }
  module.exports = Limiter;
});

// node_modules/ws/lib/permessage-deflate.js
var require_permessage_deflate = __commonJS((exports, module) => {
  var deflateOnData = function(chunk) {
    this[kBuffers].push(chunk);
    this[kTotalLength] += chunk.length;
  };
  var inflateOnData = function(chunk) {
    this[kTotalLength] += chunk.length;
    if (this[kPerMessageDeflate]._maxPayload < 1 || this[kTotalLength] <= this[kPerMessageDeflate]._maxPayload) {
      this[kBuffers].push(chunk);
      return;
    }
    this[kError] = new RangeError("Max payload size exceeded");
    this[kError].code = "WS_ERR_UNSUPPORTED_MESSAGE_LENGTH";
    this[kError][kStatusCode] = 1009;
    this.removeListener("data", inflateOnData);
    this.reset();
  };
  var inflateOnError = function(err) {
    this[kPerMessageDeflate]._inflate = null;
    err[kStatusCode] = 1007;
    this[kCallback](err);
  };
  var zlib = __require("zlib");
  var bufferUtil = require_buffer_util();
  var Limiter = require_limiter();
  var { kStatusCode } = require_constants();
  var FastBuffer = Buffer[Symbol.species];
  var TRAILER = Buffer.from([0, 0, 255, 255]);
  var kPerMessageDeflate = Symbol("permessage-deflate");
  var kTotalLength = Symbol("total-length");
  var kCallback = Symbol("callback");
  var kBuffers = Symbol("buffers");
  var kError = Symbol("error");
  var zlibLimiter;

  class PerMessageDeflate {
    constructor(options, isServer, maxPayload) {
      this._maxPayload = maxPayload | 0;
      this._options = options || {};
      this._threshold = this._options.threshold !== undefined ? this._options.threshold : 1024;
      this._isServer = !!isServer;
      this._deflate = null;
      this._inflate = null;
      this.params = null;
      if (!zlibLimiter) {
        const concurrency = this._options.concurrencyLimit !== undefined ? this._options.concurrencyLimit : 10;
        zlibLimiter = new Limiter(concurrency);
      }
    }
    static get extensionName() {
      return "permessage-deflate";
    }
    offer() {
      const params = {};
      if (this._options.serverNoContextTakeover) {
        params.server_no_context_takeover = true;
      }
      if (this._options.clientNoContextTakeover) {
        params.client_no_context_takeover = true;
      }
      if (this._options.serverMaxWindowBits) {
        params.server_max_window_bits = this._options.serverMaxWindowBits;
      }
      if (this._options.clientMaxWindowBits) {
        params.client_max_window_bits = this._options.clientMaxWindowBits;
      } else if (this._options.clientMaxWindowBits == null) {
        params.client_max_window_bits = true;
      }
      return params;
    }
    accept(configurations) {
      configurations = this.normalizeParams(configurations);
      this.params = this._isServer ? this.acceptAsServer(configurations) : this.acceptAsClient(configurations);
      return this.params;
    }
    cleanup() {
      if (this._inflate) {
        this._inflate.close();
        this._inflate = null;
      }
      if (this._deflate) {
        const callback = this._deflate[kCallback];
        this._deflate.close();
        this._deflate = null;
        if (callback) {
          callback(new Error("The deflate stream was closed while data was being processed"));
        }
      }
    }
    acceptAsServer(offers) {
      const opts = this._options;
      const accepted = offers.find((params) => {
        if (opts.serverNoContextTakeover === false && params.server_no_context_takeover || params.server_max_window_bits && (opts.serverMaxWindowBits === false || typeof opts.serverMaxWindowBits === "number" && opts.serverMaxWindowBits > params.server_max_window_bits) || typeof opts.clientMaxWindowBits === "number" && !params.client_max_window_bits) {
          return false;
        }
        return true;
      });
      if (!accepted) {
        throw new Error("None of the extension offers can be accepted");
      }
      if (opts.serverNoContextTakeover) {
        accepted.server_no_context_takeover = true;
      }
      if (opts.clientNoContextTakeover) {
        accepted.client_no_context_takeover = true;
      }
      if (typeof opts.serverMaxWindowBits === "number") {
        accepted.server_max_window_bits = opts.serverMaxWindowBits;
      }
      if (typeof opts.clientMaxWindowBits === "number") {
        accepted.client_max_window_bits = opts.clientMaxWindowBits;
      } else if (accepted.client_max_window_bits === true || opts.clientMaxWindowBits === false) {
        delete accepted.client_max_window_bits;
      }
      return accepted;
    }
    acceptAsClient(response) {
      const params = response[0];
      if (this._options.clientNoContextTakeover === false && params.client_no_context_takeover) {
        throw new Error('Unexpected parameter "client_no_context_takeover"');
      }
      if (!params.client_max_window_bits) {
        if (typeof this._options.clientMaxWindowBits === "number") {
          params.client_max_window_bits = this._options.clientMaxWindowBits;
        }
      } else if (this._options.clientMaxWindowBits === false || typeof this._options.clientMaxWindowBits === "number" && params.client_max_window_bits > this._options.clientMaxWindowBits) {
        throw new Error('Unexpected or invalid parameter "client_max_window_bits"');
      }
      return params;
    }
    normalizeParams(configurations) {
      configurations.forEach((params) => {
        Object.keys(params).forEach((key) => {
          let value = params[key];
          if (value.length > 1) {
            throw new Error(`Parameter "${key}" must have only a single value`);
          }
          value = value[0];
          if (key === "client_max_window_bits") {
            if (value !== true) {
              const num = +value;
              if (!Number.isInteger(num) || num < 8 || num > 15) {
                throw new TypeError(`Invalid value for parameter "${key}": ${value}`);
              }
              value = num;
            } else if (!this._isServer) {
              throw new TypeError(`Invalid value for parameter "${key}": ${value}`);
            }
          } else if (key === "server_max_window_bits") {
            const num = +value;
            if (!Number.isInteger(num) || num < 8 || num > 15) {
              throw new TypeError(`Invalid value for parameter "${key}": ${value}`);
            }
            value = num;
          } else if (key === "client_no_context_takeover" || key === "server_no_context_takeover") {
            if (value !== true) {
              throw new TypeError(`Invalid value for parameter "${key}": ${value}`);
            }
          } else {
            throw new Error(`Unknown parameter "${key}"`);
          }
          params[key] = value;
        });
      });
      return configurations;
    }
    decompress(data, fin, callback) {
      zlibLimiter.add((done) => {
        this._decompress(data, fin, (err, result) => {
          done();
          callback(err, result);
        });
      });
    }
    compress(data, fin, callback) {
      zlibLimiter.add((done) => {
        this._compress(data, fin, (err, result) => {
          done();
          callback(err, result);
        });
      });
    }
    _decompress(data, fin, callback) {
      const endpoint = this._isServer ? "client" : "server";
      if (!this._inflate) {
        const key = `${endpoint}_max_window_bits`;
        const windowBits = typeof this.params[key] !== "number" ? zlib.Z_DEFAULT_WINDOWBITS : this.params[key];
        this._inflate = zlib.createInflateRaw({
          ...this._options.zlibInflateOptions,
          windowBits
        });
        this._inflate[kPerMessageDeflate] = this;
        this._inflate[kTotalLength] = 0;
        this._inflate[kBuffers] = [];
        this._inflate.on("error", inflateOnError);
        this._inflate.on("data", inflateOnData);
      }
      this._inflate[kCallback] = callback;
      this._inflate.write(data);
      if (fin)
        this._inflate.write(TRAILER);
      this._inflate.flush(() => {
        const err = this._inflate[kError];
        if (err) {
          this._inflate.close();
          this._inflate = null;
          callback(err);
          return;
        }
        const data2 = bufferUtil.concat(this._inflate[kBuffers], this._inflate[kTotalLength]);
        if (this._inflate._readableState.endEmitted) {
          this._inflate.close();
          this._inflate = null;
        } else {
          this._inflate[kTotalLength] = 0;
          this._inflate[kBuffers] = [];
          if (fin && this.params[`${endpoint}_no_context_takeover`]) {
            this._inflate.reset();
          }
        }
        callback(null, data2);
      });
    }
    _compress(data, fin, callback) {
      const endpoint = this._isServer ? "server" : "client";
      if (!this._deflate) {
        const key = `${endpoint}_max_window_bits`;
        const windowBits = typeof this.params[key] !== "number" ? zlib.Z_DEFAULT_WINDOWBITS : this.params[key];
        this._deflate = zlib.createDeflateRaw({
          ...this._options.zlibDeflateOptions,
          windowBits
        });
        this._deflate[kTotalLength] = 0;
        this._deflate[kBuffers] = [];
        this._deflate.on("data", deflateOnData);
      }
      this._deflate[kCallback] = callback;
      this._deflate.write(data);
      this._deflate.flush(zlib.Z_SYNC_FLUSH, () => {
        if (!this._deflate) {
          return;
        }
        let data2 = bufferUtil.concat(this._deflate[kBuffers], this._deflate[kTotalLength]);
        if (fin) {
          data2 = new FastBuffer(data2.buffer, data2.byteOffset, data2.length - 4);
        }
        this._deflate[kCallback] = null;
        this._deflate[kTotalLength] = 0;
        this._deflate[kBuffers] = [];
        if (fin && this.params[`${endpoint}_no_context_takeover`]) {
          this._deflate.reset();
        }
        callback(null, data2);
      });
    }
  }
  module.exports = PerMessageDeflate;
});

// node_modules/utf-8-validate/fallback.js
var require_fallback2 = __commonJS((exports, module) => {
  var isValidUTF8 = function(buf) {
    const len = buf.length;
    let i = 0;
    while (i < len) {
      if ((buf[i] & 128) === 0) {
        i++;
      } else if ((buf[i] & 224) === 192) {
        if (i + 1 === len || (buf[i + 1] & 192) !== 128 || (buf[i] & 254) === 192) {
          return false;
        }
        i += 2;
      } else if ((buf[i] & 240) === 224) {
        if (i + 2 >= len || (buf[i + 1] & 192) !== 128 || (buf[i + 2] & 192) !== 128 || buf[i] === 224 && (buf[i + 1] & 224) === 128 || buf[i] === 237 && (buf[i + 1] & 224) === 160) {
          return false;
        }
        i += 3;
      } else if ((buf[i] & 248) === 240) {
        if (i + 3 >= len || (buf[i + 1] & 192) !== 128 || (buf[i + 2] & 192) !== 128 || (buf[i + 3] & 192) !== 128 || buf[i] === 240 && (buf[i + 1] & 240) === 128 || buf[i] === 244 && buf[i + 1] > 143 || buf[i] > 244) {
          return false;
        }
        i += 4;
      } else {
        return false;
      }
    }
    return true;
  };
  module.exports = isValidUTF8;
});

// node_modules/utf-8-validate/index.js
var require_utf_8_validate = __commonJS((exports, module) => {
  var __dirname = "/home/julian/code/github/js-runner/node_modules/utf-8-validate";
  try {
    module.exports = require_node_gyp_build2()(__dirname);
  } catch (e) {
    module.exports = require_fallback2();
  }
});

// node_modules/ws/lib/validation.js
var require_validation = __commonJS((exports, module) => {
  var isValidStatusCode = function(code) {
    return code >= 1000 && code <= 1014 && code !== 1004 && code !== 1005 && code !== 1006 || code >= 3000 && code <= 4999;
  };
  var _isValidUTF8 = function(buf) {
    const len = buf.length;
    let i = 0;
    while (i < len) {
      if ((buf[i] & 128) === 0) {
        i++;
      } else if ((buf[i] & 224) === 192) {
        if (i + 1 === len || (buf[i + 1] & 192) !== 128 || (buf[i] & 254) === 192) {
          return false;
        }
        i += 2;
      } else if ((buf[i] & 240) === 224) {
        if (i + 2 >= len || (buf[i + 1] & 192) !== 128 || (buf[i + 2] & 192) !== 128 || buf[i] === 224 && (buf[i + 1] & 224) === 128 || buf[i] === 237 && (buf[i + 1] & 224) === 160) {
          return false;
        }
        i += 3;
      } else if ((buf[i] & 248) === 240) {
        if (i + 3 >= len || (buf[i + 1] & 192) !== 128 || (buf[i + 2] & 192) !== 128 || (buf[i + 3] & 192) !== 128 || buf[i] === 240 && (buf[i + 1] & 240) === 128 || buf[i] === 244 && buf[i + 1] > 143 || buf[i] > 244) {
          return false;
        }
        i += 4;
      } else {
        return false;
      }
    }
    return true;
  };
  var { isUtf8 } = __require("buffer");
  var tokenChars = [
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    1,
    0,
    1,
    1,
    1,
    1,
    1,
    0,
    0,
    1,
    1,
    0,
    1,
    1,
    0,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    0,
    0,
    0,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    1,
    0,
    1,
    0,
    1,
    0
  ];
  module.exports = {
    isValidStatusCode,
    isValidUTF8: _isValidUTF8,
    tokenChars
  };
  if (isUtf8) {
    module.exports.isValidUTF8 = function(buf) {
      return buf.length < 24 ? _isValidUTF8(buf) : isUtf8(buf);
    };
  } else if (!process.env.WS_NO_UTF_8_VALIDATE) {
    try {
      const isValidUTF8 = require_utf_8_validate();
      module.exports.isValidUTF8 = function(buf) {
        return buf.length < 32 ? _isValidUTF8(buf) : isValidUTF8(buf);
      };
    } catch (e) {
    }
  }
});

// node_modules/ws/lib/receiver.js
var require_receiver = __commonJS((exports, module) => {
  var error = function(ErrorCtor, message, prefix, statusCode, errorCode) {
    const err = new ErrorCtor(prefix ? `Invalid WebSocket frame: ${message}` : message);
    Error.captureStackTrace(err, error);
    err.code = errorCode;
    err[kStatusCode] = statusCode;
    return err;
  };
  var queueMicrotaskShim = function(cb) {
    promise.then(cb).catch(throwErrorNextTick);
  };
  var throwError = function(err) {
    throw err;
  };
  var throwErrorNextTick = function(err) {
    process.nextTick(throwError, err);
  };
  var { Writable } = __require("stream");
  var PerMessageDeflate = require_permessage_deflate();
  var {
    BINARY_TYPES,
    EMPTY_BUFFER,
    kStatusCode,
    kWebSocket
  } = require_constants();
  var { concat, toArrayBuffer, unmask } = require_buffer_util();
  var { isValidStatusCode, isValidUTF8 } = require_validation();
  var FastBuffer = Buffer[Symbol.species];
  var promise = Promise.resolve();
  var queueTask = typeof queueMicrotask === "function" ? queueMicrotask : queueMicrotaskShim;
  var GET_INFO = 0;
  var GET_PAYLOAD_LENGTH_16 = 1;
  var GET_PAYLOAD_LENGTH_64 = 2;
  var GET_MASK = 3;
  var GET_DATA = 4;
  var INFLATING = 5;
  var WAIT_MICROTASK = 6;

  class Receiver extends Writable {
    constructor(options = {}) {
      super();
      this._binaryType = options.binaryType || BINARY_TYPES[0];
      this._extensions = options.extensions || {};
      this._isServer = !!options.isServer;
      this._maxPayload = options.maxPayload | 0;
      this._skipUTF8Validation = !!options.skipUTF8Validation;
      this[kWebSocket] = undefined;
      this._bufferedBytes = 0;
      this._buffers = [];
      this._compressed = false;
      this._payloadLength = 0;
      this._mask = undefined;
      this._fragmented = 0;
      this._masked = false;
      this._fin = false;
      this._opcode = 0;
      this._totalPayloadLength = 0;
      this._messageLength = 0;
      this._fragments = [];
      this._state = GET_INFO;
      this._loop = false;
    }
    _write(chunk, encoding, cb) {
      if (this._opcode === 8 && this._state == GET_INFO)
        return cb();
      this._bufferedBytes += chunk.length;
      this._buffers.push(chunk);
      this.startLoop(cb);
    }
    consume(n) {
      this._bufferedBytes -= n;
      if (n === this._buffers[0].length)
        return this._buffers.shift();
      if (n < this._buffers[0].length) {
        const buf = this._buffers[0];
        this._buffers[0] = new FastBuffer(buf.buffer, buf.byteOffset + n, buf.length - n);
        return new FastBuffer(buf.buffer, buf.byteOffset, n);
      }
      const dst = Buffer.allocUnsafe(n);
      do {
        const buf = this._buffers[0];
        const offset = dst.length - n;
        if (n >= buf.length) {
          dst.set(this._buffers.shift(), offset);
        } else {
          dst.set(new Uint8Array(buf.buffer, buf.byteOffset, n), offset);
          this._buffers[0] = new FastBuffer(buf.buffer, buf.byteOffset + n, buf.length - n);
        }
        n -= buf.length;
      } while (n > 0);
      return dst;
    }
    startLoop(cb) {
      let err;
      this._loop = true;
      do {
        switch (this._state) {
          case GET_INFO:
            err = this.getInfo();
            break;
          case GET_PAYLOAD_LENGTH_16:
            err = this.getPayloadLength16();
            break;
          case GET_PAYLOAD_LENGTH_64:
            err = this.getPayloadLength64();
            break;
          case GET_MASK:
            this.getMask();
            break;
          case GET_DATA:
            err = this.getData(cb);
            break;
          case INFLATING:
            this._loop = false;
            return;
          default:
            this._loop = false;
            queueTask(() => {
              this._state = GET_INFO;
              this.startLoop(cb);
            });
            return;
        }
      } while (this._loop);
      cb(err);
    }
    getInfo() {
      if (this._bufferedBytes < 2) {
        this._loop = false;
        return;
      }
      const buf = this.consume(2);
      if ((buf[0] & 48) !== 0) {
        this._loop = false;
        return error(RangeError, "RSV2 and RSV3 must be clear", true, 1002, "WS_ERR_UNEXPECTED_RSV_2_3");
      }
      const compressed = (buf[0] & 64) === 64;
      if (compressed && !this._extensions[PerMessageDeflate.extensionName]) {
        this._loop = false;
        return error(RangeError, "RSV1 must be clear", true, 1002, "WS_ERR_UNEXPECTED_RSV_1");
      }
      this._fin = (buf[0] & 128) === 128;
      this._opcode = buf[0] & 15;
      this._payloadLength = buf[1] & 127;
      if (this._opcode === 0) {
        if (compressed) {
          this._loop = false;
          return error(RangeError, "RSV1 must be clear", true, 1002, "WS_ERR_UNEXPECTED_RSV_1");
        }
        if (!this._fragmented) {
          this._loop = false;
          return error(RangeError, "invalid opcode 0", true, 1002, "WS_ERR_INVALID_OPCODE");
        }
        this._opcode = this._fragmented;
      } else if (this._opcode === 1 || this._opcode === 2) {
        if (this._fragmented) {
          this._loop = false;
          return error(RangeError, `invalid opcode ${this._opcode}`, true, 1002, "WS_ERR_INVALID_OPCODE");
        }
        this._compressed = compressed;
      } else if (this._opcode > 7 && this._opcode < 11) {
        if (!this._fin) {
          this._loop = false;
          return error(RangeError, "FIN must be set", true, 1002, "WS_ERR_EXPECTED_FIN");
        }
        if (compressed) {
          this._loop = false;
          return error(RangeError, "RSV1 must be clear", true, 1002, "WS_ERR_UNEXPECTED_RSV_1");
        }
        if (this._payloadLength > 125 || this._opcode === 8 && this._payloadLength === 1) {
          this._loop = false;
          return error(RangeError, `invalid payload length ${this._payloadLength}`, true, 1002, "WS_ERR_INVALID_CONTROL_PAYLOAD_LENGTH");
        }
      } else {
        this._loop = false;
        return error(RangeError, `invalid opcode ${this._opcode}`, true, 1002, "WS_ERR_INVALID_OPCODE");
      }
      if (!this._fin && !this._fragmented)
        this._fragmented = this._opcode;
      this._masked = (buf[1] & 128) === 128;
      if (this._isServer) {
        if (!this._masked) {
          this._loop = false;
          return error(RangeError, "MASK must be set", true, 1002, "WS_ERR_EXPECTED_MASK");
        }
      } else if (this._masked) {
        this._loop = false;
        return error(RangeError, "MASK must be clear", true, 1002, "WS_ERR_UNEXPECTED_MASK");
      }
      if (this._payloadLength === 126)
        this._state = GET_PAYLOAD_LENGTH_16;
      else if (this._payloadLength === 127)
        this._state = GET_PAYLOAD_LENGTH_64;
      else
        return this.haveLength();
    }
    getPayloadLength16() {
      if (this._bufferedBytes < 2) {
        this._loop = false;
        return;
      }
      this._payloadLength = this.consume(2).readUInt16BE(0);
      return this.haveLength();
    }
    getPayloadLength64() {
      if (this._bufferedBytes < 8) {
        this._loop = false;
        return;
      }
      const buf = this.consume(8);
      const num = buf.readUInt32BE(0);
      if (num > Math.pow(2, 53 - 32) - 1) {
        this._loop = false;
        return error(RangeError, "Unsupported WebSocket frame: payload length > 2^53 - 1", false, 1009, "WS_ERR_UNSUPPORTED_DATA_PAYLOAD_LENGTH");
      }
      this._payloadLength = num * Math.pow(2, 32) + buf.readUInt32BE(4);
      return this.haveLength();
    }
    haveLength() {
      if (this._payloadLength && this._opcode < 8) {
        this._totalPayloadLength += this._payloadLength;
        if (this._totalPayloadLength > this._maxPayload && this._maxPayload > 0) {
          this._loop = false;
          return error(RangeError, "Max payload size exceeded", false, 1009, "WS_ERR_UNSUPPORTED_MESSAGE_LENGTH");
        }
      }
      if (this._masked)
        this._state = GET_MASK;
      else
        this._state = GET_DATA;
    }
    getMask() {
      if (this._bufferedBytes < 4) {
        this._loop = false;
        return;
      }
      this._mask = this.consume(4);
      this._state = GET_DATA;
    }
    getData(cb) {
      let data = EMPTY_BUFFER;
      if (this._payloadLength) {
        if (this._bufferedBytes < this._payloadLength) {
          this._loop = false;
          return;
        }
        data = this.consume(this._payloadLength);
        if (this._masked && (this._mask[0] | this._mask[1] | this._mask[2] | this._mask[3]) !== 0) {
          unmask(data, this._mask);
        }
      }
      if (this._opcode > 7)
        return this.controlMessage(data);
      if (this._compressed) {
        this._state = INFLATING;
        this.decompress(data, cb);
        return;
      }
      if (data.length) {
        this._messageLength = this._totalPayloadLength;
        this._fragments.push(data);
      }
      return this.dataMessage();
    }
    decompress(data, cb) {
      const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];
      perMessageDeflate.decompress(data, this._fin, (err, buf) => {
        if (err)
          return cb(err);
        if (buf.length) {
          this._messageLength += buf.length;
          if (this._messageLength > this._maxPayload && this._maxPayload > 0) {
            return cb(error(RangeError, "Max payload size exceeded", false, 1009, "WS_ERR_UNSUPPORTED_MESSAGE_LENGTH"));
          }
          this._fragments.push(buf);
        }
        const er = this.dataMessage();
        if (er)
          return cb(er);
        this.startLoop(cb);
      });
    }
    dataMessage() {
      if (this._fin) {
        const messageLength = this._messageLength;
        const fragments = this._fragments;
        this._totalPayloadLength = 0;
        this._messageLength = 0;
        this._fragmented = 0;
        this._fragments = [];
        if (this._opcode === 2) {
          let data;
          if (this._binaryType === "nodebuffer") {
            data = concat(fragments, messageLength);
          } else if (this._binaryType === "arraybuffer") {
            data = toArrayBuffer(concat(fragments, messageLength));
          } else {
            data = fragments;
          }
          this.emit("message", data, true);
        } else {
          const buf = concat(fragments, messageLength);
          if (!this._skipUTF8Validation && !isValidUTF8(buf)) {
            this._loop = false;
            return error(Error, "invalid UTF-8 sequence", true, 1007, "WS_ERR_INVALID_UTF8");
          }
          this.emit("message", buf, false);
        }
      }
      this._state = WAIT_MICROTASK;
    }
    controlMessage(data) {
      if (this._opcode === 8) {
        this._loop = false;
        if (data.length === 0) {
          this.emit("conclude", 1005, EMPTY_BUFFER);
          this.end();
          this._state = GET_INFO;
        } else {
          const code = data.readUInt16BE(0);
          if (!isValidStatusCode(code)) {
            return error(RangeError, `invalid status code ${code}`, true, 1002, "WS_ERR_INVALID_CLOSE_CODE");
          }
          const buf = new FastBuffer(data.buffer, data.byteOffset + 2, data.length - 2);
          if (!this._skipUTF8Validation && !isValidUTF8(buf)) {
            return error(Error, "invalid UTF-8 sequence", true, 1007, "WS_ERR_INVALID_UTF8");
          }
          this.emit("conclude", code, buf);
          this.end();
          this._state = GET_INFO;
        }
      } else if (this._opcode === 9) {
        this.emit("ping", data);
        this._state = WAIT_MICROTASK;
      } else {
        this.emit("pong", data);
        this._state = WAIT_MICROTASK;
      }
    }
  }
  module.exports = Receiver;
});

// node_modules/ws/lib/sender.js
var require_sender = __commonJS((exports, module) => {
  var { Duplex } = __require("stream");
  var { randomFillSync } = __require("crypto");
  var PerMessageDeflate = require_permessage_deflate();
  var { EMPTY_BUFFER } = require_constants();
  var { isValidStatusCode } = require_validation();
  var { mask: applyMask, toBuffer } = require_buffer_util();
  var kByteLength = Symbol("kByteLength");
  var maskBuffer = Buffer.alloc(4);

  class Sender {
    constructor(socket, extensions, generateMask) {
      this._extensions = extensions || {};
      if (generateMask) {
        this._generateMask = generateMask;
        this._maskBuffer = Buffer.alloc(4);
      }
      this._socket = socket;
      this._firstFragment = true;
      this._compress = false;
      this._bufferedBytes = 0;
      this._deflating = false;
      this._queue = [];
    }
    static frame(data, options) {
      let mask;
      let merge = false;
      let offset = 2;
      let skipMasking = false;
      if (options.mask) {
        mask = options.maskBuffer || maskBuffer;
        if (options.generateMask) {
          options.generateMask(mask);
        } else {
          randomFillSync(mask, 0, 4);
        }
        skipMasking = (mask[0] | mask[1] | mask[2] | mask[3]) === 0;
        offset = 6;
      }
      let dataLength;
      if (typeof data === "string") {
        if ((!options.mask || skipMasking) && options[kByteLength] !== undefined) {
          dataLength = options[kByteLength];
        } else {
          data = Buffer.from(data);
          dataLength = data.length;
        }
      } else {
        dataLength = data.length;
        merge = options.mask && options.readOnly && !skipMasking;
      }
      let payloadLength = dataLength;
      if (dataLength >= 65536) {
        offset += 8;
        payloadLength = 127;
      } else if (dataLength > 125) {
        offset += 2;
        payloadLength = 126;
      }
      const target = Buffer.allocUnsafe(merge ? dataLength + offset : offset);
      target[0] = options.fin ? options.opcode | 128 : options.opcode;
      if (options.rsv1)
        target[0] |= 64;
      target[1] = payloadLength;
      if (payloadLength === 126) {
        target.writeUInt16BE(dataLength, 2);
      } else if (payloadLength === 127) {
        target[2] = target[3] = 0;
        target.writeUIntBE(dataLength, 4, 6);
      }
      if (!options.mask)
        return [target, data];
      target[1] |= 128;
      target[offset - 4] = mask[0];
      target[offset - 3] = mask[1];
      target[offset - 2] = mask[2];
      target[offset - 1] = mask[3];
      if (skipMasking)
        return [target, data];
      if (merge) {
        applyMask(data, mask, target, offset, dataLength);
        return [target];
      }
      applyMask(data, mask, data, 0, dataLength);
      return [target, data];
    }
    close(code, data, mask, cb) {
      let buf;
      if (code === undefined) {
        buf = EMPTY_BUFFER;
      } else if (typeof code !== "number" || !isValidStatusCode(code)) {
        throw new TypeError("First argument must be a valid error code number");
      } else if (data === undefined || !data.length) {
        buf = Buffer.allocUnsafe(2);
        buf.writeUInt16BE(code, 0);
      } else {
        const length = Buffer.byteLength(data);
        if (length > 123) {
          throw new RangeError("The message must not be greater than 123 bytes");
        }
        buf = Buffer.allocUnsafe(2 + length);
        buf.writeUInt16BE(code, 0);
        if (typeof data === "string") {
          buf.write(data, 2);
        } else {
          buf.set(data, 2);
        }
      }
      const options = {
        [kByteLength]: buf.length,
        fin: true,
        generateMask: this._generateMask,
        mask,
        maskBuffer: this._maskBuffer,
        opcode: 8,
        readOnly: false,
        rsv1: false
      };
      if (this._deflating) {
        this.enqueue([this.dispatch, buf, false, options, cb]);
      } else {
        this.sendFrame(Sender.frame(buf, options), cb);
      }
    }
    ping(data, mask, cb) {
      let byteLength;
      let readOnly;
      if (typeof data === "string") {
        byteLength = Buffer.byteLength(data);
        readOnly = false;
      } else {
        data = toBuffer(data);
        byteLength = data.length;
        readOnly = toBuffer.readOnly;
      }
      if (byteLength > 125) {
        throw new RangeError("The data size must not be greater than 125 bytes");
      }
      const options = {
        [kByteLength]: byteLength,
        fin: true,
        generateMask: this._generateMask,
        mask,
        maskBuffer: this._maskBuffer,
        opcode: 9,
        readOnly,
        rsv1: false
      };
      if (this._deflating) {
        this.enqueue([this.dispatch, data, false, options, cb]);
      } else {
        this.sendFrame(Sender.frame(data, options), cb);
      }
    }
    pong(data, mask, cb) {
      let byteLength;
      let readOnly;
      if (typeof data === "string") {
        byteLength = Buffer.byteLength(data);
        readOnly = false;
      } else {
        data = toBuffer(data);
        byteLength = data.length;
        readOnly = toBuffer.readOnly;
      }
      if (byteLength > 125) {
        throw new RangeError("The data size must not be greater than 125 bytes");
      }
      const options = {
        [kByteLength]: byteLength,
        fin: true,
        generateMask: this._generateMask,
        mask,
        maskBuffer: this._maskBuffer,
        opcode: 10,
        readOnly,
        rsv1: false
      };
      if (this._deflating) {
        this.enqueue([this.dispatch, data, false, options, cb]);
      } else {
        this.sendFrame(Sender.frame(data, options), cb);
      }
    }
    send(data, options, cb) {
      const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];
      let opcode = options.binary ? 2 : 1;
      let rsv1 = options.compress;
      let byteLength;
      let readOnly;
      if (typeof data === "string") {
        byteLength = Buffer.byteLength(data);
        readOnly = false;
      } else {
        data = toBuffer(data);
        byteLength = data.length;
        readOnly = toBuffer.readOnly;
      }
      if (this._firstFragment) {
        this._firstFragment = false;
        if (rsv1 && perMessageDeflate && perMessageDeflate.params[perMessageDeflate._isServer ? "server_no_context_takeover" : "client_no_context_takeover"]) {
          rsv1 = byteLength >= perMessageDeflate._threshold;
        }
        this._compress = rsv1;
      } else {
        rsv1 = false;
        opcode = 0;
      }
      if (options.fin)
        this._firstFragment = true;
      if (perMessageDeflate) {
        const opts = {
          [kByteLength]: byteLength,
          fin: options.fin,
          generateMask: this._generateMask,
          mask: options.mask,
          maskBuffer: this._maskBuffer,
          opcode,
          readOnly,
          rsv1
        };
        if (this._deflating) {
          this.enqueue([this.dispatch, data, this._compress, opts, cb]);
        } else {
          this.dispatch(data, this._compress, opts, cb);
        }
      } else {
        this.sendFrame(Sender.frame(data, {
          [kByteLength]: byteLength,
          fin: options.fin,
          generateMask: this._generateMask,
          mask: options.mask,
          maskBuffer: this._maskBuffer,
          opcode,
          readOnly,
          rsv1: false
        }), cb);
      }
    }
    dispatch(data, compress, options, cb) {
      if (!compress) {
        this.sendFrame(Sender.frame(data, options), cb);
        return;
      }
      const perMessageDeflate = this._extensions[PerMessageDeflate.extensionName];
      this._bufferedBytes += options[kByteLength];
      this._deflating = true;
      perMessageDeflate.compress(data, options.fin, (_, buf) => {
        if (this._socket.destroyed) {
          const err = new Error("The socket was closed while data was being compressed");
          if (typeof cb === "function")
            cb(err);
          for (let i = 0;i < this._queue.length; i++) {
            const params = this._queue[i];
            const callback = params[params.length - 1];
            if (typeof callback === "function")
              callback(err);
          }
          return;
        }
        this._bufferedBytes -= options[kByteLength];
        this._deflating = false;
        options.readOnly = false;
        this.sendFrame(Sender.frame(buf, options), cb);
        this.dequeue();
      });
    }
    dequeue() {
      while (!this._deflating && this._queue.length) {
        const params = this._queue.shift();
        this._bufferedBytes -= params[3][kByteLength];
        Reflect.apply(params[0], this, params.slice(1));
      }
    }
    enqueue(params) {
      this._bufferedBytes += params[3][kByteLength];
      this._queue.push(params);
    }
    sendFrame(list, cb) {
      if (list.length === 2) {
        this._socket.cork();
        this._socket.write(list[0]);
        this._socket.write(list[1], cb);
        this._socket.uncork();
      } else {
        this._socket.write(list[0], cb);
      }
    }
  }
  module.exports = Sender;
});

// node_modules/ws/lib/event-target.js
var require_event_target = __commonJS((exports, module) => {
  var callListener = function(listener, thisArg, event) {
    if (typeof listener === "object" && listener.handleEvent) {
      listener.handleEvent.call(listener, event);
    } else {
      listener.call(thisArg, event);
    }
  };
  var { kForOnEventAttribute, kListener } = require_constants();
  var kCode = Symbol("kCode");
  var kData = Symbol("kData");
  var kError = Symbol("kError");
  var kMessage = Symbol("kMessage");
  var kReason = Symbol("kReason");
  var kTarget = Symbol("kTarget");
  var kType = Symbol("kType");
  var kWasClean = Symbol("kWasClean");

  class Event {
    constructor(type) {
      this[kTarget] = null;
      this[kType] = type;
    }
    get target() {
      return this[kTarget];
    }
    get type() {
      return this[kType];
    }
  }
  Object.defineProperty(Event.prototype, "target", { enumerable: true });
  Object.defineProperty(Event.prototype, "type", { enumerable: true });

  class CloseEvent extends Event {
    constructor(type, options = {}) {
      super(type);
      this[kCode] = options.code === undefined ? 0 : options.code;
      this[kReason] = options.reason === undefined ? "" : options.reason;
      this[kWasClean] = options.wasClean === undefined ? false : options.wasClean;
    }
    get code() {
      return this[kCode];
    }
    get reason() {
      return this[kReason];
    }
    get wasClean() {
      return this[kWasClean];
    }
  }
  Object.defineProperty(CloseEvent.prototype, "code", { enumerable: true });
  Object.defineProperty(CloseEvent.prototype, "reason", { enumerable: true });
  Object.defineProperty(CloseEvent.prototype, "wasClean", { enumerable: true });

  class ErrorEvent extends Event {
    constructor(type, options = {}) {
      super(type);
      this[kError] = options.error === undefined ? null : options.error;
      this[kMessage] = options.message === undefined ? "" : options.message;
    }
    get error() {
      return this[kError];
    }
    get message() {
      return this[kMessage];
    }
  }
  Object.defineProperty(ErrorEvent.prototype, "error", { enumerable: true });
  Object.defineProperty(ErrorEvent.prototype, "message", { enumerable: true });

  class MessageEvent extends Event {
    constructor(type, options = {}) {
      super(type);
      this[kData] = options.data === undefined ? null : options.data;
    }
    get data() {
      return this[kData];
    }
  }
  Object.defineProperty(MessageEvent.prototype, "data", { enumerable: true });
  var EventTarget = {
    addEventListener(type, handler, options = {}) {
      for (const listener of this.listeners(type)) {
        if (!options[kForOnEventAttribute] && listener[kListener] === handler && !listener[kForOnEventAttribute]) {
          return;
        }
      }
      let wrapper;
      if (type === "message") {
        wrapper = function onMessage(data, isBinary) {
          const event = new MessageEvent("message", {
            data: isBinary ? data : data.toString()
          });
          event[kTarget] = this;
          callListener(handler, this, event);
        };
      } else if (type === "close") {
        wrapper = function onClose(code, message) {
          const event = new CloseEvent("close", {
            code,
            reason: message.toString(),
            wasClean: this._closeFrameReceived && this._closeFrameSent
          });
          event[kTarget] = this;
          callListener(handler, this, event);
        };
      } else if (type === "error") {
        wrapper = function onError(error) {
          const event = new ErrorEvent("error", {
            error,
            message: error.message
          });
          event[kTarget] = this;
          callListener(handler, this, event);
        };
      } else if (type === "open") {
        wrapper = function onOpen() {
          const event = new Event("open");
          event[kTarget] = this;
          callListener(handler, this, event);
        };
      } else {
        return;
      }
      wrapper[kForOnEventAttribute] = !!options[kForOnEventAttribute];
      wrapper[kListener] = handler;
      if (options.once) {
        this.once(type, wrapper);
      } else {
        this.on(type, wrapper);
      }
    },
    removeEventListener(type, handler) {
      for (const listener of this.listeners(type)) {
        if (listener[kListener] === handler && !listener[kForOnEventAttribute]) {
          this.removeListener(type, listener);
          break;
        }
      }
    }
  };
  module.exports = {
    CloseEvent,
    ErrorEvent,
    Event,
    EventTarget,
    MessageEvent
  };
});

// node_modules/ws/lib/extension.js
var require_extension = __commonJS((exports, module) => {
  var push = function(dest, name, elem) {
    if (dest[name] === undefined)
      dest[name] = [elem];
    else
      dest[name].push(elem);
  };
  var parse = function(header) {
    const offers = Object.create(null);
    let params = Object.create(null);
    let mustUnescape = false;
    let isEscaping = false;
    let inQuotes = false;
    let extensionName;
    let paramName;
    let start = -1;
    let code = -1;
    let end = -1;
    let i = 0;
    for (;i < header.length; i++) {
      code = header.charCodeAt(i);
      if (extensionName === undefined) {
        if (end === -1 && tokenChars[code] === 1) {
          if (start === -1)
            start = i;
        } else if (i !== 0 && (code === 32 || code === 9)) {
          if (end === -1 && start !== -1)
            end = i;
        } else if (code === 59 || code === 44) {
          if (start === -1) {
            throw new SyntaxError(`Unexpected character at index ${i}`);
          }
          if (end === -1)
            end = i;
          const name = header.slice(start, end);
          if (code === 44) {
            push(offers, name, params);
            params = Object.create(null);
          } else {
            extensionName = name;
          }
          start = end = -1;
        } else {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }
      } else if (paramName === undefined) {
        if (end === -1 && tokenChars[code] === 1) {
          if (start === -1)
            start = i;
        } else if (code === 32 || code === 9) {
          if (end === -1 && start !== -1)
            end = i;
        } else if (code === 59 || code === 44) {
          if (start === -1) {
            throw new SyntaxError(`Unexpected character at index ${i}`);
          }
          if (end === -1)
            end = i;
          push(params, header.slice(start, end), true);
          if (code === 44) {
            push(offers, extensionName, params);
            params = Object.create(null);
            extensionName = undefined;
          }
          start = end = -1;
        } else if (code === 61 && start !== -1 && end === -1) {
          paramName = header.slice(start, i);
          start = end = -1;
        } else {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }
      } else {
        if (isEscaping) {
          if (tokenChars[code] !== 1) {
            throw new SyntaxError(`Unexpected character at index ${i}`);
          }
          if (start === -1)
            start = i;
          else if (!mustUnescape)
            mustUnescape = true;
          isEscaping = false;
        } else if (inQuotes) {
          if (tokenChars[code] === 1) {
            if (start === -1)
              start = i;
          } else if (code === 34 && start !== -1) {
            inQuotes = false;
            end = i;
          } else if (code === 92) {
            isEscaping = true;
          } else {
            throw new SyntaxError(`Unexpected character at index ${i}`);
          }
        } else if (code === 34 && header.charCodeAt(i - 1) === 61) {
          inQuotes = true;
        } else if (end === -1 && tokenChars[code] === 1) {
          if (start === -1)
            start = i;
        } else if (start !== -1 && (code === 32 || code === 9)) {
          if (end === -1)
            end = i;
        } else if (code === 59 || code === 44) {
          if (start === -1) {
            throw new SyntaxError(`Unexpected character at index ${i}`);
          }
          if (end === -1)
            end = i;
          let value = header.slice(start, end);
          if (mustUnescape) {
            value = value.replace(/\\/g, "");
            mustUnescape = false;
          }
          push(params, paramName, value);
          if (code === 44) {
            push(offers, extensionName, params);
            params = Object.create(null);
            extensionName = undefined;
          }
          paramName = undefined;
          start = end = -1;
        } else {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }
      }
    }
    if (start === -1 || inQuotes || code === 32 || code === 9) {
      throw new SyntaxError("Unexpected end of input");
    }
    if (end === -1)
      end = i;
    const token = header.slice(start, end);
    if (extensionName === undefined) {
      push(offers, token, params);
    } else {
      if (paramName === undefined) {
        push(params, token, true);
      } else if (mustUnescape) {
        push(params, paramName, token.replace(/\\/g, ""));
      } else {
        push(params, paramName, token);
      }
      push(offers, extensionName, params);
    }
    return offers;
  };
  var format = function(extensions) {
    return Object.keys(extensions).map((extension) => {
      let configurations = extensions[extension];
      if (!Array.isArray(configurations))
        configurations = [configurations];
      return configurations.map((params) => {
        return [extension].concat(Object.keys(params).map((k) => {
          let values = params[k];
          if (!Array.isArray(values))
            values = [values];
          return values.map((v) => v === true ? k : `${k}=${v}`).join("; ");
        })).join("; ");
      }).join(", ");
    }).join(", ");
  };
  var { tokenChars } = require_validation();
  module.exports = { format, parse };
});

// node_modules/ws/lib/websocket.js
var require_websocket = __commonJS((exports, module) => {
  var initAsClient = function(websocket, address, protocols, options) {
    const opts = {
      protocolVersion: protocolVersions[1],
      maxPayload: 100 * 1024 * 1024,
      skipUTF8Validation: false,
      perMessageDeflate: true,
      followRedirects: false,
      maxRedirects: 10,
      ...options,
      createConnection: undefined,
      socketPath: undefined,
      hostname: undefined,
      protocol: undefined,
      timeout: undefined,
      method: "GET",
      host: undefined,
      path: undefined,
      port: undefined
    };
    if (!protocolVersions.includes(opts.protocolVersion)) {
      throw new RangeError(`Unsupported protocol version: ${opts.protocolVersion} ` + `(supported versions: ${protocolVersions.join(", ")})`);
    }
    let parsedUrl;
    if (address instanceof URL2) {
      parsedUrl = address;
    } else {
      try {
        parsedUrl = new URL2(address);
      } catch (e) {
        throw new SyntaxError(`Invalid URL: ${address}`);
      }
    }
    if (parsedUrl.protocol === "http:") {
      parsedUrl.protocol = "ws:";
    } else if (parsedUrl.protocol === "https:") {
      parsedUrl.protocol = "wss:";
    }
    websocket._url = parsedUrl.href;
    const isSecure = parsedUrl.protocol === "wss:";
    const isIpcUrl = parsedUrl.protocol === "ws+unix:";
    let invalidUrlMessage;
    if (parsedUrl.protocol !== "ws:" && !isSecure && !isIpcUrl) {
      invalidUrlMessage = 'The URL\'s protocol must be one of "ws:", "wss:", "http:", "https", or "ws+unix:"';
    } else if (isIpcUrl && !parsedUrl.pathname) {
      invalidUrlMessage = "The URL's pathname is empty";
    } else if (parsedUrl.hash) {
      invalidUrlMessage = "The URL contains a fragment identifier";
    }
    if (invalidUrlMessage) {
      const err = new SyntaxError(invalidUrlMessage);
      if (websocket._redirects === 0) {
        throw err;
      } else {
        emitErrorAndClose(websocket, err);
        return;
      }
    }
    const defaultPort = isSecure ? 443 : 80;
    const key = randomBytes(16).toString("base64");
    const request = isSecure ? https2.request : http2.request;
    const protocolSet = new Set;
    let perMessageDeflate;
    opts.createConnection = isSecure ? tlsConnect : netConnect;
    opts.defaultPort = opts.defaultPort || defaultPort;
    opts.port = parsedUrl.port || defaultPort;
    opts.host = parsedUrl.hostname.startsWith("[") ? parsedUrl.hostname.slice(1, -1) : parsedUrl.hostname;
    opts.headers = {
      ...opts.headers,
      "Sec-WebSocket-Version": opts.protocolVersion,
      "Sec-WebSocket-Key": key,
      Connection: "Upgrade",
      Upgrade: "websocket"
    };
    opts.path = parsedUrl.pathname + parsedUrl.search;
    opts.timeout = opts.handshakeTimeout;
    if (opts.perMessageDeflate) {
      perMessageDeflate = new PerMessageDeflate(opts.perMessageDeflate !== true ? opts.perMessageDeflate : {}, false, opts.maxPayload);
      opts.headers["Sec-WebSocket-Extensions"] = format({
        [PerMessageDeflate.extensionName]: perMessageDeflate.offer()
      });
    }
    if (protocols.length) {
      for (const protocol of protocols) {
        if (typeof protocol !== "string" || !subprotocolRegex.test(protocol) || protocolSet.has(protocol)) {
          throw new SyntaxError("An invalid or duplicated subprotocol was specified");
        }
        protocolSet.add(protocol);
      }
      opts.headers["Sec-WebSocket-Protocol"] = protocols.join(",");
    }
    if (opts.origin) {
      if (opts.protocolVersion < 13) {
        opts.headers["Sec-WebSocket-Origin"] = opts.origin;
      } else {
        opts.headers.Origin = opts.origin;
      }
    }
    if (parsedUrl.username || parsedUrl.password) {
      opts.auth = `${parsedUrl.username}:${parsedUrl.password}`;
    }
    if (isIpcUrl) {
      const parts = opts.path.split(":");
      opts.socketPath = parts[0];
      opts.path = parts[1];
    }
    let req;
    if (opts.followRedirects) {
      if (websocket._redirects === 0) {
        websocket._originalIpc = isIpcUrl;
        websocket._originalSecure = isSecure;
        websocket._originalHostOrSocketPath = isIpcUrl ? opts.socketPath : parsedUrl.host;
        const headers = options && options.headers;
        options = { ...options, headers: {} };
        if (headers) {
          for (const [key2, value] of Object.entries(headers)) {
            options.headers[key2.toLowerCase()] = value;
          }
        }
      } else if (websocket.listenerCount("redirect") === 0) {
        const isSameHost = isIpcUrl ? websocket._originalIpc ? opts.socketPath === websocket._originalHostOrSocketPath : false : websocket._originalIpc ? false : parsedUrl.host === websocket._originalHostOrSocketPath;
        if (!isSameHost || websocket._originalSecure && !isSecure) {
          delete opts.headers.authorization;
          delete opts.headers.cookie;
          if (!isSameHost)
            delete opts.headers.host;
          opts.auth = undefined;
        }
      }
      if (opts.auth && !options.headers.authorization) {
        options.headers.authorization = "Basic " + Buffer.from(opts.auth).toString("base64");
      }
      req = websocket._req = request(opts);
      if (websocket._redirects) {
        websocket.emit("redirect", websocket.url, req);
      }
    } else {
      req = websocket._req = request(opts);
    }
    if (opts.timeout) {
      req.on("timeout", () => {
        abortHandshake(websocket, req, "Opening handshake has timed out");
      });
    }
    req.on("error", (err) => {
      if (req === null || req[kAborted])
        return;
      req = websocket._req = null;
      emitErrorAndClose(websocket, err);
    });
    req.on("response", (res) => {
      const location = res.headers.location;
      const statusCode = res.statusCode;
      if (location && opts.followRedirects && statusCode >= 300 && statusCode < 400) {
        if (++websocket._redirects > opts.maxRedirects) {
          abortHandshake(websocket, req, "Maximum redirects exceeded");
          return;
        }
        req.abort();
        let addr;
        try {
          addr = new URL2(location, address);
        } catch (e) {
          const err = new SyntaxError(`Invalid URL: ${location}`);
          emitErrorAndClose(websocket, err);
          return;
        }
        initAsClient(websocket, addr, protocols, options);
      } else if (!websocket.emit("unexpected-response", req, res)) {
        abortHandshake(websocket, req, `Unexpected server response: ${res.statusCode}`);
      }
    });
    req.on("upgrade", (res, socket, head) => {
      websocket.emit("upgrade", res);
      if (websocket.readyState !== WebSocket.CONNECTING)
        return;
      req = websocket._req = null;
      if (res.headers.upgrade.toLowerCase() !== "websocket") {
        abortHandshake(websocket, socket, "Invalid Upgrade header");
        return;
      }
      const digest = createHash("sha1").update(key + GUID).digest("base64");
      if (res.headers["sec-websocket-accept"] !== digest) {
        abortHandshake(websocket, socket, "Invalid Sec-WebSocket-Accept header");
        return;
      }
      const serverProt = res.headers["sec-websocket-protocol"];
      let protError;
      if (serverProt !== undefined) {
        if (!protocolSet.size) {
          protError = "Server sent a subprotocol but none was requested";
        } else if (!protocolSet.has(serverProt)) {
          protError = "Server sent an invalid subprotocol";
        }
      } else if (protocolSet.size) {
        protError = "Server sent no subprotocol";
      }
      if (protError) {
        abortHandshake(websocket, socket, protError);
        return;
      }
      if (serverProt)
        websocket._protocol = serverProt;
      const secWebSocketExtensions = res.headers["sec-websocket-extensions"];
      if (secWebSocketExtensions !== undefined) {
        if (!perMessageDeflate) {
          const message = "Server sent a Sec-WebSocket-Extensions header but no extension was requested";
          abortHandshake(websocket, socket, message);
          return;
        }
        let extensions;
        try {
          extensions = parse(secWebSocketExtensions);
        } catch (err) {
          const message = "Invalid Sec-WebSocket-Extensions header";
          abortHandshake(websocket, socket, message);
          return;
        }
        const extensionNames = Object.keys(extensions);
        if (extensionNames.length !== 1 || extensionNames[0] !== PerMessageDeflate.extensionName) {
          const message = "Server indicated an extension that was not requested";
          abortHandshake(websocket, socket, message);
          return;
        }
        try {
          perMessageDeflate.accept(extensions[PerMessageDeflate.extensionName]);
        } catch (err) {
          const message = "Invalid Sec-WebSocket-Extensions header";
          abortHandshake(websocket, socket, message);
          return;
        }
        websocket._extensions[PerMessageDeflate.extensionName] = perMessageDeflate;
      }
      websocket.setSocket(socket, head, {
        generateMask: opts.generateMask,
        maxPayload: opts.maxPayload,
        skipUTF8Validation: opts.skipUTF8Validation
      });
    });
    if (opts.finishRequest) {
      opts.finishRequest(req, websocket);
    } else {
      req.end();
    }
  };
  var emitErrorAndClose = function(websocket, err) {
    websocket._readyState = WebSocket.CLOSING;
    websocket.emit("error", err);
    websocket.emitClose();
  };
  var netConnect = function(options) {
    options.path = options.socketPath;
    return net.connect(options);
  };
  var tlsConnect = function(options) {
    options.path = undefined;
    if (!options.servername && options.servername !== "") {
      options.servername = net.isIP(options.host) ? "" : options.host;
    }
    return tls.connect(options);
  };
  var abortHandshake = function(websocket, stream, message) {
    websocket._readyState = WebSocket.CLOSING;
    const err = new Error(message);
    Error.captureStackTrace(err, abortHandshake);
    if (stream.setHeader) {
      stream[kAborted] = true;
      stream.abort();
      if (stream.socket && !stream.socket.destroyed) {
        stream.socket.destroy();
      }
      process.nextTick(emitErrorAndClose, websocket, err);
    } else {
      stream.destroy(err);
      stream.once("error", websocket.emit.bind(websocket, "error"));
      stream.once("close", websocket.emitClose.bind(websocket));
    }
  };
  var sendAfterClose = function(websocket, data, cb) {
    if (data) {
      const length = toBuffer(data).length;
      if (websocket._socket)
        websocket._sender._bufferedBytes += length;
      else
        websocket._bufferedAmount += length;
    }
    if (cb) {
      const err = new Error(`WebSocket is not open: readyState ${websocket.readyState} ` + `(${readyStates[websocket.readyState]})`);
      process.nextTick(cb, err);
    }
  };
  var receiverOnConclude = function(code, reason) {
    const websocket = this[kWebSocket];
    websocket._closeFrameReceived = true;
    websocket._closeMessage = reason;
    websocket._closeCode = code;
    if (websocket._socket[kWebSocket] === undefined)
      return;
    websocket._socket.removeListener("data", socketOnData);
    process.nextTick(resume, websocket._socket);
    if (code === 1005)
      websocket.close();
    else
      websocket.close(code, reason);
  };
  var receiverOnDrain = function() {
    const websocket = this[kWebSocket];
    if (!websocket.isPaused)
      websocket._socket.resume();
  };
  var receiverOnError = function(err) {
    const websocket = this[kWebSocket];
    if (websocket._socket[kWebSocket] !== undefined) {
      websocket._socket.removeListener("data", socketOnData);
      process.nextTick(resume, websocket._socket);
      websocket.close(err[kStatusCode]);
    }
    websocket.emit("error", err);
  };
  var receiverOnFinish = function() {
    this[kWebSocket].emitClose();
  };
  var receiverOnMessage = function(data, isBinary) {
    this[kWebSocket].emit("message", data, isBinary);
  };
  var receiverOnPing = function(data) {
    const websocket = this[kWebSocket];
    websocket.pong(data, !websocket._isServer, NOOP);
    websocket.emit("ping", data);
  };
  var receiverOnPong = function(data) {
    this[kWebSocket].emit("pong", data);
  };
  var resume = function(stream) {
    stream.resume();
  };
  var socketOnClose = function() {
    const websocket = this[kWebSocket];
    this.removeListener("close", socketOnClose);
    this.removeListener("data", socketOnData);
    this.removeListener("end", socketOnEnd);
    websocket._readyState = WebSocket.CLOSING;
    let chunk;
    if (!this._readableState.endEmitted && !websocket._closeFrameReceived && !websocket._receiver._writableState.errorEmitted && (chunk = websocket._socket.read()) !== null) {
      websocket._receiver.write(chunk);
    }
    websocket._receiver.end();
    this[kWebSocket] = undefined;
    clearTimeout(websocket._closeTimer);
    if (websocket._receiver._writableState.finished || websocket._receiver._writableState.errorEmitted) {
      websocket.emitClose();
    } else {
      websocket._receiver.on("error", receiverOnFinish);
      websocket._receiver.on("finish", receiverOnFinish);
    }
  };
  var socketOnData = function(chunk) {
    if (!this[kWebSocket]._receiver.write(chunk)) {
      this.pause();
    }
  };
  var socketOnEnd = function() {
    const websocket = this[kWebSocket];
    websocket._readyState = WebSocket.CLOSING;
    websocket._receiver.end();
    this.end();
  };
  var socketOnError = function() {
    const websocket = this[kWebSocket];
    this.removeListener("error", socketOnError);
    this.on("error", NOOP);
    if (websocket) {
      websocket._readyState = WebSocket.CLOSING;
      this.destroy();
    }
  };
  var EventEmitter = __require("events");
  var https2 = __require("https");
  var http2 = __require("http");
  var net = __require("net");
  var tls = __require("tls");
  var { randomBytes, createHash } = __require("crypto");
  var { Duplex, Readable } = __require("stream");
  var { URL: URL2 } = __require("url");
  var PerMessageDeflate = require_permessage_deflate();
  var Receiver = require_receiver();
  var Sender = require_sender();
  var {
    BINARY_TYPES,
    EMPTY_BUFFER,
    GUID,
    kForOnEventAttribute,
    kListener,
    kStatusCode,
    kWebSocket,
    NOOP
  } = require_constants();
  var {
    EventTarget: { addEventListener, removeEventListener }
  } = require_event_target();
  var { format, parse } = require_extension();
  var { toBuffer } = require_buffer_util();
  var closeTimeout = 30 * 1000;
  var kAborted = Symbol("kAborted");
  var protocolVersions = [8, 13];
  var readyStates = ["CONNECTING", "OPEN", "CLOSING", "CLOSED"];
  var subprotocolRegex = /^[!#$%&'*+\-.0-9A-Z^_`|a-z~]+$/;

  class WebSocket extends EventEmitter {
    constructor(address, protocols, options) {
      super();
      this._binaryType = BINARY_TYPES[0];
      this._closeCode = 1006;
      this._closeFrameReceived = false;
      this._closeFrameSent = false;
      this._closeMessage = EMPTY_BUFFER;
      this._closeTimer = null;
      this._extensions = {};
      this._paused = false;
      this._protocol = "";
      this._readyState = WebSocket.CONNECTING;
      this._receiver = null;
      this._sender = null;
      this._socket = null;
      if (address !== null) {
        this._bufferedAmount = 0;
        this._isServer = false;
        this._redirects = 0;
        if (protocols === undefined) {
          protocols = [];
        } else if (!Array.isArray(protocols)) {
          if (typeof protocols === "object" && protocols !== null) {
            options = protocols;
            protocols = [];
          } else {
            protocols = [protocols];
          }
        }
        initAsClient(this, address, protocols, options);
      } else {
        this._isServer = true;
      }
    }
    get binaryType() {
      return this._binaryType;
    }
    set binaryType(type) {
      if (!BINARY_TYPES.includes(type))
        return;
      this._binaryType = type;
      if (this._receiver)
        this._receiver._binaryType = type;
    }
    get bufferedAmount() {
      if (!this._socket)
        return this._bufferedAmount;
      return this._socket._writableState.length + this._sender._bufferedBytes;
    }
    get extensions() {
      return Object.keys(this._extensions).join();
    }
    get isPaused() {
      return this._paused;
    }
    get onclose() {
      return null;
    }
    get onerror() {
      return null;
    }
    get onopen() {
      return null;
    }
    get onmessage() {
      return null;
    }
    get protocol() {
      return this._protocol;
    }
    get readyState() {
      return this._readyState;
    }
    get url() {
      return this._url;
    }
    setSocket(socket, head, options) {
      const receiver = new Receiver({
        binaryType: this.binaryType,
        extensions: this._extensions,
        isServer: this._isServer,
        maxPayload: options.maxPayload,
        skipUTF8Validation: options.skipUTF8Validation
      });
      this._sender = new Sender(socket, this._extensions, options.generateMask);
      this._receiver = receiver;
      this._socket = socket;
      receiver[kWebSocket] = this;
      socket[kWebSocket] = this;
      receiver.on("conclude", receiverOnConclude);
      receiver.on("drain", receiverOnDrain);
      receiver.on("error", receiverOnError);
      receiver.on("message", receiverOnMessage);
      receiver.on("ping", receiverOnPing);
      receiver.on("pong", receiverOnPong);
      if (socket.setTimeout)
        socket.setTimeout(0);
      if (socket.setNoDelay)
        socket.setNoDelay();
      if (head.length > 0)
        socket.unshift(head);
      socket.on("close", socketOnClose);
      socket.on("data", socketOnData);
      socket.on("end", socketOnEnd);
      socket.on("error", socketOnError);
      this._readyState = WebSocket.OPEN;
      this.emit("open");
    }
    emitClose() {
      if (!this._socket) {
        this._readyState = WebSocket.CLOSED;
        this.emit("close", this._closeCode, this._closeMessage);
        return;
      }
      if (this._extensions[PerMessageDeflate.extensionName]) {
        this._extensions[PerMessageDeflate.extensionName].cleanup();
      }
      this._receiver.removeAllListeners();
      this._readyState = WebSocket.CLOSED;
      this.emit("close", this._closeCode, this._closeMessage);
    }
    close(code, data) {
      if (this.readyState === WebSocket.CLOSED)
        return;
      if (this.readyState === WebSocket.CONNECTING) {
        const msg = "WebSocket was closed before the connection was established";
        abortHandshake(this, this._req, msg);
        return;
      }
      if (this.readyState === WebSocket.CLOSING) {
        if (this._closeFrameSent && (this._closeFrameReceived || this._receiver._writableState.errorEmitted)) {
          this._socket.end();
        }
        return;
      }
      this._readyState = WebSocket.CLOSING;
      this._sender.close(code, data, !this._isServer, (err) => {
        if (err)
          return;
        this._closeFrameSent = true;
        if (this._closeFrameReceived || this._receiver._writableState.errorEmitted) {
          this._socket.end();
        }
      });
      this._closeTimer = setTimeout(this._socket.destroy.bind(this._socket), closeTimeout);
    }
    pause() {
      if (this.readyState === WebSocket.CONNECTING || this.readyState === WebSocket.CLOSED) {
        return;
      }
      this._paused = true;
      this._socket.pause();
    }
    ping(data, mask, cb) {
      if (this.readyState === WebSocket.CONNECTING) {
        throw new Error("WebSocket is not open: readyState 0 (CONNECTING)");
      }
      if (typeof data === "function") {
        cb = data;
        data = mask = undefined;
      } else if (typeof mask === "function") {
        cb = mask;
        mask = undefined;
      }
      if (typeof data === "number")
        data = data.toString();
      if (this.readyState !== WebSocket.OPEN) {
        sendAfterClose(this, data, cb);
        return;
      }
      if (mask === undefined)
        mask = !this._isServer;
      this._sender.ping(data || EMPTY_BUFFER, mask, cb);
    }
    pong(data, mask, cb) {
      if (this.readyState === WebSocket.CONNECTING) {
        throw new Error("WebSocket is not open: readyState 0 (CONNECTING)");
      }
      if (typeof data === "function") {
        cb = data;
        data = mask = undefined;
      } else if (typeof mask === "function") {
        cb = mask;
        mask = undefined;
      }
      if (typeof data === "number")
        data = data.toString();
      if (this.readyState !== WebSocket.OPEN) {
        sendAfterClose(this, data, cb);
        return;
      }
      if (mask === undefined)
        mask = !this._isServer;
      this._sender.pong(data || EMPTY_BUFFER, mask, cb);
    }
    resume() {
      if (this.readyState === WebSocket.CONNECTING || this.readyState === WebSocket.CLOSED) {
        return;
      }
      this._paused = false;
      if (!this._receiver._writableState.needDrain)
        this._socket.resume();
    }
    send(data, options, cb) {
      if (this.readyState === WebSocket.CONNECTING) {
        throw new Error("WebSocket is not open: readyState 0 (CONNECTING)");
      }
      if (typeof options === "function") {
        cb = options;
        options = {};
      }
      if (typeof data === "number")
        data = data.toString();
      if (this.readyState !== WebSocket.OPEN) {
        sendAfterClose(this, data, cb);
        return;
      }
      const opts = {
        binary: typeof data !== "string",
        mask: !this._isServer,
        compress: true,
        fin: true,
        ...options
      };
      if (!this._extensions[PerMessageDeflate.extensionName]) {
        opts.compress = false;
      }
      this._sender.send(data || EMPTY_BUFFER, opts, cb);
    }
    terminate() {
      if (this.readyState === WebSocket.CLOSED)
        return;
      if (this.readyState === WebSocket.CONNECTING) {
        const msg = "WebSocket was closed before the connection was established";
        abortHandshake(this, this._req, msg);
        return;
      }
      if (this._socket) {
        this._readyState = WebSocket.CLOSING;
        this._socket.destroy();
      }
    }
  }
  Object.defineProperty(WebSocket, "CONNECTING", {
    enumerable: true,
    value: readyStates.indexOf("CONNECTING")
  });
  Object.defineProperty(WebSocket.prototype, "CONNECTING", {
    enumerable: true,
    value: readyStates.indexOf("CONNECTING")
  });
  Object.defineProperty(WebSocket, "OPEN", {
    enumerable: true,
    value: readyStates.indexOf("OPEN")
  });
  Object.defineProperty(WebSocket.prototype, "OPEN", {
    enumerable: true,
    value: readyStates.indexOf("OPEN")
  });
  Object.defineProperty(WebSocket, "CLOSING", {
    enumerable: true,
    value: readyStates.indexOf("CLOSING")
  });
  Object.defineProperty(WebSocket.prototype, "CLOSING", {
    enumerable: true,
    value: readyStates.indexOf("CLOSING")
  });
  Object.defineProperty(WebSocket, "CLOSED", {
    enumerable: true,
    value: readyStates.indexOf("CLOSED")
  });
  Object.defineProperty(WebSocket.prototype, "CLOSED", {
    enumerable: true,
    value: readyStates.indexOf("CLOSED")
  });
  [
    "binaryType",
    "bufferedAmount",
    "extensions",
    "isPaused",
    "protocol",
    "readyState",
    "url"
  ].forEach((property) => {
    Object.defineProperty(WebSocket.prototype, property, { enumerable: true });
  });
  ["open", "error", "close", "message"].forEach((method) => {
    Object.defineProperty(WebSocket.prototype, `on${method}`, {
      enumerable: true,
      get() {
        for (const listener of this.listeners(method)) {
          if (listener[kForOnEventAttribute])
            return listener[kListener];
        }
        return null;
      },
      set(handler) {
        for (const listener of this.listeners(method)) {
          if (listener[kForOnEventAttribute]) {
            this.removeListener(method, listener);
            break;
          }
        }
        if (typeof handler !== "function")
          return;
        this.addEventListener(method, handler, {
          [kForOnEventAttribute]: true
        });
      }
    });
  });
  WebSocket.prototype.addEventListener = addEventListener;
  WebSocket.prototype.removeEventListener = removeEventListener;
  module.exports = WebSocket;
});

// node_modules/ws/lib/subprotocol.js
var require_subprotocol = __commonJS((exports, module) => {
  var parse = function(header) {
    const protocols = new Set;
    let start = -1;
    let end = -1;
    let i = 0;
    for (i;i < header.length; i++) {
      const code = header.charCodeAt(i);
      if (end === -1 && tokenChars[code] === 1) {
        if (start === -1)
          start = i;
      } else if (i !== 0 && (code === 32 || code === 9)) {
        if (end === -1 && start !== -1)
          end = i;
      } else if (code === 44) {
        if (start === -1) {
          throw new SyntaxError(`Unexpected character at index ${i}`);
        }
        if (end === -1)
          end = i;
        const protocol2 = header.slice(start, end);
        if (protocols.has(protocol2)) {
          throw new SyntaxError(`The "${protocol2}" subprotocol is duplicated`);
        }
        protocols.add(protocol2);
        start = end = -1;
      } else {
        throw new SyntaxError(`Unexpected character at index ${i}`);
      }
    }
    if (start === -1 || end !== -1) {
      throw new SyntaxError("Unexpected end of input");
    }
    const protocol = header.slice(start, i);
    if (protocols.has(protocol)) {
      throw new SyntaxError(`The "${protocol}" subprotocol is duplicated`);
    }
    protocols.add(protocol);
    return protocols;
  };
  var { tokenChars } = require_validation();
  module.exports = { parse };
});

// node_modules/ws/lib/websocket-server.js
var require_websocket_server = __commonJS((exports, module) => {
  var addListeners = function(server, map) {
    for (const event of Object.keys(map))
      server.on(event, map[event]);
    return function removeListeners() {
      for (const event of Object.keys(map)) {
        server.removeListener(event, map[event]);
      }
    };
  };
  var emitClose = function(server) {
    server._state = CLOSED;
    server.emit("close");
  };
  var socketOnError = function() {
    this.destroy();
  };
  var abortHandshake = function(socket, code, message, headers) {
    message = message || http2.STATUS_CODES[code];
    headers = {
      Connection: "close",
      "Content-Type": "text/html",
      "Content-Length": Buffer.byteLength(message),
      ...headers
    };
    socket.once("finish", socket.destroy);
    socket.end(`HTTP/1.1 ${code} ${http2.STATUS_CODES[code]}\r\n` + Object.keys(headers).map((h) => `${h}: ${headers[h]}`).join("\r\n") + "\r\n\r\n" + message);
  };
  var abortHandshakeOrEmitwsClientError = function(server, req, socket, code, message) {
    if (server.listenerCount("wsClientError")) {
      const err = new Error(message);
      Error.captureStackTrace(err, abortHandshakeOrEmitwsClientError);
      server.emit("wsClientError", err, socket, req);
    } else {
      abortHandshake(socket, code, message);
    }
  };
  var EventEmitter = __require("events");
  var http2 = __require("http");
  var { Duplex } = __require("stream");
  var { createHash } = __require("crypto");
  var extension = require_extension();
  var PerMessageDeflate = require_permessage_deflate();
  var subprotocol = require_subprotocol();
  var WebSocket = require_websocket();
  var { GUID, kWebSocket } = require_constants();
  var keyRegex = /^[+/0-9A-Za-z]{22}==$/;
  var RUNNING = 0;
  var CLOSING = 1;
  var CLOSED = 2;

  class WebSocketServer extends EventEmitter {
    constructor(options, callback) {
      super();
      options = {
        maxPayload: 100 * 1024 * 1024,
        skipUTF8Validation: false,
        perMessageDeflate: false,
        handleProtocols: null,
        clientTracking: true,
        verifyClient: null,
        noServer: false,
        backlog: null,
        server: null,
        host: null,
        path: null,
        port: null,
        WebSocket,
        ...options
      };
      if (options.port == null && !options.server && !options.noServer || options.port != null && (options.server || options.noServer) || options.server && options.noServer) {
        throw new TypeError('One and only one of the "port", "server", or "noServer" options must be specified');
      }
      if (options.port != null) {
        this._server = http2.createServer((req, res) => {
          const body = http2.STATUS_CODES[426];
          res.writeHead(426, {
            "Content-Length": body.length,
            "Content-Type": "text/plain"
          });
          res.end(body);
        });
        this._server.listen(options.port, options.host, options.backlog, callback);
      } else if (options.server) {
        this._server = options.server;
      }
      if (this._server) {
        const emitConnection = this.emit.bind(this, "connection");
        this._removeListeners = addListeners(this._server, {
          listening: this.emit.bind(this, "listening"),
          error: this.emit.bind(this, "error"),
          upgrade: (req, socket, head) => {
            this.handleUpgrade(req, socket, head, emitConnection);
          }
        });
      }
      if (options.perMessageDeflate === true)
        options.perMessageDeflate = {};
      if (options.clientTracking) {
        this.clients = new Set;
        this._shouldEmitClose = false;
      }
      this.options = options;
      this._state = RUNNING;
    }
    address() {
      if (this.options.noServer) {
        throw new Error('The server is operating in "noServer" mode');
      }
      if (!this._server)
        return null;
      return this._server.address();
    }
    close(cb) {
      if (this._state === CLOSED) {
        if (cb) {
          this.once("close", () => {
            cb(new Error("The server is not running"));
          });
        }
        process.nextTick(emitClose, this);
        return;
      }
      if (cb)
        this.once("close", cb);
      if (this._state === CLOSING)
        return;
      this._state = CLOSING;
      if (this.options.noServer || this.options.server) {
        if (this._server) {
          this._removeListeners();
          this._removeListeners = this._server = null;
        }
        if (this.clients) {
          if (!this.clients.size) {
            process.nextTick(emitClose, this);
          } else {
            this._shouldEmitClose = true;
          }
        } else {
          process.nextTick(emitClose, this);
        }
      } else {
        const server = this._server;
        this._removeListeners();
        this._removeListeners = this._server = null;
        server.close(() => {
          emitClose(this);
        });
      }
    }
    shouldHandle(req) {
      if (this.options.path) {
        const index = req.url.indexOf("?");
        const pathname = index !== -1 ? req.url.slice(0, index) : req.url;
        if (pathname !== this.options.path)
          return false;
      }
      return true;
    }
    handleUpgrade(req, socket, head, cb) {
      socket.on("error", socketOnError);
      const key = req.headers["sec-websocket-key"];
      const version = +req.headers["sec-websocket-version"];
      if (req.method !== "GET") {
        const message = "Invalid HTTP method";
        abortHandshakeOrEmitwsClientError(this, req, socket, 405, message);
        return;
      }
      if (req.headers.upgrade.toLowerCase() !== "websocket") {
        const message = "Invalid Upgrade header";
        abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);
        return;
      }
      if (!key || !keyRegex.test(key)) {
        const message = "Missing or invalid Sec-WebSocket-Key header";
        abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);
        return;
      }
      if (version !== 8 && version !== 13) {
        const message = "Missing or invalid Sec-WebSocket-Version header";
        abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);
        return;
      }
      if (!this.shouldHandle(req)) {
        abortHandshake(socket, 400);
        return;
      }
      const secWebSocketProtocol = req.headers["sec-websocket-protocol"];
      let protocols = new Set;
      if (secWebSocketProtocol !== undefined) {
        try {
          protocols = subprotocol.parse(secWebSocketProtocol);
        } catch (err) {
          const message = "Invalid Sec-WebSocket-Protocol header";
          abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);
          return;
        }
      }
      const secWebSocketExtensions = req.headers["sec-websocket-extensions"];
      const extensions = {};
      if (this.options.perMessageDeflate && secWebSocketExtensions !== undefined) {
        const perMessageDeflate = new PerMessageDeflate(this.options.perMessageDeflate, true, this.options.maxPayload);
        try {
          const offers = extension.parse(secWebSocketExtensions);
          if (offers[PerMessageDeflate.extensionName]) {
            perMessageDeflate.accept(offers[PerMessageDeflate.extensionName]);
            extensions[PerMessageDeflate.extensionName] = perMessageDeflate;
          }
        } catch (err) {
          const message = "Invalid or unacceptable Sec-WebSocket-Extensions header";
          abortHandshakeOrEmitwsClientError(this, req, socket, 400, message);
          return;
        }
      }
      if (this.options.verifyClient) {
        const info = {
          origin: req.headers[`${version === 8 ? "sec-websocket-origin" : "origin"}`],
          secure: !!(req.socket.authorized || req.socket.encrypted),
          req
        };
        if (this.options.verifyClient.length === 2) {
          this.options.verifyClient(info, (verified, code, message, headers) => {
            if (!verified) {
              return abortHandshake(socket, code || 401, message, headers);
            }
            this.completeUpgrade(extensions, key, protocols, req, socket, head, cb);
          });
          return;
        }
        if (!this.options.verifyClient(info))
          return abortHandshake(socket, 401);
      }
      this.completeUpgrade(extensions, key, protocols, req, socket, head, cb);
    }
    completeUpgrade(extensions, key, protocols, req, socket, head, cb) {
      if (!socket.readable || !socket.writable)
        return socket.destroy();
      if (socket[kWebSocket]) {
        throw new Error("server.handleUpgrade() was called more than once with the same socket, possibly due to a misconfiguration");
      }
      if (this._state > RUNNING)
        return abortHandshake(socket, 503);
      const digest = createHash("sha1").update(key + GUID).digest("base64");
      const headers = [
        "HTTP/1.1 101 Switching Protocols",
        "Upgrade: websocket",
        "Connection: Upgrade",
        `Sec-WebSocket-Accept: ${digest}`
      ];
      const ws = new this.options.WebSocket(null);
      if (protocols.size) {
        const protocol = this.options.handleProtocols ? this.options.handleProtocols(protocols, req) : protocols.values().next().value;
        if (protocol) {
          headers.push(`Sec-WebSocket-Protocol: ${protocol}`);
          ws._protocol = protocol;
        }
      }
      if (extensions[PerMessageDeflate.extensionName]) {
        const params = extensions[PerMessageDeflate.extensionName].params;
        const value = extension.format({
          [PerMessageDeflate.extensionName]: [params]
        });
        headers.push(`Sec-WebSocket-Extensions: ${value}`);
        ws._extensions = extensions;
      }
      this.emit("headers", headers, req);
      socket.write(headers.concat("\r\n").join("\r\n"));
      socket.removeListener("error", socketOnError);
      ws.setSocket(socket, head, {
        maxPayload: this.options.maxPayload,
        skipUTF8Validation: this.options.skipUTF8Validation
      });
      if (this.clients) {
        this.clients.add(ws);
        ws.on("close", () => {
          this.clients.delete(ws);
          if (this._shouldEmitClose && !this.clients.size) {
            process.nextTick(emitClose, this);
          }
        });
      }
      cb(ws, req);
    }
  }
  module.exports = WebSocketServer;
});

// node_modules/kafkajs/src/loggers/index.js
var require_loggers = __commonJS((exports, module) => {
  var { assign } = Object;
  var LEVELS = {
    NOTHING: 0,
    ERROR: 1,
    WARN: 2,
    INFO: 4,
    DEBUG: 5
  };
  var createLevel = (label, level, currentLevel, namespace, logFunction) => (message, extra = {}) => {
    if (level > currentLevel())
      return;
    logFunction({
      namespace,
      level,
      label,
      log: assign({
        timestamp: new Date().toISOString(),
        logger: "kafkajs",
        message
      }, extra)
    });
  };
  var evaluateLogLevel = (logLevel) => {
    const envLogLevel = (process.env.KAFKAJS_LOG_LEVEL || "").toUpperCase();
    return LEVELS[envLogLevel] == null ? logLevel : LEVELS[envLogLevel];
  };
  var createLogger = ({ level = LEVELS.INFO, logCreator } = {}) => {
    let logLevel = evaluateLogLevel(level);
    const logFunction = logCreator(logLevel);
    const createNamespace = (namespace, logLevel2 = null) => {
      const namespaceLogLevel = evaluateLogLevel(logLevel2);
      return createLogFunctions(namespace, namespaceLogLevel);
    };
    const createLogFunctions = (namespace, namespaceLogLevel = null) => {
      const currentLogLevel = () => namespaceLogLevel == null ? logLevel : namespaceLogLevel;
      const logger = {
        info: createLevel("INFO", LEVELS.INFO, currentLogLevel, namespace, logFunction),
        error: createLevel("ERROR", LEVELS.ERROR, currentLogLevel, namespace, logFunction),
        warn: createLevel("WARN", LEVELS.WARN, currentLogLevel, namespace, logFunction),
        debug: createLevel("DEBUG", LEVELS.DEBUG, currentLogLevel, namespace, logFunction)
      };
      return assign(logger, {
        namespace: createNamespace,
        setLogLevel: (newLevel) => {
          logLevel = newLevel;
        }
      });
    };
    return createLogFunctions();
  };
  module.exports = {
    LEVELS,
    createLogger
  };
});

// node_modules/kafkajs/src/instrumentation/event.js
var require_event = __commonJS((exports, module) => {
  var id = 0;
  var nextId = () => {
    if (id === Number.MAX_VALUE) {
      id = 0;
    }
    return id++;
  };

  class InstrumentationEvent {
    constructor(type, payload) {
      this.id = nextId();
      this.type = type;
      this.timestamp = Date.now();
      this.payload = payload;
    }
  }
  module.exports = InstrumentationEvent;
});

// node_modules/kafkajs/package.json
var require_package = __commonJS((exports, module) => {
  module.exports = {
    name: "kafkajs",
    version: "2.2.4",
    description: "A modern Apache Kafka client for node.js",
    author: "Tulio Ornelas <ornelas.tulio@gmail.com>",
    main: "index.js",
    types: "types/index.d.ts",
    license: "MIT",
    keywords: [
      "kafka",
      "sasl",
      "scram"
    ],
    engines: {
      node: ">=14.0.0"
    },
    repository: {
      type: "git",
      url: "https://github.com/tulios/kafkajs.git"
    },
    bugs: {
      url: "https://github.com/tulios/kafkajs/issues"
    },
    homepage: "https://kafka.js.org",
    scripts: {
      jest: "export KAFKA_VERSION=${KAFKA_VERSION:='2.4'} && NODE_ENV=test echo \"KAFKA_VERSION: ${KAFKA_VERSION}\" && KAFKAJS_DEBUG_PROTOCOL_BUFFERS=1 jest",
      "test:local": "yarn jest --detectOpenHandles",
      "test:debug": "NODE_ENV=test KAFKAJS_DEBUG_PROTOCOL_BUFFERS=1 node --inspect-brk $(yarn bin 2>/dev/null)/jest --detectOpenHandles --runInBand --watch",
      "test:local:watch": "yarn test:local --watch",
      test: "yarn lint && JEST_JUNIT_OUTPUT_NAME=test-report.xml ./scripts/testWithKafka.sh 'yarn jest --ci --maxWorkers=4 --no-watchman --forceExit'",
      lint: "find . -path ./node_modules -prune -o -path ./coverage -prune -o -path ./website -prune -o -name '*.js' -print0 | xargs -0 eslint",
      format: "find . -path ./node_modules -prune -o -path ./coverage -prune -o -path ./website -prune -o -name '*.js' -print0 | xargs -0 prettier --write",
      precommit: "lint-staged",
      "test:group:broker": "yarn jest --forceExit --testPathPattern 'src/broker/.*'",
      "test:group:admin": "yarn jest --forceExit --testPathPattern 'src/admin/.*'",
      "test:group:producer": "yarn jest --forceExit --testPathPattern 'src/producer/.*'",
      "test:group:consumer": "yarn jest --forceExit --testPathPattern 'src/consumer/.*.spec.js'",
      "test:group:others": "yarn jest --forceExit --testPathPattern 'src/(?!(broker|admin|producer|consumer)/).*'",
      "test:group:oauthbearer": "OAUTHBEARER_ENABLED=1 yarn jest --forceExit src/producer/index.spec.js src/broker/__tests__/connect.spec.js src/consumer/__tests__/connection.spec.js src/broker/__tests__/disconnect.spec.js src/admin/__tests__/connection.spec.js src/broker/__tests__/reauthenticate.spec.js",
      "test:group:broker:ci": "JEST_JUNIT_OUTPUT_NAME=test-report.xml ./scripts/testWithKafka.sh \"yarn test:group:broker --ci --maxWorkers=4 --no-watchman\"",
      "test:group:admin:ci": "JEST_JUNIT_OUTPUT_NAME=test-report.xml ./scripts/testWithKafka.sh \"yarn test:group:admin --ci --maxWorkers=4 --no-watchman\"",
      "test:group:producer:ci": "JEST_JUNIT_OUTPUT_NAME=test-report.xml ./scripts/testWithKafka.sh \"yarn test:group:producer --ci --maxWorkers=4 --no-watchman\"",
      "test:group:consumer:ci": "JEST_JUNIT_OUTPUT_NAME=test-report.xml ./scripts/testWithKafka.sh \"yarn test:group:consumer --ci --maxWorkers=4 --no-watchman\"",
      "test:group:others:ci": "JEST_JUNIT_OUTPUT_NAME=test-report.xml ./scripts/testWithKafka.sh \"yarn test:group:others --ci --maxWorkers=4 --no-watchman\"",
      "test:group:oauthbearer:ci": "JEST_JUNIT_OUTPUT_NAME=test-report.xml COMPOSE_FILE='docker-compose.2_4_oauthbearer.yml' ./scripts/testWithKafka.sh \"yarn test:group:oauthbearer --ci --maxWorkers=4 --no-watchman\"",
      "test:types": "tsc -p types/"
    },
    devDependencies: {
      "@types/jest": "^27.4.0",
      "@types/node": "^12.0.8",
      "@typescript-eslint/typescript-estree": "^1.10.2",
      eslint: "^6.8.0",
      "eslint-config-prettier": "^6.0.0",
      "eslint-config-standard": "^13.0.1",
      "eslint-plugin-import": "^2.18.2",
      "eslint-plugin-jest": "^26.1.0",
      "eslint-plugin-node": "^11.0.0",
      "eslint-plugin-prettier": "^3.1.0",
      "eslint-plugin-promise": "^4.2.1",
      "eslint-plugin-standard": "^4.0.0",
      execa: "^2.0.3",
      glob: "^7.1.4",
      husky: "^3.0.1",
      ip: "^1.1.5",
      jest: "^25.1.0",
      "jest-circus": "^25.1.0",
      "jest-extended": "^0.11.2",
      "jest-junit": "^10.0.0",
      jsonwebtoken: "^9.0.0",
      "lint-staged": "^9.2.0",
      mockdate: "^2.0.5",
      prettier: "^1.18.2",
      semver: "^6.2.0",
      typescript: "^3.8.3",
      uuid: "^3.3.2"
    },
    dependencies: {},
    "lint-staged": {
      "*.js": [
        "prettier --write",
        "git add"
      ]
    }
  };
});

// node_modules/kafkajs/src/errors.js
var require_errors2 = __commonJS((exports, module) => {
  var pkgJson = require_package();
  var { bugs } = pkgJson;

  class KafkaJSError extends Error {
    constructor(e, { retriable = true, cause } = {}) {
      super(e, { cause });
      Error.captureStackTrace(this, this.constructor);
      this.message = e.message || e;
      this.name = "KafkaJSError";
      this.retriable = retriable;
      this.helpUrl = e.helpUrl;
      this.cause = cause;
    }
  }

  class KafkaJSNonRetriableError extends KafkaJSError {
    constructor(e, { cause } = {}) {
      super(e, { retriable: false, cause });
      this.name = "KafkaJSNonRetriableError";
    }
  }

  class KafkaJSProtocolError extends KafkaJSError {
    constructor(e, { retriable = e.retriable } = {}) {
      super(e, { retriable });
      this.type = e.type;
      this.code = e.code;
      this.name = "KafkaJSProtocolError";
    }
  }

  class KafkaJSOffsetOutOfRange extends KafkaJSProtocolError {
    constructor(e, { topic, partition }) {
      super(e);
      this.topic = topic;
      this.partition = partition;
      this.name = "KafkaJSOffsetOutOfRange";
    }
  }

  class KafkaJSMemberIdRequired extends KafkaJSProtocolError {
    constructor(e, { memberId }) {
      super(e);
      this.memberId = memberId;
      this.name = "KafkaJSMemberIdRequired";
    }
  }

  class KafkaJSNumberOfRetriesExceeded extends KafkaJSNonRetriableError {
    constructor(e, { retryCount, retryTime }) {
      super(e, { cause: e });
      this.stack = `${this.name}\n  Caused by: ${e.stack}`;
      this.retryCount = retryCount;
      this.retryTime = retryTime;
      this.name = "KafkaJSNumberOfRetriesExceeded";
    }
  }

  class KafkaJSConnectionError extends KafkaJSError {
    constructor(e, { broker, code } = {}) {
      super(e);
      this.broker = broker;
      this.code = code;
      this.name = "KafkaJSConnectionError";
    }
  }

  class KafkaJSConnectionClosedError extends KafkaJSConnectionError {
    constructor(e, { host, port } = {}) {
      super(e, { broker: `${host}:${port}` });
      this.host = host;
      this.port = port;
      this.name = "KafkaJSConnectionClosedError";
    }
  }

  class KafkaJSRequestTimeoutError extends KafkaJSError {
    constructor(e, { broker, correlationId, createdAt, sentAt, pendingDuration } = {}) {
      super(e);
      this.broker = broker;
      this.correlationId = correlationId;
      this.createdAt = createdAt;
      this.sentAt = sentAt;
      this.pendingDuration = pendingDuration;
      this.name = "KafkaJSRequestTimeoutError";
    }
  }

  class KafkaJSMetadataNotLoaded extends KafkaJSError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSMetadataNotLoaded";
    }
  }

  class KafkaJSTopicMetadataNotLoaded extends KafkaJSMetadataNotLoaded {
    constructor(e, { topic } = {}) {
      super(e);
      this.topic = topic;
      this.name = "KafkaJSTopicMetadataNotLoaded";
    }
  }

  class KafkaJSStaleTopicMetadataAssignment extends KafkaJSError {
    constructor(e, { topic, unknownPartitions } = {}) {
      super(e);
      this.topic = topic;
      this.unknownPartitions = unknownPartitions;
      this.name = "KafkaJSStaleTopicMetadataAssignment";
    }
  }

  class KafkaJSDeleteGroupsError extends KafkaJSError {
    constructor(e, groups = []) {
      super(e);
      this.groups = groups;
      this.name = "KafkaJSDeleteGroupsError";
    }
  }

  class KafkaJSServerDoesNotSupportApiKey extends KafkaJSNonRetriableError {
    constructor(e, { apiKey, apiName } = {}) {
      super(e);
      this.apiKey = apiKey;
      this.apiName = apiName;
      this.name = "KafkaJSServerDoesNotSupportApiKey";
    }
  }

  class KafkaJSBrokerNotFound extends KafkaJSError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSBrokerNotFound";
    }
  }

  class KafkaJSPartialMessageError extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSPartialMessageError";
    }
  }

  class KafkaJSSASLAuthenticationError extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSSASLAuthenticationError";
    }
  }

  class KafkaJSGroupCoordinatorNotFound extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSGroupCoordinatorNotFound";
    }
  }

  class KafkaJSNotImplemented extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSNotImplemented";
    }
  }

  class KafkaJSTimeout extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSTimeout";
    }
  }

  class KafkaJSLockTimeout extends KafkaJSTimeout {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSLockTimeout";
    }
  }

  class KafkaJSUnsupportedMagicByteInMessageSet extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSUnsupportedMagicByteInMessageSet";
    }
  }

  class KafkaJSDeleteTopicRecordsError extends KafkaJSError {
    constructor({ partitions }) {
      const retriable = partitions.filter(({ error }) => error != null).every(({ error }) => error.retriable === true);
      super("Error while deleting records", { retriable });
      this.name = "KafkaJSDeleteTopicRecordsError";
      this.partitions = partitions;
    }
  }
  var issueUrl = bugs ? bugs.url : null;

  class KafkaJSInvariantViolation extends KafkaJSNonRetriableError {
    constructor(e) {
      const message = e.message || e;
      super(`Invariant violated: ${message}. This is likely a bug and should be reported.`);
      this.name = "KafkaJSInvariantViolation";
      if (issueUrl !== null) {
        const issueTitle = encodeURIComponent(`Invariant violation: ${message}`);
        this.helpUrl = `${issueUrl}/new?assignees=&labels=bug&template=bug_report.md&title=${issueTitle}`;
      }
    }
  }

  class KafkaJSInvalidVarIntError extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSNonRetriableError";
    }
  }

  class KafkaJSInvalidLongError extends KafkaJSNonRetriableError {
    constructor() {
      super(...arguments);
      this.name = "KafkaJSNonRetriableError";
    }
  }

  class KafkaJSCreateTopicError extends KafkaJSProtocolError {
    constructor(e, topicName) {
      super(e);
      this.topic = topicName;
      this.name = "KafkaJSCreateTopicError";
    }
  }

  class KafkaJSAlterPartitionReassignmentsError extends KafkaJSProtocolError {
    constructor(e, topicName, partition) {
      super(e);
      this.topic = topicName;
      this.partition = partition;
      this.name = "KafkaJSAlterPartitionReassignmentsError";
    }
  }

  class KafkaJSAggregateError extends Error {
    constructor(message, errors) {
      super(message);
      this.errors = errors;
      this.name = "KafkaJSAggregateError";
    }
  }

  class KafkaJSFetcherRebalanceError extends Error {
  }

  class KafkaJSNoBrokerAvailableError extends KafkaJSError {
    constructor() {
      super("No broker available");
      this.name = "KafkaJSNoBrokerAvailableError";
    }
  }
  var isRebalancing = (e) => e.type === "REBALANCE_IN_PROGRESS" || e.type === "NOT_COORDINATOR_FOR_GROUP" || e.type === "ILLEGAL_GENERATION";
  var isKafkaJSError = (e) => e instanceof KafkaJSError;
  module.exports = {
    KafkaJSError,
    KafkaJSNonRetriableError,
    KafkaJSPartialMessageError,
    KafkaJSBrokerNotFound,
    KafkaJSProtocolError,
    KafkaJSConnectionError,
    KafkaJSConnectionClosedError,
    KafkaJSRequestTimeoutError,
    KafkaJSSASLAuthenticationError,
    KafkaJSNumberOfRetriesExceeded,
    KafkaJSOffsetOutOfRange,
    KafkaJSMemberIdRequired,
    KafkaJSGroupCoordinatorNotFound,
    KafkaJSNotImplemented,
    KafkaJSMetadataNotLoaded,
    KafkaJSTopicMetadataNotLoaded,
    KafkaJSStaleTopicMetadataAssignment,
    KafkaJSDeleteGroupsError,
    KafkaJSTimeout,
    KafkaJSLockTimeout,
    KafkaJSServerDoesNotSupportApiKey,
    KafkaJSUnsupportedMagicByteInMessageSet,
    KafkaJSDeleteTopicRecordsError,
    KafkaJSInvariantViolation,
    KafkaJSInvalidVarIntError,
    KafkaJSInvalidLongError,
    KafkaJSCreateTopicError,
    KafkaJSAggregateError,
    KafkaJSFetcherRebalanceError,
    KafkaJSNoBrokerAvailableError,
    KafkaJSAlterPartitionReassignmentsError,
    isRebalancing,
    isKafkaJSError
  };
});

// node_modules/kafkajs/src/instrumentation/emitter.js
var require_emitter = __commonJS((exports, module) => {
  var { EventEmitter } = __require("events");
  var InstrumentationEvent = require_event();
  var { KafkaJSError } = require_errors2();
  module.exports = class InstrumentationEventEmitter {
    constructor() {
      this.emitter = new EventEmitter;
    }
    emit(eventName, payload) {
      if (!eventName) {
        throw new KafkaJSError("Invalid event name", { retriable: false });
      }
      if (this.emitter.listenerCount(eventName) > 0) {
        const event = new InstrumentationEvent(eventName, payload);
        this.emitter.emit(eventName, event);
      }
    }
    addListener(eventName, listener) {
      this.emitter.addListener(eventName, listener);
      return () => this.emitter.removeListener(eventName, listener);
    }
  };
});

// node_modules/kafkajs/src/loggers/console.js
var require_console = __commonJS((exports, module) => {
  var { LEVELS: logLevel } = require_loggers();
  module.exports = () => ({ namespace, level, label, log }) => {
    const prefix = namespace ? `[${namespace}] ` : "";
    const message = JSON.stringify(Object.assign({ level: label }, log, {
      message: `${prefix}${log.message}`
    }));
    switch (level) {
      case logLevel.INFO:
        return console.info(message);
      case logLevel.ERROR:
        return console.error(message);
      case logLevel.WARN:
        return console.warn(message);
      case logLevel.DEBUG:
        return console.log(message);
    }
  };
});

// node_modules/kafkajs/src/utils/lock.js
var require_lock = __commonJS((exports, module) => {
  var { format } = __require("util");
  var { KafkaJSLockTimeout } = require_errors2();
  var PRIVATE = {
    LOCKED: Symbol("private:Lock:locked"),
    TIMEOUT: Symbol("private:Lock:timeout"),
    WAITING: Symbol("private:Lock:waiting"),
    TIMEOUT_ERROR_MESSAGE: Symbol("private:Lock:timeoutErrorMessage")
  };
  var TIMEOUT_MESSAGE = "Timeout while acquiring lock (%d waiting locks)";
  module.exports = class Lock {
    constructor({ timeout, description = null } = {}) {
      if (typeof timeout !== "number") {
        throw new TypeError(`'timeout' is not a number, received '${typeof timeout}'`);
      }
      this[PRIVATE.LOCKED] = false;
      this[PRIVATE.TIMEOUT] = timeout;
      this[PRIVATE.WAITING] = new Set;
      this[PRIVATE.TIMEOUT_ERROR_MESSAGE] = () => {
        const timeoutMessage = format(TIMEOUT_MESSAGE, this[PRIVATE.WAITING].size);
        return description ? `${timeoutMessage}: "${description}"` : timeoutMessage;
      };
    }
    async acquire() {
      return new Promise((resolve, reject) => {
        if (!this[PRIVATE.LOCKED]) {
          this[PRIVATE.LOCKED] = true;
          return resolve();
        }
        let timeoutId = null;
        const tryToAcquire = async () => {
          if (!this[PRIVATE.LOCKED]) {
            this[PRIVATE.LOCKED] = true;
            clearTimeout(timeoutId);
            this[PRIVATE.WAITING].delete(tryToAcquire);
            return resolve();
          }
        };
        this[PRIVATE.WAITING].add(tryToAcquire);
        timeoutId = setTimeout(() => {
          const error = new KafkaJSLockTimeout(this[PRIVATE.TIMEOUT_ERROR_MESSAGE]());
          this[PRIVATE.WAITING].delete(tryToAcquire);
          reject(error);
        }, this[PRIVATE.TIMEOUT]);
      });
    }
    async release() {
      this[PRIVATE.LOCKED] = false;
      const waitingLock = this[PRIVATE.WAITING].values().next().value;
      if (waitingLock) {
        return waitingLock();
      }
    }
  };
});

// node_modules/kafkajs/src/protocol/message/compression/gzip.js
var require_gzip = __commonJS((exports, module) => {
  var { promisify } = __require("util");
  var zlib = __require("zlib");
  var gzip = promisify(zlib.gzip);
  var unzip = promisify(zlib.unzip);
  module.exports = {
    async compress(encoder) {
      return await gzip(encoder.buffer);
    },
    async decompress(buffer) {
      return await unzip(buffer);
    }
  };
});

// node_modules/kafkajs/src/protocol/message/compression/index.js
var require_compression = __commonJS((exports, module) => {
  var { KafkaJSNotImplemented } = require_errors2();
  var COMPRESSION_CODEC_MASK = 7;
  var Types = {
    None: 0,
    GZIP: 1,
    Snappy: 2,
    LZ4: 3,
    ZSTD: 4
  };
  var Codecs = {
    [Types.GZIP]: () => require_gzip(),
    [Types.Snappy]: () => {
      throw new KafkaJSNotImplemented("Snappy compression not implemented");
    },
    [Types.LZ4]: () => {
      throw new KafkaJSNotImplemented("LZ4 compression not implemented");
    },
    [Types.ZSTD]: () => {
      throw new KafkaJSNotImplemented("ZSTD compression not implemented");
    }
  };
  var lookupCodec = (type) => Codecs[type] ? Codecs[type]() : null;
  var lookupCodecByAttributes = (attributes) => {
    const codec = Codecs[attributes & COMPRESSION_CODEC_MASK];
    return codec ? codec() : null;
  };
  module.exports = {
    Types,
    Codecs,
    lookupCodec,
    lookupCodecByAttributes,
    COMPRESSION_CODEC_MASK
  };
});

// node_modules/kafkajs/src/protocol/requests/apiKeys.js
var require_apiKeys = __commonJS((exports, module) => {
  module.exports = {
    Produce: 0,
    Fetch: 1,
    ListOffsets: 2,
    Metadata: 3,
    LeaderAndIsr: 4,
    StopReplica: 5,
    UpdateMetadata: 6,
    ControlledShutdown: 7,
    OffsetCommit: 8,
    OffsetFetch: 9,
    GroupCoordinator: 10,
    JoinGroup: 11,
    Heartbeat: 12,
    LeaveGroup: 13,
    SyncGroup: 14,
    DescribeGroups: 15,
    ListGroups: 16,
    SaslHandshake: 17,
    ApiVersions: 18,
    CreateTopics: 19,
    DeleteTopics: 20,
    DeleteRecords: 21,
    InitProducerId: 22,
    OffsetForLeaderEpoch: 23,
    AddPartitionsToTxn: 24,
    AddOffsetsToTxn: 25,
    EndTxn: 26,
    WriteTxnMarkers: 27,
    TxnOffsetCommit: 28,
    DescribeAcls: 29,
    CreateAcls: 30,
    DeleteAcls: 31,
    DescribeConfigs: 32,
    AlterConfigs: 33,
    AlterReplicaLogDirs: 34,
    DescribeLogDirs: 35,
    SaslAuthenticate: 36,
    CreatePartitions: 37,
    CreateDelegationToken: 38,
    RenewDelegationToken: 39,
    ExpireDelegationToken: 40,
    DescribeDelegationToken: 41,
    DeleteGroups: 42,
    ElectPreferredLeaders: 43,
    IncrementalAlterConfigs: 44,
    AlterPartitionReassignments: 45,
    ListPartitionReassignments: 46
  };
});

// node_modules/kafkajs/src/utils/long.js
var require_long = __commonJS((exports, module) => {
  class Long {
    constructor(value) {
      this.value = value;
    }
    static isLong(obj) {
      return typeof obj.value === "bigint";
    }
    static fromBits(value) {
      return new Long(BigInt(value));
    }
    static fromInt(value) {
      if (isNaN(value))
        return Long.ZERO;
      return new Long(BigInt.asIntN(64, BigInt(value)));
    }
    static fromNumber(value) {
      if (isNaN(value))
        return Long.ZERO;
      return new Long(BigInt(value));
    }
    static fromValue(val) {
      if (typeof val === "number")
        return this.fromNumber(val);
      if (typeof val === "string")
        return this.fromString(val);
      if (typeof val === "bigint")
        return new Long(val);
      if (this.isLong(val))
        return new Long(BigInt(val.value));
      return new Long(BigInt(val));
    }
    static fromString(str) {
      if (str.length === 0)
        throw Error("empty string");
      if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
        return Long.ZERO;
      return new Long(BigInt(str));
    }
    isZero() {
      return this.value === BigInt(0);
    }
    isNegative() {
      return this.value < BigInt(0);
    }
    toString() {
      return String(this.value);
    }
    toNumber() {
      return Number(this.value);
    }
    toInt() {
      return Number(BigInt.asIntN(32, this.value));
    }
    toJSON() {
      return this.toString();
    }
    shiftLeft(numBits) {
      return new Long(this.value << BigInt(numBits));
    }
    shiftRight(numBits) {
      return new Long(this.value >> BigInt(numBits));
    }
    or(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      return Long.fromBits(this.value | other.value);
    }
    xor(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      return new Long(this.value ^ other.value);
    }
    and(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      return new Long(this.value & other.value);
    }
    not() {
      return new Long(~this.value);
    }
    shiftRightUnsigned(numBits) {
      return new Long(this.value >> BigInt.asUintN(64, BigInt(numBits)));
    }
    equals(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      return this.value === other.value;
    }
    greaterThanOrEqual(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      return this.value >= other.value;
    }
    gte(other) {
      return this.greaterThanOrEqual(other);
    }
    notEquals(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      return !this.equals(other);
    }
    add(addend) {
      if (!Long.isLong(addend))
        addend = Long.fromValue(addend);
      return new Long(this.value + addend.value);
    }
    subtract(subtrahend) {
      if (!Long.isLong(subtrahend))
        subtrahend = Long.fromValue(subtrahend);
      return this.add(subtrahend.negate());
    }
    multiply(multiplier) {
      if (this.isZero())
        return Long.ZERO;
      if (!Long.isLong(multiplier))
        multiplier = Long.fromValue(multiplier);
      return new Long(this.value * multiplier.value);
    }
    divide(divisor) {
      if (!Long.isLong(divisor))
        divisor = Long.fromValue(divisor);
      if (divisor.isZero())
        throw Error("division by zero");
      return new Long(this.value / divisor.value);
    }
    compare(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      if (this.value === other.value)
        return 0;
      if (this.value > other.value)
        return 1;
      if (other.value > this.value)
        return -1;
    }
    lessThan(other) {
      if (!Long.isLong(other))
        other = Long.fromValue(other);
      return this.value < other.value;
    }
    negate() {
      if (this.equals(Long.MIN_VALUE)) {
        return Long.MIN_VALUE;
      }
      return this.not().add(Long.ONE);
    }
    getHighBits() {
      return Number(BigInt.asIntN(32, this.value >> BigInt(32)));
    }
    getLowBits() {
      return Number(BigInt.asIntN(32, this.value));
    }
  }
  Long.MIN_VALUE = new Long(BigInt("-9223372036854775808"));
  Long.MAX_VALUE = new Long(BigInt("9223372036854775807"));
  Long.ZERO = Long.fromInt(0);
  Long.ONE = Long.fromInt(1);
  module.exports = Long;
});

// node_modules/kafkajs/src/protocol/encoder.js
var require_encoder = __commonJS((exports, module) => {
  var Long = require_long();
  var INT8_SIZE = 1;
  var INT16_SIZE = 2;
  var INT32_SIZE = 4;
  var INT64_SIZE = 8;
  var DOUBLE_SIZE = 8;
  var MOST_SIGNIFICANT_BIT = 128;
  var OTHER_BITS = 127;
  var UNSIGNED_INT32_MAX_NUMBER = 4294967168;
  var UNSIGNED_INT64_MAX_NUMBER = 0xffffffffffffff80n;
  module.exports = class Encoder {
    static encodeZigZag(value) {
      return value << 1 ^ value >> 31;
    }
    static encodeZigZag64(value) {
      const longValue = Long.fromValue(value);
      return longValue.shiftLeft(1).xor(longValue.shiftRight(63));
    }
    static sizeOfVarInt(value) {
      let encodedValue = this.encodeZigZag(value);
      let bytes = 1;
      while ((encodedValue & UNSIGNED_INT32_MAX_NUMBER) !== 0) {
        bytes += 1;
        encodedValue >>>= 7;
      }
      return bytes;
    }
    static sizeOfVarLong(value) {
      let longValue = Encoder.encodeZigZag64(value);
      let bytes = 1;
      while (longValue.and(UNSIGNED_INT64_MAX_NUMBER).notEquals(Long.fromInt(0))) {
        bytes += 1;
        longValue = longValue.shiftRightUnsigned(7);
      }
      return bytes;
    }
    static sizeOfVarIntBytes(value) {
      const size = value == null ? -1 : Buffer.byteLength(value);
      if (size < 0) {
        return Encoder.sizeOfVarInt(-1);
      }
      return Encoder.sizeOfVarInt(size) + size;
    }
    static nextPowerOfTwo(value) {
      return 1 << 31 - Math.clz32(value) + 1;
    }
    constructor(initialSize = 511) {
      this.buf = Buffer.alloc(Encoder.nextPowerOfTwo(initialSize));
      this.offset = 0;
    }
    writeBufferInternal(buffer) {
      const bufferLength = buffer.length;
      this.ensureAvailable(bufferLength);
      buffer.copy(this.buf, this.offset, 0);
      this.offset += bufferLength;
    }
    ensureAvailable(length) {
      if (this.offset + length > this.buf.length) {
        const newLength = Encoder.nextPowerOfTwo(this.offset + length);
        const newBuffer = Buffer.alloc(newLength);
        this.buf.copy(newBuffer, 0, 0, this.offset);
        this.buf = newBuffer;
      }
    }
    get buffer() {
      return this.buf.slice(0, this.offset);
    }
    writeInt8(value) {
      this.ensureAvailable(INT8_SIZE);
      this.buf.writeInt8(value, this.offset);
      this.offset += INT8_SIZE;
      return this;
    }
    writeInt16(value) {
      this.ensureAvailable(INT16_SIZE);
      this.buf.writeInt16BE(value, this.offset);
      this.offset += INT16_SIZE;
      return this;
    }
    writeInt32(value) {
      this.ensureAvailable(INT32_SIZE);
      this.buf.writeInt32BE(value, this.offset);
      this.offset += INT32_SIZE;
      return this;
    }
    writeUInt32(value) {
      this.ensureAvailable(INT32_SIZE);
      this.buf.writeUInt32BE(value, this.offset);
      this.offset += INT32_SIZE;
      return this;
    }
    writeInt64(value) {
      this.ensureAvailable(INT64_SIZE);
      const longValue = Long.fromValue(value);
      this.buf.writeInt32BE(longValue.getHighBits(), this.offset);
      this.buf.writeInt32BE(longValue.getLowBits(), this.offset + INT32_SIZE);
      this.offset += INT64_SIZE;
      return this;
    }
    writeDouble(value) {
      this.ensureAvailable(DOUBLE_SIZE);
      this.buf.writeDoubleBE(value, this.offset);
      this.offset += DOUBLE_SIZE;
      return this;
    }
    writeBoolean(value) {
      value ? this.writeInt8(1) : this.writeInt8(0);
      return this;
    }
    writeString(value) {
      if (value == null) {
        this.writeInt16(-1);
        return this;
      }
      const byteLength = Buffer.byteLength(value, "utf8");
      this.ensureAvailable(INT16_SIZE + byteLength);
      this.writeInt16(byteLength);
      this.buf.write(value, this.offset, byteLength, "utf8");
      this.offset += byteLength;
      return this;
    }
    writeVarIntString(value) {
      if (value == null) {
        this.writeVarInt(-1);
        return this;
      }
      const byteLength = Buffer.byteLength(value, "utf8");
      this.writeVarInt(byteLength);
      this.ensureAvailable(byteLength);
      this.buf.write(value, this.offset, byteLength, "utf8");
      this.offset += byteLength;
      return this;
    }
    writeUVarIntString(value) {
      if (value == null) {
        this.writeUVarInt(0);
        return this;
      }
      const byteLength = Buffer.byteLength(value, "utf8");
      this.writeUVarInt(byteLength + 1);
      this.ensureAvailable(byteLength);
      this.buf.write(value, this.offset, byteLength, "utf8");
      this.offset += byteLength;
      return this;
    }
    writeBytes(value) {
      if (value == null) {
        this.writeInt32(-1);
        return this;
      }
      if (Buffer.isBuffer(value)) {
        this.ensureAvailable(INT32_SIZE + value.length);
        this.writeInt32(value.length);
        this.writeBufferInternal(value);
      } else {
        const valueToWrite = String(value);
        const byteLength = Buffer.byteLength(valueToWrite, "utf8");
        this.ensureAvailable(INT32_SIZE + byteLength);
        this.writeInt32(byteLength);
        this.buf.write(valueToWrite, this.offset, byteLength, "utf8");
        this.offset += byteLength;
      }
      return this;
    }
    writeVarIntBytes(value) {
      if (value == null) {
        this.writeVarInt(-1);
        return this;
      }
      if (Buffer.isBuffer(value)) {
        this.writeVarInt(value.length);
        this.writeBufferInternal(value);
      } else {
        const valueToWrite = String(value);
        const byteLength = Buffer.byteLength(valueToWrite, "utf8");
        this.writeVarInt(byteLength);
        this.ensureAvailable(byteLength);
        this.buf.write(valueToWrite, this.offset, byteLength, "utf8");
        this.offset += byteLength;
      }
      return this;
    }
    writeUVarIntBytes(value) {
      if (value == null) {
        this.writeVarInt(0);
        return this;
      }
      if (Buffer.isBuffer(value)) {
        this.writeUVarInt(value.length + 1);
        this.writeBufferInternal(value);
      } else {
        const valueToWrite = String(value);
        const byteLength = Buffer.byteLength(valueToWrite, "utf8");
        this.writeUVarInt(byteLength + 1);
        this.ensureAvailable(byteLength);
        this.buf.write(valueToWrite, this.offset, byteLength, "utf8");
        this.offset += byteLength;
      }
      return this;
    }
    writeEncoder(value) {
      if (value == null || !Buffer.isBuffer(value.buf)) {
        throw new Error("value should be an instance of Encoder");
      }
      this.writeBufferInternal(value.buffer);
      return this;
    }
    writeEncoderArray(value) {
      if (!Array.isArray(value) || value.some((v) => v == null || !Buffer.isBuffer(v.buf))) {
        throw new Error("all values should be an instance of Encoder[]");
      }
      value.forEach((v) => {
        this.writeBufferInternal(v.buffer);
      });
      return this;
    }
    writeBuffer(value) {
      if (!Buffer.isBuffer(value)) {
        throw new Error("value should be an instance of Buffer");
      }
      this.writeBufferInternal(value);
      return this;
    }
    writeNullableArray(array, type) {
      const length = array.length !== 0 ? array.length : -1;
      this.writeArray(array, type, length);
      return this;
    }
    writeArray(array, type, length) {
      const arrayLength = length == null ? array.length : length;
      this.writeInt32(arrayLength);
      if (type !== undefined) {
        switch (type) {
          case "int32":
          case "number":
            array.forEach((value) => this.writeInt32(value));
            break;
          case "string":
            array.forEach((value) => this.writeString(value));
            break;
          case "object":
            this.writeEncoderArray(array);
            break;
        }
      } else {
        array.forEach((value) => {
          switch (typeof value) {
            case "number":
              this.writeInt32(value);
              break;
            case "string":
              this.writeString(value);
              break;
            case "object":
              this.writeEncoder(value);
              break;
          }
        });
      }
      return this;
    }
    writeVarIntArray(array, type) {
      if (type === "object") {
        this.writeVarInt(array.length);
        this.writeEncoderArray(array);
      } else {
        const objectArray = array.filter((v) => typeof v === "object");
        this.writeVarInt(objectArray.length);
        this.writeEncoderArray(objectArray);
      }
      return this;
    }
    writeUVarIntArray(array, type) {
      if (type === "object") {
        this.writeUVarInt(array.length + 1);
        this.writeEncoderArray(array);
      } else if (array === null) {
        this.writeUVarInt(0);
      } else {
        const objectArray = array.filter((v) => typeof v === "object");
        this.writeUVarInt(objectArray.length + 1);
        this.writeEncoderArray(objectArray);
      }
      return this;
    }
    writeVarInt(value) {
      return this.writeUVarInt(Encoder.encodeZigZag(value));
    }
    writeUVarInt(value) {
      const byteArray = [];
      while ((value & UNSIGNED_INT32_MAX_NUMBER) !== 0) {
        byteArray.push(value & OTHER_BITS | MOST_SIGNIFICANT_BIT);
        value >>>= 7;
      }
      byteArray.push(value & OTHER_BITS);
      this.writeBufferInternal(Buffer.from(byteArray));
      return this;
    }
    writeVarLong(value) {
      const byteArray = [];
      let longValue = Encoder.encodeZigZag64(value);
      while (longValue.and(UNSIGNED_INT64_MAX_NUMBER).notEquals(Long.fromInt(0))) {
        byteArray.push(longValue.and(OTHER_BITS).or(MOST_SIGNIFICANT_BIT).toInt());
        longValue = longValue.shiftRightUnsigned(7);
      }
      byteArray.push(longValue.toInt());
      this.writeBufferInternal(Buffer.from(byteArray));
      return this;
    }
    size() {
      return this.offset;
    }
    toJSON() {
      return this.buffer.toJSON();
    }
  };
});

// node_modules/kafkajs/src/protocol/crc32.js
var require_crc32 = __commonJS((exports, module) => {
  var CRC_TABLE = new Int32Array([
    0,
    1996959894,
    3993919788,
    2567524794,
    124634137,
    1886057615,
    3915621685,
    2657392035,
    249268274,
    2044508324,
    3772115230,
    2547177864,
    162941995,
    2125561021,
    3887607047,
    2428444049,
    498536548,
    1789927666,
    4089016648,
    2227061214,
    450548861,
    1843258603,
    4107580753,
    2211677639,
    325883990,
    1684777152,
    4251122042,
    2321926636,
    335633487,
    1661365465,
    4195302755,
    2366115317,
    997073096,
    1281953886,
    3579855332,
    2724688242,
    1006888145,
    1258607687,
    3524101629,
    2768942443,
    901097722,
    1119000684,
    3686517206,
    2898065728,
    853044451,
    1172266101,
    3705015759,
    2882616665,
    651767980,
    1373503546,
    3369554304,
    3218104598,
    565507253,
    1454621731,
    3485111705,
    3099436303,
    671266974,
    1594198024,
    3322730930,
    2970347812,
    795835527,
    1483230225,
    3244367275,
    3060149565,
    1994146192,
    31158534,
    2563907772,
    4023717930,
    1907459465,
    112637215,
    2680153253,
    3904427059,
    2013776290,
    251722036,
    2517215374,
    3775830040,
    2137656763,
    141376813,
    2439277719,
    3865271297,
    1802195444,
    476864866,
    2238001368,
    4066508878,
    1812370925,
    453092731,
    2181625025,
    4111451223,
    1706088902,
    314042704,
    2344532202,
    4240017532,
    1658658271,
    366619977,
    2362670323,
    4224994405,
    1303535960,
    984961486,
    2747007092,
    3569037538,
    1256170817,
    1037604311,
    2765210733,
    3554079995,
    1131014506,
    879679996,
    2909243462,
    3663771856,
    1141124467,
    855842277,
    2852801631,
    3708648649,
    1342533948,
    654459306,
    3188396048,
    3373015174,
    1466479909,
    544179635,
    3110523913,
    3462522015,
    1591671054,
    702138776,
    2966460450,
    3352799412,
    1504918807,
    783551873,
    3082640443,
    3233442989,
    3988292384,
    2596254646,
    62317068,
    1957810842,
    3939845945,
    2647816111,
    81470997,
    1943803523,
    3814918930,
    2489596804,
    225274430,
    2053790376,
    3826175755,
    2466906013,
    167816743,
    2097651377,
    4027552580,
    2265490386,
    503444072,
    1762050814,
    4150417245,
    2154129355,
    426522225,
    1852507879,
    4275313526,
    2312317920,
    282753626,
    1742555852,
    4189708143,
    2394877945,
    397917763,
    1622183637,
    3604390888,
    2714866558,
    953729732,
    1340076626,
    3518719985,
    2797360999,
    1068828381,
    1219638859,
    3624741850,
    2936675148,
    906185462,
    1090812512,
    3747672003,
    2825379669,
    829329135,
    1181335161,
    3412177804,
    3160834842,
    628085408,
    1382605366,
    3423369109,
    3138078467,
    570562233,
    1426400815,
    3317316542,
    2998733608,
    733239954,
    1555261956,
    3268935591,
    3050360625,
    752459403,
    1541320221,
    2607071920,
    3965973030,
    1969922972,
    40735498,
    2617837225,
    3943577151,
    1913087877,
    83908371,
    2512341634,
    3803740692,
    2075208622,
    213261112,
    2463272603,
    3855990285,
    2094854071,
    198958881,
    2262029012,
    4057260610,
    1759359992,
    534414190,
    2176718541,
    4139329115,
    1873836001,
    414664567,
    2282248934,
    4279200368,
    1711684554,
    285281116,
    2405801727,
    4167216745,
    1634467795,
    376229701,
    2685067896,
    3608007406,
    1308918612,
    956543938,
    2808555105,
    3495958263,
    1231636301,
    1047427035,
    2932959818,
    3654703836,
    1088359270,
    936918000,
    2847714899,
    3736837829,
    1202900863,
    817233897,
    3183342108,
    3401237130,
    1404277552,
    615818150,
    3134207493,
    3453421203,
    1423857449,
    601450431,
    3009837614,
    3294710456,
    1567103746,
    711928724,
    3020668471,
    3272380065,
    1510334235,
    755167117
  ]);
  module.exports = (encoder) => {
    const { buffer } = encoder;
    const l = buffer.length;
    let crc = -1;
    for (let n = 0;n < l; n++) {
      crc = CRC_TABLE[(crc ^ buffer[n]) & 255] ^ crc >>> 8;
    }
    return crc ^ -1;
  };
});

// node_modules/kafkajs/src/protocol/message/v0/index.js
var require_v0 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var crc32 = require_crc32();
  var { Types: Compression, COMPRESSION_CODEC_MASK } = require_compression();
  module.exports = ({ compression = Compression.None, key, value }) => {
    const content = new Encoder().writeInt8(0).writeInt8(compression & COMPRESSION_CODEC_MASK).writeBytes(key).writeBytes(value);
    const crc = crc32(content);
    return new Encoder().writeInt32(crc).writeEncoder(content);
  };
});

// node_modules/kafkajs/src/protocol/message/v1/index.js
var require_v1 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var crc32 = require_crc32();
  var { Types: Compression, COMPRESSION_CODEC_MASK } = require_compression();
  module.exports = ({ compression = Compression.None, timestamp = Date.now(), key, value }) => {
    const content = new Encoder().writeInt8(1).writeInt8(compression & COMPRESSION_CODEC_MASK).writeInt64(timestamp).writeBytes(key).writeBytes(value);
    const crc = crc32(content);
    return new Encoder().writeInt32(crc).writeEncoder(content);
  };
});

// node_modules/kafkajs/src/protocol/message/index.js
var require_message = __commonJS((exports, module) => {
  var versions = {
    0: require_v0(),
    1: require_v1()
  };
  module.exports = ({ version = 0 }) => versions[version];
});

// node_modules/kafkajs/src/protocol/messageSet/index.js
var require_messageSet = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var MessageProtocol = require_message();
  var { Types } = require_compression();
  module.exports = ({ messageVersion = 0, compression, entries }) => {
    const isCompressed = compression !== Types.None;
    const Message = MessageProtocol({ version: messageVersion });
    const encoder = new Encoder;
    entries.forEach((entry, i) => {
      const message = Message(entry);
      encoder.writeInt64(isCompressed ? i : -1);
      encoder.writeInt32(message.size());
      encoder.writeEncoder(message);
    });
    return encoder;
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v0/request.js
var require_request = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Produce: apiKey } = require_apiKeys();
  var MessageSet = require_messageSet();
  module.exports = ({ acks, timeout, topicData }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "Produce",
    expectResponse: () => acks !== 0,
    encode: async () => {
      return new Encoder().writeInt16(acks).writeInt32(timeout).writeArray(topicData.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartitions));
  };
  var encodePartitions = ({ partition, messages }) => {
    const messageSet = MessageSet({ messageVersion: 0, entries: messages });
    return new Encoder().writeInt32(partition).writeInt32(messageSet.size()).writeEncoder(messageSet);
  };
});

// node_modules/kafkajs/src/protocol/decoder.js
var require_decoder = __commonJS((exports, module) => {
  var { KafkaJSInvalidVarIntError, KafkaJSInvalidLongError } = require_errors2();
  var Long = require_long();
  var INT8_SIZE = 1;
  var INT16_SIZE = 2;
  var INT32_SIZE = 4;
  var INT64_SIZE = 8;
  var DOUBLE_SIZE = 8;
  var MOST_SIGNIFICANT_BIT = 128;
  var OTHER_BITS = 127;
  module.exports = class Decoder {
    static int32Size() {
      return INT32_SIZE;
    }
    static decodeZigZag(value) {
      return value >>> 1 ^ -(value & 1);
    }
    static decodeZigZag64(longValue) {
      return longValue.shiftRightUnsigned(1).xor(longValue.and(Long.fromInt(1)).negate());
    }
    constructor(buffer) {
      this.buffer = buffer;
      this.offset = 0;
    }
    readInt8() {
      const value = this.buffer.readInt8(this.offset);
      this.offset += INT8_SIZE;
      return value;
    }
    canReadInt16() {
      return this.canReadBytes(INT16_SIZE);
    }
    readInt16() {
      const value = this.buffer.readInt16BE(this.offset);
      this.offset += INT16_SIZE;
      return value;
    }
    canReadInt32() {
      return this.canReadBytes(INT32_SIZE);
    }
    readInt32() {
      const value = this.buffer.readInt32BE(this.offset);
      this.offset += INT32_SIZE;
      return value;
    }
    canReadInt64() {
      return this.canReadBytes(INT64_SIZE);
    }
    readInt64() {
      const first = this.buffer[this.offset];
      const last = this.buffer[this.offset + 7];
      const low = (first << 24) + this.buffer[this.offset + 1] * 2 ** 16 + this.buffer[this.offset + 2] * 2 ** 8 + this.buffer[this.offset + 3];
      const high = this.buffer[this.offset + 4] * 2 ** 24 + this.buffer[this.offset + 5] * 2 ** 16 + this.buffer[this.offset + 6] * 2 ** 8 + last;
      this.offset += INT64_SIZE;
      return (BigInt(low) << 32n) + BigInt(high);
    }
    readDouble() {
      const value = this.buffer.readDoubleBE(this.offset);
      this.offset += DOUBLE_SIZE;
      return value;
    }
    readString() {
      const byteLength = this.readInt16();
      if (byteLength === -1) {
        return null;
      }
      const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength);
      const value = stringBuffer.toString("utf8");
      this.offset += byteLength;
      return value;
    }
    readVarIntString() {
      const byteLength = this.readVarInt();
      if (byteLength === -1) {
        return null;
      }
      const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength);
      const value = stringBuffer.toString("utf8");
      this.offset += byteLength;
      return value;
    }
    readUVarIntString() {
      const byteLength = this.readUVarInt();
      if (byteLength === 0) {
        return null;
      }
      const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength - 1);
      const value = stringBuffer.toString("utf8");
      this.offset += byteLength - 1;
      return value;
    }
    canReadBytes(length) {
      return Buffer.byteLength(this.buffer) - this.offset >= length;
    }
    readBytes(byteLength = this.readInt32()) {
      if (byteLength === -1) {
        return null;
      }
      const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength);
      this.offset += byteLength;
      return stringBuffer;
    }
    readVarIntBytes() {
      const byteLength = this.readVarInt();
      if (byteLength === -1) {
        return null;
      }
      const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength);
      this.offset += byteLength;
      return stringBuffer;
    }
    readUVarIntBytes() {
      const byteLength = this.readUVarInt();
      if (byteLength === 0) {
        return null;
      }
      const stringBuffer = this.buffer.slice(this.offset, this.offset + byteLength);
      this.offset += byteLength - 1;
      return stringBuffer;
    }
    readBoolean() {
      return this.readInt8() === 1;
    }
    readAll() {
      const result = this.buffer.slice(this.offset);
      this.offset += Buffer.byteLength(this.buffer);
      return result;
    }
    readArray(reader) {
      const length = this.readInt32();
      if (length === -1) {
        return [];
      }
      const array = new Array(length);
      for (let i = 0;i < length; i++) {
        array[i] = reader(this);
      }
      return array;
    }
    readVarIntArray(reader) {
      const length = this.readVarInt();
      if (length === -1) {
        return [];
      }
      const array = new Array(length);
      for (let i = 0;i < length; i++) {
        array[i] = reader(this);
      }
      return array;
    }
    readUVarIntArray(reader) {
      const length = this.readUVarInt();
      if (length === 0) {
        return null;
      }
      const array = new Array(length - 1);
      for (let i = 0;i < length - 1; i++) {
        array[i] = reader(this);
      }
      return array;
    }
    async readArrayAsync(reader) {
      const length = this.readInt32();
      if (length === -1) {
        return [];
      }
      const array = new Array(length);
      for (let i = 0;i < length; i++) {
        array[i] = await reader(this);
      }
      return array;
    }
    readVarInt() {
      let currentByte;
      let result = 0;
      let i = 0;
      do {
        currentByte = this.buffer[this.offset++];
        result += (currentByte & OTHER_BITS) << i;
        i += 7;
      } while (currentByte >= MOST_SIGNIFICANT_BIT);
      return Decoder.decodeZigZag(result);
    }
    readUVarInt() {
      let currentByte;
      let result = 0;
      let i = 0;
      while (((currentByte = this.buffer[this.offset++]) & MOST_SIGNIFICANT_BIT) !== 0) {
        result |= (currentByte & OTHER_BITS) << i;
        i += 7;
        if (i > 28) {
          throw new KafkaJSInvalidVarIntError("Invalid VarInt, must contain 5 bytes or less");
        }
      }
      result |= currentByte << i;
      return result >>> 0;
    }
    readTaggedFields() {
      const numberOfTaggedFields = this.readUVarInt();
      if (numberOfTaggedFields === 0) {
        return null;
      }
      const taggedFields = {};
      for (let i = 0;i < numberOfTaggedFields; i++) {
        this.readUVarInt();
        this.readUVarIntBytes();
      }
      return taggedFields;
    }
    readVarLong() {
      let currentByte;
      let result = Long.fromInt(0);
      let i = 0;
      do {
        if (i > 63) {
          throw new KafkaJSInvalidLongError("Invalid Long, must contain 9 bytes or less");
        }
        currentByte = this.buffer[this.offset++];
        result = result.add(Long.fromInt(currentByte & OTHER_BITS).shiftLeft(i));
        i += 7;
      } while (currentByte >= MOST_SIGNIFICANT_BIT);
      return Decoder.decodeZigZag64(result);
    }
    slice(size) {
      return new Decoder(this.buffer.slice(this.offset, this.offset + size));
    }
    forward(size) {
      this.offset += size;
    }
  };
});

// node_modules/kafkajs/src/utils/websiteUrl.js
var require_websiteUrl = __commonJS((exports, module) => {
  var BASE_URL = "https://kafka.js.org";
  var stripLeading = (char) => (str) => str.charAt(0) === char ? str.substring(1) : str;
  var stripLeadingSlash = stripLeading("/");
  var stripLeadingHash = stripLeading("#");
  module.exports = (path, hash) => `${BASE_URL}/${stripLeadingSlash(path)}${hash ? "#" + stripLeadingHash(hash) : ""}`;
});

// node_modules/kafkajs/src/protocol/error.js
var require_error = __commonJS((exports, module) => {
  var { KafkaJSProtocolError } = require_errors2();
  var websiteUrl = require_websiteUrl();
  var errorCodes = [
    {
      type: "UNKNOWN",
      code: -1,
      retriable: false,
      message: "The server experienced an unexpected error when processing the request"
    },
    {
      type: "OFFSET_OUT_OF_RANGE",
      code: 1,
      retriable: false,
      message: "The requested offset is not within the range of offsets maintained by the server"
    },
    {
      type: "CORRUPT_MESSAGE",
      code: 2,
      retriable: true,
      message: "This message has failed its CRC checksum, exceeds the valid size, or is otherwise corrupt"
    },
    {
      type: "UNKNOWN_TOPIC_OR_PARTITION",
      code: 3,
      retriable: true,
      message: "This server does not host this topic-partition"
    },
    {
      type: "INVALID_FETCH_SIZE",
      code: 4,
      retriable: false,
      message: "The requested fetch size is invalid"
    },
    {
      type: "LEADER_NOT_AVAILABLE",
      code: 5,
      retriable: true,
      message: "There is no leader for this topic-partition as we are in the middle of a leadership election"
    },
    {
      type: "NOT_LEADER_FOR_PARTITION",
      code: 6,
      retriable: true,
      message: "This server is not the leader for that topic-partition"
    },
    {
      type: "REQUEST_TIMED_OUT",
      code: 7,
      retriable: true,
      message: "The request timed out"
    },
    {
      type: "BROKER_NOT_AVAILABLE",
      code: 8,
      retriable: false,
      message: "The broker is not available"
    },
    {
      type: "REPLICA_NOT_AVAILABLE",
      code: 9,
      retriable: true,
      message: "The replica is not available for the requested topic-partition"
    },
    {
      type: "MESSAGE_TOO_LARGE",
      code: 10,
      retriable: false,
      message: "The request included a message larger than the max message size the server will accept"
    },
    {
      type: "STALE_CONTROLLER_EPOCH",
      code: 11,
      retriable: false,
      message: "The controller moved to another broker"
    },
    {
      type: "OFFSET_METADATA_TOO_LARGE",
      code: 12,
      retriable: false,
      message: "The metadata field of the offset request was too large"
    },
    {
      type: "NETWORK_EXCEPTION",
      code: 13,
      retriable: true,
      message: "The server disconnected before a response was received"
    },
    {
      type: "GROUP_LOAD_IN_PROGRESS",
      code: 14,
      retriable: true,
      message: "The coordinator is loading and hence can't process requests for this group"
    },
    {
      type: "GROUP_COORDINATOR_NOT_AVAILABLE",
      code: 15,
      retriable: true,
      message: "The group coordinator is not available"
    },
    {
      type: "NOT_COORDINATOR_FOR_GROUP",
      code: 16,
      retriable: true,
      message: "This is not the correct coordinator for this group"
    },
    {
      type: "INVALID_TOPIC_EXCEPTION",
      code: 17,
      retriable: false,
      message: "The request attempted to perform an operation on an invalid topic"
    },
    {
      type: "RECORD_LIST_TOO_LARGE",
      code: 18,
      retriable: false,
      message: "The request included message batch larger than the configured segment size on the server"
    },
    {
      type: "NOT_ENOUGH_REPLICAS",
      code: 19,
      retriable: true,
      message: "Messages are rejected since there are fewer in-sync replicas than required"
    },
    {
      type: "NOT_ENOUGH_REPLICAS_AFTER_APPEND",
      code: 20,
      retriable: true,
      message: "Messages are written to the log, but to fewer in-sync replicas than required"
    },
    {
      type: "INVALID_REQUIRED_ACKS",
      code: 21,
      retriable: false,
      message: "Produce request specified an invalid value for required acks"
    },
    {
      type: "ILLEGAL_GENERATION",
      code: 22,
      retriable: false,
      message: "Specified group generation id is not valid"
    },
    {
      type: "INCONSISTENT_GROUP_PROTOCOL",
      code: 23,
      retriable: false,
      message: "The group member's supported protocols are incompatible with those of existing members"
    },
    {
      type: "INVALID_GROUP_ID",
      code: 24,
      retriable: false,
      message: "The configured groupId is invalid"
    },
    {
      type: "UNKNOWN_MEMBER_ID",
      code: 25,
      retriable: false,
      message: "The coordinator is not aware of this member"
    },
    {
      type: "INVALID_SESSION_TIMEOUT",
      code: 26,
      retriable: false,
      message: "The session timeout is not within the range allowed by the broker (as configured by group.min.session.timeout.ms and group.max.session.timeout.ms)"
    },
    {
      type: "REBALANCE_IN_PROGRESS",
      code: 27,
      retriable: false,
      message: "The group is rebalancing, so a rejoin is needed",
      helpUrl: websiteUrl("docs/faq", "what-does-it-mean-to-get-rebalance-in-progress-errors")
    },
    {
      type: "INVALID_COMMIT_OFFSET_SIZE",
      code: 28,
      retriable: false,
      message: "The committing offset data size is not valid"
    },
    {
      type: "TOPIC_AUTHORIZATION_FAILED",
      code: 29,
      retriable: false,
      message: "Not authorized to access topics: [Topic authorization failed]"
    },
    {
      type: "GROUP_AUTHORIZATION_FAILED",
      code: 30,
      retriable: false,
      message: "Not authorized to access group: Group authorization failed"
    },
    {
      type: "CLUSTER_AUTHORIZATION_FAILED",
      code: 31,
      retriable: false,
      message: "Cluster authorization failed"
    },
    {
      type: "INVALID_TIMESTAMP",
      code: 32,
      retriable: false,
      message: "The timestamp of the message is out of acceptable range"
    },
    {
      type: "UNSUPPORTED_SASL_MECHANISM",
      code: 33,
      retriable: false,
      message: "The broker does not support the requested SASL mechanism"
    },
    {
      type: "ILLEGAL_SASL_STATE",
      code: 34,
      retriable: false,
      message: "Request is not valid given the current SASL state"
    },
    {
      type: "UNSUPPORTED_VERSION",
      code: 35,
      retriable: false,
      message: "The version of API is not supported"
    },
    {
      type: "TOPIC_ALREADY_EXISTS",
      code: 36,
      retriable: false,
      message: "Topic with this name already exists"
    },
    {
      type: "INVALID_PARTITIONS",
      code: 37,
      retriable: false,
      message: "Number of partitions is invalid"
    },
    {
      type: "INVALID_REPLICATION_FACTOR",
      code: 38,
      retriable: false,
      message: "Replication-factor is invalid"
    },
    {
      type: "INVALID_REPLICA_ASSIGNMENT",
      code: 39,
      retriable: false,
      message: "Replica assignment is invalid"
    },
    {
      type: "INVALID_CONFIG",
      code: 40,
      retriable: false,
      message: "Configuration is invalid"
    },
    {
      type: "NOT_CONTROLLER",
      code: 41,
      retriable: true,
      message: "This is not the correct controller for this cluster"
    },
    {
      type: "INVALID_REQUEST",
      code: 42,
      retriable: false,
      message: "This most likely occurs because of a request being malformed by the client library or the message was sent to an incompatible broker. See the broker logs for more details"
    },
    {
      type: "UNSUPPORTED_FOR_MESSAGE_FORMAT",
      code: 43,
      retriable: false,
      message: "The message format version on the broker does not support the request"
    },
    {
      type: "POLICY_VIOLATION",
      code: 44,
      retriable: false,
      message: "Request parameters do not satisfy the configured policy"
    },
    {
      type: "OUT_OF_ORDER_SEQUENCE_NUMBER",
      code: 45,
      retriable: false,
      message: "The broker received an out of order sequence number"
    },
    {
      type: "DUPLICATE_SEQUENCE_NUMBER",
      code: 46,
      retriable: false,
      message: "The broker received a duplicate sequence number"
    },
    {
      type: "INVALID_PRODUCER_EPOCH",
      code: 47,
      retriable: false,
      message: "Producer attempted an operation with an old epoch. Either there is a newer producer with the same transactionalId, or the producer's transaction has been expired by the broker"
    },
    {
      type: "INVALID_TXN_STATE",
      code: 48,
      retriable: false,
      message: "The producer attempted a transactional operation in an invalid state"
    },
    {
      type: "INVALID_PRODUCER_ID_MAPPING",
      code: 49,
      retriable: false,
      message: "The producer attempted to use a producer id which is not currently assigned to its transactional id"
    },
    {
      type: "INVALID_TRANSACTION_TIMEOUT",
      code: 50,
      retriable: false,
      message: "The transaction timeout is larger than the maximum value allowed by the broker (as configured by max.transaction.timeout.ms)"
    },
    {
      type: "CONCURRENT_TRANSACTIONS",
      code: 51,
      retriable: true,
      message: "The producer attempted to update a transaction while another concurrent operation on the same transaction was ongoing"
    },
    {
      type: "TRANSACTION_COORDINATOR_FENCED",
      code: 52,
      retriable: false,
      message: "Indicates that the transaction coordinator sending a WriteTxnMarker is no longer the current coordinator for a given producer"
    },
    {
      type: "TRANSACTIONAL_ID_AUTHORIZATION_FAILED",
      code: 53,
      retriable: false,
      message: "Transactional Id authorization failed"
    },
    {
      type: "SECURITY_DISABLED",
      code: 54,
      retriable: false,
      message: "Security features are disabled"
    },
    {
      type: "OPERATION_NOT_ATTEMPTED",
      code: 55,
      retriable: false,
      message: "The broker did not attempt to execute this operation. This may happen for batched RPCs where some operations in the batch failed, causing the broker to respond without trying the rest"
    },
    {
      type: "KAFKA_STORAGE_ERROR",
      code: 56,
      retriable: true,
      message: "Disk error when trying to access log file on the disk"
    },
    {
      type: "LOG_DIR_NOT_FOUND",
      code: 57,
      retriable: false,
      message: "The user-specified log directory is not found in the broker config"
    },
    {
      type: "SASL_AUTHENTICATION_FAILED",
      code: 58,
      retriable: false,
      message: "SASL Authentication failed",
      helpUrl: websiteUrl("docs/configuration", "sasl")
    },
    {
      type: "UNKNOWN_PRODUCER_ID",
      code: 59,
      retriable: false,
      message: "This exception is raised by the broker if it could not locate the producer metadata associated with the producerId in question. This could happen if, for instance, the producer's records were deleted because their retention time had elapsed. Once the last records of the producerId are removed, the producer's metadata is removed from the broker, and future appends by the producer will return this exception"
    },
    {
      type: "REASSIGNMENT_IN_PROGRESS",
      code: 60,
      retriable: false,
      message: "A partition reassignment is in progress"
    },
    {
      type: "DELEGATION_TOKEN_AUTH_DISABLED",
      code: 61,
      retriable: false,
      message: "Delegation Token feature is not enabled"
    },
    {
      type: "DELEGATION_TOKEN_NOT_FOUND",
      code: 62,
      retriable: false,
      message: "Delegation Token is not found on server"
    },
    {
      type: "DELEGATION_TOKEN_OWNER_MISMATCH",
      code: 63,
      retriable: false,
      message: "Specified Principal is not valid Owner/Renewer"
    },
    {
      type: "DELEGATION_TOKEN_REQUEST_NOT_ALLOWED",
      code: 64,
      retriable: false,
      message: "Delegation Token requests are not allowed on PLAINTEXT/1-way SSL channels and on delegation token authenticated channels"
    },
    {
      type: "DELEGATION_TOKEN_AUTHORIZATION_FAILED",
      code: 65,
      retriable: false,
      message: "Delegation Token authorization failed"
    },
    {
      type: "DELEGATION_TOKEN_EXPIRED",
      code: 66,
      retriable: false,
      message: "Delegation Token is expired"
    },
    {
      type: "INVALID_PRINCIPAL_TYPE",
      code: 67,
      retriable: false,
      message: "Supplied principalType is not supported"
    },
    {
      type: "NON_EMPTY_GROUP",
      code: 68,
      retriable: false,
      message: "The group is not empty"
    },
    {
      type: "GROUP_ID_NOT_FOUND",
      code: 69,
      retriable: false,
      message: "The group id was not found"
    },
    {
      type: "FETCH_SESSION_ID_NOT_FOUND",
      code: 70,
      retriable: true,
      message: "The fetch session ID was not found"
    },
    {
      type: "INVALID_FETCH_SESSION_EPOCH",
      code: 71,
      retriable: true,
      message: "The fetch session epoch is invalid"
    },
    {
      type: "LISTENER_NOT_FOUND",
      code: 72,
      retriable: true,
      message: "There is no listener on the leader broker that matches the listener on which metadata request was processed"
    },
    {
      type: "TOPIC_DELETION_DISABLED",
      code: 73,
      retriable: false,
      message: "Topic deletion is disabled"
    },
    {
      type: "FENCED_LEADER_EPOCH",
      code: 74,
      retriable: true,
      message: "The leader epoch in the request is older than the epoch on the broker"
    },
    {
      type: "UNKNOWN_LEADER_EPOCH",
      code: 75,
      retriable: true,
      message: "The leader epoch in the request is newer than the epoch on the broker"
    },
    {
      type: "UNSUPPORTED_COMPRESSION_TYPE",
      code: 76,
      retriable: false,
      message: "The requesting client does not support the compression type of given partition"
    },
    {
      type: "STALE_BROKER_EPOCH",
      code: 77,
      retriable: false,
      message: "Broker epoch has changed"
    },
    {
      type: "OFFSET_NOT_AVAILABLE",
      code: 78,
      retriable: true,
      message: "The leader high watermark has not caught up from a recent leader election so the offsets cannot be guaranteed to be monotonically increasing"
    },
    {
      type: "MEMBER_ID_REQUIRED",
      code: 79,
      retriable: false,
      message: "The group member needs to have a valid member id before actually entering a consumer group"
    },
    {
      type: "PREFERRED_LEADER_NOT_AVAILABLE",
      code: 80,
      retriable: true,
      message: "The preferred leader was not available"
    },
    {
      type: "GROUP_MAX_SIZE_REACHED",
      code: 81,
      retriable: false,
      message: "The consumer group has reached its max size. It already has the configured maximum number of members"
    },
    {
      type: "FENCED_INSTANCE_ID",
      code: 82,
      retriable: false,
      message: "The broker rejected this static consumer since another consumer with the same group instance id has registered with a different member id"
    },
    {
      type: "ELIGIBLE_LEADERS_NOT_AVAILABLE",
      code: 83,
      retriable: true,
      message: "Eligible topic partition leaders are not available"
    },
    {
      type: "ELECTION_NOT_NEEDED",
      code: 84,
      retriable: true,
      message: "Leader election not needed for topic partition"
    },
    {
      type: "NO_REASSIGNMENT_IN_PROGRESS",
      code: 85,
      retriable: false,
      message: "No partition reassignment is in progress"
    },
    {
      type: "GROUP_SUBSCRIBED_TO_TOPIC",
      code: 86,
      retriable: false,
      message: "Deleting offsets of a topic is forbidden while the consumer group is actively subscribed to it"
    },
    {
      type: "INVALID_RECORD",
      code: 87,
      retriable: false,
      message: "This record has failed the validation on broker and hence be rejected"
    },
    {
      type: "UNSTABLE_OFFSET_COMMIT",
      code: 88,
      retriable: true,
      message: "There are unstable offsets that need to be cleared"
    }
  ];
  var unknownErrorCode = (errorCode) => ({
    type: "KAFKAJS_UNKNOWN_ERROR_CODE",
    code: -99,
    retriable: false,
    message: `Unknown error code ${errorCode}`
  });
  var SUCCESS_CODE = 0;
  var UNSUPPORTED_VERSION_CODE = 35;
  var failure = (code) => code !== SUCCESS_CODE;
  var createErrorFromCode = (code) => {
    return new KafkaJSProtocolError(errorCodes.find((e) => e.code === code) || unknownErrorCode(code));
  };
  var failIfVersionNotSupported = (code) => {
    if (code === UNSUPPORTED_VERSION_CODE) {
      throw createErrorFromCode(UNSUPPORTED_VERSION_CODE);
    }
  };
  var staleMetadata = (e) => ["UNKNOWN_TOPIC_OR_PARTITION", "LEADER_NOT_AVAILABLE", "NOT_LEADER_FOR_PARTITION"].includes(e.type);
  module.exports = {
    failure,
    errorCodes,
    createErrorFromCode,
    failIfVersionNotSupported,
    staleMetadata
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v0/response.js
var require_response = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var partition = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    offset: decoder.readInt64().toString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const topics = decoder.readArray((decoder2) => ({
      topicName: decoder2.readString(),
      partitions: decoder2.readArray(partition)
    }));
    return {
      topics
    };
  };
  var parse = async (data) => {
    const errors = data.topics.flatMap((topic) => {
      return topic.partitions.filter((partition2) => failure(partition2.errorCode));
    });
    if (errors.length > 0) {
      const { errorCode } = errors[0];
      throw createErrorFromCode(errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v1/request.js
var require_request2 = __commonJS((exports, module) => {
  var requestV0 = require_request();
  module.exports = ({ acks, timeout, topicData }) => {
    return Object.assign(requestV0({ acks, timeout, topicData }), { apiVersion: 1 });
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v1/response.js
var require_response2 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response();
  var partition = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    offset: decoder.readInt64().toString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const topics = decoder.readArray((decoder2) => ({
      topicName: decoder2.readString(),
      partitions: decoder2.readArray(partition)
    }));
    const throttleTime = decoder.readInt32();
    return {
      topics,
      throttleTime
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v2/request.js
var require_request3 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Produce: apiKey } = require_apiKeys();
  var MessageSet = require_messageSet();
  var { Types, lookupCodec } = require_compression();
  module.exports = ({ acks, timeout, compression = Types.None, topicData }) => ({
    apiKey,
    apiVersion: 2,
    apiName: "Produce",
    expectResponse: () => acks !== 0,
    encode: async () => {
      const encodeTopic = topicEncoder(compression);
      const encodedTopicData = [];
      for (const data of topicData) {
        encodedTopicData.push(await encodeTopic(data));
      }
      return new Encoder().writeInt16(acks).writeInt32(timeout).writeArray(encodedTopicData);
    }
  });
  var topicEncoder = (compression) => {
    const encodePartitions = partitionsEncoder(compression);
    return async ({ topic, partitions }) => {
      const encodedPartitions = [];
      for (const data of partitions) {
        encodedPartitions.push(await encodePartitions(data));
      }
      return new Encoder().writeString(topic).writeArray(encodedPartitions);
    };
  };
  var partitionsEncoder = (compression) => async ({ partition, messages }) => {
    const messageSet = MessageSet({ messageVersion: 1, compression, entries: messages });
    if (compression === Types.None) {
      return new Encoder().writeInt32(partition).writeInt32(messageSet.size()).writeEncoder(messageSet);
    }
    const timestamp = messages[0].timestamp || Date.now();
    const codec = lookupCodec(compression);
    const compressedValue = await codec.compress(messageSet);
    const compressedMessageSet = MessageSet({
      messageVersion: 1,
      entries: [{ compression, timestamp, value: compressedValue }]
    });
    return new Encoder().writeInt32(partition).writeInt32(compressedMessageSet.size()).writeEncoder(compressedMessageSet);
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v2/response.js
var require_response3 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response();
  var partition = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    offset: decoder.readInt64().toString(),
    timestamp: decoder.readInt64().toString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const topics = decoder.readArray((decoder2) => ({
      topicName: decoder2.readString(),
      partitions: decoder2.readArray(partition)
    }));
    const throttleTime = decoder.readInt32();
    return {
      topics,
      throttleTime
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/recordBatch/header/v0/index.js
var require_v02 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  module.exports = ({ key, value }) => {
    return new Encoder().writeVarIntString(key).writeVarIntBytes(value);
  };
});

// node_modules/kafkajs/src/protocol/recordBatch/record/v0/index.js
var require_v03 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var Header = require_v02();
  module.exports = ({ offsetDelta = 0, timestampDelta = 0, key, value, headers = {} }) => {
    const headersArray = Object.keys(headers).flatMap((headerKey) => !Array.isArray(headers[headerKey]) ? [{ key: headerKey, value: headers[headerKey] }] : headers[headerKey].map((headerValue) => ({ key: headerKey, value: headerValue })));
    const sizeOfBody = 1 + Encoder.sizeOfVarLong(timestampDelta) + Encoder.sizeOfVarInt(offsetDelta) + Encoder.sizeOfVarIntBytes(key) + Encoder.sizeOfVarIntBytes(value) + sizeOfHeaders(headersArray);
    return new Encoder().writeVarInt(sizeOfBody).writeInt8(0).writeVarLong(timestampDelta).writeVarInt(offsetDelta).writeVarIntBytes(key).writeVarIntBytes(value).writeVarIntArray(headersArray.map(Header));
  };
  var sizeOfHeaders = (headersArray) => {
    let size = Encoder.sizeOfVarInt(headersArray.length);
    for (const header of headersArray) {
      const keySize = Buffer.byteLength(header.key);
      const valueSize = Buffer.byteLength(header.value);
      size += Encoder.sizeOfVarInt(keySize) + keySize;
      if (header.value === null) {
        size += Encoder.sizeOfVarInt(-1);
      } else {
        size += Encoder.sizeOfVarInt(valueSize) + valueSize;
      }
    }
    return size;
  };
});

// node_modules/kafkajs/src/protocol/recordBatch/crc32C/crc32C.js
var require_crc32C = __commonJS((exports, module) => {
  var crc32C = (buffer) => {
    let crc = 0 ^ -1;
    for (let i = 0;i < buffer.length; i++) {
      crc = T[(crc ^ buffer[i]) & 255] ^ crc >>> 8;
    }
    return (crc ^ -1) >>> 0;
  };
  module.exports = crc32C;
  var T = new Int32Array([
    0,
    4067132163,
    3778769143,
    324072436,
    3348797215,
    904991772,
    648144872,
    3570033899,
    2329499855,
    2024987596,
    1809983544,
    2575936315,
    1296289744,
    3207089363,
    2893594407,
    1578318884,
    274646895,
    3795141740,
    4049975192,
    51262619,
    3619967088,
    632279923,
    922689671,
    3298075524,
    2592579488,
    1760304291,
    2075979607,
    2312596564,
    1562183871,
    2943781820,
    3156637768,
    1313733451,
    549293790,
    3537243613,
    3246849577,
    871202090,
    3878099393,
    357341890,
    102525238,
    4101499445,
    2858735121,
    1477399826,
    1264559846,
    3107202533,
    1845379342,
    2677391885,
    2361733625,
    2125378298,
    820201905,
    3263744690,
    3520608582,
    598981189,
    4151959214,
    85089709,
    373468761,
    3827903834,
    3124367742,
    1213305469,
    1526817161,
    2842354314,
    2107672161,
    2412447074,
    2627466902,
    1861252501,
    1098587580,
    3004210879,
    2688576843,
    1378610760,
    2262928035,
    1955203488,
    1742404180,
    2511436119,
    3416409459,
    969524848,
    714683780,
    3639785095,
    205050476,
    4266873199,
    3976438427,
    526918040,
    1361435347,
    2739821008,
    2954799652,
    1114974503,
    2529119692,
    1691668175,
    2005155131,
    2247081528,
    3690758684,
    697762079,
    986182379,
    3366744552,
    476452099,
    3993867776,
    4250756596,
    255256311,
    1640403810,
    2477592673,
    2164122517,
    1922457750,
    2791048317,
    1412925310,
    1197962378,
    3037525897,
    3944729517,
    427051182,
    170179418,
    4165941337,
    746937522,
    3740196785,
    3451792453,
    1070968646,
    1905808397,
    2213795598,
    2426610938,
    1657317369,
    3053634322,
    1147748369,
    1463399397,
    2773627110,
    4215344322,
    153784257,
    444234805,
    3893493558,
    1021025245,
    3467647198,
    3722505002,
    797665321,
    2197175160,
    1889384571,
    1674398607,
    2443626636,
    1164749927,
    3070701412,
    2757221520,
    1446797203,
    137323447,
    4198817972,
    3910406976,
    461344835,
    3484808360,
    1037989803,
    781091935,
    3705997148,
    2460548119,
    1623424788,
    1939049696,
    2180517859,
    1429367560,
    2807687179,
    3020495871,
    1180866812,
    410100952,
    3927582683,
    4182430767,
    186734380,
    3756733383,
    763408580,
    1053836080,
    3434856499,
    2722870694,
    1344288421,
    1131464017,
    2971354706,
    1708204729,
    2545590714,
    2229949006,
    1988219213,
    680717673,
    3673779818,
    3383336350,
    1002577565,
    4010310262,
    493091189,
    238226049,
    4233660802,
    2987750089,
    1082061258,
    1395524158,
    2705686845,
    1972364758,
    2279892693,
    2494862625,
    1725896226,
    952904198,
    3399985413,
    3656866545,
    731699698,
    4283874585,
    222117402,
    510512622,
    3959836397,
    3280807620,
    837199303,
    582374963,
    3504198960,
    68661723,
    4135334616,
    3844915500,
    390545967,
    1230274059,
    3141532936,
    2825850620,
    1510247935,
    2395924756,
    2091215383,
    1878366691,
    2644384480,
    3553878443,
    565732008,
    854102364,
    3229815391,
    340358836,
    3861050807,
    4117890627,
    119113024,
    1493875044,
    2875275879,
    3090270611,
    1247431312,
    2660249211,
    1828433272,
    2141937292,
    2378227087,
    3811616794,
    291187481,
    34330861,
    4032846830,
    615137029,
    3603020806,
    3314634738,
    939183345,
    1776939221,
    2609017814,
    2295496738,
    2058945313,
    2926798794,
    1545135305,
    1330124605,
    3173225534,
    4084100981,
    17165430,
    307568514,
    3762199681,
    888469610,
    3332340585,
    3587147933,
    665062302,
    2042050490,
    2346497209,
    2559330125,
    1793573966,
    3190661285,
    1279665062,
    1595330642,
    2910671697
  ]);
});

// node_modules/kafkajs/src/protocol/recordBatch/crc32C/index.js
var require_crc32C2 = __commonJS((exports, module) => {
  var crc32C = require_crc32C();
  var unsigned = (value) => Uint32Array.from([value])[0];
  module.exports = (buffer) => unsigned(crc32C(buffer));
});

// node_modules/kafkajs/src/protocol/recordBatch/v0/index.js
var require_v04 = __commonJS((exports, module) => {
  var Long = require_long();
  var Encoder = require_encoder();
  var crc32C = require_crc32C2();
  var {
    Types: Compression,
    lookupCodec,
    COMPRESSION_CODEC_MASK
  } = require_compression();
  var MAGIC_BYTE = 2;
  var TIMESTAMP_MASK = 0;
  var TRANSACTIONAL_MASK = 16;
  var RecordBatch = async ({
    compression = Compression.None,
    firstOffset = Long.fromInt(0),
    firstTimestamp = Date.now(),
    maxTimestamp = Date.now(),
    partitionLeaderEpoch = 0,
    lastOffsetDelta = 0,
    transactional = false,
    producerId = Long.fromValue(-1),
    producerEpoch = 0,
    firstSequence = 0,
    records = []
  }) => {
    const COMPRESSION_CODEC = compression & COMPRESSION_CODEC_MASK;
    const IN_TRANSACTION = transactional ? TRANSACTIONAL_MASK : 0;
    const attributes = COMPRESSION_CODEC | TIMESTAMP_MASK | IN_TRANSACTION;
    const batchBody = new Encoder().writeInt16(attributes).writeInt32(lastOffsetDelta).writeInt64(firstTimestamp).writeInt64(maxTimestamp).writeInt64(producerId).writeInt16(producerEpoch).writeInt32(firstSequence);
    if (compression === Compression.None) {
      if (records.every((v) => typeof v === typeof records[0])) {
        batchBody.writeArray(records, typeof records[0]);
      } else {
        batchBody.writeArray(records);
      }
    } else {
      const compressedRecords = await compressRecords(compression, records);
      batchBody.writeInt32(records.length).writeBuffer(compressedRecords);
    }
    const batch = new Encoder().writeInt32(partitionLeaderEpoch).writeInt8(MAGIC_BYTE).writeUInt32(crc32C(batchBody.buffer)).writeEncoder(batchBody);
    return new Encoder().writeInt64(firstOffset).writeBytes(batch.buffer);
  };
  var compressRecords = async (compression, records) => {
    const codec = lookupCodec(compression);
    const recordsEncoder = new Encoder;
    recordsEncoder.writeEncoderArray(records);
    return codec.compress(recordsEncoder);
  };
  module.exports = {
    RecordBatch,
    MAGIC_BYTE
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v3/request.js
var require_request4 = __commonJS((exports, module) => {
  var Long = require_long();
  var Encoder = require_encoder();
  var { Produce: apiKey } = require_apiKeys();
  var { Types } = require_compression();
  var Record = require_v03();
  var { RecordBatch } = require_v04();
  module.exports = ({
    acks,
    timeout,
    transactionalId = null,
    producerId = Long.fromInt(-1),
    producerEpoch = 0,
    compression = Types.None,
    topicData
  }) => ({
    apiKey,
    apiVersion: 3,
    apiName: "Produce",
    expectResponse: () => acks !== 0,
    encode: async () => {
      const encodeTopic = topicEncoder(compression);
      const encodedTopicData = [];
      for (const data of topicData) {
        encodedTopicData.push(await encodeTopic({ ...data, transactionalId, producerId, producerEpoch }));
      }
      return new Encoder().writeString(transactionalId).writeInt16(acks).writeInt32(timeout).writeArray(encodedTopicData);
    }
  });
  var topicEncoder = (compression) => async ({
    topic,
    partitions,
    transactionalId,
    producerId,
    producerEpoch
  }) => {
    const encodePartitions = partitionsEncoder(compression);
    const encodedPartitions = [];
    for (const data of partitions) {
      encodedPartitions.push(await encodePartitions({ ...data, transactionalId, producerId, producerEpoch }));
    }
    return new Encoder().writeString(topic).writeArray(encodedPartitions);
  };
  var partitionsEncoder = (compression) => async ({
    partition,
    messages,
    transactionalId,
    firstSequence,
    producerId,
    producerEpoch
  }) => {
    const dateNow = Date.now();
    const messageTimestamps = messages.map((m) => m.timestamp).filter((timestamp) => timestamp != null).sort();
    const timestamps = messageTimestamps.length === 0 ? [dateNow] : messageTimestamps;
    const firstTimestamp = timestamps[0];
    const maxTimestamp = timestamps[timestamps.length - 1];
    const records = messages.map((message, i) => Record({
      ...message,
      offsetDelta: i,
      timestampDelta: (message.timestamp || dateNow) - firstTimestamp
    }));
    const recordBatch = await RecordBatch({
      compression,
      records,
      firstTimestamp,
      maxTimestamp,
      producerId,
      producerEpoch,
      firstSequence,
      transactional: !!transactionalId,
      lastOffsetDelta: records.length - 1
    });
    return new Encoder().writeInt32(partition).writeInt32(recordBatch.size()).writeEncoder(recordBatch);
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v3/response.js
var require_response4 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var partition = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    baseOffset: decoder.readInt64().toString(),
    logAppendTime: decoder.readInt64().toString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const topics = decoder.readArray((decoder2) => ({
      topicName: decoder2.readString(),
      partitions: decoder2.readArray(partition)
    }));
    const throttleTime = decoder.readInt32();
    return {
      topics,
      throttleTime
    };
  };
  var parse = async (data) => {
    const errors = data.topics.flatMap((response) => {
      return response.partitions.filter((partition2) => failure(partition2.errorCode));
    });
    if (errors.length > 0) {
      const { errorCode } = errors[0];
      throw createErrorFromCode(errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v4/request.js
var require_request5 = __commonJS((exports, module) => {
  var requestV3 = require_request4();
  module.exports = ({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }) => Object.assign(requestV3({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }), { apiVersion: 4 });
});

// node_modules/kafkajs/src/protocol/requests/produce/v4/response.js
var require_response5 = __commonJS((exports, module) => {
  var { decode, parse } = require_response4();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v5/request.js
var require_request6 = __commonJS((exports, module) => {
  var requestV3 = require_request4();
  module.exports = ({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }) => Object.assign(requestV3({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }), { apiVersion: 5 });
});

// node_modules/kafkajs/src/protocol/requests/produce/v5/response.js
var require_response6 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV3 } = require_response4();
  var partition = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    baseOffset: decoder.readInt64().toString(),
    logAppendTime: decoder.readInt64().toString(),
    logStartOffset: decoder.readInt64().toString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const topics = decoder.readArray((decoder2) => ({
      topicName: decoder2.readString(),
      partitions: decoder2.readArray(partition)
    }));
    const throttleTime = decoder.readInt32();
    return {
      topics,
      throttleTime
    };
  };
  module.exports = {
    decode,
    parse: parseV3
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v6/request.js
var require_request7 = __commonJS((exports, module) => {
  var requestV5 = require_request6();
  module.exports = ({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }) => Object.assign(requestV5({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }), { apiVersion: 6 });
});

// node_modules/kafkajs/src/protocol/requests/produce/v6/response.js
var require_response7 = __commonJS((exports, module) => {
  var { parse, decode: decodeV5 } = require_response6();
  var decode = async (rawData) => {
    const decoded = await decodeV5(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/v7/request.js
var require_request8 = __commonJS((exports, module) => {
  var requestV6 = require_request7();
  module.exports = ({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }) => Object.assign(requestV6({
    acks,
    timeout,
    transactionalId,
    producerId,
    producerEpoch,
    compression,
    topicData
  }), { apiVersion: 7 });
});

// node_modules/kafkajs/src/protocol/requests/produce/v7/response.js
var require_response8 = __commonJS((exports, module) => {
  var { decode, parse } = require_response7();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/produce/index.js
var require_produce = __commonJS((exports, module) => {
  var versions = {
    0: ({ acks, timeout, topicData }) => {
      const request = require_request();
      const response = require_response();
      return { request: request({ acks, timeout, topicData }), response };
    },
    1: ({ acks, timeout, topicData }) => {
      const request = require_request2();
      const response = require_response2();
      return { request: request({ acks, timeout, topicData }), response };
    },
    2: ({ acks, timeout, topicData, compression }) => {
      const request = require_request3();
      const response = require_response3();
      return { request: request({ acks, timeout, compression, topicData }), response };
    },
    3: ({ acks, timeout, compression, topicData, transactionalId, producerId, producerEpoch }) => {
      const request = require_request4();
      const response = require_response4();
      return {
        request: request({
          acks,
          timeout,
          compression,
          topicData,
          transactionalId,
          producerId,
          producerEpoch
        }),
        response
      };
    },
    4: ({ acks, timeout, compression, topicData, transactionalId, producerId, producerEpoch }) => {
      const request = require_request5();
      const response = require_response5();
      return {
        request: request({
          acks,
          timeout,
          compression,
          topicData,
          transactionalId,
          producerId,
          producerEpoch
        }),
        response
      };
    },
    5: ({ acks, timeout, compression, topicData, transactionalId, producerId, producerEpoch }) => {
      const request = require_request6();
      const response = require_response6();
      return {
        request: request({
          acks,
          timeout,
          compression,
          topicData,
          transactionalId,
          producerId,
          producerEpoch
        }),
        response
      };
    },
    6: ({ acks, timeout, compression, topicData, transactionalId, producerId, producerEpoch }) => {
      const request = require_request7();
      const response = require_response7();
      return {
        request: request({
          acks,
          timeout,
          compression,
          topicData,
          transactionalId,
          producerId,
          producerEpoch
        }),
        response
      };
    },
    7: ({ acks, timeout, compression, topicData, transactionalId, producerId, producerEpoch }) => {
      const request = require_request8();
      const response = require_response8();
      return {
        request: request({
          acks,
          timeout,
          compression,
          topicData,
          transactionalId,
          producerId,
          producerEpoch
        }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/isolationLevel.js
var require_isolationLevel = __commonJS((exports, module) => {
  module.exports = {
    READ_UNCOMMITTED: 0,
    READ_COMMITTED: 1
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v0/request.js
var require_request9 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Fetch: apiKey } = require_apiKeys();
  module.exports = ({ replicaId, maxWaitTime, minBytes, topics }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "Fetch",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, fetchOffset, maxBytes }) => {
    return new Encoder().writeInt32(partition).writeInt64(fetchOffset).writeInt32(maxBytes);
  };
});

// node_modules/kafkajs/src/protocol/message/v0/decoder.js
var require_decoder2 = __commonJS((exports, module) => {
  module.exports = (decoder) => ({
    attributes: decoder.readInt8(),
    key: decoder.readBytes(),
    value: decoder.readBytes()
  });
});

// node_modules/kafkajs/src/protocol/message/v1/decoder.js
var require_decoder3 = __commonJS((exports, module) => {
  module.exports = (decoder) => ({
    attributes: decoder.readInt8(),
    timestamp: decoder.readInt64().toString(),
    key: decoder.readBytes(),
    value: decoder.readBytes()
  });
});

// node_modules/kafkajs/src/protocol/message/decoder.js
var require_decoder4 = __commonJS((exports, module) => {
  var {
    KafkaJSPartialMessageError,
    KafkaJSUnsupportedMagicByteInMessageSet
  } = require_errors2();
  var V0Decoder = require_decoder2();
  var V1Decoder = require_decoder3();
  var decodeMessage = (decoder, magicByte) => {
    switch (magicByte) {
      case 0:
        return V0Decoder(decoder);
      case 1:
        return V1Decoder(decoder);
      default:
        throw new KafkaJSUnsupportedMagicByteInMessageSet(`Unsupported MessageSet message version, magic byte: ${magicByte}`);
    }
  };
  module.exports = (offset, size, decoder) => {
    const remainingBytes = Buffer.byteLength(decoder.slice(size).buffer);
    if (remainingBytes < size) {
      throw new KafkaJSPartialMessageError(`Tried to decode a partial message: remainingBytes(${remainingBytes}) < messageSize(${size})`);
    }
    const crc = decoder.readInt32();
    const magicByte = decoder.readInt8();
    const message = decodeMessage(decoder, magicByte);
    return Object.assign({ offset, size, crc, magicByte }, message);
  };
});

// node_modules/kafkajs/src/protocol/messageSet/decoder.js
var require_decoder5 = __commonJS((exports, module) => {
  var Long = require_long();
  var Decoder = require_decoder();
  var MessageDecoder = require_decoder4();
  var { lookupCodecByAttributes } = require_compression();
  var { KafkaJSPartialMessageError } = require_errors2();
  module.exports = async (primaryDecoder, size = null) => {
    const messages = [];
    const messageSetSize = size || primaryDecoder.readInt32();
    const messageSetDecoder = primaryDecoder.slice(messageSetSize);
    while (messageSetDecoder.offset < messageSetSize) {
      try {
        const message = EntryDecoder(messageSetDecoder);
        const codec = lookupCodecByAttributes(message.attributes);
        if (codec) {
          const buffer = await codec.decompress(message.value);
          messages.push(...EntriesDecoder(new Decoder(buffer), message));
        } else {
          messages.push(message);
        }
      } catch (e) {
        if (e.name === "KafkaJSPartialMessageError") {
          break;
        }
        if (e.name === "KafkaJSUnsupportedMagicByteInMessageSet") {
          break;
        }
        throw e;
      }
    }
    primaryDecoder.forward(messageSetSize);
    return messages;
  };
  var EntriesDecoder = (decoder, compressedMessage) => {
    const messages = [];
    while (decoder.offset < decoder.buffer.length) {
      messages.push(EntryDecoder(decoder));
    }
    if (compressedMessage.magicByte > 0 && compressedMessage.offset >= 0) {
      const compressedOffset = Long.fromValue(compressedMessage.offset);
      const lastMessageOffset = Long.fromValue(messages[messages.length - 1].offset);
      const baseOffset = compressedOffset - lastMessageOffset;
      for (const message of messages) {
        message.offset = Long.fromValue(message.offset).add(baseOffset).toString();
      }
    }
    return messages;
  };
  var EntryDecoder = (decoder) => {
    if (!decoder.canReadInt64()) {
      throw new KafkaJSPartialMessageError(`Tried to decode a partial message: There isn't enough bytes to read the offset`);
    }
    const offset = decoder.readInt64().toString();
    if (!decoder.canReadInt32()) {
      throw new KafkaJSPartialMessageError(`Tried to decode a partial message: There isn't enough bytes to read the message size`);
    }
    const size = decoder.readInt32();
    return MessageDecoder(offset, size, decoder);
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v0/response.js
var require_response9 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { KafkaJSOffsetOutOfRange } = require_errors2();
  var { failure, createErrorFromCode, errorCodes } = require_error();
  var MessageSetDecoder = require_decoder5();
  var decodePartition = async (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    highWatermark: decoder.readInt64().toString(),
    messages: await MessageSetDecoder(decoder)
  });
  var decodeResponse = async (decoder) => ({
    topicName: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const responses = await decoder.readArrayAsync(decodeResponse);
    return {
      responses
    };
  };
  var { code: OFFSET_OUT_OF_RANGE_ERROR_CODE } = errorCodes.find((e) => e.type === "OFFSET_OUT_OF_RANGE");
  var parse = async (data) => {
    const errors = data.responses.flatMap(({ topicName, partitions }) => {
      return partitions.filter((partition) => failure(partition.errorCode)).map((partition) => Object.assign({}, partition, { topic: topicName }));
    });
    if (errors.length > 0) {
      const { errorCode, topic, partition } = errors[0];
      if (errorCode === OFFSET_OUT_OF_RANGE_ERROR_CODE) {
        throw new KafkaJSOffsetOutOfRange(createErrorFromCode(errorCode), { topic, partition });
      }
      throw createErrorFromCode(errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v1/request.js
var require_request10 = __commonJS((exports, module) => {
  var requestV0 = require_request9();
  module.exports = ({ replicaId, maxWaitTime, minBytes, topics }) => {
    return Object.assign(requestV0({ replicaId, maxWaitTime, minBytes, topics }), { apiVersion: 1 });
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v1/response.js
var require_response10 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response9();
  var MessageSetDecoder = require_decoder5();
  var decodePartition = async (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    highWatermark: decoder.readInt64().toString(),
    messages: await MessageSetDecoder(decoder)
  });
  var decodeResponse = async (decoder) => ({
    topicName: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const responses = await decoder.readArrayAsync(decodeResponse);
    return {
      throttleTime,
      responses
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v2/request.js
var require_request11 = __commonJS((exports, module) => {
  var requestV0 = require_request9();
  module.exports = ({ replicaId, maxWaitTime, minBytes, topics }) => {
    return Object.assign(requestV0({ replicaId, maxWaitTime, minBytes, topics }), { apiVersion: 2 });
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v2/response.js
var require_response11 = __commonJS((exports, module) => {
  var { decode, parse } = require_response10();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v3/request.js
var require_request12 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Fetch: apiKey } = require_apiKeys();
  module.exports = ({ replicaId, maxWaitTime, minBytes, maxBytes, topics }) => ({
    apiKey,
    apiVersion: 3,
    apiName: "Fetch",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, fetchOffset, maxBytes }) => {
    return new Encoder().writeInt32(partition).writeInt64(fetchOffset).writeInt32(maxBytes);
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v3/response.js
var require_response12 = __commonJS((exports, module) => {
  var { decode, parse } = require_response10();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v4/request.js
var require_request13 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Fetch: apiKey } = require_apiKeys();
  var ISOLATION_LEVEL = require_isolationLevel();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED
  }) => ({
    apiKey,
    apiVersion: 4,
    apiName: "Fetch",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeInt8(isolationLevel).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, fetchOffset, maxBytes }) => {
    return new Encoder().writeInt32(partition).writeInt64(fetchOffset).writeInt32(maxBytes);
  };
});

// node_modules/kafkajs/src/protocol/recordBatch/header/v0/decoder.js
var require_decoder6 = __commonJS((exports, module) => {
  module.exports = (decoder) => ({
    key: decoder.readVarIntString(),
    value: decoder.readVarIntBytes()
  });
});

// node_modules/kafkajs/src/protocol/timestampTypes.js
var require_timestampTypes = __commonJS((exports, module) => {
  module.exports = {
    NO_TIMESTAMP: -1,
    CREATE_TIME: 0,
    LOG_APPEND_TIME: 1
  };
});

// node_modules/kafkajs/src/protocol/recordBatch/record/v0/decoder.js
var require_decoder7 = __commonJS((exports, module) => {
  var Long = require_long();
  var HeaderDecoder = require_decoder6();
  var TimestampTypes = require_timestampTypes();
  module.exports = (decoder, batchContext = {}) => {
    const {
      firstOffset,
      firstTimestamp,
      magicByte,
      isControlBatch = false,
      timestampType,
      maxTimestamp
    } = batchContext;
    const attributes = decoder.readInt8();
    const timestampDelta = decoder.readVarLong();
    const timestamp = timestampType === TimestampTypes.LOG_APPEND_TIME && maxTimestamp ? maxTimestamp : Long.fromValue(firstTimestamp).add(timestampDelta).toString();
    const offsetDelta = decoder.readVarInt();
    const offset = Long.fromValue(firstOffset).add(offsetDelta).toString();
    const key = decoder.readVarIntBytes();
    const value = decoder.readVarIntBytes();
    const headers = decoder.readVarIntArray(HeaderDecoder).reduce((obj, { key: key2, value: value2 }) => ({
      ...obj,
      [key2]: obj[key2] === undefined ? value2 : Array.isArray(obj[key2]) ? obj[key2].concat([value2]) : [obj[key2], value2]
    }), {});
    return {
      magicByte,
      attributes,
      timestamp,
      offset,
      key,
      value,
      headers,
      isControlRecord: isControlBatch,
      batchContext
    };
  };
});

// node_modules/kafkajs/src/protocol/recordBatch/v0/decoder.js
var require_decoder8 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { KafkaJSPartialMessageError } = require_errors2();
  var { lookupCodecByAttributes } = require_compression();
  var RecordDecoder = require_decoder7();
  var TimestampTypes = require_timestampTypes();
  var TIMESTAMP_TYPE_FLAG_MASK = 8;
  var TRANSACTIONAL_FLAG_MASK = 16;
  var CONTROL_FLAG_MASK = 32;
  module.exports = async (fetchDecoder) => {
    const firstOffset = fetchDecoder.readInt64().toString();
    const length = fetchDecoder.readInt32();
    const decoder = fetchDecoder.slice(length);
    fetchDecoder.forward(length);
    const remainingBytes = Buffer.byteLength(decoder.buffer);
    if (remainingBytes < length) {
      throw new KafkaJSPartialMessageError(`Tried to decode a partial record batch: remainingBytes(${remainingBytes}) < recordBatchLength(${length})`);
    }
    const partitionLeaderEpoch = decoder.readInt32();
    const magicByte = decoder.readInt8();
    const crc = decoder.readInt32();
    const attributes = decoder.readInt16();
    const lastOffsetDelta = decoder.readInt32();
    const firstTimestamp = decoder.readInt64().toString();
    const maxTimestamp = decoder.readInt64().toString();
    const producerId = decoder.readInt64().toString();
    const producerEpoch = decoder.readInt16();
    const firstSequence = decoder.readInt32();
    const inTransaction = (attributes & TRANSACTIONAL_FLAG_MASK) > 0;
    const isControlBatch = (attributes & CONTROL_FLAG_MASK) > 0;
    const timestampType = (attributes & TIMESTAMP_TYPE_FLAG_MASK) > 0 ? TimestampTypes.LOG_APPEND_TIME : TimestampTypes.CREATE_TIME;
    const codec = lookupCodecByAttributes(attributes);
    const recordContext = {
      firstOffset,
      firstTimestamp,
      partitionLeaderEpoch,
      inTransaction,
      isControlBatch,
      lastOffsetDelta,
      producerId,
      producerEpoch,
      firstSequence,
      maxTimestamp,
      timestampType
    };
    const records = await decodeRecords(codec, decoder, { ...recordContext, magicByte });
    return {
      ...recordContext,
      records
    };
  };
  var decodeRecords = async (codec, recordsDecoder, recordContext) => {
    if (!codec) {
      return recordsDecoder.readArray((decoder) => decodeRecord(decoder, recordContext));
    }
    const length = recordsDecoder.readInt32();
    if (length <= 0) {
      return [];
    }
    const compressedRecordsBuffer = recordsDecoder.readAll();
    const decompressedRecordBuffer = await codec.decompress(compressedRecordsBuffer);
    const decompressedRecordDecoder = new Decoder(decompressedRecordBuffer);
    const records = new Array(length);
    for (let i = 0;i < length; i++) {
      records[i] = decodeRecord(decompressedRecordDecoder, recordContext);
    }
    return records;
  };
  var decodeRecord = (decoder, recordContext) => {
    const recordBuffer = decoder.readVarIntBytes();
    return RecordDecoder(new Decoder(recordBuffer), recordContext);
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v4/decodeMessages.js
var require_decodeMessages = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var MessageSetDecoder = require_decoder5();
  var RecordBatchDecoder = require_decoder8();
  var { MAGIC_BYTE } = require_v04();
  var MAGIC_OFFSET = 16;
  var RECORD_BATCH_OVERHEAD = 49;
  var decodeMessages = async (decoder) => {
    const messagesSize = decoder.readInt32();
    if (messagesSize <= 0 || !decoder.canReadBytes(messagesSize)) {
      return [];
    }
    const messagesBuffer = decoder.readBytes(messagesSize);
    const messagesDecoder = new Decoder(messagesBuffer);
    const magicByte = messagesBuffer.slice(MAGIC_OFFSET).readInt8(0);
    if (magicByte === MAGIC_BYTE) {
      const records = [];
      while (messagesDecoder.canReadBytes(RECORD_BATCH_OVERHEAD)) {
        try {
          const recordBatch = await RecordBatchDecoder(messagesDecoder);
          records.push(...recordBatch.records);
        } catch (e) {
          if (e.name === "KafkaJSPartialMessageError") {
            break;
          }
          throw e;
        }
      }
      return records;
    }
    return MessageSetDecoder(messagesDecoder, messagesSize);
  };
  module.exports = decodeMessages;
});

// node_modules/kafkajs/src/protocol/requests/fetch/v4/response.js
var require_response13 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV1 } = require_response10();
  var decodeMessages = require_decodeMessages();
  var decodeAbortedTransactions = (decoder) => ({
    producerId: decoder.readInt64().toString(),
    firstOffset: decoder.readInt64().toString()
  });
  var decodePartition = async (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    highWatermark: decoder.readInt64().toString(),
    lastStableOffset: decoder.readInt64().toString(),
    abortedTransactions: decoder.readArray(decodeAbortedTransactions),
    messages: await decodeMessages(decoder)
  });
  var decodeResponse = async (decoder) => ({
    topicName: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const responses = await decoder.readArrayAsync(decodeResponse);
    return {
      throttleTime,
      responses
    };
  };
  module.exports = {
    decode,
    parse: parseV1
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v5/request.js
var require_request14 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Fetch: apiKey } = require_apiKeys();
  var ISOLATION_LEVEL = require_isolationLevel();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED
  }) => ({
    apiKey,
    apiVersion: 5,
    apiName: "Fetch",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeInt8(isolationLevel).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, fetchOffset, logStartOffset = -1, maxBytes }) => {
    return new Encoder().writeInt32(partition).writeInt64(fetchOffset).writeInt64(logStartOffset).writeInt32(maxBytes);
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v5/response.js
var require_response14 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV1 } = require_response10();
  var decodeMessages = require_decodeMessages();
  var decodeAbortedTransactions = (decoder) => ({
    producerId: decoder.readInt64().toString(),
    firstOffset: decoder.readInt64().toString()
  });
  var decodePartition = async (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    highWatermark: decoder.readInt64().toString(),
    lastStableOffset: decoder.readInt64().toString(),
    lastStartOffset: decoder.readInt64().toString(),
    abortedTransactions: decoder.readArray(decodeAbortedTransactions),
    messages: await decodeMessages(decoder)
  });
  var decodeResponse = async (decoder) => ({
    topicName: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const responses = await decoder.readArrayAsync(decodeResponse);
    return {
      throttleTime,
      responses
    };
  };
  module.exports = {
    decode,
    parse: parseV1
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v6/request.js
var require_request15 = __commonJS((exports, module) => {
  var ISOLATION_LEVEL = require_isolationLevel();
  var requestV5 = require_request14();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED
  }) => Object.assign(requestV5({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel
  }), { apiVersion: 6 });
});

// node_modules/kafkajs/src/protocol/requests/fetch/v6/response.js
var require_response15 = __commonJS((exports, module) => {
  var { decode, parse } = require_response14();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v7/request.js
var require_request16 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Fetch: apiKey } = require_apiKeys();
  var ISOLATION_LEVEL = require_isolationLevel();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
    sessionId = 0,
    sessionEpoch = -1,
    forgottenTopics = []
  }) => ({
    apiKey,
    apiVersion: 7,
    apiName: "Fetch",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeInt8(isolationLevel).writeInt32(sessionId).writeInt32(sessionEpoch).writeArray(topics.map(encodeTopic)).writeArray(forgottenTopics.map(encodeForgottenTopics));
    }
  });
  var encodeForgottenTopics = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions);
  };
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, fetchOffset, logStartOffset = -1, maxBytes }) => {
    return new Encoder().writeInt32(partition).writeInt64(fetchOffset).writeInt64(logStartOffset).writeInt32(maxBytes);
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v7/response.js
var require_response16 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV1 } = require_response10();
  var decodeMessages = require_decodeMessages();
  var decodeAbortedTransactions = (decoder) => ({
    producerId: decoder.readInt64().toString(),
    firstOffset: decoder.readInt64().toString()
  });
  var decodePartition = async (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    highWatermark: decoder.readInt64().toString(),
    lastStableOffset: decoder.readInt64().toString(),
    lastStartOffset: decoder.readInt64().toString(),
    abortedTransactions: decoder.readArray(decodeAbortedTransactions),
    messages: await decodeMessages(decoder)
  });
  var decodeResponse = async (decoder) => ({
    topicName: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    const sessionId = decoder.readInt32();
    const responses = await decoder.readArrayAsync(decodeResponse);
    return {
      throttleTime,
      errorCode,
      sessionId,
      responses
    };
  };
  module.exports = {
    decode,
    parse: parseV1
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v8/request.js
var require_request17 = __commonJS((exports, module) => {
  var ISOLATION_LEVEL = require_isolationLevel();
  var requestV7 = require_request16();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
    sessionId = 0,
    sessionEpoch = -1,
    forgottenTopics = []
  }) => Object.assign(requestV7({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel,
    sessionId,
    sessionEpoch,
    forgottenTopics
  }), { apiVersion: 8 });
});

// node_modules/kafkajs/src/protocol/requests/fetch/v8/response.js
var require_response17 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV1 } = require_response10();
  var decodeMessages = require_decodeMessages();
  var decodeAbortedTransactions = (decoder) => ({
    producerId: decoder.readInt64().toString(),
    firstOffset: decoder.readInt64().toString()
  });
  var decodePartition = async (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    highWatermark: decoder.readInt64().toString(),
    lastStableOffset: decoder.readInt64().toString(),
    lastStartOffset: decoder.readInt64().toString(),
    abortedTransactions: decoder.readArray(decodeAbortedTransactions),
    messages: await decodeMessages(decoder)
  });
  var decodeResponse = async (decoder) => ({
    topicName: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const clientSideThrottleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    const sessionId = decoder.readInt32();
    const responses = await decoder.readArrayAsync(decodeResponse);
    return {
      throttleTime: 0,
      clientSideThrottleTime,
      errorCode,
      sessionId,
      responses
    };
  };
  module.exports = {
    decode,
    parse: parseV1
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v9/request.js
var require_request18 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Fetch: apiKey } = require_apiKeys();
  var ISOLATION_LEVEL = require_isolationLevel();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
    sessionId = 0,
    sessionEpoch = -1,
    forgottenTopics = []
  }) => ({
    apiKey,
    apiVersion: 9,
    apiName: "Fetch",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeInt8(isolationLevel).writeInt32(sessionId).writeInt32(sessionEpoch).writeArray(topics.map(encodeTopic)).writeArray(forgottenTopics.map(encodeForgottenTopics));
    }
  });
  var encodeForgottenTopics = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions);
  };
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({
    partition,
    currentLeaderEpoch = -1,
    fetchOffset,
    logStartOffset = -1,
    maxBytes
  }) => {
    return new Encoder().writeInt32(partition).writeInt32(currentLeaderEpoch).writeInt64(fetchOffset).writeInt64(logStartOffset).writeInt32(maxBytes);
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v9/response.js
var require_response18 = __commonJS((exports, module) => {
  var { decode, parse } = require_response17();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v10/request.js
var require_request19 = __commonJS((exports, module) => {
  var ISOLATION_LEVEL = require_isolationLevel();
  var requestV9 = require_request18();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
    sessionId = 0,
    sessionEpoch = -1,
    forgottenTopics = []
  }) => Object.assign(requestV9({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    isolationLevel,
    sessionId,
    sessionEpoch,
    forgottenTopics
  }), { apiVersion: 10 });
});

// node_modules/kafkajs/src/protocol/requests/fetch/v10/response.js
var require_response19 = __commonJS((exports, module) => {
  var { decode, parse } = require_response18();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v11/request.js
var require_request20 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Fetch: apiKey } = require_apiKeys();
  var ISOLATION_LEVEL = require_isolationLevel();
  module.exports = ({
    replicaId,
    maxWaitTime,
    minBytes,
    maxBytes,
    topics,
    rackId = "",
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
    sessionId = 0,
    sessionEpoch = -1,
    forgottenTopics = []
  }) => ({
    apiKey,
    apiVersion: 11,
    apiName: "Fetch",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt32(maxWaitTime).writeInt32(minBytes).writeInt32(maxBytes).writeInt8(isolationLevel).writeInt32(sessionId).writeInt32(sessionEpoch).writeArray(topics.map(encodeTopic)).writeArray(forgottenTopics.map(encodeForgottenTopics)).writeString(rackId);
    }
  });
  var encodeForgottenTopics = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions);
  };
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({
    partition,
    currentLeaderEpoch = -1,
    fetchOffset,
    logStartOffset = -1,
    maxBytes
  }) => {
    return new Encoder().writeInt32(partition).writeInt32(currentLeaderEpoch).writeInt64(fetchOffset).writeInt64(logStartOffset).writeInt32(maxBytes);
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/v11/response.js
var require_response20 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV1 } = require_response10();
  var decodeMessages = require_decodeMessages();
  var decodeAbortedTransactions = (decoder) => ({
    producerId: decoder.readInt64().toString(),
    firstOffset: decoder.readInt64().toString()
  });
  var decodePartition = async (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    highWatermark: decoder.readInt64().toString(),
    lastStableOffset: decoder.readInt64().toString(),
    lastStartOffset: decoder.readInt64().toString(),
    abortedTransactions: decoder.readArray(decodeAbortedTransactions),
    preferredReadReplica: decoder.readInt32(),
    messages: await decodeMessages(decoder)
  });
  var decodeResponse = async (decoder) => ({
    topicName: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const clientSideThrottleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    const sessionId = decoder.readInt32();
    const responses = await decoder.readArrayAsync(decodeResponse);
    return {
      throttleTime: 0,
      clientSideThrottleTime,
      errorCode,
      sessionId,
      responses
    };
  };
  module.exports = {
    decode,
    parse: parseV1
  };
});

// node_modules/kafkajs/src/protocol/requests/fetch/index.js
var require_fetch = __commonJS((exports, module) => {
  var ISOLATION_LEVEL = require_isolationLevel();
  var REPLICA_ID = -1;
  var NETWORK_DELAY = 100;
  var requestTimeout = (timeout) => Number.isSafeInteger(timeout + NETWORK_DELAY) ? timeout + NETWORK_DELAY : timeout;
  var versions = {
    0: ({ replicaId = REPLICA_ID, maxWaitTime, minBytes, topics }) => {
      const request = require_request9();
      const response = require_response9();
      return {
        request: request({ replicaId, maxWaitTime, minBytes, topics }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    1: ({ replicaId = REPLICA_ID, maxWaitTime, minBytes, topics }) => {
      const request = require_request10();
      const response = require_response10();
      return {
        request: request({ replicaId, maxWaitTime, minBytes, topics }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    2: ({ replicaId = REPLICA_ID, maxWaitTime, minBytes, topics }) => {
      const request = require_request11();
      const response = require_response11();
      return {
        request: request({ replicaId, maxWaitTime, minBytes, topics }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    3: ({ replicaId = REPLICA_ID, maxWaitTime, minBytes, maxBytes, topics }) => {
      const request = require_request12();
      const response = require_response12();
      return {
        request: request({ replicaId, maxWaitTime, minBytes, maxBytes, topics }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    4: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      maxWaitTime,
      minBytes,
      maxBytes,
      topics
    }) => {
      const request = require_request13();
      const response = require_response13();
      return {
        request: request({ replicaId, isolationLevel, maxWaitTime, minBytes, maxBytes, topics }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    5: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      maxWaitTime,
      minBytes,
      maxBytes,
      topics
    }) => {
      const request = require_request14();
      const response = require_response14();
      return {
        request: request({ replicaId, isolationLevel, maxWaitTime, minBytes, maxBytes, topics }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    6: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      maxWaitTime,
      minBytes,
      maxBytes,
      topics
    }) => {
      const request = require_request15();
      const response = require_response15();
      return {
        request: request({ replicaId, isolationLevel, maxWaitTime, minBytes, maxBytes, topics }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    7: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      sessionId = 0,
      sessionEpoch = -1,
      forgottenTopics = [],
      maxWaitTime,
      minBytes,
      maxBytes,
      topics
    }) => {
      const request = require_request16();
      const response = require_response16();
      return {
        request: request({
          replicaId,
          isolationLevel,
          sessionId,
          sessionEpoch,
          forgottenTopics,
          maxWaitTime,
          minBytes,
          maxBytes,
          topics
        }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    8: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      sessionId = 0,
      sessionEpoch = -1,
      forgottenTopics = [],
      maxWaitTime,
      minBytes,
      maxBytes,
      topics
    }) => {
      const request = require_request17();
      const response = require_response17();
      return {
        request: request({
          replicaId,
          isolationLevel,
          sessionId,
          sessionEpoch,
          forgottenTopics,
          maxWaitTime,
          minBytes,
          maxBytes,
          topics
        }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    9: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      sessionId = 0,
      sessionEpoch = -1,
      forgottenTopics = [],
      maxWaitTime,
      minBytes,
      maxBytes,
      topics
    }) => {
      const request = require_request18();
      const response = require_response18();
      return {
        request: request({
          replicaId,
          isolationLevel,
          sessionId,
          sessionEpoch,
          forgottenTopics,
          maxWaitTime,
          minBytes,
          maxBytes,
          topics
        }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    10: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      sessionId = 0,
      sessionEpoch = -1,
      forgottenTopics = [],
      maxWaitTime,
      minBytes,
      maxBytes,
      topics
    }) => {
      const request = require_request19();
      const response = require_response19();
      return {
        request: request({
          replicaId,
          isolationLevel,
          sessionId,
          sessionEpoch,
          forgottenTopics,
          maxWaitTime,
          minBytes,
          maxBytes,
          topics
        }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    },
    11: ({
      replicaId = REPLICA_ID,
      isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
      sessionId = 0,
      sessionEpoch = -1,
      forgottenTopics = [],
      maxWaitTime,
      minBytes,
      maxBytes,
      topics,
      rackId
    }) => {
      const request = require_request20();
      const response = require_response20();
      return {
        request: request({
          replicaId,
          isolationLevel,
          sessionId,
          sessionEpoch,
          forgottenTopics,
          maxWaitTime,
          minBytes,
          maxBytes,
          topics,
          rackId
        }),
        response,
        requestTimeout: requestTimeout(maxWaitTime)
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v0/request.js
var require_request21 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { ListOffsets: apiKey } = require_apiKeys();
  module.exports = ({ replicaId, topics }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "ListOffsets",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, timestamp = -1, maxNumOffsets = 1 }) => {
    return new Encoder().writeInt32(partition).writeInt64(timestamp).writeInt32(maxNumOffsets);
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v0/response.js
var require_response21 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      responses: decoder.readArray(decodeResponses)
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    offsets: decoder.readArray(decodeOffsets)
  });
  var decodeOffsets = (decoder) => decoder.readInt64().toString();
  var parse = async (data) => {
    const partitionsWithError = data.responses.flatMap((response) => response.partitions.filter((partition) => failure(partition.errorCode)));
    const partitionWithError = partitionsWithError[0];
    if (partitionWithError) {
      throw createErrorFromCode(partitionWithError.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v1/request.js
var require_request22 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { ListOffsets: apiKey } = require_apiKeys();
  module.exports = ({ replicaId, topics }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "ListOffsets",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, timestamp = -1 }) => {
    return new Encoder().writeInt32(partition).writeInt64(timestamp);
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v1/response.js
var require_response22 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      responses: decoder.readArray(decodeResponses)
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    timestamp: decoder.readInt64().toString(),
    offset: decoder.readInt64().toString()
  });
  var parse = async (data) => {
    const partitionsWithError = data.responses.flatMap((response) => response.partitions.filter((partition) => failure(partition.errorCode)));
    const partitionWithError = partitionsWithError[0];
    if (partitionWithError) {
      throw createErrorFromCode(partitionWithError.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v2/request.js
var require_request23 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { ListOffsets: apiKey } = require_apiKeys();
  module.exports = ({ replicaId, isolationLevel, topics }) => ({
    apiKey,
    apiVersion: 2,
    apiName: "ListOffsets",
    encode: async () => {
      return new Encoder().writeInt32(replicaId).writeInt8(isolationLevel).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, timestamp = -1 }) => {
    return new Encoder().writeInt32(partition).writeInt64(timestamp);
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v2/response.js
var require_response23 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      throttleTime: decoder.readInt32(),
      responses: decoder.readArray(decodeResponses)
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16(),
    timestamp: decoder.readInt64().toString(),
    offset: decoder.readInt64().toString()
  });
  var parse = async (data) => {
    const partitionsWithError = data.responses.flatMap((response) => response.partitions.filter((partition) => failure(partition.errorCode)));
    const partitionWithError = partitionsWithError[0];
    if (partitionWithError) {
      throw createErrorFromCode(partitionWithError.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v3/request.js
var require_request24 = __commonJS((exports, module) => {
  var requestV2 = require_request23();
  module.exports = ({ replicaId, isolationLevel, topics }) => Object.assign(requestV2({ replicaId, isolationLevel, topics }), { apiVersion: 3 });
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/v3/response.js
var require_response24 = __commonJS((exports, module) => {
  var { parse, decode: decodeV2 } = require_response23();
  var decode = async (rawData) => {
    const decoded = await decodeV2(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listOffsets/index.js
var require_listOffsets = __commonJS((exports, module) => {
  var ISOLATION_LEVEL = require_isolationLevel();
  var REPLICA_ID = -1;
  var versions = {
    0: ({ replicaId = REPLICA_ID, topics }) => {
      const request = require_request21();
      const response = require_response21();
      return { request: request({ replicaId, topics }), response };
    },
    1: ({ replicaId = REPLICA_ID, topics }) => {
      const request = require_request22();
      const response = require_response22();
      return { request: request({ replicaId, topics }), response };
    },
    2: ({ replicaId = REPLICA_ID, isolationLevel = ISOLATION_LEVEL.READ_COMMITTED, topics }) => {
      const request = require_request23();
      const response = require_response23();
      return { request: request({ replicaId, isolationLevel, topics }), response };
    },
    3: ({ replicaId = REPLICA_ID, isolationLevel = ISOLATION_LEVEL.READ_COMMITTED, topics }) => {
      const request = require_request24();
      const response = require_response24();
      return { request: request({ replicaId, isolationLevel, topics }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/v0/request.js
var require_request25 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Metadata: apiKey } = require_apiKeys();
  module.exports = ({ topics }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "Metadata",
    encode: async () => {
      return new Encoder().writeArray(topics);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/metadata/v0/response.js
var require_response25 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var broker = (decoder) => ({
    nodeId: decoder.readInt32(),
    host: decoder.readString(),
    port: decoder.readInt32()
  });
  var topicMetadata = (decoder) => ({
    topicErrorCode: decoder.readInt16(),
    topic: decoder.readString(),
    partitionMetadata: decoder.readArray(partitionMetadata)
  });
  var partitionMetadata = (decoder) => ({
    partitionErrorCode: decoder.readInt16(),
    partitionId: decoder.readInt32(),
    leader: decoder.readInt32(),
    replicas: decoder.readArray((d) => d.readInt32()),
    isr: decoder.readArray((d) => d.readInt32())
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      brokers: decoder.readArray(broker),
      topicMetadata: decoder.readArray(topicMetadata)
    };
  };
  var parse = async (data) => {
    const topicsWithErrors = data.topicMetadata.filter((topic) => failure(topic.topicErrorCode));
    if (topicsWithErrors.length > 0) {
      const { topicErrorCode } = topicsWithErrors[0];
      throw createErrorFromCode(topicErrorCode);
    }
    const errors = data.topicMetadata.flatMap((topic) => {
      return topic.partitionMetadata.filter((partition) => failure(partition.partitionErrorCode));
    });
    if (errors.length > 0) {
      const { partitionErrorCode } = errors[0];
      throw createErrorFromCode(partitionErrorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/v1/request.js
var require_request26 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Metadata: apiKey } = require_apiKeys();
  module.exports = ({ topics }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "Metadata",
    encode: async () => {
      return new Encoder().writeNullableArray(topics);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/metadata/v1/response.js
var require_response26 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response25();
  var broker = (decoder) => ({
    nodeId: decoder.readInt32(),
    host: decoder.readString(),
    port: decoder.readInt32(),
    rack: decoder.readString()
  });
  var topicMetadata = (decoder) => ({
    topicErrorCode: decoder.readInt16(),
    topic: decoder.readString(),
    isInternal: decoder.readBoolean(),
    partitionMetadata: decoder.readArray(partitionMetadata)
  });
  var partitionMetadata = (decoder) => ({
    partitionErrorCode: decoder.readInt16(),
    partitionId: decoder.readInt32(),
    leader: decoder.readInt32(),
    replicas: decoder.readArray((d) => d.readInt32()),
    isr: decoder.readArray((d) => d.readInt32())
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      brokers: decoder.readArray(broker),
      controllerId: decoder.readInt32(),
      topicMetadata: decoder.readArray(topicMetadata)
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/v2/request.js
var require_request27 = __commonJS((exports, module) => {
  var requestV1 = require_request26();
  module.exports = ({ topics }) => Object.assign(requestV1({ topics }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/metadata/v2/response.js
var require_response27 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response25();
  var broker = (decoder) => ({
    nodeId: decoder.readInt32(),
    host: decoder.readString(),
    port: decoder.readInt32(),
    rack: decoder.readString()
  });
  var topicMetadata = (decoder) => ({
    topicErrorCode: decoder.readInt16(),
    topic: decoder.readString(),
    isInternal: decoder.readBoolean(),
    partitionMetadata: decoder.readArray(partitionMetadata)
  });
  var partitionMetadata = (decoder) => ({
    partitionErrorCode: decoder.readInt16(),
    partitionId: decoder.readInt32(),
    leader: decoder.readInt32(),
    replicas: decoder.readArray((d) => d.readInt32()),
    isr: decoder.readArray((d) => d.readInt32())
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      brokers: decoder.readArray(broker),
      clusterId: decoder.readString(),
      controllerId: decoder.readInt32(),
      topicMetadata: decoder.readArray(topicMetadata)
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/v3/request.js
var require_request28 = __commonJS((exports, module) => {
  var requestV1 = require_request26();
  module.exports = ({ topics }) => Object.assign(requestV1({ topics }), { apiVersion: 3 });
});

// node_modules/kafkajs/src/protocol/requests/metadata/v3/response.js
var require_response28 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response25();
  var broker = (decoder) => ({
    nodeId: decoder.readInt32(),
    host: decoder.readString(),
    port: decoder.readInt32(),
    rack: decoder.readString()
  });
  var topicMetadata = (decoder) => ({
    topicErrorCode: decoder.readInt16(),
    topic: decoder.readString(),
    isInternal: decoder.readBoolean(),
    partitionMetadata: decoder.readArray(partitionMetadata)
  });
  var partitionMetadata = (decoder) => ({
    partitionErrorCode: decoder.readInt16(),
    partitionId: decoder.readInt32(),
    leader: decoder.readInt32(),
    replicas: decoder.readArray((d) => d.readInt32()),
    isr: decoder.readArray((d) => d.readInt32())
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      throttleTime: decoder.readInt32(),
      brokers: decoder.readArray(broker),
      clusterId: decoder.readString(),
      controllerId: decoder.readInt32(),
      topicMetadata: decoder.readArray(topicMetadata)
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/v4/request.js
var require_request29 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Metadata: apiKey } = require_apiKeys();
  module.exports = ({ topics, allowAutoTopicCreation = true }) => ({
    apiKey,
    apiVersion: 4,
    apiName: "Metadata",
    encode: async () => {
      return new Encoder().writeNullableArray(topics).writeBoolean(allowAutoTopicCreation);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/metadata/v4/response.js
var require_response29 = __commonJS((exports, module) => {
  var { parse: parseV3, decode: decodeV3 } = require_response28();
  module.exports = {
    parse: parseV3,
    decode: decodeV3
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/v5/request.js
var require_request30 = __commonJS((exports, module) => {
  var requestV4 = require_request29();
  module.exports = ({ topics, allowAutoTopicCreation = true }) => Object.assign(requestV4({ topics, allowAutoTopicCreation }), { apiVersion: 5 });
});

// node_modules/kafkajs/src/protocol/requests/metadata/v5/response.js
var require_response30 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response25();
  var broker = (decoder) => ({
    nodeId: decoder.readInt32(),
    host: decoder.readString(),
    port: decoder.readInt32(),
    rack: decoder.readString()
  });
  var topicMetadata = (decoder) => ({
    topicErrorCode: decoder.readInt16(),
    topic: decoder.readString(),
    isInternal: decoder.readBoolean(),
    partitionMetadata: decoder.readArray(partitionMetadata)
  });
  var partitionMetadata = (decoder) => ({
    partitionErrorCode: decoder.readInt16(),
    partitionId: decoder.readInt32(),
    leader: decoder.readInt32(),
    replicas: decoder.readArray((d) => d.readInt32()),
    isr: decoder.readArray((d) => d.readInt32()),
    offlineReplicas: decoder.readArray((d) => d.readInt32())
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      throttleTime: decoder.readInt32(),
      brokers: decoder.readArray(broker),
      clusterId: decoder.readString(),
      controllerId: decoder.readInt32(),
      topicMetadata: decoder.readArray(topicMetadata)
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/v6/request.js
var require_request31 = __commonJS((exports, module) => {
  var requestV5 = require_request30();
  module.exports = ({ topics, allowAutoTopicCreation = true }) => Object.assign(requestV5({ topics, allowAutoTopicCreation }), { apiVersion: 6 });
});

// node_modules/kafkajs/src/protocol/requests/metadata/v6/response.js
var require_response31 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response30();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/metadata/index.js
var require_metadata = __commonJS((exports, module) => {
  var versions = {
    0: ({ topics }) => {
      const request = require_request25();
      const response = require_response25();
      return { request: request({ topics }), response };
    },
    1: ({ topics }) => {
      const request = require_request26();
      const response = require_response26();
      return { request: request({ topics }), response };
    },
    2: ({ topics }) => {
      const request = require_request27();
      const response = require_response27();
      return { request: request({ topics }), response };
    },
    3: ({ topics }) => {
      const request = require_request28();
      const response = require_response28();
      return { request: request({ topics }), response };
    },
    4: ({ topics, allowAutoTopicCreation }) => {
      const request = require_request29();
      const response = require_response29();
      return { request: request({ topics, allowAutoTopicCreation }), response };
    },
    5: ({ topics, allowAutoTopicCreation }) => {
      const request = require_request30();
      const response = require_response30();
      return { request: request({ topics, allowAutoTopicCreation }), response };
    },
    6: ({ topics, allowAutoTopicCreation }) => {
      const request = require_request31();
      const response = require_response31();
      return { request: request({ topics, allowAutoTopicCreation }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v0/request.js
var require_request32 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { OffsetCommit: apiKey } = require_apiKeys();
  module.exports = ({ groupId, topics }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "OffsetCommit",
    encode: async () => {
      return new Encoder().writeString(groupId).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, offset, metadata = null }) => {
    return new Encoder().writeInt32(partition).writeInt64(offset).writeString(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v0/response.js
var require_response32 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      responses: decoder.readArray(decodeResponses)
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16()
  });
  var parse = async (data) => {
    const partitionsWithError = data.responses.flatMap((response) => response.partitions.filter((partition) => failure(partition.errorCode)));
    const partitionWithError = partitionsWithError[0];
    if (partitionWithError) {
      throw createErrorFromCode(partitionWithError.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v1/request.js
var require_request33 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { OffsetCommit: apiKey } = require_apiKeys();
  module.exports = ({ groupId, groupGenerationId, memberId, topics }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "OffsetCommit",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(groupGenerationId).writeString(memberId).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, offset, timestamp = Date.now(), metadata = null }) => {
    return new Encoder().writeInt32(partition).writeInt64(offset).writeInt64(timestamp).writeString(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v1/response.js
var require_response33 = __commonJS((exports, module) => {
  var { parse, decode } = require_response32();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v2/request.js
var require_request34 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { OffsetCommit: apiKey } = require_apiKeys();
  module.exports = ({ groupId, groupGenerationId, memberId, retentionTime, topics }) => ({
    apiKey,
    apiVersion: 2,
    apiName: "OffsetCommit",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(groupGenerationId).writeString(memberId).writeInt64(retentionTime).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, offset, metadata = null }) => {
    return new Encoder().writeInt32(partition).writeInt64(offset).writeString(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v2/response.js
var require_response34 = __commonJS((exports, module) => {
  var { parse, decode } = require_response32();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v3/request.js
var require_request35 = __commonJS((exports, module) => {
  var requestV2 = require_request34();
  module.exports = ({ groupId, groupGenerationId, memberId, retentionTime, topics }) => Object.assign(requestV2({ groupId, groupGenerationId, memberId, retentionTime, topics }), {
    apiVersion: 3
  });
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v3/response.js
var require_response35 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response32();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      throttleTime: decoder.readInt32(),
      responses: decoder.readArray(decodeResponses)
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16()
  });
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v4/request.js
var require_request36 = __commonJS((exports, module) => {
  var requestV3 = require_request35();
  module.exports = ({ groupId, groupGenerationId, memberId, retentionTime, topics }) => Object.assign(requestV3({ groupId, groupGenerationId, memberId, retentionTime, topics }), {
    apiVersion: 4
  });
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v4/response.js
var require_response36 = __commonJS((exports, module) => {
  var { parse, decode: decodeV3 } = require_response35();
  var decode = async (rawData) => {
    const decoded = await decodeV3(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v5/request.js
var require_request37 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { OffsetCommit: apiKey } = require_apiKeys();
  module.exports = ({ groupId, groupGenerationId, memberId, topics }) => ({
    apiKey,
    apiVersion: 5,
    apiName: "OffsetCommit",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(groupGenerationId).writeString(memberId).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, offset, metadata = null }) => {
    return new Encoder().writeInt32(partition).writeInt64(offset).writeString(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/v5/response.js
var require_response37 = __commonJS((exports, module) => {
  var { parse, decode } = require_response36();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetCommit/index.js
var require_offsetCommit = __commonJS((exports, module) => {
  var RETENTION_TIME = -1;
  var versions = {
    0: ({ groupId, topics }) => {
      const request = require_request32();
      const response = require_response32();
      return { request: request({ groupId, topics }), response };
    },
    1: ({ groupId, groupGenerationId, memberId, topics }) => {
      const request = require_request33();
      const response = require_response33();
      return { request: request({ groupId, groupGenerationId, memberId, topics }), response };
    },
    2: ({ groupId, groupGenerationId, memberId, retentionTime = RETENTION_TIME, topics }) => {
      const request = require_request34();
      const response = require_response34();
      return {
        request: request({
          groupId,
          groupGenerationId,
          memberId,
          retentionTime,
          topics
        }),
        response
      };
    },
    3: ({ groupId, groupGenerationId, memberId, retentionTime = RETENTION_TIME, topics }) => {
      const request = require_request35();
      const response = require_response35();
      return {
        request: request({
          groupId,
          groupGenerationId,
          memberId,
          retentionTime,
          topics
        }),
        response
      };
    },
    4: ({ groupId, groupGenerationId, memberId, retentionTime = RETENTION_TIME, topics }) => {
      const request = require_request36();
      const response = require_response36();
      return {
        request: request({
          groupId,
          groupGenerationId,
          memberId,
          retentionTime,
          topics
        }),
        response
      };
    },
    5: ({ groupId, groupGenerationId, memberId, topics }) => {
      const request = require_request37();
      const response = require_response37();
      return {
        request: request({
          groupId,
          groupGenerationId,
          memberId,
          topics
        }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v1/request.js
var require_request38 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { OffsetFetch: apiKey } = require_apiKeys();
  module.exports = ({ groupId, topics }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "OffsetFetch",
    encode: async () => {
      return new Encoder().writeString(groupId).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition }) => {
    return new Encoder().writeInt32(partition);
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v1/response.js
var require_response38 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      responses: decoder.readArray(decodeResponses)
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    offset: decoder.readInt64().toString(),
    metadata: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  var parse = async (data) => {
    const partitionsWithError = data.responses.flatMap((response) => response.partitions.filter((partition) => failure(partition.errorCode)));
    const partitionWithError = partitionsWithError[0];
    if (partitionWithError) {
      throw createErrorFromCode(partitionWithError.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v2/request.js
var require_request39 = __commonJS((exports, module) => {
  var requestV1 = require_request38();
  module.exports = ({ groupId, topics }) => Object.assign(requestV1({ groupId, topics }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v2/response.js
var require_response39 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      responses: decoder.readArray(decodeResponses),
      errorCode: decoder.readInt16()
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    offset: decoder.readInt64().toString(),
    metadata: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    const partitionsWithError = data.responses.flatMap((response) => response.partitions.filter((partition) => failure(partition.errorCode)));
    const partitionWithError = partitionsWithError[0];
    if (partitionWithError) {
      throw createErrorFromCode(partitionWithError.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v3/request.js
var require_request40 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { OffsetFetch: apiKey } = require_apiKeys();
  module.exports = ({ groupId, topics }) => ({
    apiKey,
    apiVersion: 3,
    apiName: "OffsetFetch",
    encode: async () => {
      return new Encoder().writeString(groupId).writeNullableArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition }) => {
    return new Encoder().writeInt32(partition);
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v3/response.js
var require_response40 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV2 } = require_response39();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      throttleTime: decoder.readInt32(),
      responses: decoder.readArray(decodeResponses),
      errorCode: decoder.readInt16()
    };
  };
  var decodeResponses = (decoder) => ({
    topic: decoder.readString(),
    partitions: decoder.readArray(decodePartitions)
  });
  var decodePartitions = (decoder) => ({
    partition: decoder.readInt32(),
    offset: decoder.readInt64().toString(),
    metadata: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  module.exports = {
    decode,
    parse: parseV2
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v4/request.js
var require_request41 = __commonJS((exports, module) => {
  var requestV3 = require_request40();
  module.exports = ({ groupId, topics }) => Object.assign(requestV3({ groupId, topics }), { apiVersion: 4 });
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/v4/response.js
var require_response41 = __commonJS((exports, module) => {
  var { parse, decode: decodeV3 } = require_response40();
  var decode = async (rawData) => {
    const decoded = await decodeV3(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/offsetFetch/index.js
var require_offsetFetch = __commonJS((exports, module) => {
  var versions = {
    1: ({ groupId, topics }) => {
      const request = require_request38();
      const response = require_response38();
      return { request: request({ groupId, topics }), response };
    },
    2: ({ groupId, topics }) => {
      const request = require_request39();
      const response = require_response39();
      return { request: request({ groupId, topics }), response };
    },
    3: ({ groupId, topics }) => {
      const request = require_request40();
      const response = require_response40();
      return { request: request({ groupId, topics }), response };
    },
    4: ({ groupId, topics }) => {
      const request = require_request41();
      const response = require_response41();
      return { request: request({ groupId, topics }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/coordinatorTypes.js
var require_coordinatorTypes = __commonJS((exports, module) => {
  module.exports = {
    GROUP: 0,
    TRANSACTION: 1
  };
});

// node_modules/kafkajs/src/protocol/requests/findCoordinator/v0/request.js
var require_request42 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { GroupCoordinator: apiKey } = require_apiKeys();
  module.exports = ({ groupId }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "GroupCoordinator",
    encode: async () => {
      return new Encoder().writeString(groupId);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/findCoordinator/v0/response.js
var require_response42 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    const coordinator = {
      nodeId: decoder.readInt32(),
      host: decoder.readString(),
      port: decoder.readInt32()
    };
    return {
      errorCode,
      coordinator
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/findCoordinator/v1/request.js
var require_request43 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { GroupCoordinator: apiKey } = require_apiKeys();
  module.exports = ({ coordinatorKey, coordinatorType }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "GroupCoordinator",
    encode: async () => {
      return new Encoder().writeString(coordinatorKey).writeInt8(coordinatorType);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/findCoordinator/v1/response.js
var require_response43 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    const errorMessage = decoder.readString();
    const coordinator = {
      nodeId: decoder.readInt32(),
      host: decoder.readString(),
      port: decoder.readInt32()
    };
    return {
      throttleTime,
      errorCode,
      errorMessage,
      coordinator
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/findCoordinator/v2/request.js
var require_request44 = __commonJS((exports, module) => {
  var requestV1 = require_request43();
  module.exports = ({ coordinatorKey, coordinatorType }) => Object.assign(requestV1({ coordinatorKey, coordinatorType }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/findCoordinator/v2/response.js
var require_response44 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response43();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/findCoordinator/index.js
var require_findCoordinator = __commonJS((exports, module) => {
  var COORDINATOR_TYPES = require_coordinatorTypes();
  var versions = {
    0: ({ groupId }) => {
      const request = require_request42();
      const response = require_response42();
      return { request: request({ groupId }), response };
    },
    1: ({ groupId, coordinatorType = COORDINATOR_TYPES.GROUP }) => {
      const request = require_request43();
      const response = require_response43();
      return { request: request({ coordinatorKey: groupId, coordinatorType }), response };
    },
    2: ({ groupId, coordinatorType = COORDINATOR_TYPES.GROUP }) => {
      const request = require_request44();
      const response = require_response44();
      return { request: request({ coordinatorKey: groupId, coordinatorType }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v0/request.js
var require_request45 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { JoinGroup: apiKey } = require_apiKeys();
  module.exports = ({ groupId, sessionTimeout, memberId, protocolType, groupProtocols }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "JoinGroup",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(sessionTimeout).writeString(memberId).writeString(protocolType).writeArray(groupProtocols.map(encodeGroupProtocols));
    }
  });
  var encodeGroupProtocols = ({ name, metadata = Buffer.alloc(0) }) => {
    return new Encoder().writeString(name).writeBytes(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v0/response.js
var require_response45 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      errorCode,
      generationId: decoder.readInt32(),
      groupProtocol: decoder.readString(),
      leaderId: decoder.readString(),
      memberId: decoder.readString(),
      members: decoder.readArray((decoder2) => ({
        memberId: decoder2.readString(),
        memberMetadata: decoder2.readBytes()
      }))
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v1/request.js
var require_request46 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { JoinGroup: apiKey } = require_apiKeys();
  module.exports = ({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    protocolType,
    groupProtocols
  }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "JoinGroup",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(sessionTimeout).writeInt32(rebalanceTimeout).writeString(memberId).writeString(protocolType).writeArray(groupProtocols.map(encodeGroupProtocols));
    }
  });
  var encodeGroupProtocols = ({ name, metadata = Buffer.alloc(0) }) => {
    return new Encoder().writeString(name).writeBytes(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v1/response.js
var require_response46 = __commonJS((exports, module) => {
  var { parse, decode } = require_response45();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v2/request.js
var require_request47 = __commonJS((exports, module) => {
  var requestV1 = require_request46();
  module.exports = ({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    protocolType,
    groupProtocols
  }) => Object.assign(requestV1({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    protocolType,
    groupProtocols
  }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v2/response.js
var require_response47 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failIfVersionNotSupported } = require_error();
  var { parse: parseV0 } = require_response45();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      throttleTime,
      errorCode,
      generationId: decoder.readInt32(),
      groupProtocol: decoder.readString(),
      leaderId: decoder.readString(),
      memberId: decoder.readString(),
      members: decoder.readArray((decoder2) => ({
        memberId: decoder2.readString(),
        memberMetadata: decoder2.readBytes()
      }))
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v3/request.js
var require_request48 = __commonJS((exports, module) => {
  var requestV2 = require_request47();
  module.exports = ({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    protocolType,
    groupProtocols
  }) => Object.assign(requestV2({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    protocolType,
    groupProtocols
  }), { apiVersion: 3 });
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v3/response.js
var require_response48 = __commonJS((exports, module) => {
  var { parse, decode: decodeV2 } = require_response47();
  var decode = async (rawData) => {
    const decoded = await decodeV2(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v4/request.js
var require_request49 = __commonJS((exports, module) => {
  var requestV3 = require_request48();
  module.exports = ({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    protocolType,
    groupProtocols
  }) => Object.assign(requestV3({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    protocolType,
    groupProtocols
  }), { apiVersion: 4 });
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v4/response.js
var require_response49 = __commonJS((exports, module) => {
  var { decode } = require_response48();
  var { KafkaJSMemberIdRequired } = require_errors2();
  var { failure, createErrorFromCode, errorCodes } = require_error();
  var { code: MEMBER_ID_REQUIRED_ERROR_CODE } = errorCodes.find((e) => e.type === "MEMBER_ID_REQUIRED");
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      if (data.errorCode === MEMBER_ID_REQUIRED_ERROR_CODE) {
        throw new KafkaJSMemberIdRequired(createErrorFromCode(data.errorCode), {
          memberId: data.memberId
        });
      }
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v5/request.js
var require_request50 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { JoinGroup: apiKey } = require_apiKeys();
  module.exports = ({
    groupId,
    sessionTimeout,
    rebalanceTimeout,
    memberId,
    groupInstanceId = null,
    protocolType,
    groupProtocols
  }) => ({
    apiKey,
    apiVersion: 5,
    apiName: "JoinGroup",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(sessionTimeout).writeInt32(rebalanceTimeout).writeString(memberId).writeString(groupInstanceId).writeString(protocolType).writeArray(groupProtocols.map(encodeGroupProtocols));
    }
  });
  var encodeGroupProtocols = ({ name, metadata = Buffer.alloc(0) }) => {
    return new Encoder().writeString(name).writeBytes(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/v5/response.js
var require_response50 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { KafkaJSMemberIdRequired } = require_errors2();
  var {
    failure,
    createErrorFromCode,
    errorCodes,
    failIfVersionNotSupported
  } = require_error();
  var { code: MEMBER_ID_REQUIRED_ERROR_CODE } = errorCodes.find((e) => e.type === "MEMBER_ID_REQUIRED");
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      if (data.errorCode === MEMBER_ID_REQUIRED_ERROR_CODE) {
        throw new KafkaJSMemberIdRequired(createErrorFromCode(data.errorCode), {
          memberId: data.memberId
        });
      }
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      throttleTime: 0,
      clientSideThrottleTime: throttleTime,
      errorCode,
      generationId: decoder.readInt32(),
      groupProtocol: decoder.readString(),
      leaderId: decoder.readString(),
      memberId: decoder.readString(),
      members: decoder.readArray((decoder2) => ({
        memberId: decoder2.readString(),
        groupInstanceId: decoder2.readString(),
        memberMetadata: decoder2.readBytes()
      }))
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/joinGroup/index.js
var require_joinGroup = __commonJS((exports, module) => {
  var NETWORK_DELAY = 5000;
  var requestTimeout = ({ rebalanceTimeout, sessionTimeout }) => {
    const timeout = rebalanceTimeout || sessionTimeout;
    return Number.isSafeInteger(timeout + NETWORK_DELAY) ? timeout + NETWORK_DELAY : timeout;
  };
  var logResponseError = (memberId) => memberId != null && memberId !== "";
  var versions = {
    0: ({ groupId, sessionTimeout, memberId, protocolType, groupProtocols }) => {
      const request = require_request45();
      const response = require_response45();
      return {
        request: request({
          groupId,
          sessionTimeout,
          memberId,
          protocolType,
          groupProtocols
        }),
        response,
        requestTimeout: requestTimeout({ rebalanceTimeout: null, sessionTimeout })
      };
    },
    1: ({ groupId, sessionTimeout, rebalanceTimeout, memberId, protocolType, groupProtocols }) => {
      const request = require_request46();
      const response = require_response46();
      return {
        request: request({
          groupId,
          sessionTimeout,
          rebalanceTimeout,
          memberId,
          protocolType,
          groupProtocols
        }),
        response,
        requestTimeout: requestTimeout({ rebalanceTimeout, sessionTimeout })
      };
    },
    2: ({ groupId, sessionTimeout, rebalanceTimeout, memberId, protocolType, groupProtocols }) => {
      const request = require_request47();
      const response = require_response47();
      return {
        request: request({
          groupId,
          sessionTimeout,
          rebalanceTimeout,
          memberId,
          protocolType,
          groupProtocols
        }),
        response,
        requestTimeout: requestTimeout({ rebalanceTimeout, sessionTimeout })
      };
    },
    3: ({ groupId, sessionTimeout, rebalanceTimeout, memberId, protocolType, groupProtocols }) => {
      const request = require_request48();
      const response = require_response48();
      return {
        request: request({
          groupId,
          sessionTimeout,
          rebalanceTimeout,
          memberId,
          protocolType,
          groupProtocols
        }),
        response,
        requestTimeout: requestTimeout({ rebalanceTimeout, sessionTimeout })
      };
    },
    4: ({ groupId, sessionTimeout, rebalanceTimeout, memberId, protocolType, groupProtocols }) => {
      const request = require_request49();
      const response = require_response49();
      return {
        request: request({
          groupId,
          sessionTimeout,
          rebalanceTimeout,
          memberId,
          protocolType,
          groupProtocols
        }),
        response,
        requestTimeout: requestTimeout({ rebalanceTimeout, sessionTimeout }),
        logResponseError: logResponseError(memberId)
      };
    },
    5: ({
      groupId,
      sessionTimeout,
      rebalanceTimeout,
      memberId,
      groupInstanceId,
      protocolType,
      groupProtocols
    }) => {
      const request = require_request50();
      const response = require_response50();
      return {
        request: request({
          groupId,
          sessionTimeout,
          rebalanceTimeout,
          memberId,
          groupInstanceId,
          protocolType,
          groupProtocols
        }),
        response,
        requestTimeout: requestTimeout({ rebalanceTimeout, sessionTimeout }),
        logResponseError: logResponseError(memberId)
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v0/request.js
var require_request51 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Heartbeat: apiKey } = require_apiKeys();
  module.exports = ({ groupId, groupGenerationId, memberId }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "Heartbeat",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(groupGenerationId).writeString(memberId);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v0/response.js
var require_response51 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return { errorCode };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v1/request.js
var require_request52 = __commonJS((exports, module) => {
  var requestV0 = require_request51();
  module.exports = ({ groupId, groupGenerationId, memberId }) => Object.assign(requestV0({ groupId, groupGenerationId, memberId }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v1/response.js
var require_response52 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failIfVersionNotSupported } = require_error();
  var { parse: parseV0 } = require_response51();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return { throttleTime, errorCode };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v2/request.js
var require_request53 = __commonJS((exports, module) => {
  var requestV1 = require_request52();
  module.exports = ({ groupId, groupGenerationId, memberId }) => Object.assign(requestV1({ groupId, groupGenerationId, memberId }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v2/response.js
var require_response53 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response52();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v3/request.js
var require_request54 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { Heartbeat: apiKey } = require_apiKeys();
  module.exports = ({ groupId, groupGenerationId, memberId, groupInstanceId }) => ({
    apiKey,
    apiVersion: 3,
    apiName: "Heartbeat",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(groupGenerationId).writeString(memberId).writeString(groupInstanceId);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/v3/response.js
var require_response54 = __commonJS((exports, module) => {
  var { parse, decode } = require_response53();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/heartbeat/index.js
var require_heartbeat = __commonJS((exports, module) => {
  var versions = {
    0: ({ groupId, groupGenerationId, memberId }) => {
      const request = require_request51();
      const response = require_response51();
      return {
        request: request({ groupId, groupGenerationId, memberId }),
        response
      };
    },
    1: ({ groupId, groupGenerationId, memberId }) => {
      const request = require_request52();
      const response = require_response52();
      return {
        request: request({ groupId, groupGenerationId, memberId }),
        response
      };
    },
    2: ({ groupId, groupGenerationId, memberId }) => {
      const request = require_request53();
      const response = require_response53();
      return {
        request: request({ groupId, groupGenerationId, memberId }),
        response
      };
    },
    3: ({ groupId, groupGenerationId, memberId, groupInstanceId }) => {
      const request = require_request54();
      const response = require_response54();
      return {
        request: request({ groupId, groupGenerationId, memberId, groupInstanceId }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v0/request.js
var require_request55 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { LeaveGroup: apiKey } = require_apiKeys();
  module.exports = ({ groupId, memberId }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "LeaveGroup",
    encode: async () => {
      return new Encoder().writeString(groupId).writeString(memberId);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v0/response.js
var require_response55 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return { errorCode };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v1/request.js
var require_request56 = __commonJS((exports, module) => {
  var requestV0 = require_request55();
  module.exports = ({ groupId, memberId }) => Object.assign(requestV0({ groupId, memberId }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v1/response.js
var require_response56 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failIfVersionNotSupported } = require_error();
  var { parse: parseV0 } = require_response55();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return { throttleTime, errorCode };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v2/request.js
var require_request57 = __commonJS((exports, module) => {
  var requestV1 = require_request56();
  module.exports = ({ groupId, memberId }) => Object.assign(requestV1({ groupId, memberId }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v2/response.js
var require_response57 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response56();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v3/request.js
var require_request58 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { LeaveGroup: apiKey } = require_apiKeys();
  module.exports = ({ groupId, members }) => ({
    apiKey,
    apiVersion: 3,
    apiName: "LeaveGroup",
    encode: async () => {
      return new Encoder().writeString(groupId).writeArray(members.map((member) => encodeMember(member)));
    }
  });
  var encodeMember = ({ memberId, groupInstanceId = null }) => {
    return new Encoder().writeString(memberId).writeString(groupInstanceId);
  };
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/v3/response.js
var require_response58 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failIfVersionNotSupported, failure, createErrorFromCode } = require_error();
  var { parse: parseV2 } = require_response57();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    const members = decoder.readArray(decodeMembers);
    failIfVersionNotSupported(errorCode);
    return { throttleTime: 0, clientSideThrottleTime: throttleTime, errorCode, members };
  };
  var decodeMembers = (decoder) => ({
    memberId: decoder.readString(),
    groupInstanceId: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  var parse = async (data) => {
    const parsed = parseV2(data);
    const memberWithError = data.members.find((member) => failure(member.errorCode));
    if (memberWithError) {
      throw createErrorFromCode(memberWithError.errorCode);
    }
    return parsed;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/leaveGroup/index.js
var require_leaveGroup = __commonJS((exports, module) => {
  var versions = {
    0: ({ groupId, memberId }) => {
      const request = require_request55();
      const response = require_response55();
      return {
        request: request({ groupId, memberId }),
        response
      };
    },
    1: ({ groupId, memberId }) => {
      const request = require_request56();
      const response = require_response56();
      return {
        request: request({ groupId, memberId }),
        response
      };
    },
    2: ({ groupId, memberId }) => {
      const request = require_request57();
      const response = require_response57();
      return {
        request: request({ groupId, memberId }),
        response
      };
    },
    3: ({ groupId, memberId, groupInstanceId }) => {
      const request = require_request58();
      const response = require_response58();
      return {
        request: request({ groupId, members: [{ memberId, groupInstanceId }] }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v0/request.js
var require_request59 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { SyncGroup: apiKey } = require_apiKeys();
  module.exports = ({ groupId, generationId, memberId, groupAssignment }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "SyncGroup",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(generationId).writeString(memberId).writeArray(groupAssignment.map(encodeGroupAssignment));
    }
  });
  var encodeGroupAssignment = ({ memberId, memberAssignment }) => {
    return new Encoder().writeString(memberId).writeBytes(memberAssignment);
  };
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v0/response.js
var require_response59 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      errorCode,
      memberAssignment: decoder.readBytes()
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v1/request.js
var require_request60 = __commonJS((exports, module) => {
  var requestV0 = require_request59();
  module.exports = ({ groupId, generationId, memberId, groupAssignment }) => Object.assign(requestV0({ groupId, generationId, memberId, groupAssignment }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v1/response.js
var require_response60 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failIfVersionNotSupported } = require_error();
  var { parse: parseV0 } = require_response59();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      throttleTime,
      errorCode,
      memberAssignment: decoder.readBytes()
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v2/request.js
var require_request61 = __commonJS((exports, module) => {
  var requestV1 = require_request60();
  module.exports = ({ groupId, generationId, memberId, groupAssignment }) => Object.assign(requestV1({ groupId, generationId, memberId, groupAssignment }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v2/response.js
var require_response61 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response60();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v3/request.js
var require_request62 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { SyncGroup: apiKey } = require_apiKeys();
  module.exports = ({
    groupId,
    generationId,
    memberId,
    groupInstanceId = null,
    groupAssignment
  }) => ({
    apiKey,
    apiVersion: 3,
    apiName: "SyncGroup",
    encode: async () => {
      return new Encoder().writeString(groupId).writeInt32(generationId).writeString(memberId).writeString(groupInstanceId).writeArray(groupAssignment.map(encodeGroupAssignment));
    }
  });
  var encodeGroupAssignment = ({ memberId, memberAssignment }) => {
    return new Encoder().writeString(memberId).writeBytes(memberAssignment);
  };
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/v3/response.js
var require_response62 = __commonJS((exports, module) => {
  var { decode, parse } = require_response61();
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/syncGroup/index.js
var require_syncGroup = __commonJS((exports, module) => {
  var versions = {
    0: ({ groupId, generationId, memberId, groupAssignment }) => {
      const request = require_request59();
      const response = require_response59();
      return {
        request: request({ groupId, generationId, memberId, groupAssignment }),
        response
      };
    },
    1: ({ groupId, generationId, memberId, groupAssignment }) => {
      const request = require_request60();
      const response = require_response60();
      return {
        request: request({ groupId, generationId, memberId, groupAssignment }),
        response
      };
    },
    2: ({ groupId, generationId, memberId, groupAssignment }) => {
      const request = require_request61();
      const response = require_response61();
      return {
        request: request({ groupId, generationId, memberId, groupAssignment }),
        response
      };
    },
    3: ({ groupId, generationId, memberId, groupInstanceId, groupAssignment }) => {
      const request = require_request62();
      const response = require_response62();
      return {
        request: request({ groupId, generationId, memberId, groupInstanceId, groupAssignment }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/describeGroups/v0/request.js
var require_request63 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DescribeGroups: apiKey } = require_apiKeys();
  module.exports = ({ groupIds }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "DescribeGroups",
    encode: async () => {
      return new Encoder().writeArray(groupIds);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/describeGroups/v0/response.js
var require_response63 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decoderMember = (decoder) => ({
    memberId: decoder.readString(),
    clientId: decoder.readString(),
    clientHost: decoder.readString(),
    memberMetadata: decoder.readBytes(),
    memberAssignment: decoder.readBytes()
  });
  var decodeGroup = (decoder) => ({
    errorCode: decoder.readInt16(),
    groupId: decoder.readString(),
    state: decoder.readString(),
    protocolType: decoder.readString(),
    protocol: decoder.readString(),
    members: decoder.readArray(decoderMember)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const groups = decoder.readArray(decodeGroup);
    return {
      groups
    };
  };
  var parse = async (data) => {
    const groupsWithError = data.groups.filter(({ errorCode }) => failure(errorCode));
    if (groupsWithError.length > 0) {
      throw createErrorFromCode(groupsWithError[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/describeGroups/v1/request.js
var require_request64 = __commonJS((exports, module) => {
  var requestV0 = require_request63();
  module.exports = ({ groupIds }) => Object.assign(requestV0({ groupIds }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/describeGroups/v1/response.js
var require_response64 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response63();
  var decoderMember = (decoder) => ({
    memberId: decoder.readString(),
    clientId: decoder.readString(),
    clientHost: decoder.readString(),
    memberMetadata: decoder.readBytes(),
    memberAssignment: decoder.readBytes()
  });
  var decodeGroup = (decoder) => ({
    errorCode: decoder.readInt16(),
    groupId: decoder.readString(),
    state: decoder.readString(),
    protocolType: decoder.readString(),
    protocol: decoder.readString(),
    members: decoder.readArray(decoderMember)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const groups = decoder.readArray(decodeGroup);
    return {
      throttleTime,
      groups
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/describeGroups/v2/request.js
var require_request65 = __commonJS((exports, module) => {
  var requestV1 = require_request64();
  module.exports = ({ groupIds }) => Object.assign(requestV1({ groupIds }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/describeGroups/v2/response.js
var require_response65 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response64();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/describeGroups/index.js
var require_describeGroups = __commonJS((exports, module) => {
  var versions = {
    0: ({ groupIds }) => {
      const request = require_request63();
      const response = require_response63();
      return { request: request({ groupIds }), response };
    },
    1: ({ groupIds }) => {
      const request = require_request64();
      const response = require_response64();
      return { request: request({ groupIds }), response };
    },
    2: ({ groupIds }) => {
      const request = require_request65();
      const response = require_response65();
      return { request: request({ groupIds }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/listGroups/v0/request.js
var require_request66 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { ListGroups: apiKey } = require_apiKeys();
  module.exports = () => ({
    apiKey,
    apiVersion: 0,
    apiName: "ListGroups",
    encode: async () => {
      return new Encoder;
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/listGroups/v0/response.js
var require_response66 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeGroup = (decoder) => ({
    groupId: decoder.readString(),
    protocolType: decoder.readString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    const groups = decoder.readArray(decodeGroup);
    return {
      errorCode,
      groups
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decodeGroup,
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listGroups/v1/request.js
var require_request67 = __commonJS((exports, module) => {
  var requestV0 = require_request66();
  module.exports = () => Object.assign(requestV0(), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/listGroups/v1/response.js
var require_response67 = __commonJS((exports, module) => {
  var responseV0 = require_response66();
  var Decoder = require_decoder();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    const groups = decoder.readArray(responseV0.decodeGroup);
    return {
      throttleTime,
      errorCode,
      groups
    };
  };
  module.exports = {
    decode,
    parse: responseV0.parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listGroups/v2/request.js
var require_request68 = __commonJS((exports, module) => {
  var requestV1 = require_request67();
  module.exports = () => Object.assign(requestV1(), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/listGroups/v2/response.js
var require_response68 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response67();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listGroups/index.js
var require_listGroups = __commonJS((exports, module) => {
  var versions = {
    0: () => {
      const request = require_request66();
      const response = require_response66();
      return { request: request(), response };
    },
    1: () => {
      const request = require_request67();
      const response = require_response67();
      return { request: request(), response };
    },
    2: () => {
      const request = require_request68();
      const response = require_response68();
      return { request: request(), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/saslHandshake/v0/request.js
var require_request69 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { SaslHandshake: apiKey } = require_apiKeys();
  module.exports = ({ mechanism }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "SaslHandshake",
    encode: async () => new Encoder().writeString(mechanism)
  });
});

// node_modules/kafkajs/src/protocol/requests/saslHandshake/v0/response.js
var require_response69 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      errorCode,
      enabledMechanisms: decoder.readArray((decoder2) => decoder2.readString())
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/saslHandshake/v1/request.js
var require_request70 = __commonJS((exports, module) => {
  var requestV0 = require_request69();
  module.exports = ({ mechanism }) => ({ ...requestV0({ mechanism }), apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/saslHandshake/v1/response.js
var require_response70 = __commonJS((exports, module) => {
  var { decode: decodeV0, parse: parseV0 } = require_response69();
  module.exports = {
    decode: decodeV0,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/saslHandshake/index.js
var require_saslHandshake = __commonJS((exports, module) => {
  var versions = {
    0: ({ mechanism }) => {
      const request = require_request69();
      const response = require_response69();
      return { request: request({ mechanism }), response };
    },
    1: ({ mechanism }) => {
      const request = require_request70();
      const response = require_response70();
      return { request: request({ mechanism }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/apiVersions/v0/request.js
var require_request71 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { ApiVersions: apiKey } = require_apiKeys();
  module.exports = () => ({
    apiKey,
    apiVersion: 0,
    apiName: "ApiVersions",
    encode: async () => new Encoder
  });
});

// node_modules/kafkajs/src/protocol/requests/apiVersions/v0/response.js
var require_response71 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var apiVersion = (decoder) => ({
    apiKey: decoder.readInt16(),
    minVersion: decoder.readInt16(),
    maxVersion: decoder.readInt16()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      errorCode,
      apiVersions: decoder.readArray(apiVersion)
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/apiVersions/v1/request.js
var require_request72 = __commonJS((exports, module) => {
  var requestV0 = require_request71();
  module.exports = () => ({ ...requestV0(), apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/apiVersions/v1/response.js
var require_response72 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failIfVersionNotSupported } = require_error();
  var { parse: parseV0 } = require_response71();
  var apiVersion = (decoder) => ({
    apiKey: decoder.readInt16(),
    minVersion: decoder.readInt16(),
    maxVersion: decoder.readInt16()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    const apiVersions = decoder.readArray(apiVersion);
    const throttleTime = decoder.canReadInt32() ? decoder.readInt32() : 0;
    return {
      errorCode,
      apiVersions,
      throttleTime
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/apiVersions/v2/request.js
var require_request73 = __commonJS((exports, module) => {
  var requestV0 = require_request71();
  module.exports = () => ({ ...requestV0(), apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/apiVersions/v2/response.js
var require_response73 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response72();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/apiVersions/index.js
var require_apiVersions = __commonJS((exports, module) => {
  var logResponseError = false;
  var versions = {
    0: () => {
      const request = require_request71();
      const response = require_response71();
      return { request: request(), response, logResponseError: true };
    },
    1: () => {
      const request = require_request72();
      const response = require_response72();
      return { request: request(), response, logResponseError };
    },
    2: () => {
      const request = require_request73();
      const response = require_response73();
      return { request: request(), response, logResponseError };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v0/request.js
var require_request74 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { CreateTopics: apiKey } = require_apiKeys();
  module.exports = ({ topics, timeout = 5000 }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "CreateTopics",
    encode: async () => {
      return new Encoder().writeArray(topics.map(encodeTopics)).writeInt32(timeout);
    }
  });
  var encodeTopics = ({
    topic,
    numPartitions = -1,
    replicationFactor = -1,
    replicaAssignment = [],
    configEntries = []
  }) => {
    return new Encoder().writeString(topic).writeInt32(numPartitions).writeInt16(replicationFactor).writeArray(replicaAssignment.map(encodeReplicaAssignment)).writeArray(configEntries.map(encodeConfigEntries));
  };
  var encodeReplicaAssignment = ({ partition, replicas }) => {
    return new Encoder().writeInt32(partition).writeArray(replicas);
  };
  var encodeConfigEntries = ({ name, value }) => {
    return new Encoder().writeString(name).writeString(value);
  };
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v0/response.js
var require_response74 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var { KafkaJSAggregateError, KafkaJSCreateTopicError } = require_errors2();
  var topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);
  var topicErrors = (decoder) => ({
    topic: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      topicErrors: decoder.readArray(topicErrors).sort(topicNameComparator)
    };
  };
  var parse = async (data) => {
    const topicsWithError = data.topicErrors.filter(({ errorCode }) => failure(errorCode));
    if (topicsWithError.length > 0) {
      throw new KafkaJSAggregateError("Topic creation errors", topicsWithError.map((error) => new KafkaJSCreateTopicError(createErrorFromCode(error.errorCode), error.topic)));
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v1/request.js
var require_request75 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { CreateTopics: apiKey } = require_apiKeys();
  module.exports = ({ topics, validateOnly = false, timeout = 5000 }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "CreateTopics",
    encode: async () => {
      return new Encoder().writeArray(topics.map(encodeTopics)).writeInt32(timeout).writeBoolean(validateOnly);
    }
  });
  var encodeTopics = ({
    topic,
    numPartitions = -1,
    replicationFactor = -1,
    replicaAssignment = [],
    configEntries = []
  }) => {
    return new Encoder().writeString(topic).writeInt32(numPartitions).writeInt16(replicationFactor).writeArray(replicaAssignment.map(encodeReplicaAssignment)).writeArray(configEntries.map(encodeConfigEntries));
  };
  var encodeReplicaAssignment = ({ partition, replicas }) => {
    return new Encoder().writeInt32(partition).writeArray(replicas);
  };
  var encodeConfigEntries = ({ name, value }) => {
    return new Encoder().writeString(name).writeString(value);
  };
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v1/response.js
var require_response75 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response74();
  var topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);
  var topicErrors = (decoder) => ({
    topic: decoder.readString(),
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      topicErrors: decoder.readArray(topicErrors).sort(topicNameComparator)
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v2/request.js
var require_request76 = __commonJS((exports, module) => {
  var requestV1 = require_request75();
  module.exports = ({ topics, validateOnly, timeout }) => Object.assign(requestV1({ topics, validateOnly, timeout }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v2/response.js
var require_response76 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV1 } = require_response75();
  var topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);
  var topicErrors = (decoder) => ({
    topic: decoder.readString(),
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      throttleTime: decoder.readInt32(),
      topicErrors: decoder.readArray(topicErrors).sort(topicNameComparator)
    };
  };
  module.exports = {
    decode,
    parse: parseV1
  };
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v3/request.js
var require_request77 = __commonJS((exports, module) => {
  var requestV2 = require_request76();
  module.exports = ({ topics, validateOnly, timeout }) => Object.assign(requestV2({ topics, validateOnly, timeout }), { apiVersion: 3 });
});

// node_modules/kafkajs/src/protocol/requests/createTopics/v3/response.js
var require_response77 = __commonJS((exports, module) => {
  var { parse, decode: decodeV2 } = require_response76();
  var decode = async (rawData) => {
    const decoded = await decodeV2(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/createTopics/index.js
var require_createTopics = __commonJS((exports, module) => {
  var versions = {
    0: ({ topics, timeout }) => {
      const request = require_request74();
      const response = require_response74();
      return { request: request({ topics, timeout }), response };
    },
    1: ({ topics, validateOnly, timeout }) => {
      const request = require_request75();
      const response = require_response75();
      return { request: request({ topics, validateOnly, timeout }), response };
    },
    2: ({ topics, validateOnly, timeout }) => {
      const request = require_request76();
      const response = require_response76();
      return { request: request({ topics, validateOnly, timeout }), response };
    },
    3: ({ topics, validateOnly, timeout }) => {
      const request = require_request77();
      const response = require_response77();
      return { request: request({ topics, validateOnly, timeout }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteTopics/v0/request.js
var require_request78 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DeleteTopics: apiKey } = require_apiKeys();
  module.exports = ({ topics, timeout = 5000 }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "DeleteTopics",
    encode: async () => {
      return new Encoder().writeArray(topics).writeInt32(timeout);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/deleteTopics/v0/response.js
var require_response78 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);
  var topicErrors = (decoder) => ({
    topic: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      topicErrors: decoder.readArray(topicErrors).sort(topicNameComparator)
    };
  };
  var parse = async (data) => {
    const topicsWithError = data.topicErrors.filter(({ errorCode }) => failure(errorCode));
    if (topicsWithError.length > 0) {
      throw createErrorFromCode(topicsWithError[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteTopics/v1/request.js
var require_request79 = __commonJS((exports, module) => {
  var requestV0 = require_request78();
  module.exports = ({ topics, timeout }) => Object.assign(requestV0({ topics, timeout }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/deleteTopics/v1/response.js
var require_response79 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response78();
  var topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);
  var topicErrors = (decoder) => ({
    topic: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    return {
      throttleTime: 0,
      clientSideThrottleTime: throttleTime,
      topicErrors: decoder.readArray(topicErrors).sort(topicNameComparator)
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteTopics/index.js
var require_deleteTopics = __commonJS((exports, module) => {
  var versions = {
    0: ({ topics, timeout }) => {
      const request = require_request78();
      const response = require_response78();
      return { request: request({ topics, timeout }), response };
    },
    1: ({ topics, timeout }) => {
      const request = require_request79();
      const response = require_response79();
      return { request: request({ topics, timeout }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteRecords/v0/request.js
var require_request80 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DeleteRecords: apiKey } = require_apiKeys();
  module.exports = ({ topics, timeout = 5000 }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "DeleteRecords",
    encode: async () => {
      return new Encoder().writeArray(topics.map(({ topic, partitions }) => {
        return new Encoder().writeString(topic).writeArray(partitions.map(({ partition, offset }) => {
          return new Encoder().writeInt32(partition).writeInt64(offset);
        }));
      })).writeInt32(timeout);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/deleteRecords/v0/response.js
var require_response80 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { KafkaJSDeleteTopicRecordsError } = require_errors2();
  var { failure, createErrorFromCode } = require_error();
  var topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    return {
      throttleTime: decoder.readInt32(),
      topics: decoder.readArray((decoder2) => ({
        topic: decoder2.readString(),
        partitions: decoder2.readArray((decoder3) => ({
          partition: decoder3.readInt32(),
          lowWatermark: decoder3.readInt64(),
          errorCode: decoder3.readInt16()
        }))
      })).sort(topicNameComparator)
    };
  };
  var parse = (requestTopics) => async (data) => {
    const topicsWithErrors = data.topics.map(({ partitions }) => ({
      partitionsWithErrors: partitions.filter(({ errorCode }) => failure(errorCode))
    })).filter(({ partitionsWithErrors }) => partitionsWithErrors.length);
    if (topicsWithErrors.length > 0) {
      const [{ topic }] = data.topics;
      const [{ partitions: requestPartitions }] = requestTopics;
      const [{ partitionsWithErrors }] = topicsWithErrors;
      throw new KafkaJSDeleteTopicRecordsError({
        topic,
        partitions: partitionsWithErrors.map(({ partition, errorCode }) => ({
          partition,
          error: createErrorFromCode(errorCode),
          offset: requestPartitions.find((p) => p.partition === partition).offset
        }))
      });
    }
    return data;
  };
  module.exports = ({ topics }) => ({
    decode,
    parse: parse(topics)
  });
});

// node_modules/kafkajs/src/protocol/requests/deleteRecords/v1/request.js
var require_request81 = __commonJS((exports, module) => {
  var requestV0 = require_request80();
  module.exports = ({ topics, timeout }) => Object.assign(requestV0({ topics, timeout }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/deleteRecords/v1/response.js
var require_response81 = __commonJS((exports, module) => {
  var responseV0 = require_response80();
  module.exports = ({ topics }) => {
    const { parse, decode: decodeV0 } = responseV0({ topics });
    const decode = async (rawData) => {
      const decoded = await decodeV0(rawData);
      return {
        ...decoded,
        throttleTime: 0,
        clientSideThrottleTime: decoded.throttleTime
      };
    };
    return {
      decode,
      parse
    };
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteRecords/index.js
var require_deleteRecords = __commonJS((exports, module) => {
  var versions = {
    0: ({ topics, timeout }) => {
      const request = require_request80();
      const response = require_response80();
      return { request: request({ topics, timeout }), response: response({ topics }) };
    },
    1: ({ topics, timeout }) => {
      const request = require_request81();
      const response = require_response81();
      return { request: request({ topics, timeout }), response: response({ topics }) };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/initProducerId/v0/request.js
var require_request82 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { InitProducerId: apiKey } = require_apiKeys();
  module.exports = ({ transactionalId, transactionTimeout }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "InitProducerId",
    encode: async () => {
      return new Encoder().writeString(transactionalId).writeInt32(transactionTimeout);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/initProducerId/v0/response.js
var require_response82 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      throttleTime,
      errorCode,
      producerId: decoder.readInt64().toString(),
      producerEpoch: decoder.readInt16()
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/initProducerId/v1/request.js
var require_request83 = __commonJS((exports, module) => {
  var requestV0 = require_request82();
  module.exports = ({ transactionalId, transactionTimeout }) => Object.assign(requestV0({ transactionalId, transactionTimeout }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/initProducerId/v1/response.js
var require_response83 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response82();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/initProducerId/index.js
var require_initProducerId = __commonJS((exports, module) => {
  var versions = {
    0: ({ transactionalId, transactionTimeout = 5000 }) => {
      const request = require_request82();
      const response = require_response82();
      return { request: request({ transactionalId, transactionTimeout }), response };
    },
    1: ({ transactionalId, transactionTimeout = 5000 }) => {
      const request = require_request83();
      const response = require_response83();
      return { request: request({ transactionalId, transactionTimeout }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/addPartitionsToTxn/v0/request.js
var require_request84 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { AddPartitionsToTxn: apiKey } = require_apiKeys();
  module.exports = ({ transactionalId, producerId, producerEpoch, topics }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "AddPartitionsToTxn",
    encode: async () => {
      return new Encoder().writeString(transactionalId).writeInt64(producerId).writeInt16(producerEpoch).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = (partition) => {
    return new Encoder().writeInt32(partition);
  };
});

// node_modules/kafkajs/src/protocol/requests/addPartitionsToTxn/v0/response.js
var require_response84 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errors = await decoder.readArrayAsync(decodeError);
    return {
      throttleTime,
      errors
    };
  };
  var decodeError = async (decoder) => ({
    topic: decoder.readString(),
    partitionErrors: await decoder.readArrayAsync(decodePartitionError)
  });
  var decodePartitionError = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16()
  });
  var parse = async (data) => {
    const topicsWithErrors = data.errors.map(({ partitionErrors }) => ({
      partitionsWithErrors: partitionErrors.filter(({ errorCode }) => failure(errorCode))
    })).filter(({ partitionsWithErrors }) => partitionsWithErrors.length);
    if (topicsWithErrors.length > 0) {
      throw createErrorFromCode(topicsWithErrors[0].partitionsWithErrors[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/addPartitionsToTxn/v1/request.js
var require_request85 = __commonJS((exports, module) => {
  var requestV0 = require_request84();
  module.exports = ({ transactionalId, producerId, producerEpoch, topics }) => Object.assign(requestV0({
    transactionalId,
    producerId,
    producerEpoch,
    topics
  }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/addPartitionsToTxn/v1/response.js
var require_response85 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response84();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/addPartitionsToTxn/index.js
var require_addPartitionsToTxn = __commonJS((exports, module) => {
  var versions = {
    0: ({ transactionalId, producerId, producerEpoch, topics }) => {
      const request = require_request84();
      const response = require_response84();
      return { request: request({ transactionalId, producerId, producerEpoch, topics }), response };
    },
    1: ({ transactionalId, producerId, producerEpoch, topics }) => {
      const request = require_request85();
      const response = require_response85();
      return { request: request({ transactionalId, producerId, producerEpoch, topics }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/addOffsetsToTxn/v0/request.js
var require_request86 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { AddOffsetsToTxn: apiKey } = require_apiKeys();
  module.exports = ({ transactionalId, producerId, producerEpoch, groupId }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "AddOffsetsToTxn",
    encode: async () => {
      return new Encoder().writeString(transactionalId).writeInt64(producerId).writeInt16(producerEpoch).writeString(groupId);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/addOffsetsToTxn/v0/response.js
var require_response86 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      throttleTime,
      errorCode
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/addOffsetsToTxn/v1/request.js
var require_request87 = __commonJS((exports, module) => {
  var requestV0 = require_request86();
  module.exports = ({ transactionalId, producerId, producerEpoch, groupId }) => Object.assign(requestV0({
    transactionalId,
    producerId,
    producerEpoch,
    groupId
  }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/addOffsetsToTxn/v1/response.js
var require_response87 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response86();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/addOffsetsToTxn/index.js
var require_addOffsetsToTxn = __commonJS((exports, module) => {
  var versions = {
    0: ({ transactionalId, producerId, producerEpoch, groupId }) => {
      const request = require_request86();
      const response = require_response86();
      return { request: request({ transactionalId, producerId, producerEpoch, groupId }), response };
    },
    1: ({ transactionalId, producerId, producerEpoch, groupId }) => {
      const request = require_request87();
      const response = require_response87();
      return { request: request({ transactionalId, producerId, producerEpoch, groupId }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/endTxn/v0/request.js
var require_request88 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { EndTxn: apiKey } = require_apiKeys();
  module.exports = ({ transactionalId, producerId, producerEpoch, transactionResult }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "EndTxn",
    encode: async () => {
      return new Encoder().writeString(transactionalId).writeInt64(producerId).writeInt16(producerEpoch).writeBoolean(transactionResult);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/endTxn/v0/response.js
var require_response88 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode, failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    return {
      throttleTime,
      errorCode
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/endTxn/v1/request.js
var require_request89 = __commonJS((exports, module) => {
  var requestV0 = require_request88();
  module.exports = ({ transactionalId, producerId, producerEpoch, transactionResult }) => Object.assign(requestV0({ transactionalId, producerId, producerEpoch, transactionResult }), {
    apiVersion: 1
  });
});

// node_modules/kafkajs/src/protocol/requests/endTxn/v1/response.js
var require_response89 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response88();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/endTxn/index.js
var require_endTxn = __commonJS((exports, module) => {
  var versions = {
    0: ({ transactionalId, producerId, producerEpoch, transactionResult }) => {
      const request = require_request88();
      const response = require_response88();
      return {
        request: request({ transactionalId, producerId, producerEpoch, transactionResult }),
        response
      };
    },
    1: ({ transactionalId, producerId, producerEpoch, transactionResult }) => {
      const request = require_request89();
      const response = require_response89();
      return {
        request: request({ transactionalId, producerId, producerEpoch, transactionResult }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/txnOffsetCommit/v0/request.js
var require_request90 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { TxnOffsetCommit: apiKey } = require_apiKeys();
  module.exports = ({ transactionalId, groupId, producerId, producerEpoch, topics }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "TxnOffsetCommit",
    encode: async () => {
      return new Encoder().writeString(transactionalId).writeString(groupId).writeInt64(producerId).writeInt16(producerEpoch).writeArray(topics.map(encodeTopic));
    }
  });
  var encodeTopic = ({ topic, partitions }) => {
    return new Encoder().writeString(topic).writeArray(partitions.map(encodePartition));
  };
  var encodePartition = ({ partition, offset, metadata }) => {
    return new Encoder().writeInt32(partition).writeInt64(offset).writeString(metadata);
  };
});

// node_modules/kafkajs/src/protocol/requests/txnOffsetCommit/v0/response.js
var require_response90 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const topics = await decoder.readArrayAsync(decodeTopic);
    return {
      throttleTime,
      topics
    };
  };
  var decodeTopic = async (decoder) => ({
    topic: decoder.readString(),
    partitions: await decoder.readArrayAsync(decodePartition)
  });
  var decodePartition = (decoder) => ({
    partition: decoder.readInt32(),
    errorCode: decoder.readInt16()
  });
  var parse = async (data) => {
    const topicsWithErrors = data.topics.map(({ partitions }) => ({
      partitionsWithErrors: partitions.filter(({ errorCode }) => failure(errorCode))
    })).filter(({ partitionsWithErrors }) => partitionsWithErrors.length);
    if (topicsWithErrors.length > 0) {
      throw createErrorFromCode(topicsWithErrors[0].partitionsWithErrors[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/txnOffsetCommit/v1/request.js
var require_request91 = __commonJS((exports, module) => {
  var requestV0 = require_request90();
  module.exports = ({ transactionalId, groupId, producerId, producerEpoch, topics }) => Object.assign(requestV0({ transactionalId, groupId, producerId, producerEpoch, topics }), {
    apiVersion: 1
  });
});

// node_modules/kafkajs/src/protocol/requests/txnOffsetCommit/v1/response.js
var require_response91 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response90();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/txnOffsetCommit/index.js
var require_txnOffsetCommit = __commonJS((exports, module) => {
  var versions = {
    0: ({ transactionalId, groupId, producerId, producerEpoch, topics }) => {
      const request = require_request90();
      const response = require_response90();
      return {
        request: request({ transactionalId, groupId, producerId, producerEpoch, topics }),
        response
      };
    },
    1: ({ transactionalId, groupId, producerId, producerEpoch, topics }) => {
      const request = require_request91();
      const response = require_response91();
      return {
        request: request({ transactionalId, groupId, producerId, producerEpoch, topics }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/describeAcls/v0/request.js
var require_request92 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DescribeAcls: apiKey } = require_apiKeys();
  module.exports = ({ resourceType, resourceName, principal, host, operation, permissionType }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "DescribeAcls",
    encode: async () => {
      return new Encoder().writeInt8(resourceType).writeString(resourceName).writeString(principal).writeString(host).writeInt8(operation).writeInt8(permissionType);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/describeAcls/v0/response.js
var require_response92 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeAcls = (decoder) => ({
    principal: decoder.readString(),
    host: decoder.readString(),
    operation: decoder.readInt8(),
    permissionType: decoder.readInt8()
  });
  var decodeResources = (decoder) => ({
    resourceType: decoder.readInt8(),
    resourceName: decoder.readString(),
    acls: decoder.readArray(decodeAcls)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    const errorMessage = decoder.readString();
    const resources = decoder.readArray(decodeResources);
    return {
      throttleTime,
      errorCode,
      errorMessage,
      resources
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/describeAcls/v1/request.js
var require_request93 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DescribeAcls: apiKey } = require_apiKeys();
  module.exports = ({
    resourceType,
    resourceName,
    resourcePatternType,
    principal,
    host,
    operation,
    permissionType
  }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "DescribeAcls",
    encode: async () => {
      return new Encoder().writeInt8(resourceType).writeString(resourceName).writeInt8(resourcePatternType).writeString(principal).writeString(host).writeInt8(operation).writeInt8(permissionType);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/describeAcls/v1/response.js
var require_response93 = __commonJS((exports, module) => {
  var { parse } = require_response92();
  var Decoder = require_decoder();
  var decodeAcls = (decoder) => ({
    principal: decoder.readString(),
    host: decoder.readString(),
    operation: decoder.readInt8(),
    permissionType: decoder.readInt8()
  });
  var decodeResources = (decoder) => ({
    resourceType: decoder.readInt8(),
    resourceName: decoder.readString(),
    resourcePatternType: decoder.readInt8(),
    acls: decoder.readArray(decodeAcls)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    const errorMessage = decoder.readString();
    const resources = decoder.readArray(decodeResources);
    return {
      throttleTime: 0,
      clientSideThrottleTime: throttleTime,
      errorCode,
      errorMessage,
      resources
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/describeAcls/index.js
var require_describeAcls = __commonJS((exports, module) => {
  var versions = {
    0: ({ resourceType, resourceName, principal, host, operation, permissionType }) => {
      const request = require_request92();
      const response = require_response92();
      return {
        request: request({ resourceType, resourceName, principal, host, operation, permissionType }),
        response
      };
    },
    1: ({
      resourceType,
      resourceName,
      resourcePatternType,
      principal,
      host,
      operation,
      permissionType
    }) => {
      const request = require_request93();
      const response = require_response93();
      return {
        request: request({
          resourceType,
          resourceName,
          resourcePatternType,
          principal,
          host,
          operation,
          permissionType
        }),
        response
      };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/createAcls/v0/request.js
var require_request94 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { CreateAcls: apiKey } = require_apiKeys();
  var encodeCreations = ({
    resourceType,
    resourceName,
    principal,
    host,
    operation,
    permissionType
  }) => {
    return new Encoder().writeInt8(resourceType).writeString(resourceName).writeString(principal).writeString(host).writeInt8(operation).writeInt8(permissionType);
  };
  module.exports = ({ creations }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "CreateAcls",
    encode: async () => {
      return new Encoder().writeArray(creations.map(encodeCreations));
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/createAcls/v0/response.js
var require_response94 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeCreationResponse = (decoder) => ({
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const creationResponses = decoder.readArray(decodeCreationResponse);
    return {
      throttleTime,
      creationResponses
    };
  };
  var parse = async (data) => {
    const creationResponsesWithError = data.creationResponses.filter(({ errorCode }) => failure(errorCode));
    if (creationResponsesWithError.length > 0) {
      throw createErrorFromCode(creationResponsesWithError[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/createAcls/v1/request.js
var require_request95 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { CreateAcls: apiKey } = require_apiKeys();
  var encodeCreations = ({
    resourceType,
    resourceName,
    resourcePatternType,
    principal,
    host,
    operation,
    permissionType
  }) => {
    return new Encoder().writeInt8(resourceType).writeString(resourceName).writeInt8(resourcePatternType).writeString(principal).writeString(host).writeInt8(operation).writeInt8(permissionType);
  };
  module.exports = ({ creations }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "CreateAcls",
    encode: async () => {
      return new Encoder().writeArray(creations.map(encodeCreations));
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/createAcls/v1/response.js
var require_response95 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response94();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/createAcls/index.js
var require_createAcls = __commonJS((exports, module) => {
  var versions = {
    0: ({ creations }) => {
      const request = require_request94();
      const response = require_response94();
      return { request: request({ creations }), response };
    },
    1: ({ creations }) => {
      const request = require_request95();
      const response = require_response95();
      return { request: request({ creations }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteAcls/v0/request.js
var require_request96 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DeleteAcls: apiKey } = require_apiKeys();
  var encodeFilters = ({
    resourceType,
    resourceName,
    principal,
    host,
    operation,
    permissionType
  }) => {
    return new Encoder().writeInt8(resourceType).writeString(resourceName).writeString(principal).writeString(host).writeInt8(operation).writeInt8(permissionType);
  };
  module.exports = ({ filters }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "DeleteAcls",
    encode: async () => {
      return new Encoder().writeArray(filters.map(encodeFilters));
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/deleteAcls/v0/response.js
var require_response96 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeMatchingAcls = (decoder) => ({
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString(),
    resourceType: decoder.readInt8(),
    resourceName: decoder.readString(),
    principal: decoder.readString(),
    host: decoder.readString(),
    operation: decoder.readInt8(),
    permissionType: decoder.readInt8()
  });
  var decodeFilterResponse = (decoder) => ({
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString(),
    matchingAcls: decoder.readArray(decodeMatchingAcls)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const filterResponses = decoder.readArray(decodeFilterResponse);
    return {
      throttleTime,
      filterResponses
    };
  };
  var parse = async (data) => {
    const filterResponsesWithError = data.filterResponses.filter(({ errorCode }) => failure(errorCode));
    if (filterResponsesWithError.length > 0) {
      throw createErrorFromCode(filterResponsesWithError[0].errorCode);
    }
    for (const filterResponse of data.filterResponses) {
      const matchingAcls = filterResponse.matchingAcls;
      const matchingAclsWithError = matchingAcls.filter(({ errorCode }) => failure(errorCode));
      if (matchingAclsWithError.length > 0) {
        throw createErrorFromCode(matchingAclsWithError[0].errorCode);
      }
    }
    return data;
  };
  module.exports = {
    decodeMatchingAcls,
    decodeFilterResponse,
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteAcls/v1/request.js
var require_request97 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DeleteAcls: apiKey } = require_apiKeys();
  var encodeFilters = ({
    resourceType,
    resourceName,
    resourcePatternType,
    principal,
    host,
    operation,
    permissionType
  }) => {
    return new Encoder().writeInt8(resourceType).writeString(resourceName).writeInt8(resourcePatternType).writeString(principal).writeString(host).writeInt8(operation).writeInt8(permissionType);
  };
  module.exports = ({ filters }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "DeleteAcls",
    encode: async () => {
      return new Encoder().writeArray(filters.map(encodeFilters));
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/deleteAcls/v1/response.js
var require_response97 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response96();
  var decodeMatchingAcls = (decoder) => ({
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString(),
    resourceType: decoder.readInt8(),
    resourceName: decoder.readString(),
    resourcePatternType: decoder.readInt8(),
    principal: decoder.readString(),
    host: decoder.readString(),
    operation: decoder.readInt8(),
    permissionType: decoder.readInt8()
  });
  var decodeFilterResponse = (decoder) => ({
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString(),
    matchingAcls: decoder.readArray(decodeMatchingAcls)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const filterResponses = decoder.readArray(decodeFilterResponse);
    return {
      throttleTime: 0,
      clientSideThrottleTime: throttleTime,
      filterResponses
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteAcls/index.js
var require_deleteAcls = __commonJS((exports, module) => {
  var versions = {
    0: ({ filters }) => {
      const request = require_request96();
      const response = require_response96();
      return { request: request({ filters }), response };
    },
    1: ({ filters }) => {
      const request = require_request97();
      const response = require_response97();
      return { request: request({ filters }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/describeConfigs/v0/request.js
var require_request98 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DescribeConfigs: apiKey } = require_apiKeys();
  module.exports = ({ resources }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "DescribeConfigs",
    encode: async () => {
      return new Encoder().writeArray(resources.map(encodeResource));
    }
  });
  var encodeResource = ({ type, name, configNames = [] }) => {
    return new Encoder().writeInt8(type).writeString(name).writeNullableArray(configNames);
  };
});

// node_modules/kafkajs/src/protocol/configSource.js
var require_configSource = __commonJS((exports, module) => {
  module.exports = {
    UNKNOWN: 0,
    TOPIC_CONFIG: 1,
    DYNAMIC_BROKER_CONFIG: 2,
    DYNAMIC_DEFAULT_BROKER_CONFIG: 3,
    STATIC_BROKER_CONFIG: 4,
    DEFAULT_CONFIG: 5,
    DYNAMIC_BROKER_LOGGER_CONFIG: 6
  };
});

// node_modules/kafkajs/src/protocol/configResourceTypes.js
var require_configResourceTypes = __commonJS((exports, module) => {
  module.exports = {
    UNKNOWN: 0,
    TOPIC: 2,
    BROKER: 4,
    BROKER_LOGGER: 8
  };
});

// node_modules/kafkajs/src/protocol/requests/describeConfigs/v0/response.js
var require_response98 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var ConfigSource = require_configSource();
  var ConfigResourceTypes = require_configResourceTypes();
  var decodeConfigEntries = (decoder, resourceType) => {
    const configName = decoder.readString();
    const configValue = decoder.readString();
    const readOnly = decoder.readBoolean();
    const isDefault = decoder.readBoolean();
    const isSensitive = decoder.readBoolean();
    let configSource;
    if (isDefault) {
      configSource = ConfigSource.DEFAULT_CONFIG;
    } else {
      switch (resourceType) {
        case ConfigResourceTypes.BROKER:
          configSource = ConfigSource.STATIC_BROKER_CONFIG;
          break;
        case ConfigResourceTypes.TOPIC:
          configSource = ConfigSource.TOPIC_CONFIG;
          break;
        default:
          configSource = ConfigSource.UNKNOWN;
      }
    }
    return {
      configName,
      configValue,
      readOnly,
      isDefault,
      configSource,
      isSensitive
    };
  };
  var decodeResources = (decoder) => {
    const errorCode = decoder.readInt16();
    const errorMessage = decoder.readString();
    const resourceType = decoder.readInt8();
    const resourceName = decoder.readString();
    const configEntries = decoder.readArray((decoder2) => decodeConfigEntries(decoder2, resourceType));
    return {
      errorCode,
      errorMessage,
      resourceType,
      resourceName,
      configEntries
    };
  };
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const resources = decoder.readArray(decodeResources);
    return {
      throttleTime,
      resources
    };
  };
  var parse = async (data) => {
    const resourcesWithError = data.resources.filter(({ errorCode }) => failure(errorCode));
    if (resourcesWithError.length > 0) {
      throw createErrorFromCode(resourcesWithError[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/describeConfigs/v1/request.js
var require_request99 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DescribeConfigs: apiKey } = require_apiKeys();
  module.exports = ({ resources, includeSynonyms = false }) => ({
    apiKey,
    apiVersion: 1,
    apiName: "DescribeConfigs",
    encode: async () => {
      return new Encoder().writeArray(resources.map(encodeResource)).writeBoolean(includeSynonyms);
    }
  });
  var encodeResource = ({ type, name, configNames = [] }) => {
    return new Encoder().writeInt8(type).writeString(name).writeNullableArray(configNames);
  };
});

// node_modules/kafkajs/src/protocol/requests/describeConfigs/v1/response.js
var require_response99 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { parse: parseV0 } = require_response98();
  var { DEFAULT_CONFIG } = require_configSource();
  var decodeSynonyms = (decoder) => ({
    configName: decoder.readString(),
    configValue: decoder.readString(),
    configSource: decoder.readInt8()
  });
  var decodeConfigEntries = (decoder) => {
    const configName = decoder.readString();
    const configValue = decoder.readString();
    const readOnly = decoder.readBoolean();
    const configSource = decoder.readInt8();
    const isSensitive = decoder.readBoolean();
    const configSynonyms = decoder.readArray(decodeSynonyms);
    return {
      configName,
      configValue,
      readOnly,
      isDefault: configSource === DEFAULT_CONFIG,
      configSource,
      isSensitive,
      configSynonyms
    };
  };
  var decodeResources = (decoder) => ({
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString(),
    resourceType: decoder.readInt8(),
    resourceName: decoder.readString(),
    configEntries: decoder.readArray(decodeConfigEntries)
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const resources = decoder.readArray(decodeResources);
    return {
      throttleTime,
      resources
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/describeConfigs/v2/request.js
var require_request100 = __commonJS((exports, module) => {
  var requestV1 = require_request99();
  module.exports = ({ resources, includeSynonyms }) => Object.assign(requestV1({ resources, includeSynonyms }), { apiVersion: 2 });
});

// node_modules/kafkajs/src/protocol/requests/describeConfigs/v2/response.js
var require_response100 = __commonJS((exports, module) => {
  var { parse, decode: decodeV1 } = require_response99();
  var decode = async (rawData) => {
    const decoded = await decodeV1(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/describeConfigs/index.js
var require_describeConfigs = __commonJS((exports, module) => {
  var versions = {
    0: ({ resources }) => {
      const request = require_request98();
      const response = require_response98();
      return { request: request({ resources }), response };
    },
    1: ({ resources, includeSynonyms }) => {
      const request = require_request99();
      const response = require_response99();
      return { request: request({ resources, includeSynonyms }), response };
    },
    2: ({ resources, includeSynonyms }) => {
      const request = require_request100();
      const response = require_response100();
      return { request: request({ resources, includeSynonyms }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/alterConfigs/v0/request.js
var require_request101 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { AlterConfigs: apiKey } = require_apiKeys();
  module.exports = ({ resources, validateOnly = false }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "AlterConfigs",
    encode: async () => {
      return new Encoder().writeArray(resources.map(encodeResource)).writeBoolean(validateOnly);
    }
  });
  var encodeResource = ({ type, name, configEntries }) => {
    return new Encoder().writeInt8(type).writeString(name).writeArray(configEntries.map(encodeConfigEntries));
  };
  var encodeConfigEntries = ({ name, value }) => {
    return new Encoder().writeString(name).writeString(value);
  };
});

// node_modules/kafkajs/src/protocol/requests/alterConfigs/v0/response.js
var require_response101 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeResources = (decoder) => ({
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString(),
    resourceType: decoder.readInt8(),
    resourceName: decoder.readString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    const resources = decoder.readArray(decodeResources);
    return {
      throttleTime,
      resources
    };
  };
  var parse = async (data) => {
    const resourcesWithError = data.resources.filter(({ errorCode }) => failure(errorCode));
    if (resourcesWithError.length > 0) {
      throw createErrorFromCode(resourcesWithError[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/alterConfigs/v1/request.js
var require_request102 = __commonJS((exports, module) => {
  var requestV0 = require_request101();
  module.exports = ({ resources, validateOnly }) => Object.assign(requestV0({
    resources,
    validateOnly
  }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/alterConfigs/v1/response.js
var require_response102 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response101();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/alterConfigs/index.js
var require_alterConfigs = __commonJS((exports, module) => {
  var versions = {
    0: ({ resources, validateOnly }) => {
      const request = require_request101();
      const response = require_response101();
      return { request: request({ resources, validateOnly }), response };
    },
    1: ({ resources, validateOnly }) => {
      const request = require_request102();
      const response = require_response102();
      return { request: request({ resources, validateOnly }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/saslAuthenticate/v0/request.js
var require_request103 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { SaslAuthenticate: apiKey } = require_apiKeys();
  module.exports = ({ authBytes }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "SaslAuthenticate",
    encode: async () => {
      return new Encoder().writeBuffer(authBytes);
    }
  });
});

// node_modules/kafkajs/src/protocol/requests/saslAuthenticate/v0/response.js
var require_response103 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var Encoder = require_encoder();
  var {
    failure,
    createErrorFromCode,
    failIfVersionNotSupported,
    errorCodes
  } = require_error();
  var { KafkaJSProtocolError } = require_errors2();
  var SASL_AUTHENTICATION_FAILED = 58;
  var protocolAuthError = errorCodes.find((e) => e.code === SASL_AUTHENTICATION_FAILED);
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    const errorMessage = decoder.readString();
    const authBytesEncoder = new Encoder().writeBytes(decoder.readBytes());
    const authBytes = authBytesEncoder.buffer;
    return {
      errorCode,
      errorMessage,
      authBytes
    };
  };
  var parse = async (data) => {
    if (data.errorCode === SASL_AUTHENTICATION_FAILED && data.errorMessage) {
      throw new KafkaJSProtocolError({
        ...protocolAuthError,
        message: data.errorMessage
      });
    }
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/saslAuthenticate/v1/request.js
var require_request104 = __commonJS((exports, module) => {
  var requestV0 = require_request103();
  module.exports = ({ authBytes }) => Object.assign(requestV0({ authBytes }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/saslAuthenticate/v1/response.js
var require_response104 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var Encoder = require_encoder();
  var { parse: parseV0 } = require_response103();
  var { failIfVersionNotSupported } = require_error();
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const errorCode = decoder.readInt16();
    failIfVersionNotSupported(errorCode);
    const errorMessage = decoder.readString();
    const authBytesEncoder = new Encoder().writeBytes(decoder.readBytes());
    const authBytes = authBytesEncoder.buffer;
    const sessionLifetimeMs = decoder.readInt64().toString();
    return {
      errorCode,
      errorMessage,
      authBytes,
      sessionLifetimeMs
    };
  };
  module.exports = {
    decode,
    parse: parseV0
  };
});

// node_modules/kafkajs/src/protocol/requests/saslAuthenticate/index.js
var require_saslAuthenticate = __commonJS((exports, module) => {
  var versions = {
    0: ({ authBytes }) => {
      const request = require_request103();
      const response = require_response103();
      return { request: request({ authBytes }), response };
    },
    1: ({ authBytes }) => {
      const request = require_request104();
      const response = require_response104();
      return { request: request({ authBytes }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/createPartitions/v0/request.js
var require_request105 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { CreatePartitions: apiKey } = require_apiKeys();
  module.exports = ({ topicPartitions, validateOnly = false, timeout = 5000 }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "CreatePartitions",
    encode: async () => {
      return new Encoder().writeArray(topicPartitions.map(encodeTopicPartitions)).writeInt32(timeout).writeBoolean(validateOnly);
    }
  });
  var encodeTopicPartitions = ({ topic, count, assignments = [] }) => {
    return new Encoder().writeString(topic).writeInt32(count).writeNullableArray(assignments.map(encodeAssignments));
  };
  var encodeAssignments = (brokerIds) => {
    return new Encoder().writeNullableArray(brokerIds);
  };
});

// node_modules/kafkajs/src/protocol/requests/createPartitions/v0/response.js
var require_response105 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var topicNameComparator = (a, b) => a.topic.localeCompare(b.topic);
  var topicErrors = (decoder) => ({
    topic: decoder.readString(),
    errorCode: decoder.readInt16(),
    errorMessage: decoder.readString()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTime = decoder.readInt32();
    return {
      throttleTime,
      topicErrors: decoder.readArray(topicErrors).sort(topicNameComparator)
    };
  };
  var parse = async (data) => {
    const topicsWithError = data.topicErrors.filter(({ errorCode }) => failure(errorCode));
    if (topicsWithError.length > 0) {
      throw createErrorFromCode(topicsWithError[0].errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/createPartitions/v1/request.js
var require_request106 = __commonJS((exports, module) => {
  var requestV0 = require_request105();
  module.exports = ({ topicPartitions, validateOnly, timeout }) => Object.assign(requestV0({ topicPartitions, validateOnly, timeout }), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/createPartitions/v1/response.js
var require_response106 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response105();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/createPartitions/index.js
var require_createPartitions = __commonJS((exports, module) => {
  var versions = {
    0: ({ topicPartitions, timeout, validateOnly }) => {
      const request = require_request105();
      const response = require_response105();
      return { request: request({ topicPartitions, timeout, validateOnly }), response };
    },
    1: ({ topicPartitions, validateOnly, timeout }) => {
      const request = require_request106();
      const response = require_response106();
      return { request: request({ topicPartitions, validateOnly, timeout }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteGroups/v0/request.js
var require_request107 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { DeleteGroups: apiKey } = require_apiKeys();
  module.exports = (groupIds) => ({
    apiKey,
    apiVersion: 0,
    apiName: "DeleteGroups",
    encode: async () => {
      return new Encoder().writeArray(groupIds.map(encodeGroups));
    }
  });
  var encodeGroups = (group) => {
    return new Encoder().writeString(group);
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteGroups/v0/response.js
var require_response107 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeGroup = (decoder) => ({
    groupId: decoder.readString(),
    errorCode: decoder.readInt16()
  });
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    const throttleTimeMs = decoder.readInt32();
    const results = decoder.readArray(decodeGroup);
    for (const result of results) {
      if (failure(result.errorCode)) {
        result.error = createErrorFromCode(result.errorCode);
      }
    }
    return {
      throttleTimeMs,
      results
    };
  };
  var parse = async (data) => {
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteGroups/v1/request.js
var require_request108 = __commonJS((exports, module) => {
  var requestV0 = require_request107();
  module.exports = (groupIds) => Object.assign(requestV0(groupIds), { apiVersion: 1 });
});

// node_modules/kafkajs/src/protocol/requests/deleteGroups/v1/response.js
var require_response108 = __commonJS((exports, module) => {
  var { parse, decode: decodeV0 } = require_response107();
  var decode = async (rawData) => {
    const decoded = await decodeV0(rawData);
    return {
      ...decoded,
      throttleTime: 0,
      clientSideThrottleTime: decoded.throttleTime
    };
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/deleteGroups/index.js
var require_deleteGroups = __commonJS((exports, module) => {
  var versions = {
    0: (groupIds) => {
      const request = require_request107();
      const response = require_response107();
      return { request: request(groupIds), response };
    },
    1: (groupIds) => {
      const request = require_request108();
      const response = require_response108();
      return { request: request(groupIds), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/alterPartitionReassignments/v0/request.js
var require_request109 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { AlterPartitionReassignments: apiKey } = require_apiKeys();
  module.exports = ({ topics, timeout = 5000 }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "AlterPartitionReassignments",
    encode: async () => {
      return new Encoder().writeUVarIntBytes().writeInt32(timeout).writeUVarIntArray(topics.map(encodeTopics)).writeUVarIntBytes();
    }
  });
  var encodeTopics = ({ topic, partitionAssignment }) => {
    return new Encoder().writeUVarIntString(topic).writeUVarIntArray(partitionAssignment.map(encodePartitionAssignment)).writeUVarIntBytes();
  };
  var encodePartitionAssignment = ({ partition, replicas }) => {
    return new Encoder().writeInt32(partition).writeUVarIntArray(replicas.map(encodeReplicas)).writeUVarIntBytes();
  };
  var encodeReplicas = (replica) => {
    return new Encoder().writeInt32(replica);
  };
});

// node_modules/kafkajs/src/protocol/requests/alterPartitionReassignments/v0/response.js
var require_response109 = __commonJS((exports, module) => {
  var {
    KafkaJSAggregateError,
    KafkaJSAlterPartitionReassignmentsError
  } = require_errors2();
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeResponses = (decoder) => {
    const response = {
      topic: decoder.readUVarIntString(),
      partitions: decoder.readUVarIntArray(decodePartitions)
    };
    decoder.readTaggedFields();
    return response;
  };
  var decodePartitions = (decoder) => {
    const partition = {
      partition: decoder.readInt32(),
      errorCode: decoder.readInt16()
    };
    decoder.readUVarIntString();
    decoder.readTaggedFields();
    return partition;
  };
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    decoder.readTaggedFields();
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    decoder.readUVarIntString();
    return {
      throttleTime,
      errorCode,
      responses: decoder.readUVarIntArray(decodeResponses)
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw new KafkaJSAlterPartitionReassignmentsError(createErrorFromCode(data.errorCode));
    }
    const topicPartitionsWithError = data.responses.flatMap(({ partitions, topic }) => partitions.filter((partition) => failure(partition.errorCode)).map((partition) => ({
      ...partition,
      topic
    })));
    if (topicPartitionsWithError.length > 0) {
      throw new KafkaJSAggregateError("Errors altering partition reassignments", topicPartitionsWithError.map(({ topic, partition, errorCode }) => new KafkaJSAlterPartitionReassignmentsError(createErrorFromCode(errorCode), topic, partition)));
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/alterPartitionReassignments/index.js
var require_alterPartitionReassignments = __commonJS((exports, module) => {
  var versions = {
    0: ({ topics, timeout }) => {
      const request = require_request109();
      const response = require_response109();
      return { request: request({ topics, timeout }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/listPartitionReassignments/v0/request.js
var require_request110 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var { ListPartitionReassignments: apiKey } = require_apiKeys();
  module.exports = ({ topics = null, timeout = 5000 }) => ({
    apiKey,
    apiVersion: 0,
    apiName: "ListPartitionReassignments",
    encode: async () => {
      return new Encoder().writeUVarIntBytes().writeInt32(timeout).writeUVarIntArray(topics === null ? topics : topics.map(encodeTopics)).writeUVarIntBytes();
    }
  });
  var encodeTopics = ({ topic, partitions }) => {
    return new Encoder().writeUVarIntString(topic).writeUVarIntArray(partitions.map(encodePartitions)).writeUVarIntBytes();
  };
  var encodePartitions = (partition) => {
    return new Encoder().writeInt32(partition);
  };
});

// node_modules/kafkajs/src/protocol/requests/listPartitionReassignments/v0/response.js
var require_response110 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var { failure, createErrorFromCode } = require_error();
  var decodeReplicas = (decoder) => {
    return decoder.readInt32();
  };
  var decodePartitions = (decoder) => {
    const partition = {
      partition: decoder.readInt32(),
      replicas: decoder.readUVarIntArray(decodeReplicas),
      addingReplicas: decoder.readUVarIntArray(decodeReplicas),
      removingReplicas: decoder.readUVarIntArray(decodeReplicas)
    };
    decoder.readTaggedFields();
    return partition;
  };
  var decodeTopics = (decoder) => {
    const topic = {
      name: decoder.readUVarIntString(),
      partitions: decoder.readUVarIntArray(decodePartitions)
    };
    decoder.readTaggedFields();
    return topic;
  };
  var decode = async (rawData) => {
    const decoder = new Decoder(rawData);
    decoder.readTaggedFields();
    const throttleTime = decoder.readInt32();
    const errorCode = decoder.readInt16();
    decoder.readUVarIntString();
    return {
      throttleTime,
      errorCode,
      topics: decoder.readUVarIntArray(decodeTopics)
    };
  };
  var parse = async (data) => {
    if (failure(data.errorCode)) {
      throw createErrorFromCode(data.errorCode);
    }
    return data;
  };
  module.exports = {
    decode,
    parse
  };
});

// node_modules/kafkajs/src/protocol/requests/listPartitionReassignments/index.js
var require_listPartitionReassignments = __commonJS((exports, module) => {
  var versions = {
    0: ({ topics, timeout }) => {
      const request = require_request110();
      const response = require_response110();
      return { request: request({ topics, timeout }), response };
    }
  };
  module.exports = {
    versions: Object.keys(versions),
    protocol: ({ version }) => versions[version]
  };
});

// node_modules/kafkajs/src/protocol/requests/index.js
var require_requests = __commonJS((exports, module) => {
  var apiKeys = require_apiKeys();
  var { KafkaJSServerDoesNotSupportApiKey, KafkaJSNotImplemented } = require_errors2();
  var noImplementedRequestDefinitions = {
    versions: [],
    protocol: () => {
      throw new KafkaJSNotImplemented;
    }
  };
  var requests = {
    Produce: require_produce(),
    Fetch: require_fetch(),
    ListOffsets: require_listOffsets(),
    Metadata: require_metadata(),
    LeaderAndIsr: noImplementedRequestDefinitions,
    StopReplica: noImplementedRequestDefinitions,
    UpdateMetadata: noImplementedRequestDefinitions,
    ControlledShutdown: noImplementedRequestDefinitions,
    OffsetCommit: require_offsetCommit(),
    OffsetFetch: require_offsetFetch(),
    GroupCoordinator: require_findCoordinator(),
    JoinGroup: require_joinGroup(),
    Heartbeat: require_heartbeat(),
    LeaveGroup: require_leaveGroup(),
    SyncGroup: require_syncGroup(),
    DescribeGroups: require_describeGroups(),
    ListGroups: require_listGroups(),
    SaslHandshake: require_saslHandshake(),
    ApiVersions: require_apiVersions(),
    CreateTopics: require_createTopics(),
    DeleteTopics: require_deleteTopics(),
    DeleteRecords: require_deleteRecords(),
    InitProducerId: require_initProducerId(),
    OffsetForLeaderEpoch: noImplementedRequestDefinitions,
    AddPartitionsToTxn: require_addPartitionsToTxn(),
    AddOffsetsToTxn: require_addOffsetsToTxn(),
    EndTxn: require_endTxn(),
    WriteTxnMarkers: noImplementedRequestDefinitions,
    TxnOffsetCommit: require_txnOffsetCommit(),
    DescribeAcls: require_describeAcls(),
    CreateAcls: require_createAcls(),
    DeleteAcls: require_deleteAcls(),
    DescribeConfigs: require_describeConfigs(),
    AlterConfigs: require_alterConfigs(),
    AlterReplicaLogDirs: noImplementedRequestDefinitions,
    DescribeLogDirs: noImplementedRequestDefinitions,
    SaslAuthenticate: require_saslAuthenticate(),
    CreatePartitions: require_createPartitions(),
    CreateDelegationToken: noImplementedRequestDefinitions,
    RenewDelegationToken: noImplementedRequestDefinitions,
    ExpireDelegationToken: noImplementedRequestDefinitions,
    DescribeDelegationToken: noImplementedRequestDefinitions,
    DeleteGroups: require_deleteGroups(),
    ElectLeaders: noImplementedRequestDefinitions,
    IncrementalAlterConfigs: noImplementedRequestDefinitions,
    AlterPartitionReassignments: require_alterPartitionReassignments(),
    ListPartitionReassignments: require_listPartitionReassignments()
  };
  var names = Object.keys(apiKeys);
  var keys = Object.values(apiKeys);
  var findApiName = (apiKey) => names[keys.indexOf(apiKey)];
  var lookup = (versions) => (apiKey, definition) => {
    const version = versions[apiKey];
    const availableVersions = definition.versions.map(Number);
    const bestImplementedVersion = Math.max(...availableVersions);
    if (!version || version.maxVersion == null) {
      throw new KafkaJSServerDoesNotSupportApiKey(`The Kafka server does not support the requested API version`, { apiKey, apiName: findApiName(apiKey) });
    }
    const bestSupportedVersion = Math.min(bestImplementedVersion, version.maxVersion);
    return definition.protocol({ version: bestSupportedVersion });
  };
  module.exports = {
    requests,
    lookup
  };
});

// node_modules/kafkajs/src/utils/shuffle.js
var require_shuffle = __commonJS((exports, module) => {
  module.exports = (array) => {
    if (!Array.isArray(array)) {
      throw new TypeError("'array' is not an array");
    }
    if (array.length < 2) {
      return array;
    }
    const copy = array.slice();
    for (let i = copy.length - 1;i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      const temp = copy[i];
      copy[i] = copy[j];
      copy[j] = temp;
    }
    return copy;
  };
});

// node_modules/kafkajs/src/broker/index.js
var require_broker = __commonJS((exports, module) => {
  var Lock = require_lock();
  var { Types: Compression } = require_compression();
  var { requests, lookup } = require_requests();
  var { KafkaJSNonRetriableError } = require_errors2();
  var apiKeys = require_apiKeys();
  var shuffle = require_shuffle();
  var PRIVATE = {
    SEND_REQUEST: Symbol("private:Broker:sendRequest")
  };
  var notInitializedLookup = () => {
    throw new Error("Broker not connected");
  };
  module.exports = class Broker {
    constructor({
      connectionPool,
      logger,
      nodeId = null,
      versions = null,
      authenticationTimeout = 1e4,
      allowAutoTopicCreation = true
    }) {
      this.connectionPool = connectionPool;
      this.nodeId = nodeId;
      this.rootLogger = logger;
      this.logger = logger.namespace("Broker");
      this.versions = versions;
      this.authenticationTimeout = authenticationTimeout;
      this.allowAutoTopicCreation = allowAutoTopicCreation;
      const lockTimeout = 2 * this.connectionPool.connectionTimeout + this.authenticationTimeout;
      this.brokerAddress = `${this.connectionPool.host}:${this.connectionPool.port}`;
      this.lock = new Lock({
        timeout: lockTimeout,
        description: `connect to broker ${this.brokerAddress}`
      });
      this.lookupRequest = notInitializedLookup;
    }
    isConnected() {
      return this.connectionPool.sasl ? this.connectionPool.isConnected() && this.connectionPool.isAuthenticated() : this.connectionPool.isConnected();
    }
    async connect() {
      await this.lock.acquire();
      try {
        if (this.isConnected()) {
          return;
        }
        const connection = await this.connectionPool.getConnection();
        if (!this.versions) {
          this.versions = await this.apiVersions();
        }
        this.connectionPool.setVersions(this.versions);
        this.lookupRequest = lookup(this.versions);
        if (connection.getSupportAuthenticationProtocol() === null) {
          let supportAuthenticationProtocol = false;
          try {
            this.lookupRequest(apiKeys.SaslAuthenticate, requests.SaslAuthenticate);
            supportAuthenticationProtocol = true;
          } catch (_) {
            supportAuthenticationProtocol = false;
          }
          this.connectionPool.setSupportAuthenticationProtocol(supportAuthenticationProtocol);
          this.logger.debug(`Verified support for SaslAuthenticate`, {
            broker: this.brokerAddress,
            supportAuthenticationProtocol
          });
        }
        await connection.authenticate();
      } finally {
        await this.lock.release();
      }
    }
    async disconnect() {
      await this.connectionPool.destroy();
    }
    async apiVersions() {
      let response;
      const availableVersions = requests.ApiVersions.versions.map(Number).sort().reverse();
      for (const candidateVersion of availableVersions) {
        try {
          const apiVersions = requests.ApiVersions.protocol({ version: candidateVersion });
          response = await this[PRIVATE.SEND_REQUEST]({
            ...apiVersions(),
            requestTimeout: this.connectionPool.connectionTimeout
          });
          break;
        } catch (e) {
          if (e.type !== "UNSUPPORTED_VERSION") {
            throw e;
          }
        }
      }
      if (!response) {
        throw new KafkaJSNonRetriableError("API Versions not supported");
      }
      return response.apiVersions.reduce((obj, version) => Object.assign(obj, {
        [version.apiKey]: {
          minVersion: version.minVersion,
          maxVersion: version.maxVersion
        }
      }), {});
    }
    async metadata(topics = []) {
      const metadata = this.lookupRequest(apiKeys.Metadata, requests.Metadata);
      const shuffledTopics = shuffle(topics);
      return await this[PRIVATE.SEND_REQUEST](metadata({ topics: shuffledTopics, allowAutoTopicCreation: this.allowAutoTopicCreation }));
    }
    async produce({
      topicData,
      transactionalId,
      producerId,
      producerEpoch,
      acks = -1,
      timeout = 30000,
      compression = Compression.None
    }) {
      const produce = this.lookupRequest(apiKeys.Produce, requests.Produce);
      return await this[PRIVATE.SEND_REQUEST](produce({
        acks,
        timeout,
        compression,
        topicData,
        transactionalId,
        producerId,
        producerEpoch
      }));
    }
    async fetch({
      replicaId,
      isolationLevel,
      maxWaitTime = 5000,
      minBytes = 1,
      maxBytes = 10485760,
      topics,
      rackId = ""
    }) {
      const fetch = this.lookupRequest(apiKeys.Fetch, requests.Fetch);
      const flattenedTopicPartitions = topics.reduce((topicPartitions, { topic, partitions }) => {
        partitions.forEach((partition) => {
          topicPartitions.push({ topic, partition });
        });
        return topicPartitions;
      }, []);
      const shuffledTopicPartitions = shuffle(flattenedTopicPartitions);
      const consolidatedTopicPartitions = shuffledTopicPartitions.reduce((topicPartitions, { topic, partition }) => {
        const last = topicPartitions[topicPartitions.length - 1];
        if (last != null && last.topic === topic) {
          topicPartitions[topicPartitions.length - 1].partitions.push(partition);
        } else {
          topicPartitions.push({ topic, partitions: [partition] });
        }
        return topicPartitions;
      }, []);
      return await this[PRIVATE.SEND_REQUEST](fetch({
        replicaId,
        isolationLevel,
        maxWaitTime,
        minBytes,
        maxBytes,
        topics: consolidatedTopicPartitions,
        rackId
      }));
    }
    async heartbeat({ groupId, groupGenerationId, memberId }) {
      const heartbeat = this.lookupRequest(apiKeys.Heartbeat, requests.Heartbeat);
      return await this[PRIVATE.SEND_REQUEST](heartbeat({ groupId, groupGenerationId, memberId }));
    }
    async findGroupCoordinator({ groupId, coordinatorType }) {
      const findCoordinator = this.lookupRequest(apiKeys.GroupCoordinator, requests.GroupCoordinator);
      return await this[PRIVATE.SEND_REQUEST](findCoordinator({ groupId, coordinatorType }));
    }
    async joinGroup({
      groupId,
      sessionTimeout,
      rebalanceTimeout,
      memberId = "",
      protocolType = "consumer",
      groupProtocols
    }) {
      const joinGroup = this.lookupRequest(apiKeys.JoinGroup, requests.JoinGroup);
      const makeRequest = (assignedMemberId = memberId) => this[PRIVATE.SEND_REQUEST](joinGroup({
        groupId,
        sessionTimeout,
        rebalanceTimeout,
        memberId: assignedMemberId,
        protocolType,
        groupProtocols
      }));
      try {
        return await makeRequest();
      } catch (error) {
        if (error.name === "KafkaJSMemberIdRequired") {
          return makeRequest(error.memberId);
        }
        throw error;
      }
    }
    async leaveGroup({ groupId, memberId }) {
      const leaveGroup = this.lookupRequest(apiKeys.LeaveGroup, requests.LeaveGroup);
      return await this[PRIVATE.SEND_REQUEST](leaveGroup({ groupId, memberId }));
    }
    async syncGroup({ groupId, generationId, memberId, groupAssignment }) {
      const syncGroup = this.lookupRequest(apiKeys.SyncGroup, requests.SyncGroup);
      return await this[PRIVATE.SEND_REQUEST](syncGroup({
        groupId,
        generationId,
        memberId,
        groupAssignment
      }));
    }
    async listOffsets({ replicaId, isolationLevel, topics }) {
      const listOffsets = this.lookupRequest(apiKeys.ListOffsets, requests.ListOffsets);
      const result = await this[PRIVATE.SEND_REQUEST](listOffsets({ replicaId, isolationLevel, topics }));
      for (const response of result.responses) {
        response.partitions = response.partitions.map(({ offsets, ...partitionData }) => {
          return offsets ? { ...partitionData, offset: offsets.pop() } : partitionData;
        });
      }
      return result;
    }
    async offsetCommit({ groupId, groupGenerationId, memberId, retentionTime, topics }) {
      const offsetCommit = this.lookupRequest(apiKeys.OffsetCommit, requests.OffsetCommit);
      return await this[PRIVATE.SEND_REQUEST](offsetCommit({
        groupId,
        groupGenerationId,
        memberId,
        retentionTime,
        topics
      }));
    }
    async offsetFetch({ groupId, topics }) {
      const offsetFetch = this.lookupRequest(apiKeys.OffsetFetch, requests.OffsetFetch);
      return await this[PRIVATE.SEND_REQUEST](offsetFetch({ groupId, topics }));
    }
    async describeGroups({ groupIds }) {
      const describeGroups = this.lookupRequest(apiKeys.DescribeGroups, requests.DescribeGroups);
      return await this[PRIVATE.SEND_REQUEST](describeGroups({ groupIds }));
    }
    async createTopics({ topics, validateOnly = false, timeout = 5000 }) {
      const createTopics = this.lookupRequest(apiKeys.CreateTopics, requests.CreateTopics);
      return await this[PRIVATE.SEND_REQUEST](createTopics({ topics, validateOnly, timeout }));
    }
    async createPartitions({ topicPartitions, validateOnly = false, timeout = 5000 }) {
      const createPartitions = this.lookupRequest(apiKeys.CreatePartitions, requests.CreatePartitions);
      return await this[PRIVATE.SEND_REQUEST](createPartitions({ topicPartitions, validateOnly, timeout }));
    }
    async deleteTopics({ topics, timeout = 5000 }) {
      const deleteTopics = this.lookupRequest(apiKeys.DeleteTopics, requests.DeleteTopics);
      return await this[PRIVATE.SEND_REQUEST](deleteTopics({ topics, timeout }));
    }
    async describeConfigs({ resources, includeSynonyms = false }) {
      const describeConfigs = this.lookupRequest(apiKeys.DescribeConfigs, requests.DescribeConfigs);
      return await this[PRIVATE.SEND_REQUEST](describeConfigs({ resources, includeSynonyms }));
    }
    async alterConfigs({ resources, validateOnly = false }) {
      const alterConfigs = this.lookupRequest(apiKeys.AlterConfigs, requests.AlterConfigs);
      return await this[PRIVATE.SEND_REQUEST](alterConfigs({ resources, validateOnly }));
    }
    async initProducerId({ transactionalId, transactionTimeout }) {
      const initProducerId = this.lookupRequest(apiKeys.InitProducerId, requests.InitProducerId);
      return await this[PRIVATE.SEND_REQUEST](initProducerId({ transactionalId, transactionTimeout }));
    }
    async addPartitionsToTxn({ transactionalId, producerId, producerEpoch, topics }) {
      const addPartitionsToTxn = this.lookupRequest(apiKeys.AddPartitionsToTxn, requests.AddPartitionsToTxn);
      return await this[PRIVATE.SEND_REQUEST](addPartitionsToTxn({ transactionalId, producerId, producerEpoch, topics }));
    }
    async addOffsetsToTxn({ transactionalId, producerId, producerEpoch, groupId }) {
      const addOffsetsToTxn = this.lookupRequest(apiKeys.AddOffsetsToTxn, requests.AddOffsetsToTxn);
      return await this[PRIVATE.SEND_REQUEST](addOffsetsToTxn({ transactionalId, producerId, producerEpoch, groupId }));
    }
    async txnOffsetCommit({ transactionalId, groupId, producerId, producerEpoch, topics }) {
      const txnOffsetCommit = this.lookupRequest(apiKeys.TxnOffsetCommit, requests.TxnOffsetCommit);
      return await this[PRIVATE.SEND_REQUEST](txnOffsetCommit({ transactionalId, groupId, producerId, producerEpoch, topics }));
    }
    async endTxn({ transactionalId, producerId, producerEpoch, transactionResult }) {
      const endTxn = this.lookupRequest(apiKeys.EndTxn, requests.EndTxn);
      return await this[PRIVATE.SEND_REQUEST](endTxn({ transactionalId, producerId, producerEpoch, transactionResult }));
    }
    async listGroups() {
      const listGroups = this.lookupRequest(apiKeys.ListGroups, requests.ListGroups);
      return await this[PRIVATE.SEND_REQUEST](listGroups());
    }
    async deleteGroups(groupIds) {
      const deleteGroups = this.lookupRequest(apiKeys.DeleteGroups, requests.DeleteGroups);
      return await this[PRIVATE.SEND_REQUEST](deleteGroups(groupIds));
    }
    async deleteRecords({ topics }) {
      const deleteRecords = this.lookupRequest(apiKeys.DeleteRecords, requests.DeleteRecords);
      return await this[PRIVATE.SEND_REQUEST](deleteRecords({ topics }));
    }
    async createAcls({ acl }) {
      const createAcls = this.lookupRequest(apiKeys.CreateAcls, requests.CreateAcls);
      return await this[PRIVATE.SEND_REQUEST](createAcls({ creations: acl }));
    }
    async describeAcls({
      resourceType,
      resourceName,
      resourcePatternType,
      principal,
      host,
      operation,
      permissionType
    }) {
      const describeAcls = this.lookupRequest(apiKeys.DescribeAcls, requests.DescribeAcls);
      return await this[PRIVATE.SEND_REQUEST](describeAcls({
        resourceType,
        resourceName,
        resourcePatternType,
        principal,
        host,
        operation,
        permissionType
      }));
    }
    async deleteAcls({ filters }) {
      const deleteAcls = this.lookupRequest(apiKeys.DeleteAcls, requests.DeleteAcls);
      return await this[PRIVATE.SEND_REQUEST](deleteAcls({ filters }));
    }
    async alterPartitionReassignments({ topics, timeout }) {
      const alterPartitionReassignments = this.lookupRequest(apiKeys.AlterPartitionReassignments, requests.AlterPartitionReassignments);
      return await this[PRIVATE.SEND_REQUEST](alterPartitionReassignments({ topics, timeout }));
    }
    async listPartitionReassignments({ topics = null, timeout }) {
      const listPartitionReassignments = this.lookupRequest(apiKeys.ListPartitionReassignments, requests.ListPartitionReassignments);
      return await this[PRIVATE.SEND_REQUEST](listPartitionReassignments({ topics, timeout }));
    }
    async[PRIVATE.SEND_REQUEST](protocolRequest) {
      try {
        return await this.connectionPool.send(protocolRequest);
      } catch (e) {
        if (e.name === "KafkaJSConnectionClosedError") {
          await this.disconnect();
        }
        throw e;
      }
    }
  };
});

// node_modules/kafkajs/src/retry/defaults.test.js
var require_defaults_test = __commonJS((exports, module) => {
  module.exports = {
    maxRetryTime: 1000,
    initialRetryTime: 50,
    factor: 0.02,
    multiplier: 1.5,
    retries: 15
  };
});

// node_modules/kafkajs/src/retry/defaults.js
var require_defaults = __commonJS((exports, module) => {
  module.exports = {
    maxRetryTime: 30 * 1000,
    initialRetryTime: 300,
    factor: 0.2,
    multiplier: 2,
    retries: 5
  };
});

// node_modules/kafkajs/src/retry/index.js
var require_retry = __commonJS((exports, module) => {
  var { KafkaJSNumberOfRetriesExceeded, KafkaJSNonRetriableError } = require_errors2();
  var isTestMode = false;
  var RETRY_DEFAULT = isTestMode ? require_defaults_test() : require_defaults();
  var random = (min, max) => {
    return Math.random() * (max - min) + min;
  };
  var randomFromRetryTime = (factor, retryTime) => {
    const delta = factor * retryTime;
    return Math.ceil(random(retryTime - delta, retryTime + delta));
  };
  var UNRECOVERABLE_ERRORS = ["RangeError", "ReferenceError", "SyntaxError", "TypeError"];
  var isErrorUnrecoverable = (e) => UNRECOVERABLE_ERRORS.includes(e.name);
  var isErrorRetriable = (error) => (error.retriable || error.retriable !== false) && !isErrorUnrecoverable(error);
  var createRetriable = (configs, resolve, reject, fn) => {
    let aborted = false;
    const { factor, multiplier, maxRetryTime, retries } = configs;
    const bail = (error) => {
      aborted = true;
      reject(error || new Error("Aborted"));
    };
    const calculateExponentialRetryTime = (retryTime) => {
      return Math.min(randomFromRetryTime(factor, retryTime) * multiplier, maxRetryTime);
    };
    const retry = (retryTime, retryCount = 0) => {
      if (aborted)
        return;
      const nextRetryTime = calculateExponentialRetryTime(retryTime);
      const shouldRetry = retryCount < retries;
      const scheduleRetry = () => {
        setTimeout(() => retry(nextRetryTime, retryCount + 1), retryTime);
      };
      fn(bail, retryCount, retryTime).then(resolve).catch((e) => {
        if (isErrorRetriable(e)) {
          if (shouldRetry) {
            scheduleRetry();
          } else {
            reject(new KafkaJSNumberOfRetriesExceeded(e, { retryCount, retryTime, cause: e.cause || e }));
          }
        } else {
          reject(new KafkaJSNonRetriableError(e, { cause: e.cause || e }));
        }
      });
    };
    return retry;
  };
  module.exports = (opts = {}) => (fn) => {
    return new Promise((resolve, reject) => {
      const configs = Object.assign({}, RETRY_DEFAULT, opts);
      const start = createRetriable(configs, resolve, reject, fn);
      start(randomFromRetryTime(configs.factor, configs.initialRetryTime));
    });
  };
});

// node_modules/kafkajs/src/utils/arrayDiff.js
var require_arrayDiff = __commonJS((exports, module) => {
  module.exports = (a, b) => {
    const result = [];
    const length = a.length;
    let i = 0;
    while (i < length) {
      if (b.indexOf(a[i]) === -1) {
        result.push(a[i]);
      }
      i += 1;
    }
    return result;
  };
});

// node_modules/kafkajs/src/cluster/brokerPool.js
var require_brokerPool = __commonJS((exports, module) => {
  var Broker = require_broker();
  var createRetry = require_retry();
  var shuffle = require_shuffle();
  var arrayDiff = require_arrayDiff();
  var { KafkaJSBrokerNotFound, KafkaJSProtocolError } = require_errors2();
  var { keys, assign, values } = Object;
  var hasBrokerBeenReplaced = (broker, { host, port, rack }) => broker.connectionPool.host !== host || broker.connectionPool.port !== port || broker.connectionPool.rack !== rack;
  module.exports = class BrokerPool {
    constructor({
      connectionPoolBuilder,
      logger,
      retry,
      allowAutoTopicCreation,
      authenticationTimeout,
      metadataMaxAge
    }) {
      this.rootLogger = logger;
      this.connectionPoolBuilder = connectionPoolBuilder;
      this.metadataMaxAge = metadataMaxAge || 0;
      this.logger = logger.namespace("BrokerPool");
      this.retrier = createRetry(assign({}, retry));
      this.createBroker = (options) => new Broker({
        allowAutoTopicCreation,
        authenticationTimeout,
        ...options
      });
      this.brokers = {};
      this.seedBroker = undefined;
      this.metadata = null;
      this.metadataExpireAt = null;
      this.versions = null;
    }
    hasConnectedBrokers() {
      const brokers = values(this.brokers);
      return !!brokers.find((broker) => broker.isConnected()) || (this.seedBroker ? this.seedBroker.isConnected() : false);
    }
    async createSeedBroker() {
      if (this.seedBroker) {
        await this.seedBroker.disconnect();
      }
      const connectionPool = await this.connectionPoolBuilder.build();
      this.seedBroker = this.createBroker({
        connectionPool,
        logger: this.rootLogger
      });
    }
    async connect() {
      if (this.hasConnectedBrokers()) {
        return;
      }
      if (!this.seedBroker) {
        await this.createSeedBroker();
      }
      return this.retrier(async (bail, retryCount, retryTime) => {
        try {
          await this.seedBroker.connect();
          this.versions = this.seedBroker.versions;
        } catch (e) {
          if (e.name === "KafkaJSConnectionError" || e.type === "ILLEGAL_SASL_STATE") {
            await this.createSeedBroker();
            this.logger.error(`Failed to connect to seed broker, trying another broker from the list: ${e.message}`, { retryCount, retryTime });
          } else {
            this.logger.error(e.message, { retryCount, retryTime });
          }
          if (e.retriable)
            throw e;
          bail(e);
        }
      });
    }
    async disconnect() {
      this.seedBroker && await this.seedBroker.disconnect();
      await Promise.all(values(this.brokers).map((broker) => broker.disconnect()));
      this.brokers = {};
      this.metadata = null;
      this.versions = null;
    }
    removeBroker({ host, port }) {
      const removedBroker = values(this.brokers).find((broker) => broker.connectionPool.host === host && broker.connectionPool.port === port);
      if (removedBroker) {
        delete this.brokers[removedBroker.nodeId];
        this.metadataExpireAt = null;
        if (this.seedBroker.nodeId === removedBroker.nodeId) {
          this.seedBroker = shuffle(values(this.brokers))[0];
        }
      }
    }
    async refreshMetadata(topics) {
      const broker = await this.findConnectedBroker();
      const { host: seedHost, port: seedPort } = this.seedBroker.connectionPool;
      return this.retrier(async (bail, retryCount, retryTime) => {
        try {
          this.metadata = await broker.metadata(topics);
          this.metadataExpireAt = Date.now() + this.metadataMaxAge;
          const replacedBrokers = [];
          this.brokers = await this.metadata.brokers.reduce(async (resultPromise, { nodeId, host, port, rack }) => {
            const result = await resultPromise;
            if (result[nodeId]) {
              if (!hasBrokerBeenReplaced(result[nodeId], { host, port, rack })) {
                return result;
              }
              replacedBrokers.push(result[nodeId]);
            }
            if (host === seedHost && port === seedPort) {
              this.seedBroker.nodeId = nodeId;
              this.seedBroker.connectionPool.rack = rack;
              return assign(result, {
                [nodeId]: this.seedBroker
              });
            }
            return assign(result, {
              [nodeId]: this.createBroker({
                logger: this.rootLogger,
                versions: this.versions,
                connectionPool: await this.connectionPoolBuilder.build({ host, port, rack }),
                nodeId
              })
            });
          }, this.brokers);
          const freshBrokerIds = this.metadata.brokers.map(({ nodeId }) => `${nodeId}`).sort();
          const currentBrokerIds = keys(this.brokers).sort();
          const unusedBrokerIds = arrayDiff(currentBrokerIds, freshBrokerIds);
          const brokerDisconnects = unusedBrokerIds.map((nodeId) => {
            const broker2 = this.brokers[nodeId];
            return broker2.disconnect().then(() => {
              delete this.brokers[nodeId];
            });
          });
          const replacedBrokersDisconnects = replacedBrokers.map((broker2) => broker2.disconnect());
          await Promise.all([...brokerDisconnects, ...replacedBrokersDisconnects]);
        } catch (e) {
          if (e.type === "LEADER_NOT_AVAILABLE") {
            throw e;
          }
          bail(e);
        }
      });
    }
    async refreshMetadataIfNecessary(topics) {
      const shouldRefresh = this.metadata == null || this.metadataExpireAt == null || Date.now() > this.metadataExpireAt || !topics.every((topic) => this.metadata.topicMetadata.some((topicMetadata) => topicMetadata.topic === topic));
      if (shouldRefresh) {
        return this.refreshMetadata(topics);
      }
    }
    getNodeIds() {
      return keys(this.brokers);
    }
    async findBroker({ nodeId }) {
      const broker = this.brokers[nodeId];
      if (!broker) {
        throw new KafkaJSBrokerNotFound(`Broker ${nodeId} not found in the cached metadata`);
      }
      await this.connectBroker(broker);
      return broker;
    }
    async withBroker(callback) {
      const brokers = shuffle(keys(this.brokers));
      if (brokers.length === 0) {
        throw new KafkaJSBrokerNotFound("No brokers in the broker pool");
      }
      for (const nodeId of brokers) {
        const broker = await this.findBroker({ nodeId });
        try {
          return await callback({ nodeId, broker });
        } catch (e) {
        }
      }
      return null;
    }
    async findConnectedBroker() {
      const nodeIds = shuffle(keys(this.brokers));
      const connectedBrokerId = nodeIds.find((nodeId) => this.brokers[nodeId].isConnected());
      if (connectedBrokerId) {
        return await this.findBroker({ nodeId: connectedBrokerId });
      }
      for (const nodeId of nodeIds) {
        try {
          return await this.findBroker({ nodeId });
        } catch (e) {
        }
      }
      await this.connect();
      return this.seedBroker;
    }
    async connectBroker(broker) {
      if (broker.isConnected()) {
        return;
      }
      return this.retrier(async (bail, retryCount, retryTime) => {
        try {
          await broker.connect();
        } catch (e) {
          if (e.name === "KafkaJSConnectionError" || e.type === "ILLEGAL_SASL_STATE") {
            await broker.disconnect();
          }
          if (e.name === "KafkaJSConnectionError") {
            return bail(e);
          }
          if (e.type === "ILLEGAL_SASL_STATE") {
            broker.connectionPool = await this.connectionPoolBuilder.build({
              host: broker.connectionPool.host,
              port: broker.connectionPool.port,
              rack: broker.connectionPool.rack
            });
            this.logger.error(`Failed to connect to broker, reconnecting`, { retryCount, retryTime });
            throw new KafkaJSProtocolError(e, { retriable: true });
          }
          if (e.retriable)
            throw e;
          this.logger.error(e, { retryCount, retryTime, stack: e.stack });
          bail(e);
        }
      });
    }
  };
});

// node_modules/kafkajs/src/utils/sharedPromiseTo.js
var require_sharedPromiseTo = __commonJS((exports, module) => {
  module.exports = (asyncFunction) => {
    let promise = null;
    return (...args) => {
      if (promise == null) {
        promise = asyncFunction(...args).finally(() => promise = null);
      }
      return promise;
    };
  };
});

// node_modules/kafkajs/src/network/socket.js
var require_socket = __commonJS((exports, module) => {
  module.exports = ({
    socketFactory,
    host,
    port,
    ssl,
    onConnect,
    onData,
    onEnd,
    onError,
    onTimeout
  }) => {
    const socket = socketFactory({ host, port, ssl, onConnect });
    socket.on("data", onData);
    socket.on("end", onEnd);
    socket.on("error", onError);
    socket.on("timeout", onTimeout);
    return socket;
  };
});

// node_modules/kafkajs/src/protocol/request.js
var require_request111 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  module.exports = async ({ correlationId, clientId, request: { apiKey, apiVersion, encode } }) => {
    const payload = await encode();
    const requestPayload = new Encoder().writeInt16(apiKey).writeInt16(apiVersion).writeInt32(correlationId).writeString(clientId).writeEncoder(payload);
    return new Encoder().writeInt32(requestPayload.size()).writeEncoder(requestPayload);
  };
});

// node_modules/kafkajs/src/constants.js
var require_constants2 = __commonJS((exports, module) => {
  var EARLIEST_OFFSET = -2;
  var LATEST_OFFSET = -1;
  var INT_32_MAX_VALUE = Math.pow(2, 31) - 1;
  module.exports = {
    EARLIEST_OFFSET,
    LATEST_OFFSET,
    INT_32_MAX_VALUE
  };
});

// node_modules/kafkajs/src/env.js
var require_env = __commonJS((exports, module) => {
  module.exports = () => ({
    KAFKAJS_DEBUG_PROTOCOL_BUFFERS: process.env.KAFKAJS_DEBUG_PROTOCOL_BUFFERS,
    KAFKAJS_DEBUG_EXTENDED_PROTOCOL_BUFFERS: process.env.KAFKAJS_DEBUG_EXTENDED_PROTOCOL_BUFFERS
  });
});

// node_modules/kafkajs/src/instrumentation/eventType.js
var require_eventType = __commonJS((exports, module) => {
  module.exports = (namespace) => (type) => `${namespace}.${type}`;
});

// node_modules/kafkajs/src/network/instrumentationEvents.js
var require_instrumentationEvents = __commonJS((exports, module) => {
  var InstrumentationEventType = require_eventType();
  var eventType = InstrumentationEventType("network");
  module.exports = {
    NETWORK_REQUEST: eventType("request"),
    NETWORK_REQUEST_TIMEOUT: eventType("request_timeout"),
    NETWORK_REQUEST_QUEUE_SIZE: eventType("request_queue_size")
  };
});

// node_modules/kafkajs/src/network/requestQueue/socketRequest.js
var require_socketRequest = __commonJS((exports, module) => {
  var { KafkaJSRequestTimeoutError, KafkaJSNonRetriableError } = require_errors2();
  var events = require_instrumentationEvents();
  var PRIVATE = {
    STATE: Symbol("private:SocketRequest:state"),
    EMIT_EVENT: Symbol("private:SocketRequest:emitEvent")
  };
  var REQUEST_STATE = {
    PENDING: Symbol("PENDING"),
    SENT: Symbol("SENT"),
    COMPLETED: Symbol("COMPLETED"),
    REJECTED: Symbol("REJECTED")
  };
  module.exports = class SocketRequest {
    constructor({
      requestTimeout,
      broker,
      clientId,
      entry,
      expectResponse,
      send,
      timeout,
      instrumentationEmitter = null
    }) {
      this.createdAt = Date.now();
      this.requestTimeout = requestTimeout;
      this.broker = broker;
      this.clientId = clientId;
      this.entry = entry;
      this.correlationId = entry.correlationId;
      this.expectResponse = expectResponse;
      this.sendRequest = send;
      this.timeoutHandler = timeout;
      this.sentAt = null;
      this.duration = null;
      this.pendingDuration = null;
      this[PRIVATE.STATE] = REQUEST_STATE.PENDING;
      this[PRIVATE.EMIT_EVENT] = (eventName, payload) => instrumentationEmitter && instrumentationEmitter.emit(eventName, payload);
    }
    send() {
      this.throwIfInvalidState({
        accepted: [REQUEST_STATE.PENDING],
        next: REQUEST_STATE.SENT
      });
      this.sendRequest();
      this.sentAt = Date.now();
      this.pendingDuration = this.sentAt - this.createdAt;
      this[PRIVATE.STATE] = REQUEST_STATE.SENT;
    }
    timeoutRequest() {
      const { apiName, apiKey, apiVersion } = this.entry;
      const requestInfo = `${apiName}(key: ${apiKey}, version: ${apiVersion})`;
      const eventData = {
        broker: this.broker,
        clientId: this.clientId,
        correlationId: this.correlationId,
        createdAt: this.createdAt,
        sentAt: this.sentAt,
        pendingDuration: this.pendingDuration
      };
      this.timeoutHandler();
      this.rejected(new KafkaJSRequestTimeoutError(`Request ${requestInfo} timed out`, eventData));
      this[PRIVATE.EMIT_EVENT](events.NETWORK_REQUEST_TIMEOUT, {
        ...eventData,
        apiName,
        apiKey,
        apiVersion
      });
    }
    completed({ size, payload }) {
      this.throwIfInvalidState({
        accepted: [REQUEST_STATE.SENT],
        next: REQUEST_STATE.COMPLETED
      });
      const { entry, correlationId, broker, clientId, createdAt, sentAt, pendingDuration } = this;
      this[PRIVATE.STATE] = REQUEST_STATE.COMPLETED;
      this.duration = Date.now() - this.sentAt;
      entry.resolve({ correlationId, entry, size, payload });
      this[PRIVATE.EMIT_EVENT](events.NETWORK_REQUEST, {
        broker,
        clientId,
        correlationId,
        size,
        createdAt,
        sentAt,
        pendingDuration,
        duration: this.duration,
        apiName: entry.apiName,
        apiKey: entry.apiKey,
        apiVersion: entry.apiVersion
      });
    }
    rejected(error) {
      this.throwIfInvalidState({
        accepted: [REQUEST_STATE.PENDING, REQUEST_STATE.SENT],
        next: REQUEST_STATE.REJECTED
      });
      this[PRIVATE.STATE] = REQUEST_STATE.REJECTED;
      this.duration = Date.now() - this.sentAt;
      this.entry.reject(error);
    }
    throwIfInvalidState({ accepted, next }) {
      if (accepted.includes(this[PRIVATE.STATE])) {
        return;
      }
      const current = this[PRIVATE.STATE].toString();
      throw new KafkaJSNonRetriableError(`Invalid state, can't transition from ${current} to ${next.toString()}`);
    }
  };
});

// node_modules/kafkajs/src/network/requestQueue/index.js
var require_requestQueue = __commonJS((exports, module) => {
  var { EventEmitter } = __require("events");
  var SocketRequest = require_socketRequest();
  var events = require_instrumentationEvents();
  var { KafkaJSInvariantViolation } = require_errors2();
  var PRIVATE = {
    EMIT_QUEUE_SIZE_EVENT: Symbol("private:RequestQueue:emitQueueSizeEvent"),
    EMIT_REQUEST_QUEUE_EMPTY: Symbol("private:RequestQueue:emitQueueEmpty")
  };
  var REQUEST_QUEUE_EMPTY = "requestQueueEmpty";
  var CHECK_PENDING_REQUESTS_INTERVAL = 10;
  module.exports = class RequestQueue extends EventEmitter {
    constructor({
      instrumentationEmitter = null,
      maxInFlightRequests,
      requestTimeout,
      enforceRequestTimeout,
      clientId,
      broker,
      logger,
      isConnected = () => true
    }) {
      super();
      this.instrumentationEmitter = instrumentationEmitter;
      this.maxInFlightRequests = maxInFlightRequests;
      this.requestTimeout = requestTimeout;
      this.enforceRequestTimeout = enforceRequestTimeout;
      this.clientId = clientId;
      this.broker = broker;
      this.logger = logger;
      this.isConnected = isConnected;
      this.inflight = new Map;
      this.pending = [];
      this.throttledUntil = -1;
      this.throttleCheckTimeoutId = null;
      this[PRIVATE.EMIT_REQUEST_QUEUE_EMPTY] = () => {
        if (this.pending.length === 0 && this.inflight.size === 0) {
          this.emit(REQUEST_QUEUE_EMPTY);
        }
      };
      this[PRIVATE.EMIT_QUEUE_SIZE_EVENT] = () => {
        instrumentationEmitter && instrumentationEmitter.emit(events.NETWORK_REQUEST_QUEUE_SIZE, {
          broker: this.broker,
          clientId: this.clientId,
          queueSize: this.pending.length
        });
        this[PRIVATE.EMIT_REQUEST_QUEUE_EMPTY]();
      };
    }
    scheduleRequestTimeoutCheck() {
      if (this.enforceRequestTimeout) {
        this.destroy();
        this.requestTimeoutIntervalId = setInterval(() => {
          this.inflight.forEach((request) => {
            if (Date.now() - request.sentAt > request.requestTimeout) {
              request.timeoutRequest();
            }
          });
          if (!this.isConnected()) {
            this.destroy();
          }
        }, Math.min(this.requestTimeout, 100));
      }
    }
    maybeThrottle(clientSideThrottleTime) {
      if (clientSideThrottleTime !== null && clientSideThrottleTime > 0) {
        this.logger.debug(`Client side throttling in effect for ${clientSideThrottleTime}ms`);
        const minimumThrottledUntil = Date.now() + clientSideThrottleTime;
        this.throttledUntil = Math.max(minimumThrottledUntil, this.throttledUntil);
      }
    }
    createSocketRequest(pushedRequest) {
      const { correlationId } = pushedRequest.entry;
      const defaultRequestTimeout = this.requestTimeout;
      const customRequestTimeout = pushedRequest.requestTimeout;
      const requestTimeout = Math.max(defaultRequestTimeout, customRequestTimeout || 0);
      const socketRequest = new SocketRequest({
        entry: pushedRequest.entry,
        expectResponse: pushedRequest.expectResponse,
        broker: this.broker,
        clientId: this.clientId,
        instrumentationEmitter: this.instrumentationEmitter,
        requestTimeout,
        send: () => {
          if (this.inflight.has(correlationId)) {
            throw new KafkaJSInvariantViolation("Correlation id already exists");
          }
          this.inflight.set(correlationId, socketRequest);
          pushedRequest.sendRequest();
        },
        timeout: () => {
          this.inflight.delete(correlationId);
          this.checkPendingRequests();
          this[PRIVATE.EMIT_REQUEST_QUEUE_EMPTY]();
        }
      });
      return socketRequest;
    }
    push(pushedRequest) {
      const { correlationId } = pushedRequest.entry;
      const socketRequest = this.createSocketRequest(pushedRequest);
      if (this.canSendSocketRequestImmediately()) {
        this.sendSocketRequest(socketRequest);
        return;
      }
      this.pending.push(socketRequest);
      this.scheduleCheckPendingRequests();
      this.logger.debug(`Request enqueued`, {
        clientId: this.clientId,
        broker: this.broker,
        correlationId
      });
      this[PRIVATE.EMIT_QUEUE_SIZE_EVENT]();
    }
    sendSocketRequest(socketRequest) {
      socketRequest.send();
      if (!socketRequest.expectResponse) {
        this.logger.debug(`Request does not expect a response, resolving immediately`, {
          clientId: this.clientId,
          broker: this.broker,
          correlationId: socketRequest.correlationId
        });
        this.inflight.delete(socketRequest.correlationId);
        socketRequest.completed({ size: 0, payload: null });
      }
    }
    fulfillRequest({ correlationId, payload, size }) {
      const socketRequest = this.inflight.get(correlationId);
      this.inflight.delete(correlationId);
      this.checkPendingRequests();
      if (socketRequest) {
        socketRequest.completed({ size, payload });
      } else {
        this.logger.warn(`Response without match`, {
          clientId: this.clientId,
          broker: this.broker,
          correlationId
        });
      }
      this[PRIVATE.EMIT_REQUEST_QUEUE_EMPTY]();
    }
    rejectAll(error) {
      const requests = [...this.inflight.values(), ...this.pending];
      for (const socketRequest of requests) {
        socketRequest.rejected(error);
        this.inflight.delete(socketRequest.correlationId);
      }
      this.pending = [];
      this.inflight.clear();
      this[PRIVATE.EMIT_QUEUE_SIZE_EVENT]();
    }
    waitForPendingRequests() {
      return new Promise((resolve) => {
        if (this.pending.length === 0 && this.inflight.size === 0) {
          return resolve();
        }
        this.logger.debug("Waiting for pending requests", {
          clientId: this.clientId,
          broker: this.broker,
          currentInflightRequests: this.inflight.size,
          currentPendingQueueSize: this.pending.length
        });
        this.once(REQUEST_QUEUE_EMPTY, () => resolve());
      });
    }
    destroy() {
      clearInterval(this.requestTimeoutIntervalId);
      clearTimeout(this.throttleCheckTimeoutId);
      this.throttleCheckTimeoutId = null;
    }
    canSendSocketRequestImmediately() {
      const shouldEnqueue = this.maxInFlightRequests != null && this.inflight.size >= this.maxInFlightRequests || this.throttledUntil > Date.now();
      return !shouldEnqueue;
    }
    checkPendingRequests() {
      while (this.pending.length > 0 && this.canSendSocketRequestImmediately()) {
        const pendingRequest = this.pending.shift();
        this.sendSocketRequest(pendingRequest);
        this.logger.debug(`Consumed pending request`, {
          clientId: this.clientId,
          broker: this.broker,
          correlationId: pendingRequest.correlationId,
          pendingDuration: pendingRequest.pendingDuration,
          currentPendingQueueSize: this.pending.length
        });
        this[PRIVATE.EMIT_QUEUE_SIZE_EVENT]();
      }
      this.scheduleCheckPendingRequests();
    }
    scheduleCheckPendingRequests() {
      let scheduleAt = this.throttledUntil - Date.now();
      if (!this.throttleCheckTimeoutId) {
        if (this.pending.length > 0) {
          scheduleAt = scheduleAt > 0 ? scheduleAt : CHECK_PENDING_REQUESTS_INTERVAL;
        }
        this.throttleCheckTimeoutId = setTimeout(() => {
          this.throttleCheckTimeoutId = null;
          this.checkPendingRequests();
        }, scheduleAt);
      }
    }
  };
});

// node_modules/kafkajs/src/network/connectionStatus.js
var require_connectionStatus = __commonJS((exports, module) => {
  var CONNECTION_STATUS = {
    CONNECTED: "connected",
    DISCONNECTING: "disconnecting",
    DISCONNECTED: "disconnected"
  };
  var CONNECTED_STATUS = [CONNECTION_STATUS.CONNECTED, CONNECTION_STATUS.DISCONNECTING];
  module.exports = {
    CONNECTION_STATUS,
    CONNECTED_STATUS
  };
});

// node_modules/kafkajs/src/protocol/sasl/plain/request.js
var require_request112 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var US_ASCII_NULL_CHAR = "\0";
  module.exports = ({ authorizationIdentity = null, username, password }) => ({
    encode: async () => {
      return new Encoder().writeBytes([authorizationIdentity, username, password].join(US_ASCII_NULL_CHAR)).buffer;
    }
  });
});

// node_modules/kafkajs/src/protocol/sasl/plain/response.js
var require_response111 = __commonJS((exports, module) => {
  module.exports = {
    decode: async () => true,
    parse: async () => true
  };
});

// node_modules/kafkajs/src/protocol/sasl/plain/index.js
var require_plain = __commonJS((exports, module) => {
  module.exports = {
    request: require_request112(),
    response: require_response111()
  };
});

// node_modules/kafkajs/src/broker/saslAuthenticator/plain.js
var require_plain2 = __commonJS((exports, module) => {
  var { request, response } = require_plain();
  var { KafkaJSSASLAuthenticationError } = require_errors2();
  var plainAuthenticatorProvider = (sasl) => ({ host, port, logger, saslAuthenticate }) => {
    return {
      authenticate: async () => {
        if (sasl.username == null || sasl.password == null) {
          throw new KafkaJSSASLAuthenticationError("SASL Plain: Invalid username or password");
        }
        const broker = `${host}:${port}`;
        try {
          logger.debug("Authenticate with SASL PLAIN", { broker });
          await saslAuthenticate({ request: request(sasl), response });
          logger.debug("SASL PLAIN authentication successful", { broker });
        } catch (e) {
          const error = new KafkaJSSASLAuthenticationError(`SASL PLAIN authentication failed: ${e.message}`);
          logger.error(error.message, { broker });
          throw error;
        }
      }
    };
  };
  module.exports = plainAuthenticatorProvider;
});

// node_modules/kafkajs/src/protocol/sasl/scram/firstMessage/request.js
var require_request113 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  module.exports = ({ clientFirstMessage }) => ({
    encode: async () => new Encoder().writeBytes(clientFirstMessage).buffer
  });
});

// node_modules/kafkajs/src/protocol/sasl/scram/firstMessage/response.js
var require_response112 = __commonJS((exports, module) => {
  var Decoder = require_decoder();
  var ENTRY_REGEX = /^([rsiev])=(.*)$/;
  module.exports = {
    decode: async (rawData) => {
      return new Decoder(rawData).readBytes();
    },
    parse: async (data) => {
      const processed = data.toString().split(",").map((str) => {
        const [_, key, value] = str.match(ENTRY_REGEX);
        return [key, value];
      }).reduce((obj, entry) => ({ ...obj, [entry[0]]: entry[1] }), {});
      return { original: data.toString(), ...processed };
    }
  };
});

// node_modules/kafkajs/src/protocol/sasl/scram/finalMessage/request.js
var require_request114 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  module.exports = ({ finalMessage }) => ({
    encode: async () => new Encoder().writeBytes(finalMessage).buffer
  });
});

// node_modules/kafkajs/src/protocol/sasl/scram/index.js
var require_scram = __commonJS((exports, module) => {
  module.exports = {
    firstMessage: {
      request: require_request113(),
      response: require_response112()
    },
    finalMessage: {
      request: require_request114(),
      response: require_response112()
    }
  };
});

// node_modules/kafkajs/src/broker/saslAuthenticator/scram.js
var require_scram2 = __commonJS((exports, module) => {
  var crypto = __require("crypto");
  var scram = require_scram();
  var { KafkaJSSASLAuthenticationError, KafkaJSNonRetriableError } = require_errors2();
  var GS2_HEADER = "n,,";
  var EQUAL_SIGN_REGEX = /=/g;
  var COMMA_SIGN_REGEX = /,/g;
  var URLSAFE_BASE64_PLUS_REGEX = /\+/g;
  var URLSAFE_BASE64_SLASH_REGEX = /\//g;
  var URLSAFE_BASE64_TRAILING_EQUAL_REGEX = /=+$/;
  var HMAC_CLIENT_KEY = "Client Key";
  var HMAC_SERVER_KEY = "Server Key";
  var DIGESTS = {
    SHA256: {
      length: 32,
      type: "sha256",
      minIterations: 4096
    },
    SHA512: {
      length: 64,
      type: "sha512",
      minIterations: 4096
    }
  };
  var encode64 = (str) => Buffer.from(str).toString("base64");

  class SCRAM {
    static sanitizeString(str) {
      return str.replace(EQUAL_SIGN_REGEX, "=3D").replace(COMMA_SIGN_REGEX, "=2C");
    }
    static nonce() {
      return crypto.randomBytes(16).toString("base64").replace(URLSAFE_BASE64_PLUS_REGEX, "-").replace(URLSAFE_BASE64_SLASH_REGEX, "_").replace(URLSAFE_BASE64_TRAILING_EQUAL_REGEX, "").toString("ascii");
    }
    static hi(password, salt, iterations, digestDefinition) {
      return new Promise((resolve, reject) => {
        crypto.pbkdf2(password, salt, iterations, digestDefinition.length, digestDefinition.type, (err, derivedKey) => err ? reject(err) : resolve(derivedKey));
      });
    }
    static xor(left, right) {
      const bufferA = Buffer.from(left);
      const bufferB = Buffer.from(right);
      const length = Buffer.byteLength(bufferA);
      if (length !== Buffer.byteLength(bufferB)) {
        throw new KafkaJSNonRetriableError("Buffers must be of the same length");
      }
      const result = [];
      for (let i = 0;i < length; i++) {
        result.push(bufferA[i] ^ bufferB[i]);
      }
      return Buffer.from(result);
    }
    constructor(sasl, host, port, logger, saslAuthenticate, digestDefinition) {
      this.sasl = sasl;
      this.host = host;
      this.port = port;
      this.logger = logger;
      this.saslAuthenticate = saslAuthenticate;
      this.digestDefinition = digestDefinition;
      const digestType = digestDefinition.type.toUpperCase();
      this.PREFIX = `SASL SCRAM ${digestType} authentication`;
      this.currentNonce = SCRAM.nonce();
    }
    async authenticate() {
      const { PREFIX } = this;
      const broker = `${this.host}:${this.port}`;
      if (this.sasl.username == null || this.sasl.password == null) {
        throw new KafkaJSSASLAuthenticationError(`${this.PREFIX}: Invalid username or password`);
      }
      try {
        this.logger.debug("Exchanging first client message", { broker });
        const clientMessageResponse = await this.sendClientFirstMessage();
        this.logger.debug("Sending final message", { broker });
        const finalResponse = await this.sendClientFinalMessage(clientMessageResponse);
        if (finalResponse.e) {
          throw new Error(finalResponse.e);
        }
        const serverKey = await this.serverKey(clientMessageResponse);
        const serverSignature = this.serverSignature(serverKey, clientMessageResponse);
        if (finalResponse.v !== serverSignature) {
          throw new Error("Invalid server signature in server final message");
        }
        this.logger.debug(`${PREFIX} successful`, { broker });
      } catch (e) {
        const error = new KafkaJSSASLAuthenticationError(`${PREFIX} failed: ${e.message}`);
        this.logger.error(error.message, { broker });
        throw error;
      }
    }
    async sendClientFirstMessage() {
      const clientFirstMessage = `${GS2_HEADER}${this.firstMessageBare()}`;
      const request = scram.firstMessage.request({ clientFirstMessage });
      const response = scram.firstMessage.response;
      return this.saslAuthenticate({
        request,
        response
      });
    }
    async sendClientFinalMessage(clientMessageResponse) {
      const { PREFIX } = this;
      const iterations = parseInt(clientMessageResponse.i, 10);
      const { minIterations } = this.digestDefinition;
      if (!clientMessageResponse.r.startsWith(this.currentNonce)) {
        throw new KafkaJSSASLAuthenticationError(`${PREFIX} failed: Invalid server nonce, it does not start with the client nonce`);
      }
      if (iterations < minIterations) {
        throw new KafkaJSSASLAuthenticationError(`${PREFIX} failed: Requested iterations ${iterations} is less than the minimum ${minIterations}`);
      }
      const finalMessageWithoutProof = this.finalMessageWithoutProof(clientMessageResponse);
      const clientProof = await this.clientProof(clientMessageResponse);
      const finalMessage = `${finalMessageWithoutProof},p=${clientProof}`;
      const request = scram.finalMessage.request({ finalMessage });
      const response = scram.finalMessage.response;
      return this.saslAuthenticate({
        request,
        response
      });
    }
    async clientProof(clientMessageResponse) {
      const clientKey = await this.clientKey(clientMessageResponse);
      const storedKey = this.H(clientKey);
      const clientSignature = this.clientSignature(storedKey, clientMessageResponse);
      return encode64(SCRAM.xor(clientKey, clientSignature));
    }
    async clientKey(clientMessageResponse) {
      const saltedPassword = await this.saltPassword(clientMessageResponse);
      return this.HMAC(saltedPassword, HMAC_CLIENT_KEY);
    }
    async serverKey(clientMessageResponse) {
      const saltedPassword = await this.saltPassword(clientMessageResponse);
      return this.HMAC(saltedPassword, HMAC_SERVER_KEY);
    }
    clientSignature(storedKey, clientMessageResponse) {
      return this.HMAC(storedKey, this.authMessage(clientMessageResponse));
    }
    serverSignature(serverKey, clientMessageResponse) {
      return encode64(this.HMAC(serverKey, this.authMessage(clientMessageResponse)));
    }
    authMessage(clientMessageResponse) {
      return [
        this.firstMessageBare(),
        clientMessageResponse.original,
        this.finalMessageWithoutProof(clientMessageResponse)
      ].join(",");
    }
    async saltPassword(clientMessageResponse) {
      const salt = Buffer.from(clientMessageResponse.s, "base64");
      const iterations = parseInt(clientMessageResponse.i, 10);
      return SCRAM.hi(this.encodedPassword(), salt, iterations, this.digestDefinition);
    }
    firstMessageBare() {
      return `n=${this.encodedUsername()},r=${this.currentNonce}`;
    }
    finalMessageWithoutProof(clientMessageResponse) {
      const rnonce = clientMessageResponse.r;
      return `c=${encode64(GS2_HEADER)},r=${rnonce}`;
    }
    encodedUsername() {
      const { username } = this.sasl;
      return SCRAM.sanitizeString(username).toString("utf-8");
    }
    encodedPassword() {
      const { password } = this.sasl;
      return password.toString("utf-8");
    }
    H(data) {
      return crypto.createHash(this.digestDefinition.type).update(data).digest();
    }
    HMAC(key, data) {
      return crypto.createHmac(this.digestDefinition.type, key).update(data).digest();
    }
  }
  module.exports = {
    DIGESTS,
    SCRAM
  };
});

// node_modules/kafkajs/src/broker/saslAuthenticator/scram256.js
var require_scram256 = __commonJS((exports, module) => {
  var { SCRAM, DIGESTS } = require_scram2();
  var scram256AuthenticatorProvider = (sasl) => ({ host, port, logger, saslAuthenticate }) => {
    const scram = new SCRAM(sasl, host, port, logger, saslAuthenticate, DIGESTS.SHA256);
    return {
      authenticate: async () => await scram.authenticate()
    };
  };
  module.exports = scram256AuthenticatorProvider;
});

// node_modules/kafkajs/src/broker/saslAuthenticator/scram512.js
var require_scram512 = __commonJS((exports, module) => {
  var { SCRAM, DIGESTS } = require_scram2();
  var scram512AuthenticatorProvider = (sasl) => ({ host, port, logger, saslAuthenticate }) => {
    const scram = new SCRAM(sasl, host, port, logger, saslAuthenticate, DIGESTS.SHA512);
    return {
      authenticate: async () => await scram.authenticate()
    };
  };
  module.exports = scram512AuthenticatorProvider;
});

// node_modules/kafkajs/src/protocol/sasl/awsIam/request.js
var require_request115 = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var US_ASCII_NULL_CHAR = "\0";
  module.exports = ({ authorizationIdentity, accessKeyId, secretAccessKey, sessionToken = "" }) => ({
    encode: async () => {
      return new Encoder().writeBytes([authorizationIdentity, accessKeyId, secretAccessKey, sessionToken].join(US_ASCII_NULL_CHAR)).buffer;
    }
  });
});

// node_modules/kafkajs/src/protocol/sasl/awsIam/response.js
var require_response113 = __commonJS((exports, module) => {
  module.exports = {
    decode: async () => true,
    parse: async () => true
  };
});

// node_modules/kafkajs/src/protocol/sasl/awsIam/index.js
var require_awsIam = __commonJS((exports, module) => {
  module.exports = {
    request: require_request115(),
    response: require_response113()
  };
});

// node_modules/kafkajs/src/broker/saslAuthenticator/awsIam.js
var require_awsIam2 = __commonJS((exports, module) => {
  var { request, response } = require_awsIam();
  var { KafkaJSSASLAuthenticationError } = require_errors2();
  var awsIAMAuthenticatorProvider = (sasl) => ({ host, port, logger, saslAuthenticate }) => {
    return {
      authenticate: async () => {
        if (!sasl.authorizationIdentity) {
          throw new KafkaJSSASLAuthenticationError("SASL AWS-IAM: Missing authorizationIdentity");
        }
        if (!sasl.accessKeyId) {
          throw new KafkaJSSASLAuthenticationError("SASL AWS-IAM: Missing accessKeyId");
        }
        if (!sasl.secretAccessKey) {
          throw new KafkaJSSASLAuthenticationError("SASL AWS-IAM: Missing secretAccessKey");
        }
        if (!sasl.sessionToken) {
          sasl.sessionToken = "";
        }
        const broker = `${host}:${port}`;
        try {
          logger.debug("Authenticate with SASL AWS-IAM", { broker });
          await saslAuthenticate({ request: request(sasl), response });
          logger.debug("SASL AWS-IAM authentication successful", { broker });
        } catch (e) {
          const error = new KafkaJSSASLAuthenticationError(`SASL AWS-IAM authentication failed: ${e.message}`);
          logger.error(error.message, { broker });
          throw error;
        }
      }
    };
  };
  module.exports = awsIAMAuthenticatorProvider;
});

// node_modules/kafkajs/src/protocol/sasl/oauthBearer/request.js
var require_request116 = __commonJS((exports, module) => {
  var formatExtensions = function(extensions) {
    let msg = "";
    if (extensions == null) {
      return msg;
    }
    let prefix = "";
    for (const k in extensions) {
      msg += `${prefix}${k}=${extensions[k]}`;
      prefix = SEPARATOR;
    }
    return msg;
  };
  var Encoder = require_encoder();
  var SEPARATOR = "\x01";
  module.exports = async ({ authorizationIdentity = null }, oauthBearerToken) => {
    const authzid = authorizationIdentity == null ? "" : `"a=${authorizationIdentity}`;
    let ext = formatExtensions(oauthBearerToken.extensions);
    if (ext.length > 0) {
      ext = `${SEPARATOR}${ext}`;
    }
    const oauthMsg = `n,${authzid},${SEPARATOR}auth=Bearer ${oauthBearerToken.value}${ext}${SEPARATOR}${SEPARATOR}`;
    return {
      encode: async () => {
        return new Encoder().writeBytes(Buffer.from(oauthMsg)).buffer;
      }
    };
  };
});

// node_modules/kafkajs/src/protocol/sasl/oauthBearer/response.js
var require_response114 = __commonJS((exports, module) => {
  module.exports = {
    decode: async () => true,
    parse: async () => true
  };
});

// node_modules/kafkajs/src/protocol/sasl/oauthBearer/index.js
var require_oauthBearer = __commonJS((exports, module) => {
  module.exports = {
    request: require_request116(),
    response: require_response114()
  };
});

// node_modules/kafkajs/src/broker/saslAuthenticator/oauthBearer.js
var require_oauthBearer2 = __commonJS((exports, module) => {
  var { request } = require_oauthBearer();
  var { KafkaJSSASLAuthenticationError } = require_errors2();
  var oauthBearerAuthenticatorProvider = (sasl) => ({ host, port, logger, saslAuthenticate }) => {
    return {
      authenticate: async () => {
        const { oauthBearerProvider } = sasl;
        if (oauthBearerProvider == null) {
          throw new KafkaJSSASLAuthenticationError("SASL OAUTHBEARER: Missing OAuth bearer token provider");
        }
        const oauthBearerToken = await oauthBearerProvider();
        if (oauthBearerToken.value == null) {
          throw new KafkaJSSASLAuthenticationError("SASL OAUTHBEARER: Invalid OAuth bearer token");
        }
        const broker = `${host}:${port}`;
        try {
          logger.debug("Authenticate with SASL OAUTHBEARER", { broker });
          await saslAuthenticate({ request: await request(sasl, oauthBearerToken) });
          logger.debug("SASL OAUTHBEARER authentication successful", { broker });
        } catch (e) {
          const error = new KafkaJSSASLAuthenticationError(`SASL OAUTHBEARER authentication failed: ${e.message}`);
          logger.error(error.message, { broker });
          throw error;
        }
      }
    };
  };
  module.exports = oauthBearerAuthenticatorProvider;
});

// node_modules/kafkajs/src/broker/saslAuthenticator/index.js
var require_saslAuthenticator = __commonJS((exports, module) => {
  var { requests, lookup } = require_requests();
  var apiKeys = require_apiKeys();
  var plainAuthenticatorProvider = require_plain2();
  var scram256AuthenticatorProvider = require_scram256();
  var scram512AuthenticatorProvider = require_scram512();
  var awsIAMAuthenticatorProvider = require_awsIam2();
  var oauthBearerAuthenticatorProvider = require_oauthBearer2();
  var { KafkaJSSASLAuthenticationError } = require_errors2();
  var BUILT_IN_AUTHENTICATION_PROVIDERS = {
    AWS: awsIAMAuthenticatorProvider,
    PLAIN: plainAuthenticatorProvider,
    OAUTHBEARER: oauthBearerAuthenticatorProvider,
    "SCRAM-SHA-256": scram256AuthenticatorProvider,
    "SCRAM-SHA-512": scram512AuthenticatorProvider
  };
  var UNLIMITED_SESSION_LIFETIME = "0";
  module.exports = class SASLAuthenticator {
    constructor(connection, logger, versions, supportAuthenticationProtocol) {
      this.connection = connection;
      this.logger = logger;
      this.sessionLifetime = UNLIMITED_SESSION_LIFETIME;
      const lookupRequest = lookup(versions);
      this.saslHandshake = lookupRequest(apiKeys.SaslHandshake, requests.SaslHandshake);
      this.protocolAuthentication = supportAuthenticationProtocol ? lookupRequest(apiKeys.SaslAuthenticate, requests.SaslAuthenticate) : null;
    }
    async authenticate() {
      const mechanism = this.connection.sasl.mechanism.toUpperCase();
      const handshake = await this.connection.send(this.saslHandshake({ mechanism }));
      if (!handshake.enabledMechanisms.includes(mechanism)) {
        throw new KafkaJSSASLAuthenticationError(`SASL ${mechanism} mechanism is not supported by the server`);
      }
      const saslAuthenticate = async ({ request, response }) => {
        if (this.protocolAuthentication) {
          const requestAuthBytes = await request.encode();
          const authResponse = await this.connection.send(this.protocolAuthentication({ authBytes: requestAuthBytes }));
          this.sessionLifetime = authResponse.sessionLifetimeMs || UNLIMITED_SESSION_LIFETIME;
          if (!response) {
            return;
          }
          const { authBytes: responseAuthBytes } = authResponse;
          const payloadDecoded = await response.decode(responseAuthBytes);
          return response.parse(payloadDecoded);
        }
        return this.connection.sendAuthRequest({ request, response });
      };
      if (!this.connection.sasl.authenticationProvider && Object.keys(BUILT_IN_AUTHENTICATION_PROVIDERS).includes(mechanism)) {
        this.connection.sasl.authenticationProvider = BUILT_IN_AUTHENTICATION_PROVIDERS[mechanism](this.connection.sasl);
      }
      await this.connection.sasl.authenticationProvider({
        host: this.connection.host,
        port: this.connection.port,
        logger: this.logger.namespace(`SaslAuthenticator-${mechanism}`),
        saslAuthenticate
      }).authenticate();
    }
  };
});

// node_modules/kafkajs/src/network/connection.js
var require_connection = __commonJS((exports, module) => {
  var createSocket = require_socket();
  var createRequest = require_request111();
  var Decoder = require_decoder();
  var { KafkaJSConnectionError, KafkaJSConnectionClosedError } = require_errors2();
  var { INT_32_MAX_VALUE } = require_constants2();
  var getEnv = require_env();
  var RequestQueue = require_requestQueue();
  var { CONNECTION_STATUS, CONNECTED_STATUS } = require_connectionStatus();
  var sharedPromiseTo = require_sharedPromiseTo();
  var Long = require_long();
  var SASLAuthenticator = require_saslAuthenticator();
  var apiKeys = require_apiKeys();
  var requestInfo = ({ apiName, apiKey, apiVersion }) => `${apiName}(key: ${apiKey}, version: ${apiVersion})`;
  var isAuthenticatedRequest = (request) => {
    return ![apiKeys.ApiVersions, apiKeys.SaslHandshake, apiKeys.SaslAuthenticate].includes(request.apiKey);
  };
  var PRIVATE = {
    SHOULD_REAUTHENTICATE: Symbol("private:Connection:shouldReauthenticate"),
    AUTHENTICATE: Symbol("private:Connection:authenticate")
  };
  module.exports = class Connection {
    constructor({
      host,
      port,
      logger,
      socketFactory,
      requestTimeout,
      reauthenticationThreshold = 1e4,
      rack = null,
      ssl = null,
      sasl = null,
      clientId = "kafkajs",
      connectionTimeout,
      enforceRequestTimeout = true,
      maxInFlightRequests = null,
      instrumentationEmitter = null
    }) {
      this.host = host;
      this.port = port;
      this.rack = rack;
      this.clientId = clientId;
      this.broker = `${this.host}:${this.port}`;
      this.logger = logger.namespace("Connection");
      this.socketFactory = socketFactory;
      this.ssl = ssl;
      this.sasl = sasl;
      this.requestTimeout = requestTimeout;
      this.connectionTimeout = connectionTimeout;
      this.reauthenticationThreshold = reauthenticationThreshold;
      this.bytesBuffered = 0;
      this.bytesNeeded = Decoder.int32Size();
      this.chunks = [];
      this.connectionStatus = CONNECTION_STATUS.DISCONNECTED;
      this.correlationId = 0;
      this.requestQueue = new RequestQueue({
        instrumentationEmitter,
        maxInFlightRequests,
        requestTimeout,
        enforceRequestTimeout,
        clientId,
        broker: this.broker,
        logger: logger.namespace("RequestQueue"),
        isConnected: () => this.isConnected()
      });
      this.versions = null;
      this.authHandlers = null;
      this.authExpectResponse = false;
      const log = (level) => (message, extra = {}) => {
        const logFn = this.logger[level];
        logFn(message, { broker: this.broker, clientId, ...extra });
      };
      this.logDebug = log("debug");
      this.logError = log("error");
      const env = getEnv();
      this.shouldLogBuffers = env.KAFKAJS_DEBUG_PROTOCOL_BUFFERS === "1";
      this.shouldLogFetchBuffer = this.shouldLogBuffers && env.KAFKAJS_DEBUG_EXTENDED_PROTOCOL_BUFFERS === "1";
      this.authenticatedAt = null;
      this.sessionLifetime = Long.ZERO;
      this.supportAuthenticationProtocol = null;
      this[PRIVATE.AUTHENTICATE] = sharedPromiseTo(async () => {
        if (this.sasl && !this.isAuthenticated()) {
          const authenticator = new SASLAuthenticator(this, this.logger, this.versions, this.supportAuthenticationProtocol);
          await authenticator.authenticate();
          this.authenticatedAt = process.hrtime();
          this.sessionLifetime = Long.fromValue(authenticator.sessionLifetime);
        }
      });
    }
    getSupportAuthenticationProtocol() {
      return this.supportAuthenticationProtocol;
    }
    setSupportAuthenticationProtocol(isSupported) {
      this.supportAuthenticationProtocol = isSupported;
    }
    setVersions(versions) {
      this.versions = versions;
    }
    isConnected() {
      return CONNECTED_STATUS.includes(this.connectionStatus);
    }
    connect() {
      return new Promise((resolve, reject) => {
        if (this.isConnected()) {
          return resolve(true);
        }
        this.authenticatedAt = null;
        let timeoutId;
        const onConnect = () => {
          clearTimeout(timeoutId);
          this.connectionStatus = CONNECTION_STATUS.CONNECTED;
          this.requestQueue.scheduleRequestTimeoutCheck();
          resolve(true);
        };
        const onData = (data) => {
          this.processData(data);
        };
        const onEnd = async () => {
          clearTimeout(timeoutId);
          const wasConnected = this.isConnected();
          if (this.authHandlers) {
            this.authHandlers.onError();
          } else if (wasConnected) {
            this.logDebug("Kafka server has closed connection");
            this.rejectRequests(new KafkaJSConnectionClosedError("Closed connection", {
              host: this.host,
              port: this.port
            }));
          }
          await this.disconnect();
        };
        const onError = async (e) => {
          clearTimeout(timeoutId);
          const error = new KafkaJSConnectionError(`Connection error: ${e.message}`, {
            broker: `${this.host}:${this.port}`,
            code: e.code
          });
          this.logError(error.message, { stack: e.stack });
          this.rejectRequests(error);
          await this.disconnect();
          reject(error);
        };
        const onTimeout = async () => {
          const error = new KafkaJSConnectionError("Connection timeout", {
            broker: `${this.host}:${this.port}`
          });
          this.logError(error.message);
          this.rejectRequests(error);
          await this.disconnect();
          reject(error);
        };
        this.logDebug(`Connecting`, {
          ssl: !!this.ssl,
          sasl: !!this.sasl
        });
        try {
          timeoutId = setTimeout(onTimeout, this.connectionTimeout);
          this.socket = createSocket({
            socketFactory: this.socketFactory,
            host: this.host,
            port: this.port,
            ssl: this.ssl,
            onConnect,
            onData,
            onEnd,
            onError,
            onTimeout
          });
        } catch (e) {
          clearTimeout(timeoutId);
          reject(new KafkaJSConnectionError(`Failed to connect: ${e.message}`, {
            broker: `${this.host}:${this.port}`
          }));
        }
      });
    }
    async disconnect() {
      this.authenticatedAt = null;
      this.connectionStatus = CONNECTION_STATUS.DISCONNECTING;
      this.logDebug("disconnecting...");
      await this.requestQueue.waitForPendingRequests();
      this.requestQueue.destroy();
      if (this.socket) {
        this.socket.end();
        this.socket.unref();
      }
      this.connectionStatus = CONNECTION_STATUS.DISCONNECTED;
      this.logDebug("disconnected");
      return true;
    }
    isAuthenticated() {
      return this.authenticatedAt != null && !this[PRIVATE.SHOULD_REAUTHENTICATE]();
    }
    [PRIVATE.SHOULD_REAUTHENTICATE]() {
      if (this.sessionLifetime.equals(Long.ZERO)) {
        return false;
      }
      if (this.authenticatedAt == null) {
        return true;
      }
      const [secondsSince, remainingNanosSince] = process.hrtime(this.authenticatedAt);
      const millisSince = Long.fromValue(secondsSince).multiply(1000).add(Long.fromValue(remainingNanosSince).divide(1e6));
      const reauthenticateAt = millisSince.add(this.reauthenticationThreshold);
      return reauthenticateAt.greaterThanOrEqual(this.sessionLifetime);
    }
    async authenticate() {
      await this[PRIVATE.AUTHENTICATE]();
    }
    sendAuthRequest({ request, response }) {
      this.authExpectResponse = !!response;
      return new Promise(async (resolve, reject) => {
        this.authHandlers = {
          onSuccess: (rawData) => {
            this.authHandlers = null;
            this.authExpectResponse = false;
            response.decode(rawData).then((data) => response.parse(data)).then(resolve).catch(reject);
          },
          onError: () => {
            this.authHandlers = null;
            this.authExpectResponse = false;
            reject(new KafkaJSConnectionError("Connection closed by the server", {
              broker: `${this.host}:${this.port}`
            }));
          }
        };
        try {
          const requestPayload = await request.encode();
          this.failIfNotConnected();
          this.socket.write(requestPayload, "binary");
        } catch (e) {
          reject(e);
        }
      });
    }
    async send({ request, response, requestTimeout = null, logResponseError = true }) {
      if (!this.isAuthenticated() && isAuthenticatedRequest(request)) {
        await this[PRIVATE.AUTHENTICATE]();
      }
      this.failIfNotConnected();
      const expectResponse = !request.expectResponse || request.expectResponse();
      const sendRequest = async () => {
        const { clientId } = this;
        const correlationId2 = this.nextCorrelationId();
        const requestPayload = await createRequest({ request, correlationId: correlationId2, clientId });
        const { apiKey, apiName, apiVersion } = request;
        this.logDebug(`Request ${requestInfo(request)}`, {
          correlationId: correlationId2,
          expectResponse,
          size: Buffer.byteLength(requestPayload.buffer)
        });
        return new Promise((resolve, reject) => {
          try {
            this.failIfNotConnected();
            const entry2 = { apiKey, apiName, apiVersion, correlationId: correlationId2, resolve, reject };
            this.requestQueue.push({
              entry: entry2,
              expectResponse,
              requestTimeout,
              sendRequest: () => {
                this.socket.write(requestPayload.buffer, "binary");
              }
            });
          } catch (e) {
            reject(e);
          }
        });
      };
      const { correlationId, size, entry, payload } = await sendRequest();
      if (!expectResponse) {
        return;
      }
      try {
        const payloadDecoded = await response.decode(payload);
        this.requestQueue.maybeThrottle(payloadDecoded.clientSideThrottleTime);
        const data = await response.parse(payloadDecoded);
        const isFetchApi = entry.apiName === "Fetch";
        this.logDebug(`Response ${requestInfo(entry)}`, {
          correlationId,
          size,
          data: isFetchApi && !this.shouldLogFetchBuffer ? "[filtered]" : data
        });
        return data;
      } catch (e) {
        if (logResponseError) {
          this.logError(`Response ${requestInfo(entry)}`, {
            error: e.message,
            correlationId,
            size
          });
        }
        const isBuffer = Buffer.isBuffer(payload);
        this.logDebug(`Response ${requestInfo(entry)}`, {
          error: e.message,
          correlationId,
          payload: isBuffer && !this.shouldLogBuffers ? { type: "Buffer", data: "[filtered]" } : payload
        });
        throw e;
      }
    }
    failIfNotConnected() {
      if (!this.isConnected()) {
        throw new KafkaJSConnectionError("Not connected", {
          broker: `${this.host}:${this.port}`
        });
      }
    }
    nextCorrelationId() {
      if (this.correlationId >= INT_32_MAX_VALUE) {
        this.correlationId = 0;
      }
      return this.correlationId++;
    }
    processData(rawData) {
      if (this.authHandlers && !this.authExpectResponse) {
        return this.authHandlers.onSuccess(rawData);
      }
      this.chunks.push(rawData);
      this.bytesBuffered += Buffer.byteLength(rawData);
      while (this.bytesNeeded <= this.bytesBuffered) {
        const buffer = this.chunks.length > 1 ? Buffer.concat(this.chunks) : this.chunks[0];
        const decoder = new Decoder(buffer);
        const expectedResponseSize = decoder.readInt32();
        if (!decoder.canReadBytes(expectedResponseSize)) {
          this.chunks = [buffer];
          this.bytesBuffered = Buffer.byteLength(buffer);
          this.bytesNeeded = Decoder.int32Size() + expectedResponseSize;
          return;
        }
        const response = new Decoder(decoder.readBytes(expectedResponseSize));
        const remainderBuffer = decoder.readAll();
        this.chunks = [remainderBuffer];
        this.bytesBuffered = Buffer.byteLength(remainderBuffer);
        this.bytesNeeded = Decoder.int32Size();
        if (this.authHandlers) {
          const rawResponseSize = Decoder.int32Size() + expectedResponseSize;
          const rawResponseBuffer = buffer.slice(0, rawResponseSize);
          return this.authHandlers.onSuccess(rawResponseBuffer);
        }
        const correlationId = response.readInt32();
        const payload = response.readAll();
        this.requestQueue.fulfillRequest({
          size: expectedResponseSize,
          correlationId,
          payload
        });
      }
    }
    rejectRequests(error) {
      this.requestQueue.rejectAll(error);
    }
  };
});

// node_modules/kafkajs/src/network/connectionPool.js
var require_connectionPool = __commonJS((exports, module) => {
  var apiKeys = require_apiKeys();
  var Connection = require_connection();
  module.exports = class ConnectionPool {
    constructor(options) {
      this.logger = options.logger.namespace("ConnectionPool");
      this.connectionTimeout = options.connectionTimeout;
      this.host = options.host;
      this.port = options.port;
      this.rack = options.rack;
      this.ssl = options.ssl;
      this.sasl = options.sasl;
      this.clientId = options.clientId;
      this.socketFactory = options.socketFactory;
      this.pool = new Array(2).fill().map(() => new Connection(options));
    }
    isConnected() {
      return this.pool.some((c) => c.isConnected());
    }
    isAuthenticated() {
      return this.pool.some((c) => c.isAuthenticated());
    }
    setSupportAuthenticationProtocol(isSupported) {
      this.map((c) => c.setSupportAuthenticationProtocol(isSupported));
    }
    setVersions(versions) {
      this.map((c) => c.setVersions(versions));
    }
    map(callback) {
      return this.pool.map((c) => callback(c));
    }
    async send(protocolRequest) {
      const connection = await this.getConnectionByRequest(protocolRequest);
      return connection.send(protocolRequest);
    }
    getConnectionByRequest({ request: { apiKey } }) {
      const index = { [apiKeys.Fetch]: 1 }[apiKey] || 0;
      return this.getConnection(index);
    }
    async getConnection(index = 0) {
      const connection = this.pool[index];
      if (!connection.isConnected()) {
        await connection.connect();
      }
      return connection;
    }
    async destroy() {
      await Promise.all(this.map((c) => c.disconnect()));
    }
  };
});

// node_modules/kafkajs/src/cluster/connectionPoolBuilder.js
var require_connectionPoolBuilder = __commonJS((exports, module) => {
  var { KafkaJSConnectionError, KafkaJSNonRetriableError } = require_errors2();
  var ConnectionPool = require_connectionPool();
  module.exports = ({
    socketFactory,
    brokers,
    ssl,
    sasl,
    clientId,
    requestTimeout,
    enforceRequestTimeout,
    connectionTimeout,
    maxInFlightRequests,
    logger,
    instrumentationEmitter = null,
    reauthenticationThreshold
  }) => {
    let index = 0;
    const isValidBroker = (broker) => {
      return broker && typeof broker === "string" && broker.length > 0;
    };
    const validateBrokers = (brokers2) => {
      if (!brokers2) {
        throw new KafkaJSNonRetriableError(`Failed to connect: brokers should not be null`);
      }
      if (Array.isArray(brokers2)) {
        if (!brokers2.length) {
          throw new KafkaJSNonRetriableError(`Failed to connect: brokers array is empty`);
        }
        brokers2.forEach((broker, index2) => {
          if (!isValidBroker(broker)) {
            throw new KafkaJSNonRetriableError(`Failed to connect: broker at index ${index2} is invalid "${typeof broker}"`);
          }
        });
      }
    };
    const getBrokers = async () => {
      let list;
      if (typeof brokers === "function") {
        try {
          list = await brokers();
        } catch (e) {
          const wrappedError = new KafkaJSConnectionError(`Failed to connect: "config.brokers" threw: ${e.message}`);
          wrappedError.stack = `${wrappedError.name}\n  Caused by: ${e.stack}`;
          throw wrappedError;
        }
      } else {
        list = brokers;
      }
      validateBrokers(list);
      return list;
    };
    return {
      build: async ({ host, port, rack } = {}) => {
        if (!host) {
          const list = await getBrokers();
          const randomBroker = list[index++ % list.length];
          host = randomBroker.split(":")[0];
          port = Number(randomBroker.split(":")[1]);
        }
        return new ConnectionPool({
          host,
          port,
          rack,
          sasl,
          ssl,
          clientId,
          socketFactory,
          connectionTimeout,
          requestTimeout,
          enforceRequestTimeout,
          maxInFlightRequests,
          instrumentationEmitter,
          logger,
          reauthenticationThreshold
        });
      }
    };
  };
});

// node_modules/kafkajs/src/cluster/index.js
var require_cluster = __commonJS((exports, module) => {
  var BrokerPool = require_brokerPool();
  var Lock = require_lock();
  var sharedPromiseTo = require_sharedPromiseTo();
  var createRetry = require_retry();
  var connectionPoolBuilder = require_connectionPoolBuilder();
  var { EARLIEST_OFFSET, LATEST_OFFSET } = require_constants2();
  var {
    KafkaJSError,
    KafkaJSBrokerNotFound,
    KafkaJSMetadataNotLoaded,
    KafkaJSTopicMetadataNotLoaded,
    KafkaJSGroupCoordinatorNotFound
  } = require_errors2();
  var COORDINATOR_TYPES = require_coordinatorTypes();
  var { keys } = Object;
  var mergeTopics = (obj, { topic, partitions }) => ({
    ...obj,
    [topic]: [...obj[topic] || [], ...partitions]
  });
  var PRIVATE = {
    CONNECT: Symbol("private:Cluster:connect"),
    REFRESH_METADATA: Symbol("private:Cluster:refreshMetadata"),
    REFRESH_METADATA_IF_NECESSARY: Symbol("private:Cluster:refreshMetadataIfNecessary"),
    FIND_CONTROLLER_BROKER: Symbol("private:Cluster:findControllerBroker")
  };
  module.exports = class Cluster {
    constructor({
      logger: rootLogger,
      socketFactory,
      brokers,
      ssl,
      sasl,
      clientId,
      connectionTimeout,
      authenticationTimeout,
      reauthenticationThreshold,
      requestTimeout = 30000,
      enforceRequestTimeout,
      metadataMaxAge,
      retry,
      allowAutoTopicCreation,
      maxInFlightRequests,
      isolationLevel,
      instrumentationEmitter = null,
      offsets = new Map
    }) {
      this.rootLogger = rootLogger;
      this.logger = rootLogger.namespace("Cluster");
      this.retrier = createRetry(retry);
      this.connectionPoolBuilder = connectionPoolBuilder({
        logger: rootLogger,
        instrumentationEmitter,
        socketFactory,
        brokers,
        ssl,
        sasl,
        clientId,
        connectionTimeout,
        requestTimeout,
        enforceRequestTimeout,
        maxInFlightRequests,
        reauthenticationThreshold
      });
      this.targetTopics = new Set;
      this.mutatingTargetTopics = new Lock({
        description: `updating target topics`,
        timeout: requestTimeout
      });
      this.isolationLevel = isolationLevel;
      this.brokerPool = new BrokerPool({
        connectionPoolBuilder: this.connectionPoolBuilder,
        logger: this.rootLogger,
        retry,
        allowAutoTopicCreation,
        authenticationTimeout,
        metadataMaxAge
      });
      this.committedOffsetsByGroup = offsets;
      this[PRIVATE.CONNECT] = sharedPromiseTo(async () => {
        return await this.brokerPool.connect();
      });
      this[PRIVATE.REFRESH_METADATA] = sharedPromiseTo(async () => {
        return await this.brokerPool.refreshMetadata(Array.from(this.targetTopics));
      });
      this[PRIVATE.REFRESH_METADATA_IF_NECESSARY] = sharedPromiseTo(async () => {
        return await this.brokerPool.refreshMetadataIfNecessary(Array.from(this.targetTopics));
      });
      this[PRIVATE.FIND_CONTROLLER_BROKER] = sharedPromiseTo(async () => {
        const { metadata } = this.brokerPool;
        if (!metadata || metadata.controllerId == null) {
          throw new KafkaJSMetadataNotLoaded("Topic metadata not loaded");
        }
        const broker = await this.findBroker({ nodeId: metadata.controllerId });
        if (!broker) {
          throw new KafkaJSBrokerNotFound(`Controller broker with id ${metadata.controllerId} not found in the cached metadata`);
        }
        return broker;
      });
    }
    isConnected() {
      return this.brokerPool.hasConnectedBrokers();
    }
    async connect() {
      await this[PRIVATE.CONNECT]();
    }
    async disconnect() {
      await this.brokerPool.disconnect();
    }
    removeBroker({ host, port }) {
      this.brokerPool.removeBroker({ host, port });
    }
    async refreshMetadata() {
      await this[PRIVATE.REFRESH_METADATA]();
    }
    async refreshMetadataIfNecessary() {
      await this[PRIVATE.REFRESH_METADATA_IF_NECESSARY]();
    }
    async metadata({ topics = [] } = {}) {
      return this.retrier(async (bail, retryCount, retryTime) => {
        try {
          await this.brokerPool.refreshMetadataIfNecessary(topics);
          return this.brokerPool.withBroker(async ({ broker }) => broker.metadata(topics));
        } catch (e) {
          if (e.type === "LEADER_NOT_AVAILABLE") {
            throw e;
          }
          bail(e);
        }
      });
    }
    async addTargetTopic(topic) {
      return this.addMultipleTargetTopics([topic]);
    }
    async addMultipleTargetTopics(topics) {
      await this.mutatingTargetTopics.acquire();
      try {
        const previousSize = this.targetTopics.size;
        const previousTopics = new Set(this.targetTopics);
        for (const topic of topics) {
          this.targetTopics.add(topic);
        }
        const hasChanged = previousSize !== this.targetTopics.size || !this.brokerPool.metadata;
        if (hasChanged) {
          try {
            await this.refreshMetadata();
          } catch (e) {
            if (e.type === "INVALID_TOPIC_EXCEPTION" || e.type === "UNKNOWN_TOPIC_OR_PARTITION" || e.type === "TOPIC_AUTHORIZATION_FAILED") {
              this.targetTopics = previousTopics;
            }
            throw e;
          }
        }
      } finally {
        await this.mutatingTargetTopics.release();
      }
    }
    getNodeIds() {
      return this.brokerPool.getNodeIds();
    }
    async findBroker({ nodeId }) {
      try {
        return await this.brokerPool.findBroker({ nodeId });
      } catch (e) {
        if (e.name === "KafkaJSBrokerNotFound" || e.name === "KafkaJSLockTimeout" || e.name === "KafkaJSConnectionError") {
          await this.refreshMetadata();
        }
        throw e;
      }
    }
    async findControllerBroker() {
      return await this[PRIVATE.FIND_CONTROLLER_BROKER]();
    }
    findTopicPartitionMetadata(topic) {
      const { metadata } = this.brokerPool;
      if (!metadata || !metadata.topicMetadata) {
        throw new KafkaJSTopicMetadataNotLoaded("Topic metadata not loaded", { topic });
      }
      const topicMetadata = metadata.topicMetadata.find((t) => t.topic === topic);
      return topicMetadata ? topicMetadata.partitionMetadata : [];
    }
    findLeaderForPartitions(topic, partitions) {
      const partitionMetadata = this.findTopicPartitionMetadata(topic);
      return partitions.reduce((result, id) => {
        const partitionId = parseInt(id, 10);
        const metadata = partitionMetadata.find((p) => p.partitionId === partitionId);
        if (!metadata) {
          return result;
        }
        if (metadata.leader === null || metadata.leader === undefined) {
          throw new KafkaJSError("Invalid partition metadata", { topic, partitionId, metadata });
        }
        const { leader } = metadata;
        const current = result[leader] || [];
        return { ...result, [leader]: [...current, partitionId] };
      }, {});
    }
    async findGroupCoordinator({ groupId, coordinatorType = COORDINATOR_TYPES.GROUP }) {
      return this.retrier(async (bail, retryCount, retryTime) => {
        try {
          const { coordinator } = await this.findGroupCoordinatorMetadata({
            groupId,
            coordinatorType
          });
          return await this.findBroker({ nodeId: coordinator.nodeId });
        } catch (e) {
          if (e.name === "KafkaJSBrokerNotFound" || e.type === "GROUP_COORDINATOR_NOT_AVAILABLE") {
            this.logger.debug(`${e.message}, refreshing metadata and trying again...`, {
              groupId,
              retryCount,
              retryTime
            });
            await this.refreshMetadata();
            throw e;
          }
          if (e.code === "ECONNREFUSED") {
            throw e;
          }
          bail(e);
        }
      });
    }
    async findGroupCoordinatorMetadata({ groupId, coordinatorType }) {
      const brokerMetadata = await this.brokerPool.withBroker(async ({ nodeId, broker }) => {
        return await this.retrier(async (bail, retryCount, retryTime) => {
          try {
            const brokerMetadata2 = await broker.findGroupCoordinator({ groupId, coordinatorType });
            this.logger.debug("Found group coordinator", {
              broker: brokerMetadata2.host,
              nodeId: brokerMetadata2.coordinator.nodeId
            });
            return brokerMetadata2;
          } catch (e) {
            this.logger.debug("Tried to find group coordinator", {
              nodeId,
              groupId,
              error: e
            });
            if (e.type === "GROUP_COORDINATOR_NOT_AVAILABLE") {
              this.logger.debug("Group coordinator not available, retrying...", {
                nodeId,
                retryCount,
                retryTime
              });
              throw e;
            }
            bail(e);
          }
        });
      });
      if (brokerMetadata) {
        return brokerMetadata;
      }
      throw new KafkaJSGroupCoordinatorNotFound("Failed to find group coordinator");
    }
    defaultOffset({ fromBeginning }) {
      return fromBeginning ? EARLIEST_OFFSET : LATEST_OFFSET;
    }
    async fetchTopicsOffset(topics) {
      const partitionsPerBroker = {};
      const topicConfigurations = {};
      const addDefaultOffset = (topic) => (partition) => {
        const { timestamp } = topicConfigurations[topic];
        return { ...partition, timestamp };
      };
      for (const topicData of topics) {
        const { topic, partitions, fromBeginning, fromTimestamp } = topicData;
        const partitionsPerLeader = this.findLeaderForPartitions(topic, partitions.map((p) => p.partition));
        const timestamp = fromTimestamp != null ? fromTimestamp : this.defaultOffset({ fromBeginning });
        topicConfigurations[topic] = { timestamp };
        keys(partitionsPerLeader).forEach((nodeId) => {
          partitionsPerBroker[nodeId] = partitionsPerBroker[nodeId] || {};
          partitionsPerBroker[nodeId][topic] = partitions.filter((p) => partitionsPerLeader[nodeId].includes(p.partition));
        });
      }
      const requests = keys(partitionsPerBroker).map(async (nodeId) => {
        const broker = await this.findBroker({ nodeId });
        const partitions = partitionsPerBroker[nodeId];
        const { responses: topicOffsets } = await broker.listOffsets({
          isolationLevel: this.isolationLevel,
          topics: keys(partitions).map((topic) => ({
            topic,
            partitions: partitions[topic].map(addDefaultOffset(topic))
          }))
        });
        return topicOffsets;
      });
      const responses = await Promise.all(requests);
      const partitionsPerTopic = responses.flat().reduce(mergeTopics, {});
      return keys(partitionsPerTopic).map((topic) => ({
        topic,
        partitions: partitionsPerTopic[topic].map(({ partition, offset }) => ({
          partition,
          offset
        }))
      }));
    }
    committedOffsets({ groupId }) {
      if (!this.committedOffsetsByGroup.has(groupId)) {
        this.committedOffsetsByGroup.set(groupId, {});
      }
      return this.committedOffsetsByGroup.get(groupId);
    }
    markOffsetAsCommitted({ groupId, topic, partition, offset }) {
      const committedOffsets = this.committedOffsets({ groupId });
      committedOffsets[topic] = committedOffsets[topic] || {};
      committedOffsets[topic][partition] = offset;
    }
  };
});

// node_modules/kafkajs/src/producer/partitioners/default/murmur2.js
var require_murmur2 = __commonJS((exports, module) => {
  var Long = require_long();
  var SEED = Long.fromValue(2538058380);
  var M = Long.fromValue(1540483477);
  var R = Long.fromValue(24);
  module.exports = (key) => {
    const data = Buffer.isBuffer(key) ? key : Buffer.from(String(key));
    const length = data.length;
    let h = Long.fromValue(SEED.xor(length));
    let length4 = Math.floor(length / 4);
    for (let i = 0;i < length4; i++) {
      const i4 = i * 4;
      let k = (data[i4 + 0] & 255) + ((data[i4 + 1] & 255) << 8) + ((data[i4 + 2] & 255) << 16) + ((data[i4 + 3] & 255) << 24);
      k = Long.fromValue(k);
      k = k.multiply(M);
      k = k.xor(k.toInt() >>> R);
      k = Long.fromValue(k).multiply(M);
      h = h.multiply(M);
      h = h.xor(k);
    }
    switch (length % 4) {
      case 3:
        h = h.xor((data[(length & ~3) + 2] & 255) << 16);
      case 2:
        h = h.xor((data[(length & ~3) + 1] & 255) << 8);
      case 1:
        h = h.xor(data[length & ~3] & 255);
        h = h.multiply(M);
    }
    h = h.xor(h.toInt() >>> 13);
    h = h.multiply(M);
    h = h.xor(h.toInt() >>> 15);
    return h.toInt();
  };
});

// node_modules/kafkajs/src/producer/partitioners/legacy/randomBytes.js
var require_randomBytes = __commonJS((exports, module) => {
  var { KafkaJSNonRetriableError } = require_errors2();
  var toNodeCompatible = (crypto) => ({
    randomBytes: (size) => crypto.getRandomValues(Buffer.allocUnsafe(size))
  });
  var cryptoImplementation = null;
  if (global && global.crypto) {
    cryptoImplementation = global.crypto.randomBytes === undefined ? toNodeCompatible(global.crypto) : global.crypto;
  } else if (global && global.msCrypto) {
    cryptoImplementation = toNodeCompatible(global.msCrypto);
  } else if (global && !global.crypto) {
    cryptoImplementation = __require("crypto");
  }
  var MAX_BYTES = 65536;
  module.exports = (size) => {
    if (size > MAX_BYTES) {
      throw new KafkaJSNonRetriableError(`Byte length (${size}) exceeds the max number of bytes of entropy available (${MAX_BYTES})`);
    }
    if (!cryptoImplementation) {
      throw new KafkaJSNonRetriableError("No available crypto implementation");
    }
    return cryptoImplementation.randomBytes(size);
  };
});

// node_modules/kafkajs/src/producer/partitioners/legacy/partitioner.js
var require_partitioner = __commonJS((exports, module) => {
  var randomBytes = require_randomBytes();
  var toPositive = (x) => x & 2147483647;
  module.exports = (murmur2) => () => {
    const counters = {};
    return ({ topic, partitionMetadata, message }) => {
      if (!(topic in counters)) {
        counters[topic] = randomBytes(32).readUInt32BE(0);
      }
      const numPartitions = partitionMetadata.length;
      const availablePartitions = partitionMetadata.filter((p) => p.leader >= 0);
      const numAvailablePartitions = availablePartitions.length;
      if (message.partition !== null && message.partition !== undefined) {
        return message.partition;
      }
      if (message.key !== null && message.key !== undefined) {
        return toPositive(murmur2(message.key)) % numPartitions;
      }
      if (numAvailablePartitions > 0) {
        const i = toPositive(++counters[topic]) % numAvailablePartitions;
        return availablePartitions[i].partitionId;
      }
      return toPositive(++counters[topic]) % numPartitions;
    };
  };
});

// node_modules/kafkajs/src/producer/partitioners/default/index.js
var require_default = __commonJS((exports, module) => {
  var murmur2 = require_murmur2();
  var createDefaultPartitioner = require_partitioner();
  module.exports = createDefaultPartitioner(murmur2);
});

// node_modules/kafkajs/src/producer/partitioners/legacy/murmur2.js
var require_murmur22 = __commonJS((exports, module) => {
  var SEED = 2538058380;
  var M = 1540483477;
  var R = 24;
  module.exports = (key) => {
    const data = Buffer.isBuffer(key) ? key : Buffer.from(String(key));
    const length = data.length;
    let h = SEED ^ length;
    let length4 = length / 4;
    for (let i = 0;i < length4; i++) {
      const i4 = i * 4;
      let k = (data[i4 + 0] & 255) + ((data[i4 + 1] & 255) << 8) + ((data[i4 + 2] & 255) << 16) + ((data[i4 + 3] & 255) << 24);
      k *= M;
      k ^= k >>> R;
      k *= M;
      h *= M;
      h ^= k;
    }
    switch (length % 4) {
      case 3:
        h ^= (data[(length & ~3) + 2] & 255) << 16;
      case 2:
        h ^= (data[(length & ~3) + 1] & 255) << 8;
      case 1:
        h ^= data[length & ~3] & 255;
        h *= M;
    }
    h ^= h >>> 13;
    h *= M;
    h ^= h >>> 15;
    return h;
  };
});

// node_modules/kafkajs/src/producer/partitioners/legacy/index.js
var require_legacy2 = __commonJS((exports, module) => {
  var murmur2 = require_murmur22();
  var createLegacyPartitioner = require_partitioner();
  module.exports = createLegacyPartitioner(murmur2);
});

// node_modules/kafkajs/src/producer/partitioners/index.js
var require_partitioners = __commonJS((exports, module) => {
  var DefaultPartitioner = require_default();
  var LegacyPartitioner = require_legacy2();
  module.exports = {
    DefaultPartitioner,
    LegacyPartitioner,
    JavaCompatiblePartitioner: DefaultPartitioner
  };
});

// node_modules/kafkajs/src/producer/eosManager/transactionStates.js
var require_transactionStates = __commonJS((exports, module) => {
  module.exports = {
    UNINITIALIZED: "UNINITIALIZED",
    READY: "READY",
    TRANSACTING: "TRANSACTING",
    COMMITTING: "COMMITTING",
    ABORTING: "ABORTING"
  };
});

// node_modules/kafkajs/src/producer/eosManager/transactionStateMachine.js
var require_transactionStateMachine = __commonJS((exports, module) => {
  var { EventEmitter } = __require("events");
  var { KafkaJSNonRetriableError } = require_errors2();
  var STATES = require_transactionStates();
  var VALID_STATE_TRANSITIONS = {
    [STATES.UNINITIALIZED]: [STATES.READY],
    [STATES.READY]: [STATES.READY, STATES.TRANSACTING],
    [STATES.TRANSACTING]: [STATES.COMMITTING, STATES.ABORTING],
    [STATES.COMMITTING]: [STATES.READY],
    [STATES.ABORTING]: [STATES.READY]
  };
  module.exports = ({ logger, initialState = STATES.UNINITIALIZED }) => {
    let currentState = initialState;
    const guard = (object, method, { legalStates, async: isAsync = true }) => {
      if (!object[method]) {
        throw new KafkaJSNonRetriableError(`Cannot add guard on missing method "${method}"`);
      }
      return (...args) => {
        const fn = object[method];
        if (!legalStates.includes(currentState)) {
          const error = new KafkaJSNonRetriableError(`Transaction state exception: Cannot call "${method}" in state "${currentState}"`);
          if (isAsync) {
            return Promise.reject(error);
          } else {
            throw error;
          }
        }
        return fn.apply(object, args);
      };
    };
    const stateMachine = Object.assign(new EventEmitter, {
      createGuarded(object, methodStateMapping) {
        const guardedMethods = Object.keys(methodStateMapping).reduce((guards, method) => {
          guards[method] = guard(object, method, methodStateMapping[method]);
          return guards;
        }, {});
        return { ...object, ...guardedMethods };
      },
      transitionTo(state) {
        logger.debug(`Transaction state transition ${currentState} --> ${state}`);
        if (!VALID_STATE_TRANSITIONS[currentState].includes(state)) {
          throw new KafkaJSNonRetriableError(`Transaction state exception: Invalid transition ${currentState} --> ${state}`);
        }
        stateMachine.emit("transition", { to: state, from: currentState });
        currentState = state;
      },
      state() {
        return currentState;
      }
    });
    return stateMachine;
  };
});

// node_modules/kafkajs/src/producer/eosManager/index.js
var require_eosManager = __commonJS((exports, module) => {
  var createRetry = require_retry();
  var Lock = require_lock();
  var { KafkaJSNonRetriableError } = require_errors2();
  var COORDINATOR_TYPES = require_coordinatorTypes();
  var createStateMachine = require_transactionStateMachine();
  var { INT_32_MAX_VALUE } = require_constants2();
  var assert = __require("assert");
  var STATES = require_transactionStates();
  var NO_PRODUCER_ID = -1;
  var SEQUENCE_START = 0;
  var INIT_PRODUCER_RETRIABLE_PROTOCOL_ERRORS = [
    "NOT_COORDINATOR_FOR_GROUP",
    "GROUP_COORDINATOR_NOT_AVAILABLE",
    "GROUP_LOAD_IN_PROGRESS",
    "CONCURRENT_TRANSACTIONS"
  ];
  var COMMIT_RETRIABLE_PROTOCOL_ERRORS = [
    "UNKNOWN_TOPIC_OR_PARTITION",
    "COORDINATOR_LOAD_IN_PROGRESS"
  ];
  var COMMIT_STALE_COORDINATOR_PROTOCOL_ERRORS = ["COORDINATOR_NOT_AVAILABLE", "NOT_COORDINATOR"];
  module.exports = ({
    logger,
    cluster,
    transactionTimeout = 60000,
    transactional,
    transactionalId
  }) => {
    if (transactional && !transactionalId) {
      throw new KafkaJSNonRetriableError("Cannot manage transactions without a transactionalId");
    }
    const retrier = createRetry(cluster.retry);
    let producerId = NO_PRODUCER_ID;
    let producerEpoch = 0;
    let producerSequence = {};
    let brokerMutexLocks = {};
    let transactionTopicPartitions = {};
    let hasOffsetsAddedToTransaction = false;
    const stateMachine = createStateMachine({ logger });
    stateMachine.on("transition", ({ to }) => {
      if (to === STATES.READY) {
        transactionTopicPartitions = {};
        hasOffsetsAddedToTransaction = false;
      }
    });
    const findTransactionCoordinator = () => {
      return cluster.findGroupCoordinator({
        groupId: transactionalId,
        coordinatorType: COORDINATOR_TYPES.TRANSACTION
      });
    };
    const transactionalGuard = () => {
      if (!transactional) {
        throw new KafkaJSNonRetriableError("Method unavailable if non-transactional");
      }
    };
    const isOngoing = () => {
      return hasOffsetsAddedToTransaction || Object.entries(transactionTopicPartitions).some(([, partitions]) => {
        return Object.entries(partitions).some(([, isPartitionAddedToTransaction]) => isPartitionAddedToTransaction);
      });
    };
    const eosManager = stateMachine.createGuarded({
      getProducerId() {
        return producerId;
      },
      getProducerEpoch() {
        return producerEpoch;
      },
      getTransactionalId() {
        return transactionalId;
      },
      async initProducerId() {
        return retrier(async (bail, retryCount, retryTime) => {
          try {
            await cluster.refreshMetadataIfNecessary();
            const broker = await (transactional ? findTransactionCoordinator() : cluster.findControllerBroker());
            const result = await broker.initProducerId({
              transactionalId: transactional ? transactionalId : undefined,
              transactionTimeout
            });
            stateMachine.transitionTo(STATES.READY);
            producerId = result.producerId;
            producerEpoch = result.producerEpoch;
            producerSequence = {};
            brokerMutexLocks = {};
            logger.debug("Initialized producer id & epoch", { producerId, producerEpoch });
          } catch (e) {
            if (INIT_PRODUCER_RETRIABLE_PROTOCOL_ERRORS.includes(e.type)) {
              if (e.type === "CONCURRENT_TRANSACTIONS") {
                logger.debug("There is an ongoing transaction on this transactionId, retrying", {
                  error: e.message,
                  stack: e.stack,
                  transactionalId,
                  retryCount,
                  retryTime
                });
              }
              throw e;
            }
            bail(e);
          }
        });
      },
      getSequence(topic, partition) {
        if (!eosManager.isInitialized()) {
          return SEQUENCE_START;
        }
        producerSequence[topic] = producerSequence[topic] || {};
        producerSequence[topic][partition] = producerSequence[topic][partition] || SEQUENCE_START;
        return producerSequence[topic][partition];
      },
      updateSequence(topic, partition, increment) {
        if (!eosManager.isInitialized()) {
          return;
        }
        const previous = eosManager.getSequence(topic, partition);
        let sequence = previous + increment;
        if (sequence >= INT_32_MAX_VALUE) {
          logger.debug(`Sequence for ${topic} ${partition} exceeds max value (${sequence}). Rotating to 0.`);
          sequence = 0;
        }
        producerSequence[topic][partition] = sequence;
      },
      beginTransaction() {
        transactionalGuard();
        stateMachine.transitionTo(STATES.TRANSACTING);
      },
      async addPartitionsToTransaction(topicData) {
        transactionalGuard();
        const newTopicPartitions = {};
        topicData.forEach(({ topic, partitions }) => {
          transactionTopicPartitions[topic] = transactionTopicPartitions[topic] || {};
          partitions.forEach(({ partition }) => {
            if (!transactionTopicPartitions[topic][partition]) {
              newTopicPartitions[topic] = newTopicPartitions[topic] || [];
              newTopicPartitions[topic].push(partition);
            }
          });
        });
        const topics = Object.keys(newTopicPartitions).map((topic) => ({
          topic,
          partitions: newTopicPartitions[topic]
        }));
        if (topics.length) {
          const broker = await findTransactionCoordinator();
          await broker.addPartitionsToTxn({ transactionalId, producerId, producerEpoch, topics });
        }
        topics.forEach(({ topic, partitions }) => {
          partitions.forEach((partition) => {
            transactionTopicPartitions[topic][partition] = true;
          });
        });
      },
      async commit() {
        transactionalGuard();
        stateMachine.transitionTo(STATES.COMMITTING);
        if (!isOngoing()) {
          logger.debug("No partitions or offsets registered, not sending EndTxn");
          stateMachine.transitionTo(STATES.READY);
          return;
        }
        const broker = await findTransactionCoordinator();
        await broker.endTxn({
          producerId,
          producerEpoch,
          transactionalId,
          transactionResult: true
        });
        stateMachine.transitionTo(STATES.READY);
      },
      async abort() {
        transactionalGuard();
        stateMachine.transitionTo(STATES.ABORTING);
        if (!isOngoing()) {
          logger.debug("No partitions or offsets registered, not sending EndTxn");
          stateMachine.transitionTo(STATES.READY);
          return;
        }
        const broker = await findTransactionCoordinator();
        await broker.endTxn({
          producerId,
          producerEpoch,
          transactionalId,
          transactionResult: false
        });
        stateMachine.transitionTo(STATES.READY);
      },
      isInitialized() {
        return producerId !== NO_PRODUCER_ID;
      },
      isTransactional() {
        return transactional;
      },
      isInTransaction() {
        return stateMachine.state() === STATES.TRANSACTING;
      },
      async acquireBrokerLock(broker) {
        if (this.isInitialized()) {
          brokerMutexLocks[broker.nodeId] = brokerMutexLocks[broker.nodeId] || new Lock({ timeout: 65535 });
          await brokerMutexLocks[broker.nodeId].acquire();
        }
      },
      releaseBrokerLock(broker) {
        if (this.isInitialized())
          brokerMutexLocks[broker.nodeId].release();
      },
      async sendOffsets({ consumerGroupId, topics }) {
        assert(consumerGroupId, "Missing consumerGroupId");
        assert(topics, "Missing offset topics");
        const transactionCoordinator = await findTransactionCoordinator();
        await transactionCoordinator.addOffsetsToTxn({
          transactionalId,
          producerId,
          producerEpoch,
          groupId: consumerGroupId
        });
        hasOffsetsAddedToTransaction = true;
        let groupCoordinator = await cluster.findGroupCoordinator({
          groupId: consumerGroupId,
          coordinatorType: COORDINATOR_TYPES.GROUP
        });
        return retrier(async (bail, retryCount, retryTime) => {
          try {
            await groupCoordinator.txnOffsetCommit({
              transactionalId,
              producerId,
              producerEpoch,
              groupId: consumerGroupId,
              topics
            });
          } catch (e) {
            if (COMMIT_RETRIABLE_PROTOCOL_ERRORS.includes(e.type)) {
              logger.debug("Group coordinator is not ready yet, retrying", {
                error: e.message,
                stack: e.stack,
                transactionalId,
                retryCount,
                retryTime
              });
              throw e;
            }
            if (COMMIT_STALE_COORDINATOR_PROTOCOL_ERRORS.includes(e.type) || e.code === "ECONNREFUSED") {
              logger.debug("Invalid group coordinator, finding new group coordinator and retrying", {
                error: e.message,
                stack: e.stack,
                transactionalId,
                retryCount,
                retryTime
              });
              groupCoordinator = await cluster.findGroupCoordinator({
                groupId: consumerGroupId,
                coordinatorType: COORDINATOR_TYPES.GROUP
              });
              throw e;
            }
            bail(e);
          }
        });
      }
    }, {
      initProducerId: { legalStates: [STATES.UNINITIALIZED, STATES.READY] },
      beginTransaction: { legalStates: [STATES.READY], async: false },
      addPartitionsToTransaction: { legalStates: [STATES.TRANSACTING] },
      sendOffsets: { legalStates: [STATES.TRANSACTING] },
      commit: { legalStates: [STATES.TRANSACTING] },
      abort: { legalStates: [STATES.TRANSACTING] }
    });
    return eosManager;
  };
});

// node_modules/kafkajs/src/producer/groupMessagesPerPartition.js
var require_groupMessagesPerPartition = __commonJS((exports, module) => {
  module.exports = ({ topic, partitionMetadata, messages, partitioner }) => {
    if (partitionMetadata.length === 0) {
      return {};
    }
    return messages.reduce((result, message) => {
      const partition = partitioner({ topic, partitionMetadata, message });
      const current = result[partition] || [];
      return Object.assign(result, { [partition]: [...current, message] });
    }, {});
  };
});

// node_modules/kafkajs/src/producer/createTopicData.js
var require_createTopicData = __commonJS((exports, module) => {
  module.exports = (topicDataForBroker) => {
    return topicDataForBroker.map(({ topic, partitions, messagesPerPartition, sequencePerPartition }) => ({
      topic,
      partitions: partitions.map((partition) => ({
        partition,
        messages: messagesPerPartition[partition]
      }))
    }));
  };
});

// node_modules/kafkajs/src/producer/responseSerializer.js
var require_responseSerializer = __commonJS((exports, module) => {
  module.exports = ({ topics }) => topics.flatMap(({ topicName, partitions }) => partitions.map((partition) => ({ topicName, ...partition })));
});

// node_modules/kafkajs/src/producer/sendMessages.js
var require_sendMessages = __commonJS((exports, module) => {
  var { KafkaJSMetadataNotLoaded } = require_errors2();
  var { staleMetadata } = require_error();
  var groupMessagesPerPartition = require_groupMessagesPerPartition();
  var createTopicData = require_createTopicData();
  var responseSerializer = require_responseSerializer();
  var { keys } = Object;
  module.exports = ({ logger, cluster, partitioner, eosManager, retrier }) => {
    return async ({ acks, timeout, compression, topicMessages }) => {
      const responsePerBroker = new Map;
      const createProducerRequests = async (responsePerBroker2) => {
        const topicMetadata = new Map;
        await cluster.refreshMetadataIfNecessary();
        for (const { topic, messages } of topicMessages) {
          const partitionMetadata = cluster.findTopicPartitionMetadata(topic);
          if (partitionMetadata.length === 0) {
            logger.debug("Producing to topic without metadata", {
              topic,
              targetTopics: Array.from(cluster.targetTopics)
            });
            throw new KafkaJSMetadataNotLoaded("Producing to topic without metadata");
          }
          const messagesPerPartition = groupMessagesPerPartition({
            topic,
            partitionMetadata,
            messages,
            partitioner
          });
          const partitions = keys(messagesPerPartition);
          const partitionsPerLeader = cluster.findLeaderForPartitions(topic, partitions);
          const leaders = keys(partitionsPerLeader);
          topicMetadata.set(topic, {
            partitionsPerLeader,
            messagesPerPartition
          });
          for (const nodeId of leaders) {
            const broker = await cluster.findBroker({ nodeId });
            if (!responsePerBroker2.has(broker)) {
              responsePerBroker2.set(broker, null);
            }
          }
        }
        const brokers = Array.from(responsePerBroker2.keys());
        const brokersWithoutResponse = brokers.filter((broker) => !responsePerBroker2.get(broker));
        return brokersWithoutResponse.map(async (broker) => {
          const entries = Array.from(topicMetadata.entries());
          const topicDataForBroker = entries.filter(([_, { partitionsPerLeader }]) => !!partitionsPerLeader[broker.nodeId]).map(([topic, { partitionsPerLeader, messagesPerPartition, sequencePerPartition }]) => ({
            topic,
            partitions: partitionsPerLeader[broker.nodeId],
            messagesPerPartition
          }));
          const topicData = createTopicData(topicDataForBroker);
          await eosManager.acquireBrokerLock(broker);
          try {
            if (eosManager.isTransactional()) {
              await eosManager.addPartitionsToTransaction(topicData);
            }
            topicData.forEach(({ topic, partitions }) => {
              partitions.forEach((entry) => {
                entry["firstSequence"] = eosManager.getSequence(topic, entry.partition);
                eosManager.updateSequence(topic, entry.partition, entry.messages.length);
              });
            });
            let response;
            try {
              response = await broker.produce({
                transactionalId: eosManager.isTransactional() ? eosManager.getTransactionalId() : undefined,
                producerId: eosManager.getProducerId(),
                producerEpoch: eosManager.getProducerEpoch(),
                acks,
                timeout,
                compression,
                topicData
              });
            } catch (e) {
              topicData.forEach(({ topic, partitions }) => {
                partitions.forEach((entry) => {
                  eosManager.updateSequence(topic, entry.partition, -entry.messages.length);
                });
              });
              throw e;
            }
            const expectResponse = acks !== 0;
            const formattedResponse = expectResponse ? responseSerializer(response) : [];
            responsePerBroker2.set(broker, formattedResponse);
          } catch (e) {
            responsePerBroker2.delete(broker);
            throw e;
          } finally {
            await eosManager.releaseBrokerLock(broker);
          }
        });
      };
      return retrier(async (bail, retryCount, retryTime) => {
        const topics = topicMessages.map(({ topic }) => topic);
        await cluster.addMultipleTargetTopics(topics);
        try {
          const requests = await createProducerRequests(responsePerBroker);
          await Promise.all(requests);
          return Array.from(responsePerBroker.values()).flat();
        } catch (e) {
          if (e.name === "KafkaJSConnectionClosedError") {
            cluster.removeBroker({ host: e.host, port: e.port });
          }
          if (!cluster.isConnected()) {
            logger.debug(`Cluster has disconnected, reconnecting: ${e.message}`, {
              retryCount,
              retryTime
            });
            await cluster.connect();
            await cluster.refreshMetadata();
            throw e;
          }
          if (staleMetadata(e) || e.name === "KafkaJSMetadataNotLoaded" || e.name === "KafkaJSConnectionError" || e.name === "KafkaJSConnectionClosedError" || e.name === "KafkaJSProtocolError" && e.retriable) {
            logger.error(`Failed to send messages: ${e.message}`, { retryCount, retryTime });
            await cluster.refreshMetadata();
            throw e;
          }
          logger.error(`${e.message}`, { retryCount, retryTime });
          if (e.retriable)
            throw e;
          bail(e);
        }
      });
    };
  };
});

// node_modules/kafkajs/src/producer/messageProducer.js
var require_messageProducer = __commonJS((exports, module) => {
  var createSendMessages = require_sendMessages();
  var { KafkaJSError, KafkaJSNonRetriableError } = require_errors2();
  var { CONNECTION_STATUS } = require_connectionStatus();
  module.exports = ({
    logger,
    cluster,
    partitioner,
    eosManager,
    idempotent,
    retrier,
    getConnectionStatus
  }) => {
    const sendMessages = createSendMessages({
      logger,
      cluster,
      retrier,
      partitioner,
      eosManager
    });
    const validateConnectionStatus = () => {
      const connectionStatus = getConnectionStatus();
      switch (connectionStatus) {
        case CONNECTION_STATUS.DISCONNECTING:
          throw new KafkaJSNonRetriableError(`The producer is disconnecting; therefore, it can't safely accept messages anymore`);
        case CONNECTION_STATUS.DISCONNECTED:
          throw new KafkaJSError("The producer is disconnected");
      }
    };
    const sendBatch = async ({ acks = -1, timeout, compression, topicMessages = [] }) => {
      if (topicMessages.some(({ topic }) => !topic)) {
        throw new KafkaJSNonRetriableError(`Invalid topic`);
      }
      if (idempotent && acks !== -1) {
        throw new KafkaJSNonRetriableError(`Not requiring ack for all messages invalidates the idempotent producer's EoS guarantees`);
      }
      for (const { topic, messages } of topicMessages) {
        if (!messages) {
          throw new KafkaJSNonRetriableError(`Invalid messages array [${messages}] for topic "${topic}"`);
        }
        const messageWithoutValue = messages.find((message) => message.value === undefined);
        if (messageWithoutValue) {
          throw new KafkaJSNonRetriableError(`Invalid message without value for topic "${topic}": ${JSON.stringify(messageWithoutValue)}`);
        }
      }
      validateConnectionStatus();
      const mergedTopicMessages = topicMessages.reduce((merged, { topic, messages }) => {
        const index = merged.findIndex(({ topic: mergedTopic }) => topic === mergedTopic);
        if (index === -1) {
          merged.push({ topic, messages });
        } else {
          merged[index].messages = [...merged[index].messages, ...messages];
        }
        return merged;
      }, []);
      return await sendMessages({
        acks,
        timeout,
        compression,
        topicMessages: mergedTopicMessages
      });
    };
    const send = async ({ acks, timeout, compression, topic, messages }) => {
      const topicMessage = { topic, messages };
      return sendBatch({
        acks,
        timeout,
        compression,
        topicMessages: [topicMessage]
      });
    };
    return {
      send,
      sendBatch
    };
  };
});

// node_modules/kafkajs/src/utils/swapObject.js
var require_swapObject = __commonJS((exports, module) => {
  var { keys } = Object;
  module.exports = (object) => keys(object).reduce((result, key) => ({ ...result, [object[key]]: key }), {});
});

// node_modules/kafkajs/src/producer/instrumentationEvents.js
var require_instrumentationEvents2 = __commonJS((exports, module) => {
  var swapObject = require_swapObject();
  var networkEvents = require_instrumentationEvents();
  var InstrumentationEventType = require_eventType();
  var producerType = InstrumentationEventType("producer");
  var events = {
    CONNECT: producerType("connect"),
    DISCONNECT: producerType("disconnect"),
    REQUEST: producerType(networkEvents.NETWORK_REQUEST),
    REQUEST_TIMEOUT: producerType(networkEvents.NETWORK_REQUEST_TIMEOUT),
    REQUEST_QUEUE_SIZE: producerType(networkEvents.NETWORK_REQUEST_QUEUE_SIZE)
  };
  var wrappedEvents = {
    [events.REQUEST]: networkEvents.NETWORK_REQUEST,
    [events.REQUEST_TIMEOUT]: networkEvents.NETWORK_REQUEST_TIMEOUT,
    [events.REQUEST_QUEUE_SIZE]: networkEvents.NETWORK_REQUEST_QUEUE_SIZE
  };
  var reversedWrappedEvents = swapObject(wrappedEvents);
  var unwrap = (eventName) => wrappedEvents[eventName] || eventName;
  var wrap = (eventName) => reversedWrappedEvents[eventName] || eventName;
  module.exports = {
    events,
    wrap,
    unwrap
  };
});

// node_modules/kafkajs/src/producer/index.js
var require_producer = __commonJS((exports, module) => {
  var createRetry = require_retry();
  var { CONNECTION_STATUS } = require_connectionStatus();
  var { DefaultPartitioner } = require_partitioners();
  var InstrumentationEventEmitter = require_emitter();
  var createEosManager = require_eosManager();
  var createMessageProducer = require_messageProducer();
  var { events, wrap: wrapEvent, unwrap: unwrapEvent } = require_instrumentationEvents2();
  var { KafkaJSNonRetriableError } = require_errors2();
  var { values, keys } = Object;
  var eventNames = values(events);
  var eventKeys = keys(events).map((key) => `producer.events.${key}`).join(", ");
  var { CONNECT, DISCONNECT } = events;
  module.exports = ({
    cluster,
    logger: rootLogger,
    createPartitioner = DefaultPartitioner,
    retry,
    idempotent = false,
    transactionalId,
    transactionTimeout,
    instrumentationEmitter: rootInstrumentationEmitter
  }) => {
    let connectionStatus = CONNECTION_STATUS.DISCONNECTED;
    retry = retry || { retries: idempotent ? Number.MAX_SAFE_INTEGER : 5 };
    if (idempotent && retry.retries < 1) {
      throw new KafkaJSNonRetriableError("Idempotent producer must allow retries to protect against transient errors");
    }
    const logger = rootLogger.namespace("Producer");
    if (idempotent && retry.retries < Number.MAX_SAFE_INTEGER) {
      logger.warn("Limiting retries for the idempotent producer may invalidate EoS guarantees");
    }
    const partitioner = createPartitioner();
    const retrier = createRetry(Object.assign({}, cluster.retry, retry));
    const instrumentationEmitter = rootInstrumentationEmitter || new InstrumentationEventEmitter;
    const idempotentEosManager = createEosManager({
      logger,
      cluster,
      transactionTimeout,
      transactional: false,
      transactionalId
    });
    const { send, sendBatch } = createMessageProducer({
      logger,
      cluster,
      partitioner,
      eosManager: idempotentEosManager,
      idempotent,
      retrier,
      getConnectionStatus: () => connectionStatus
    });
    let transactionalEosManager;
    const on = (eventName, listener) => {
      if (!eventNames.includes(eventName)) {
        throw new KafkaJSNonRetriableError(`Event name should be one of ${eventKeys}`);
      }
      return instrumentationEmitter.addListener(unwrapEvent(eventName), (event) => {
        event.type = wrapEvent(event.type);
        Promise.resolve(listener(event)).catch((e) => {
          logger.error(`Failed to execute listener: ${e.message}`, {
            eventName,
            stack: e.stack
          });
        });
      });
    };
    const transaction = async () => {
      if (!transactionalId) {
        throw new KafkaJSNonRetriableError("Must provide transactional id for transactional producer");
      }
      let transactionDidEnd = false;
      transactionalEosManager = transactionalEosManager || createEosManager({
        logger,
        cluster,
        transactionTimeout,
        transactional: true,
        transactionalId
      });
      if (transactionalEosManager.isInTransaction()) {
        throw new KafkaJSNonRetriableError("There is already an ongoing transaction for this producer. Please end the transaction before beginning another.");
      }
      if (!transactionalEosManager.isInitialized()) {
        await transactionalEosManager.initProducerId();
      }
      transactionalEosManager.beginTransaction();
      const { send: sendTxn, sendBatch: sendBatchTxn } = createMessageProducer({
        logger,
        cluster,
        partitioner,
        retrier,
        eosManager: transactionalEosManager,
        idempotent: true,
        getConnectionStatus: () => connectionStatus
      });
      const isActive = () => transactionalEosManager.isInTransaction() && !transactionDidEnd;
      const transactionGuard = (fn) => (...args) => {
        if (!isActive()) {
          return Promise.reject(new KafkaJSNonRetriableError("Cannot continue to use transaction once ended"));
        }
        return fn(...args);
      };
      return {
        sendBatch: transactionGuard(sendBatchTxn),
        send: transactionGuard(sendTxn),
        abort: transactionGuard(async () => {
          await transactionalEosManager.abort();
          transactionDidEnd = true;
        }),
        commit: transactionGuard(async () => {
          await transactionalEosManager.commit();
          transactionDidEnd = true;
        }),
        sendOffsets: transactionGuard(async ({ consumerGroupId, topics }) => {
          await transactionalEosManager.sendOffsets({ consumerGroupId, topics });
          for (const topicOffsets of topics) {
            const { topic, partitions } = topicOffsets;
            for (const { partition, offset } of partitions) {
              cluster.markOffsetAsCommitted({
                groupId: consumerGroupId,
                topic,
                partition,
                offset
              });
            }
          }
        }),
        isActive
      };
    };
    const getLogger = () => logger;
    return {
      connect: async () => {
        await cluster.connect();
        connectionStatus = CONNECTION_STATUS.CONNECTED;
        instrumentationEmitter.emit(CONNECT);
        if (idempotent && !idempotentEosManager.isInitialized()) {
          await idempotentEosManager.initProducerId();
        }
      },
      disconnect: async () => {
        connectionStatus = CONNECTION_STATUS.DISCONNECTING;
        await cluster.disconnect();
        connectionStatus = CONNECTION_STATUS.DISCONNECTED;
        instrumentationEmitter.emit(DISCONNECT);
      },
      isIdempotent: () => {
        return idempotent;
      },
      events,
      on,
      send,
      sendBatch,
      transaction,
      logger: getLogger
    };
  };
});

// node_modules/kafkajs/src/utils/sleep.js
var require_sleep = __commonJS((exports, module) => {
  module.exports = (timeInMs) => new Promise((resolve) => {
    setTimeout(resolve, timeInMs);
  });
});

// node_modules/kafkajs/src/consumer/offsetManager/isInvalidOffset.js
var require_isInvalidOffset = __commonJS((exports, module) => {
  var Long = require_long();
  module.exports = (offset) => !offset && offset !== 0 || Long.fromValue(offset).isNegative();
});

// node_modules/kafkajs/src/consumer/offsetManager/initializeConsumerOffsets.js
var require_initializeConsumerOffsets = __commonJS((exports, module) => {
  var isInvalidOffset = require_isInvalidOffset();
  var { keys, assign } = Object;
  var indexPartitions = (obj, { partition, offset }) => assign(obj, { [partition]: offset });
  var indexTopics = (obj, { topic, partitions }) => assign(obj, { [topic]: partitions.reduce(indexPartitions, {}) });
  module.exports = (consumerOffsets, topicOffsets) => {
    const indexedConsumerOffsets = consumerOffsets.reduce(indexTopics, {});
    const indexedTopicOffsets = topicOffsets.reduce(indexTopics, {});
    return keys(indexedConsumerOffsets).map((topic) => {
      const partitions = indexedConsumerOffsets[topic];
      return {
        topic,
        partitions: keys(partitions).map((partition) => {
          const offset = partitions[partition];
          const resolvedOffset = isInvalidOffset(offset) ? indexedTopicOffsets[topic][partition] : offset;
          return { partition: Number(partition), offset: resolvedOffset };
        })
      };
    });
  };
});

// node_modules/kafkajs/src/consumer/instrumentationEvents.js
var require_instrumentationEvents3 = __commonJS((exports, module) => {
  var swapObject = require_swapObject();
  var InstrumentationEventType = require_eventType();
  var networkEvents = require_instrumentationEvents();
  var consumerType = InstrumentationEventType("consumer");
  var events = {
    HEARTBEAT: consumerType("heartbeat"),
    COMMIT_OFFSETS: consumerType("commit_offsets"),
    GROUP_JOIN: consumerType("group_join"),
    FETCH: consumerType("fetch"),
    FETCH_START: consumerType("fetch_start"),
    START_BATCH_PROCESS: consumerType("start_batch_process"),
    END_BATCH_PROCESS: consumerType("end_batch_process"),
    CONNECT: consumerType("connect"),
    DISCONNECT: consumerType("disconnect"),
    STOP: consumerType("stop"),
    CRASH: consumerType("crash"),
    REBALANCING: consumerType("rebalancing"),
    RECEIVED_UNSUBSCRIBED_TOPICS: consumerType("received_unsubscribed_topics"),
    REQUEST: consumerType(networkEvents.NETWORK_REQUEST),
    REQUEST_TIMEOUT: consumerType(networkEvents.NETWORK_REQUEST_TIMEOUT),
    REQUEST_QUEUE_SIZE: consumerType(networkEvents.NETWORK_REQUEST_QUEUE_SIZE)
  };
  var wrappedEvents = {
    [events.REQUEST]: networkEvents.NETWORK_REQUEST,
    [events.REQUEST_TIMEOUT]: networkEvents.NETWORK_REQUEST_TIMEOUT,
    [events.REQUEST_QUEUE_SIZE]: networkEvents.NETWORK_REQUEST_QUEUE_SIZE
  };
  var reversedWrappedEvents = swapObject(wrappedEvents);
  var unwrap = (eventName) => wrappedEvents[eventName] || eventName;
  var wrap = (eventName) => reversedWrappedEvents[eventName] || eventName;
  module.exports = {
    events,
    wrap,
    unwrap
  };
});

// node_modules/kafkajs/src/consumer/offsetManager/index.js
var require_offsetManager = __commonJS((exports, module) => {
  var Long = require_long();
  var isInvalidOffset = require_isInvalidOffset();
  var initializeConsumerOffsets = require_initializeConsumerOffsets();
  var {
    events: { COMMIT_OFFSETS }
  } = require_instrumentationEvents3();
  var { keys, assign } = Object;
  var indexTopics = (topics) => topics.reduce((obj, topic) => assign(obj, { [topic]: {} }), {});
  var PRIVATE = {
    COMMITTED_OFFSETS: Symbol("private:OffsetManager:committedOffsets")
  };
  module.exports = class OffsetManager {
    constructor({
      cluster,
      coordinator,
      memberAssignment,
      autoCommit,
      autoCommitInterval,
      autoCommitThreshold,
      topicConfigurations,
      instrumentationEmitter,
      groupId,
      generationId,
      memberId
    }) {
      this.cluster = cluster;
      this.coordinator = coordinator;
      this.memberAssignment = memberAssignment;
      this.topicConfigurations = topicConfigurations;
      this.instrumentationEmitter = instrumentationEmitter;
      this.groupId = groupId;
      this.generationId = generationId;
      this.memberId = memberId;
      this.autoCommit = autoCommit;
      this.autoCommitInterval = autoCommitInterval;
      this.autoCommitThreshold = autoCommitThreshold;
      this.lastCommit = Date.now();
      this.topics = keys(memberAssignment);
      this.clearAllOffsets();
    }
    nextOffset(topic, partition) {
      if (!this.resolvedOffsets[topic][partition]) {
        this.resolvedOffsets[topic][partition] = this.committedOffsets()[topic][partition];
      }
      let offset = this.resolvedOffsets[topic][partition];
      if (isInvalidOffset(offset)) {
        offset = "0";
      }
      return Long.fromValue(offset);
    }
    async getCoordinator() {
      if (!this.coordinator.isConnected()) {
        this.coordinator = await this.cluster.findBroker(this.coordinator);
      }
      return this.coordinator;
    }
    resetOffset({ topic, partition }) {
      this.resolvedOffsets[topic][partition] = this.committedOffsets()[topic][partition];
    }
    resolveOffset({ topic, partition, offset }) {
      this.resolvedOffsets[topic][partition] = Long.fromValue(offset).add(1).toString();
    }
    countResolvedOffsets() {
      const committedOffsets = this.committedOffsets();
      const subtractOffsets = (resolvedOffset, committedOffset) => {
        const resolvedOffsetLong = Long.fromValue(resolvedOffset);
        return isInvalidOffset(committedOffset) ? resolvedOffsetLong : resolvedOffsetLong.subtract(Long.fromValue(committedOffset));
      };
      const subtractPartitionOffsets = (resolvedTopicOffsets, committedTopicOffsets) => keys(resolvedTopicOffsets).map((partition) => subtractOffsets(resolvedTopicOffsets[partition], committedTopicOffsets[partition]));
      const subtractTopicOffsets = (topic) => subtractPartitionOffsets(this.resolvedOffsets[topic], committedOffsets[topic]);
      const offsetsDiff = this.topics.flatMap(subtractTopicOffsets);
      return offsetsDiff.reduce((sum, offset) => sum.add(offset), Long.fromValue(0));
    }
    async setDefaultOffset({ topic, partition }) {
      const { groupId, generationId, memberId } = this;
      const defaultOffset = this.cluster.defaultOffset(this.topicConfigurations[topic]);
      const coordinator = await this.getCoordinator();
      await coordinator.offsetCommit({
        groupId,
        memberId,
        groupGenerationId: generationId,
        topics: [
          {
            topic,
            partitions: [{ partition, offset: defaultOffset }]
          }
        ]
      });
      this.clearOffsets({ topic, partition });
    }
    async seek({ topic, partition, offset }) {
      if (!this.memberAssignment[topic] || !this.memberAssignment[topic].includes(partition)) {
        return;
      }
      if (!this.autoCommit) {
        this.resolveOffset({
          topic,
          partition,
          offset: Long.fromValue(offset).subtract(1).toString()
        });
        return;
      }
      const { groupId, generationId, memberId } = this;
      const coordinator = await this.getCoordinator();
      await coordinator.offsetCommit({
        groupId,
        memberId,
        groupGenerationId: generationId,
        topics: [
          {
            topic,
            partitions: [{ partition, offset }]
          }
        ]
      });
      this.clearOffsets({ topic, partition });
    }
    async commitOffsetsIfNecessary() {
      const now = Date.now();
      const timeoutReached = this.autoCommitInterval != null && now >= this.lastCommit + this.autoCommitInterval;
      const thresholdReached = this.autoCommitThreshold != null && this.countResolvedOffsets().gte(Long.fromValue(this.autoCommitThreshold));
      if (timeoutReached || thresholdReached) {
        return this.commitOffsets();
      }
    }
    uncommittedOffsets() {
      const offsets = (topic) => keys(this.resolvedOffsets[topic]);
      const emptyPartitions = ({ partitions }) => partitions.length > 0;
      const toPartitions = (topic) => (partition) => ({
        partition,
        offset: this.resolvedOffsets[topic][partition]
      });
      const changedOffsets = (topic) => ({ partition, offset }) => {
        return offset !== this.committedOffsets()[topic][partition] && Long.fromValue(offset).greaterThanOrEqual(0);
      };
      const topicsWithPartitionsToCommit = this.topics.map((topic) => ({
        topic,
        partitions: offsets(topic).map(toPartitions(topic)).filter(changedOffsets(topic))
      })).filter(emptyPartitions);
      return { topics: topicsWithPartitionsToCommit };
    }
    async commitOffsets(offsets = {}) {
      const { groupId, generationId, memberId } = this;
      const { topics = this.uncommittedOffsets().topics } = offsets;
      if (topics.length === 0) {
        this.lastCommit = Date.now();
        return;
      }
      const payload = {
        groupId,
        memberId,
        groupGenerationId: generationId,
        topics
      };
      try {
        const coordinator = await this.getCoordinator();
        await coordinator.offsetCommit(payload);
        this.instrumentationEmitter.emit(COMMIT_OFFSETS, payload);
        topics.forEach(({ topic, partitions }) => {
          const updatedOffsets = partitions.reduce((obj, { partition, offset }) => assign(obj, { [partition]: offset }), {});
          this[PRIVATE.COMMITTED_OFFSETS][topic] = assign({}, this.committedOffsets()[topic], updatedOffsets);
        });
        this.lastCommit = Date.now();
      } catch (e) {
        if (e.type === "NOT_COORDINATOR_FOR_GROUP") {
          await this.cluster.refreshMetadata();
        }
        throw e;
      }
    }
    async resolveOffsets() {
      const { groupId } = this;
      const invalidOffset = (topic) => (partition) => {
        return isInvalidOffset(this.committedOffsets()[topic][partition]);
      };
      const pendingPartitions = this.topics.map((topic) => ({
        topic,
        partitions: this.memberAssignment[topic].filter(invalidOffset(topic)).map((partition) => ({ partition }))
      })).filter((t) => t.partitions.length > 0);
      if (pendingPartitions.length === 0) {
        return;
      }
      const coordinator = await this.getCoordinator();
      const { responses: consumerOffsets } = await coordinator.offsetFetch({
        groupId,
        topics: pendingPartitions
      });
      const unresolvedPartitions = consumerOffsets.map(({ topic, partitions }) => assign({
        topic,
        partitions: partitions.filter(({ offset }) => isInvalidOffset(offset)).map(({ partition }) => assign({ partition }))
      }, this.topicConfigurations[topic]));
      const indexPartitions = (obj, { partition, offset }) => {
        return assign(obj, { [partition]: offset });
      };
      const hasUnresolvedPartitions = () => unresolvedPartitions.some((t) => t.partitions.length > 0);
      let offsets = consumerOffsets;
      if (hasUnresolvedPartitions()) {
        const topicOffsets = await this.cluster.fetchTopicsOffset(unresolvedPartitions);
        offsets = initializeConsumerOffsets(consumerOffsets, topicOffsets);
      }
      offsets.forEach(({ topic, partitions }) => {
        this.committedOffsets()[topic] = partitions.reduce(indexPartitions, {
          ...this.committedOffsets()[topic]
        });
      });
    }
    clearOffsets({ topic, partition }) {
      delete this.committedOffsets()[topic][partition];
      delete this.resolvedOffsets[topic][partition];
    }
    clearAllOffsets() {
      const committedOffsets = this.committedOffsets();
      for (const topic in committedOffsets) {
        delete committedOffsets[topic];
      }
      for (const topic of this.topics) {
        committedOffsets[topic] = {};
      }
      this.resolvedOffsets = indexTopics(this.topics);
    }
    committedOffsets() {
      if (!this[PRIVATE.COMMITTED_OFFSETS]) {
        this[PRIVATE.COMMITTED_OFFSETS] = this.groupId ? this.cluster.committedOffsets({ groupId: this.groupId }) : {};
      }
      return this[PRIVATE.COMMITTED_OFFSETS];
    }
  };
});

// node_modules/kafkajs/src/consumer/filterAbortedMessages.js
var require_filterAbortedMessages = __commonJS((exports, module) => {
  var Long = require_long();
  var ABORTED_MESSAGE_KEY = Buffer.from([0, 0, 0, 0]);
  var isAbortMarker = ({ key }) => {
    if (!key)
      return false;
    return Buffer.from(key).equals(ABORTED_MESSAGE_KEY);
  };
  module.exports = ({ messages, abortedTransactions }) => {
    const currentAbortedTransactions = new Map;
    if (!abortedTransactions || !abortedTransactions.length) {
      return messages;
    }
    const remainingAbortedTransactions = [...abortedTransactions];
    return messages.filter((message) => {
      if (remainingAbortedTransactions.length && Long.fromValue(message.offset).gte(remainingAbortedTransactions[0].firstOffset)) {
        const { producerId: producerId2 } = remainingAbortedTransactions.shift();
        currentAbortedTransactions.set(producerId2, true);
      }
      const { producerId, inTransaction } = message.batchContext;
      if (isAbortMarker(message)) {
        currentAbortedTransactions.delete(producerId);
      } else if (currentAbortedTransactions.has(producerId) && inTransaction) {
        return false;
      }
      return true;
    });
  };
});

// node_modules/kafkajs/src/consumer/batch.js
var require_batch = __commonJS((exports, module) => {
  var Long = require_long();
  var filterAbortedMessages = require_filterAbortedMessages();
  module.exports = class Batch {
    constructor(topic, fetchedOffset, partitionData) {
      this.fetchedOffset = fetchedOffset;
      const longFetchedOffset = Long.fromValue(this.fetchedOffset);
      const { abortedTransactions, messages } = partitionData;
      this.topic = topic;
      this.partition = partitionData.partition;
      this.highWatermark = partitionData.highWatermark;
      this.rawMessages = messages;
      this.messagesWithinOffset = this.rawMessages.filter((message) => Long.fromValue(message.offset).gte(longFetchedOffset));
      this.messages = filterAbortedMessages({
        messages: this.messagesWithinOffset,
        abortedTransactions
      }).filter((message) => !message.isControlRecord);
    }
    isEmpty() {
      return this.messages.length === 0;
    }
    isEmptyIncludingFiltered() {
      return this.messagesWithinOffset.length === 0;
    }
    isEmptyDueToFiltering() {
      return this.isEmpty() && this.rawMessages.length > 0;
    }
    isEmptyControlRecord() {
      return this.isEmpty() && this.messagesWithinOffset.some(({ isControlRecord }) => isControlRecord);
    }
    isEmptyDueToLogCompactedMessages() {
      const hasMessages = this.rawMessages.length > 0;
      return hasMessages && this.isEmptyIncludingFiltered();
    }
    firstOffset() {
      return this.isEmptyIncludingFiltered() ? null : this.messagesWithinOffset[0].offset;
    }
    lastOffset() {
      if (this.isEmptyDueToLogCompactedMessages()) {
        return this.fetchedOffset;
      }
      if (this.isEmptyIncludingFiltered()) {
        return Long.fromValue(this.highWatermark).add(-1).toString();
      }
      return this.messagesWithinOffset[this.messagesWithinOffset.length - 1].offset;
    }
    offsetLag() {
      const lastOffsetOfPartition = Long.fromValue(this.highWatermark).add(-1);
      const lastConsumedOffset = Long.fromValue(this.lastOffset());
      return lastOffsetOfPartition.add(lastConsumedOffset.multiply(-1)).toString();
    }
    offsetLagLow() {
      if (this.isEmptyIncludingFiltered()) {
        return "0";
      }
      const lastOffsetOfPartition = Long.fromValue(this.highWatermark).add(-1);
      const firstConsumedOffset = Long.fromValue(this.firstOffset());
      return lastOffsetOfPartition.add(firstConsumedOffset.multiply(-1)).toString();
    }
  };
});

// node_modules/kafkajs/src/consumer/seekOffsets.js
var require_seekOffsets = __commonJS((exports, module) => {
  module.exports = class SeekOffsets extends Map {
    getKey(topic, partition) {
      return JSON.stringify([topic, partition]);
    }
    set(topic, partition, offset) {
      const key = this.getKey(topic, partition);
      super.set(key, offset);
    }
    has(topic, partition) {
      const key = this.getKey(topic, partition);
      return super.has(key);
    }
    pop(topic, partition) {
      if (this.size === 0 || !this.has(topic, partition)) {
        return;
      }
      const key = this.getKey(topic, partition);
      const offset = this.get(key);
      this.delete(key);
      return { topic, partition, offset };
    }
  };
});

// node_modules/kafkajs/src/consumer/subscriptionState.js
var require_subscriptionState = __commonJS((exports, module) => {
  var createState = (topic) => ({
    topic,
    paused: new Set,
    pauseAll: false,
    resumed: new Set
  });
  module.exports = class SubscriptionState {
    constructor() {
      this.assignedPartitionsByTopic = {};
      this.subscriptionStatesByTopic = {};
    }
    assign(topicPartitions = []) {
      this.assignedPartitionsByTopic = topicPartitions.reduce((assigned, { topic, partitions = [] }) => {
        return { ...assigned, [topic]: { topic, partitions } };
      }, {});
    }
    pause(topicPartitions = []) {
      topicPartitions.forEach(({ topic, partitions }) => {
        const state = this.subscriptionStatesByTopic[topic] || createState(topic);
        if (typeof partitions === "undefined") {
          state.paused.clear();
          state.resumed.clear();
          state.pauseAll = true;
        } else if (Array.isArray(partitions)) {
          partitions.forEach((partition) => {
            state.paused.add(partition);
            state.resumed.delete(partition);
          });
          state.pauseAll = false;
        }
        this.subscriptionStatesByTopic[topic] = state;
      });
    }
    resume(topicPartitions = []) {
      topicPartitions.forEach(({ topic, partitions }) => {
        const state = this.subscriptionStatesByTopic[topic] || createState(topic);
        if (typeof partitions === "undefined") {
          state.paused.clear();
          state.resumed.clear();
          state.pauseAll = false;
        } else if (Array.isArray(partitions)) {
          partitions.forEach((partition) => {
            state.paused.delete(partition);
            if (state.pauseAll) {
              state.resumed.add(partition);
            }
          });
        }
        this.subscriptionStatesByTopic[topic] = state;
      });
    }
    assigned() {
      return Object.values(this.assignedPartitionsByTopic).map(({ topic, partitions }) => ({
        topic,
        partitions: partitions.sort()
      }));
    }
    active() {
      return Object.values(this.assignedPartitionsByTopic).map(({ topic, partitions }) => ({
        topic,
        partitions: partitions.filter((partition) => !this.isPaused(topic, partition)).sort()
      }));
    }
    paused() {
      return Object.values(this.assignedPartitionsByTopic).map(({ topic, partitions }) => ({
        topic,
        partitions: partitions.filter((partition) => this.isPaused(topic, partition)).sort()
      })).filter(({ partitions }) => partitions.length !== 0);
    }
    isPaused(topic, partition) {
      const state = this.subscriptionStatesByTopic[topic];
      if (!state) {
        return false;
      }
      const partitionResumed = state.resumed.has(partition);
      const partitionPaused = state.paused.has(partition);
      return state.pauseAll && !partitionResumed || partitionPaused;
    }
  };
});

// node_modules/kafkajs/src/consumer/assignerProtocol.js
var require_assignerProtocol = __commonJS((exports, module) => {
  var Encoder = require_encoder();
  var Decoder = require_decoder();
  var MemberMetadata = {
    encode({ version, topics, userData = Buffer.alloc(0) }) {
      return new Encoder().writeInt16(version).writeArray(topics).writeBytes(userData).buffer;
    },
    decode(buffer) {
      const decoder = new Decoder(buffer);
      return {
        version: decoder.readInt16(),
        topics: decoder.readArray((d) => d.readString()),
        userData: decoder.readBytes()
      };
    }
  };
  var MemberAssignment = {
    encode({ version, assignment, userData = Buffer.alloc(0) }) {
      return new Encoder().writeInt16(version).writeArray(Object.keys(assignment).map((topic) => new Encoder().writeString(topic).writeArray(assignment[topic]))).writeBytes(userData).buffer;
    },
    decode(buffer) {
      const decoder = new Decoder(buffer);
      const decodePartitions = (d) => d.readInt32();
      const decodeAssignment = (d) => ({
        topic: d.readString(),
        partitions: d.readArray(decodePartitions)
      });
      const indexAssignment = (obj, { topic, partitions }) => Object.assign(obj, { [topic]: partitions });
      if (!decoder.canReadInt16()) {
        return null;
      }
      return {
        version: decoder.readInt16(),
        assignment: decoder.readArray(decodeAssignment).reduce(indexAssignment, {}),
        userData: decoder.readBytes()
      };
    }
  };
  module.exports = {
    MemberMetadata,
    MemberAssignment
  };
});

// node_modules/kafkajs/src/consumer/consumerGroup.js
var require_consumerGroup = __commonJS((exports, module) => {
  var sleep = require_sleep();
  var websiteUrl = require_websiteUrl();
  var arrayDiff = require_arrayDiff();
  var createRetry = require_retry();
  var sharedPromiseTo = require_sharedPromiseTo();
  var OffsetManager = require_offsetManager();
  var Batch = require_batch();
  var SeekOffsets = require_seekOffsets();
  var SubscriptionState = require_subscriptionState();
  var {
    events: { GROUP_JOIN, HEARTBEAT, CONNECT, RECEIVED_UNSUBSCRIBED_TOPICS }
  } = require_instrumentationEvents3();
  var { MemberAssignment } = require_assignerProtocol();
  var {
    KafkaJSError,
    KafkaJSNonRetriableError,
    KafkaJSStaleTopicMetadataAssignment,
    isRebalancing
  } = require_errors2();
  var { keys } = Object;
  var STALE_METADATA_ERRORS = [
    "LEADER_NOT_AVAILABLE",
    "NOT_LEADER_FOR_PARTITION",
    "FENCED_LEADER_EPOCH",
    "UNKNOWN_LEADER_EPOCH",
    "UNKNOWN_TOPIC_OR_PARTITION"
  ];
  var PRIVATE = {
    JOIN: Symbol("private:ConsumerGroup:join"),
    SYNC: Symbol("private:ConsumerGroup:sync"),
    SHARED_HEARTBEAT: Symbol("private:ConsumerGroup:sharedHeartbeat")
  };
  module.exports = class ConsumerGroup {
    constructor({
      retry,
      cluster,
      groupId,
      topics,
      topicConfigurations,
      logger,
      instrumentationEmitter,
      assigners,
      sessionTimeout,
      rebalanceTimeout,
      maxBytesPerPartition,
      minBytes,
      maxBytes,
      maxWaitTimeInMs,
      autoCommit,
      autoCommitInterval,
      autoCommitThreshold,
      isolationLevel,
      rackId,
      metadataMaxAge
    }) {
      this.cluster = cluster;
      this.groupId = groupId;
      this.topics = topics;
      this.topicsSubscribed = topics;
      this.topicConfigurations = topicConfigurations;
      this.logger = logger.namespace("ConsumerGroup");
      this.instrumentationEmitter = instrumentationEmitter;
      this.retrier = createRetry(Object.assign({}, retry));
      this.assigners = assigners;
      this.sessionTimeout = sessionTimeout;
      this.rebalanceTimeout = rebalanceTimeout;
      this.maxBytesPerPartition = maxBytesPerPartition;
      this.minBytes = minBytes;
      this.maxBytes = maxBytes;
      this.maxWaitTime = maxWaitTimeInMs;
      this.autoCommit = autoCommit;
      this.autoCommitInterval = autoCommitInterval;
      this.autoCommitThreshold = autoCommitThreshold;
      this.isolationLevel = isolationLevel;
      this.rackId = rackId;
      this.metadataMaxAge = metadataMaxAge;
      this.seekOffset = new SeekOffsets;
      this.coordinator = null;
      this.generationId = null;
      this.leaderId = null;
      this.memberId = null;
      this.members = null;
      this.groupProtocol = null;
      this.partitionsPerSubscribedTopic = null;
      this.preferredReadReplicasPerTopicPartition = {};
      this.offsetManager = null;
      this.subscriptionState = new SubscriptionState;
      this.lastRequest = Date.now();
      this[PRIVATE.SHARED_HEARTBEAT] = sharedPromiseTo(async ({ interval }) => {
        const { groupId: groupId2, generationId, memberId } = this;
        const now = Date.now();
        if (memberId && now >= this.lastRequest + interval) {
          const payload = {
            groupId: groupId2,
            memberId,
            groupGenerationId: generationId
          };
          await this.coordinator.heartbeat(payload);
          this.instrumentationEmitter.emit(HEARTBEAT, payload);
          this.lastRequest = Date.now();
        }
      });
    }
    isLeader() {
      return this.leaderId && this.memberId === this.leaderId;
    }
    getNodeIds() {
      return this.cluster.getNodeIds();
    }
    async connect() {
      await this.cluster.connect();
      this.instrumentationEmitter.emit(CONNECT);
      await this.cluster.refreshMetadataIfNecessary();
    }
    async[PRIVATE.JOIN]() {
      const { groupId, sessionTimeout, rebalanceTimeout } = this;
      this.coordinator = await this.cluster.findGroupCoordinator({ groupId });
      const groupData = await this.coordinator.joinGroup({
        groupId,
        sessionTimeout,
        rebalanceTimeout,
        memberId: this.memberId || "",
        groupProtocols: this.assigners.map((assigner) => assigner.protocol({
          topics: this.topicsSubscribed
        }))
      });
      this.generationId = groupData.generationId;
      this.leaderId = groupData.leaderId;
      this.memberId = groupData.memberId;
      this.members = groupData.members;
      this.groupProtocol = groupData.groupProtocol;
    }
    async leave() {
      const { groupId, memberId } = this;
      if (memberId) {
        await this.coordinator.leaveGroup({ groupId, memberId });
        this.memberId = null;
      }
    }
    async[PRIVATE.SYNC]() {
      let assignment = [];
      const {
        groupId,
        generationId,
        memberId,
        members,
        groupProtocol,
        topics,
        topicsSubscribed,
        coordinator
      } = this;
      if (this.isLeader()) {
        this.logger.debug("Chosen as group leader", { groupId, generationId, memberId, topics });
        const assigner = this.assigners.find(({ name }) => name === groupProtocol);
        if (!assigner) {
          throw new KafkaJSNonRetriableError(`Unsupported partition assigner "${groupProtocol}", the assigner wasn't found in the assigners list`);
        }
        await this.cluster.refreshMetadata();
        assignment = await assigner.assign({ members, topics: topicsSubscribed });
        this.logger.debug("Group assignment", {
          groupId,
          generationId,
          groupProtocol,
          assignment,
          topics: topicsSubscribed
        });
      }
      this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic();
      const { memberAssignment } = await this.coordinator.syncGroup({
        groupId,
        generationId,
        memberId,
        groupAssignment: assignment
      });
      const decodedMemberAssignment = MemberAssignment.decode(memberAssignment);
      const decodedAssignment = decodedMemberAssignment != null ? decodedMemberAssignment.assignment : {};
      this.logger.debug("Received assignment", {
        groupId,
        generationId,
        memberId,
        memberAssignment: decodedAssignment
      });
      const assignedTopics = keys(decodedAssignment);
      const topicsNotSubscribed = arrayDiff(assignedTopics, topicsSubscribed);
      if (topicsNotSubscribed.length > 0) {
        const payload = {
          groupId,
          generationId,
          memberId,
          assignedTopics,
          topicsSubscribed,
          topicsNotSubscribed
        };
        this.instrumentationEmitter.emit(RECEIVED_UNSUBSCRIBED_TOPICS, payload);
        this.logger.warn("Consumer group received unsubscribed topics", {
          ...payload,
          helpUrl: websiteUrl("docs/faq", "why-am-i-receiving-messages-for-topics-i-m-not-subscribed-to")
        });
      }
      const safeAssignment = arrayDiff(assignedTopics, topicsNotSubscribed);
      const currentMemberAssignment = safeAssignment.map((topic) => ({
        topic,
        partitions: decodedAssignment[topic]
      }));
      for (const assignment2 of currentMemberAssignment) {
        const { topic, partitions: assignedPartitions } = assignment2;
        const knownPartitions = this.partitionsPerSubscribedTopic.get(topic);
        const isAwareOfAllAssignedPartitions = assignedPartitions.every((partition) => knownPartitions.includes(partition));
        if (!isAwareOfAllAssignedPartitions) {
          this.logger.warn("Consumer is not aware of all assigned partitions, refreshing metadata", {
            groupId,
            generationId,
            memberId,
            topic,
            knownPartitions,
            assignedPartitions
          });
          await this.cluster.refreshMetadata();
          this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic();
          break;
        }
      }
      this.topics = currentMemberAssignment.map(({ topic }) => topic);
      this.subscriptionState.assign(currentMemberAssignment);
      this.offsetManager = new OffsetManager({
        cluster: this.cluster,
        topicConfigurations: this.topicConfigurations,
        instrumentationEmitter: this.instrumentationEmitter,
        memberAssignment: currentMemberAssignment.reduce((partitionsByTopic, { topic, partitions }) => ({
          ...partitionsByTopic,
          [topic]: partitions
        }), {}),
        autoCommit: this.autoCommit,
        autoCommitInterval: this.autoCommitInterval,
        autoCommitThreshold: this.autoCommitThreshold,
        coordinator,
        groupId,
        generationId,
        memberId
      });
    }
    joinAndSync() {
      const startJoin = Date.now();
      return this.retrier(async (bail) => {
        try {
          await this[PRIVATE.JOIN]();
          await this[PRIVATE.SYNC]();
          const memberAssignment = this.assigned().reduce((result, { topic, partitions }) => ({ ...result, [topic]: partitions }), {});
          const payload = {
            groupId: this.groupId,
            memberId: this.memberId,
            leaderId: this.leaderId,
            isLeader: this.isLeader(),
            memberAssignment,
            groupProtocol: this.groupProtocol,
            duration: Date.now() - startJoin
          };
          this.instrumentationEmitter.emit(GROUP_JOIN, payload);
          this.logger.info("Consumer has joined the group", payload);
        } catch (e) {
          if (isRebalancing(e)) {
            throw new KafkaJSError(e);
          }
          if (e.type === "UNKNOWN_MEMBER_ID") {
            this.memberId = null;
            throw new KafkaJSError(e);
          }
          bail(e);
        }
      });
    }
    resetOffset({ topic, partition }) {
      this.offsetManager.resetOffset({ topic, partition });
    }
    resolveOffset({ topic, partition, offset }) {
      this.offsetManager.resolveOffset({ topic, partition, offset });
    }
    seek({ topic, partition, offset }) {
      this.seekOffset.set(topic, partition, offset);
    }
    pause(topicPartitions) {
      this.logger.info(`Pausing fetching from ${topicPartitions.length} topics`, {
        topicPartitions
      });
      this.subscriptionState.pause(topicPartitions);
    }
    resume(topicPartitions) {
      this.logger.info(`Resuming fetching from ${topicPartitions.length} topics`, {
        topicPartitions
      });
      this.subscriptionState.resume(topicPartitions);
    }
    assigned() {
      return this.subscriptionState.assigned();
    }
    paused() {
      return this.subscriptionState.paused();
    }
    isPaused(topic, partition) {
      return this.subscriptionState.isPaused(topic, partition);
    }
    async commitOffsetsIfNecessary() {
      await this.offsetManager.commitOffsetsIfNecessary();
    }
    async commitOffsets(offsets) {
      await this.offsetManager.commitOffsets(offsets);
    }
    uncommittedOffsets() {
      return this.offsetManager.uncommittedOffsets();
    }
    async heartbeat({ interval }) {
      return this[PRIVATE.SHARED_HEARTBEAT]({ interval });
    }
    async fetch(nodeId) {
      try {
        await this.cluster.refreshMetadataIfNecessary();
        this.checkForStaleAssignment();
        let topicPartitions = this.subscriptionState.assigned();
        topicPartitions = this.filterPartitionsByNode(nodeId, topicPartitions);
        await this.seekOffsets(topicPartitions);
        const committedOffsets = this.offsetManager.committedOffsets();
        const activeTopicPartitions = this.getActiveTopicPartitions();
        const requests = topicPartitions.map(({ topic, partitions }) => ({
          topic,
          partitions: partitions.filter((partition) => committedOffsets[topic][partition] != null && activeTopicPartitions[topic].has(partition)).map((partition) => ({
            partition,
            fetchOffset: this.offsetManager.nextOffset(topic, partition).toString(),
            maxBytes: this.maxBytesPerPartition
          }))
        })).filter(({ partitions }) => partitions.length);
        if (!requests.length) {
          await sleep(this.maxWaitTime);
          return [];
        }
        const broker = await this.cluster.findBroker({ nodeId });
        const { responses } = await broker.fetch({
          maxWaitTime: this.maxWaitTime,
          minBytes: this.minBytes,
          maxBytes: this.maxBytes,
          isolationLevel: this.isolationLevel,
          topics: requests,
          rackId: this.rackId
        });
        return responses.flatMap(({ topicName, partitions }) => {
          const topicRequestData = requests.find(({ topic }) => topic === topicName);
          let preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topicName];
          if (!preferredReadReplicas) {
            this.preferredReadReplicasPerTopicPartition[topicName] = preferredReadReplicas = {};
          }
          return partitions.filter(({ partition }) => !this.seekOffset.has(topicName, partition) && !this.subscriptionState.isPaused(topicName, partition)).map((partitionData) => {
            const { partition, preferredReadReplica } = partitionData;
            if (preferredReadReplica != null && preferredReadReplica !== -1) {
              const { nodeId: currentPreferredReadReplica } = preferredReadReplicas[partition] || {};
              if (currentPreferredReadReplica !== preferredReadReplica) {
                this.logger.info(`Preferred read replica is now ${preferredReadReplica}`, {
                  groupId: this.groupId,
                  memberId: this.memberId,
                  topic: topicName,
                  partition
                });
              }
              preferredReadReplicas[partition] = {
                nodeId: preferredReadReplica,
                expireAt: Date.now() + this.metadataMaxAge
              };
            }
            const partitionRequestData = topicRequestData.partitions.find(({ partition: partition2 }) => partition2 === partitionData.partition);
            const fetchedOffset = partitionRequestData.fetchOffset;
            return new Batch(topicName, fetchedOffset, partitionData);
          });
        });
      } catch (e) {
        await this.recoverFromFetch(e);
        return [];
      }
    }
    async recoverFromFetch(e) {
      if (STALE_METADATA_ERRORS.includes(e.type) || e.name === "KafkaJSTopicMetadataNotLoaded") {
        this.logger.debug("Stale cluster metadata, refreshing...", {
          groupId: this.groupId,
          memberId: this.memberId,
          error: e.message
        });
        await this.cluster.refreshMetadata();
        await this.joinAndSync();
        return;
      }
      if (e.name === "KafkaJSStaleTopicMetadataAssignment") {
        this.logger.warn(`${e.message}, resync group`, {
          groupId: this.groupId,
          memberId: this.memberId,
          topic: e.topic,
          unknownPartitions: e.unknownPartitions
        });
        await this.joinAndSync();
        return;
      }
      if (e.name === "KafkaJSOffsetOutOfRange") {
        await this.recoverFromOffsetOutOfRange(e);
        return;
      }
      if (e.name === "KafkaJSConnectionClosedError") {
        this.cluster.removeBroker({ host: e.host, port: e.port });
        return;
      }
      if (e.name === "KafkaJSBrokerNotFound" || e.name === "KafkaJSConnectionClosedError") {
        this.logger.debug(`${e.message}, refreshing metadata and retrying...`);
        await this.cluster.refreshMetadata();
        return;
      }
      throw e;
    }
    async recoverFromOffsetOutOfRange(e) {
      const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[e.topic];
      if (preferredReadReplicas && typeof preferredReadReplicas[e.partition] === "number") {
        this.logger.info("Offset out of range while fetching from follower, retrying with leader", {
          topic: e.topic,
          partition: e.partition,
          groupId: this.groupId,
          memberId: this.memberId
        });
        delete preferredReadReplicas[e.partition];
      } else {
        this.logger.error("Offset out of range, resetting to default offset", {
          topic: e.topic,
          partition: e.partition,
          groupId: this.groupId,
          memberId: this.memberId
        });
        await this.offsetManager.setDefaultOffset({
          topic: e.topic,
          partition: e.partition
        });
      }
    }
    generatePartitionsPerSubscribedTopic() {
      const map = new Map;
      for (const topic of this.topicsSubscribed) {
        const partitions = this.cluster.findTopicPartitionMetadata(topic).map((m) => m.partitionId).sort();
        map.set(topic, partitions);
      }
      return map;
    }
    checkForStaleAssignment() {
      if (!this.partitionsPerSubscribedTopic) {
        return;
      }
      const newPartitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic();
      for (const [topic, partitions] of newPartitionsPerSubscribedTopic) {
        const diff = arrayDiff(partitions, this.partitionsPerSubscribedTopic.get(topic));
        if (diff.length > 0) {
          throw new KafkaJSStaleTopicMetadataAssignment("Topic has been updated", {
            topic,
            unknownPartitions: diff
          });
        }
      }
    }
    async seekOffsets(topicPartitions) {
      for (const { topic, partitions } of topicPartitions) {
        for (const partition of partitions) {
          const seekEntry = this.seekOffset.pop(topic, partition);
          if (!seekEntry) {
            continue;
          }
          this.logger.debug("Seek offset", {
            groupId: this.groupId,
            memberId: this.memberId,
            seek: seekEntry
          });
          await this.offsetManager.seek(seekEntry);
        }
      }
      await this.offsetManager.resolveOffsets();
    }
    hasSeekOffset({ topic, partition }) {
      return this.seekOffset.has(topic, partition);
    }
    findReadReplicaForPartitions(topic, partitions) {
      const partitionMetadata = this.cluster.findTopicPartitionMetadata(topic);
      const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topic];
      return partitions.reduce((result, id) => {
        const partitionId = parseInt(id, 10);
        const metadata = partitionMetadata.find((p) => p.partitionId === partitionId);
        if (!metadata) {
          return result;
        }
        if (metadata.leader == null) {
          throw new KafkaJSError("Invalid partition metadata", { topic, partitionId, metadata });
        }
        let nodeId = metadata.leader;
        if (preferredReadReplicas) {
          const { nodeId: preferredReadReplica, expireAt } = preferredReadReplicas[partitionId] || {};
          if (Date.now() >= expireAt) {
            this.logger.debug("Preferred read replica information has expired, using leader", {
              topic,
              partitionId,
              groupId: this.groupId,
              memberId: this.memberId,
              preferredReadReplica,
              leader: metadata.leader
            });
            delete preferredReadReplicas[partitionId];
          } else if (preferredReadReplica != null) {
            const offlineReplicas = metadata.offlineReplicas;
            if (Array.isArray(offlineReplicas) && offlineReplicas.includes(nodeId)) {
              this.logger.debug("Preferred read replica is offline, using leader", {
                topic,
                partitionId,
                groupId: this.groupId,
                memberId: this.memberId,
                preferredReadReplica,
                leader: metadata.leader
              });
            } else {
              nodeId = preferredReadReplica;
            }
          }
        }
        const current = result[nodeId] || [];
        return { ...result, [nodeId]: [...current, partitionId] };
      }, {});
    }
    filterPartitionsByNode(nodeId, topicPartitions) {
      return topicPartitions.map(({ topic, partitions }) => ({
        topic,
        partitions: this.findReadReplicaForPartitions(topic, partitions)[nodeId] || []
      }));
    }
    getActiveTopicPartitions() {
      const activeSubscriptionState = this.subscriptionState.active();
      const activeTopicPartitions = {};
      activeSubscriptionState.forEach(({ topic, partitions }) => {
        activeTopicPartitions[topic] = new Set(partitions);
      });
      return activeTopicPartitions;
    }
  };
});

// node_modules/kafkajs/src/utils/seq.js
var require_seq = __commonJS((exports, module) => {
  var seq = (count, callback = (x) => x) => new Array(count).fill(0).map((_, index) => callback(index));
  module.exports = seq;
});

// node_modules/kafkajs/src/consumer/fetcher.js
var require_fetcher = __commonJS((exports, module) => {
  var EventEmitter = __require("events");
  var createFetcher = ({
    nodeId,
    workerQueue,
    partitionAssignments,
    fetch,
    logger: rootLogger
  }) => {
    const logger = rootLogger.namespace(`Fetcher ${nodeId}`);
    const emitter = new EventEmitter;
    let isRunning = false;
    const getWorkerQueue = () => workerQueue;
    const assignmentKey = ({ topic, partition }) => `${topic}|${partition}`;
    const getAssignedFetcher = (batch) => partitionAssignments.get(assignmentKey(batch));
    const assignTopicPartition = (batch) => partitionAssignments.set(assignmentKey(batch), nodeId);
    const unassignTopicPartition = (batch) => partitionAssignments.delete(assignmentKey(batch));
    const filterUnassignedBatches = (batches) => batches.filter((batch) => {
      const assignedFetcher = getAssignedFetcher(batch);
      if (assignedFetcher != null && assignedFetcher !== nodeId) {
        logger.info("Filtering out batch due to partition already being processed by another fetcher", {
          topic: batch.topic,
          partition: batch.partition,
          assignedFetcher,
          fetcher: nodeId
        });
        return false;
      }
      return true;
    });
    const start = async () => {
      if (isRunning)
        return;
      isRunning = true;
      while (isRunning) {
        try {
          const batches = await fetch(nodeId);
          if (isRunning) {
            const availableBatches = filterUnassignedBatches(batches);
            if (availableBatches.length > 0) {
              availableBatches.forEach(assignTopicPartition);
              try {
                await workerQueue.push(...availableBatches);
              } finally {
                availableBatches.forEach(unassignTopicPartition);
              }
            }
          }
        } catch (error) {
          isRunning = false;
          emitter.emit("end");
          throw error;
        }
      }
      emitter.emit("end");
    };
    const stop = async () => {
      if (!isRunning)
        return;
      isRunning = false;
      await new Promise((resolve) => emitter.once("end", () => resolve()));
    };
    return { start, stop, getWorkerQueue };
  };
  module.exports = createFetcher;
});

// node_modules/kafkajs/src/consumer/worker.js
var require_worker = __commonJS((exports, module) => {
  var sharedPromiseTo = require_sharedPromiseTo();
  var createWorker = ({ handler, workerId }) => {
    const run = sharedPromiseTo(async ({ next }) => {
      while (true) {
        const item = next();
        if (!item)
          break;
        const { batch, resolve, reject } = item;
        try {
          await handler(batch, { workerId });
          resolve();
        } catch (error) {
          reject(error);
        }
      }
    });
    return { run };
  };
  module.exports = createWorker;
});

// node_modules/kafkajs/src/consumer/workerQueue.js
var require_workerQueue = __commonJS((exports, module) => {
  var createWorkerQueue = ({ workers }) => {
    const queue = [];
    const getWorkers = () => workers;
    const push = async (...batches) => {
      const promises2 = batches.map((batch) => new Promise((resolve, reject) => queue.push({ batch, resolve, reject })));
      workers.forEach((worker) => worker.run({ next: () => queue.shift() }));
      const results = await Promise.allSettled(promises2);
      const rejected = results.find((result) => result.status === "rejected");
      if (rejected) {
        throw rejected.reason;
      }
    };
    return { push, getWorkers };
  };
  module.exports = createWorkerQueue;
});

// node_modules/kafkajs/src/consumer/fetchManager.js
var require_fetchManager = __commonJS((exports, module) => {
  var seq = require_seq();
  var createFetcher = require_fetcher();
  var createWorker = require_worker();
  var createWorkerQueue = require_workerQueue();
  var { KafkaJSFetcherRebalanceError, KafkaJSNoBrokerAvailableError } = require_errors2();
  var createFetchManager = ({
    logger: rootLogger,
    getNodeIds,
    fetch,
    handler,
    concurrency = 1
  }) => {
    const logger = rootLogger.namespace("FetchManager");
    const workers = seq(concurrency, (workerId) => createWorker({ handler, workerId }));
    const workerQueue = createWorkerQueue({ workers });
    let fetchers = [];
    const getFetchers = () => fetchers;
    const createFetchers = () => {
      const nodeIds = getNodeIds();
      const partitionAssignments = new Map;
      if (nodeIds.length === 0) {
        throw new KafkaJSNoBrokerAvailableError;
      }
      const validateShouldRebalance = () => {
        const current = getNodeIds();
        const hasChanged = nodeIds.length !== current.length || nodeIds.some((nodeId) => !current.includes(nodeId));
        if (hasChanged && current.length !== 0) {
          throw new KafkaJSFetcherRebalanceError;
        }
      };
      const fetchers2 = nodeIds.map((nodeId) => createFetcher({
        nodeId,
        workerQueue,
        partitionAssignments,
        fetch: async (nodeId2) => {
          validateShouldRebalance();
          return fetch(nodeId2);
        },
        logger
      }));
      logger.debug(`Created ${fetchers2.length} fetchers`, { nodeIds, concurrency });
      return fetchers2;
    };
    const start = async () => {
      logger.debug("Starting...");
      while (true) {
        fetchers = createFetchers();
        try {
          await Promise.all(fetchers.map((fetcher) => fetcher.start()));
        } catch (error) {
          await stop();
          if (error instanceof KafkaJSFetcherRebalanceError) {
            logger.debug("Rebalancing fetchers...");
            continue;
          }
          throw error;
        }
        break;
      }
    };
    const stop = async () => {
      logger.debug("Stopping fetchers...");
      await Promise.all(fetchers.map((fetcher) => fetcher.stop()));
      logger.debug("Stopped fetchers");
    };
    return { start, stop, getFetchers };
  };
  module.exports = createFetchManager;
});

// node_modules/kafkajs/src/consumer/runner.js
var require_runner = __commonJS((exports, module) => {
  var { EventEmitter } = __require("events");
  var Long = require_long();
  var createRetry = require_retry();
  var { isKafkaJSError, isRebalancing } = require_errors2();
  var {
    events: { FETCH, FETCH_START, START_BATCH_PROCESS, END_BATCH_PROCESS, REBALANCING }
  } = require_instrumentationEvents3();
  var createFetchManager = require_fetchManager();
  var isSameOffset = (offsetA, offsetB) => Long.fromValue(offsetA).equals(Long.fromValue(offsetB));
  var CONSUMING_START = "consuming-start";
  var CONSUMING_STOP = "consuming-stop";
  module.exports = class Runner extends EventEmitter {
    constructor({
      logger,
      consumerGroup,
      instrumentationEmitter,
      eachBatchAutoResolve = true,
      concurrency,
      eachBatch,
      eachMessage,
      heartbeatInterval,
      onCrash,
      retry,
      autoCommit = true
    }) {
      super();
      this.logger = logger.namespace("Runner");
      this.consumerGroup = consumerGroup;
      this.instrumentationEmitter = instrumentationEmitter;
      this.eachBatchAutoResolve = eachBatchAutoResolve;
      this.eachBatch = eachBatch;
      this.eachMessage = eachMessage;
      this.heartbeatInterval = heartbeatInterval;
      this.retrier = createRetry(Object.assign({}, retry));
      this.onCrash = onCrash;
      this.autoCommit = autoCommit;
      this.fetchManager = createFetchManager({
        logger: this.logger,
        getNodeIds: () => this.consumerGroup.getNodeIds(),
        fetch: (nodeId) => this.fetch(nodeId),
        handler: (batch) => this.handleBatch(batch),
        concurrency
      });
      this.running = false;
      this.consuming = false;
    }
    get consuming() {
      return this._consuming;
    }
    set consuming(value) {
      if (this._consuming !== value) {
        this._consuming = value;
        this.emit(value ? CONSUMING_START : CONSUMING_STOP);
      }
    }
    async start() {
      if (this.running) {
        return;
      }
      try {
        await this.consumerGroup.connect();
        await this.consumerGroup.joinAndSync();
      } catch (e) {
        return this.onCrash(e);
      }
      this.running = true;
      this.scheduleFetchManager();
    }
    scheduleFetchManager() {
      if (!this.running) {
        this.consuming = false;
        this.logger.info("consumer not running, exiting", {
          groupId: this.consumerGroup.groupId,
          memberId: this.consumerGroup.memberId
        });
        return;
      }
      this.consuming = true;
      this.retrier(async (bail, retryCount, retryTime) => {
        if (!this.running) {
          return;
        }
        try {
          await this.fetchManager.start();
        } catch (e) {
          if (isRebalancing(e)) {
            this.logger.warn("The group is rebalancing, re-joining", {
              groupId: this.consumerGroup.groupId,
              memberId: this.consumerGroup.memberId,
              error: e.message
            });
            this.instrumentationEmitter.emit(REBALANCING, {
              groupId: this.consumerGroup.groupId,
              memberId: this.consumerGroup.memberId
            });
            await this.consumerGroup.joinAndSync();
            return;
          }
          if (e.type === "UNKNOWN_MEMBER_ID") {
            this.logger.error("The coordinator is not aware of this member, re-joining the group", {
              groupId: this.consumerGroup.groupId,
              memberId: this.consumerGroup.memberId,
              error: e.message
            });
            this.consumerGroup.memberId = null;
            await this.consumerGroup.joinAndSync();
            return;
          }
          if (e.name === "KafkaJSNotImplemented") {
            return bail(e);
          }
          if (e.name === "KafkaJSNoBrokerAvailableError") {
            return bail(e);
          }
          this.logger.debug("Error while scheduling fetch manager, trying again...", {
            groupId: this.consumerGroup.groupId,
            memberId: this.consumerGroup.memberId,
            error: e.message,
            stack: e.stack,
            retryCount,
            retryTime
          });
          throw e;
        }
      }).then(() => {
        this.scheduleFetchManager();
      }).catch((e) => {
        this.onCrash(e);
        this.consuming = false;
        this.running = false;
      });
    }
    async stop() {
      if (!this.running) {
        return;
      }
      this.logger.debug("stop consumer group", {
        groupId: this.consumerGroup.groupId,
        memberId: this.consumerGroup.memberId
      });
      this.running = false;
      try {
        await this.fetchManager.stop();
        await this.waitForConsumer();
        await this.consumerGroup.leave();
      } catch (e) {
      }
    }
    waitForConsumer() {
      return new Promise((resolve) => {
        if (!this.consuming) {
          return resolve();
        }
        this.logger.debug("waiting for consumer to finish...", {
          groupId: this.consumerGroup.groupId,
          memberId: this.consumerGroup.memberId
        });
        this.once(CONSUMING_STOP, () => resolve());
      });
    }
    async heartbeat() {
      try {
        await this.consumerGroup.heartbeat({ interval: this.heartbeatInterval });
      } catch (e) {
        if (isRebalancing(e)) {
          await this.autoCommitOffsets();
        }
        throw e;
      }
    }
    async processEachMessage(batch) {
      const { topic, partition } = batch;
      const pause = () => {
        this.consumerGroup.pause([{ topic, partitions: [partition] }]);
        return () => this.consumerGroup.resume([{ topic, partitions: [partition] }]);
      };
      for (const message of batch.messages) {
        if (!this.running || this.consumerGroup.hasSeekOffset({ topic, partition })) {
          break;
        }
        try {
          await this.eachMessage({
            topic,
            partition,
            message,
            heartbeat: () => this.heartbeat(),
            pause
          });
        } catch (e) {
          if (!isKafkaJSError(e)) {
            this.logger.error(`Error when calling eachMessage`, {
              topic,
              partition,
              offset: message.offset,
              stack: e.stack,
              error: e
            });
          }
          await this.autoCommitOffsets();
          throw e;
        }
        this.consumerGroup.resolveOffset({ topic, partition, offset: message.offset });
        await this.heartbeat();
        await this.autoCommitOffsetsIfNecessary();
        if (this.consumerGroup.isPaused(topic, partition)) {
          break;
        }
      }
    }
    async processEachBatch(batch) {
      const { topic, partition } = batch;
      const lastFilteredMessage = batch.messages[batch.messages.length - 1];
      const pause = () => {
        this.consumerGroup.pause([{ topic, partitions: [partition] }]);
        return () => this.consumerGroup.resume([{ topic, partitions: [partition] }]);
      };
      try {
        await this.eachBatch({
          batch,
          resolveOffset: (offset) => {
            const offsetToResolve = lastFilteredMessage && isSameOffset(offset, lastFilteredMessage.offset) ? batch.lastOffset() : offset;
            this.consumerGroup.resolveOffset({ topic, partition, offset: offsetToResolve });
          },
          heartbeat: () => this.heartbeat(),
          pause,
          commitOffsetsIfNecessary: async (offsets) => {
            return offsets ? this.consumerGroup.commitOffsets(offsets) : this.consumerGroup.commitOffsetsIfNecessary();
          },
          uncommittedOffsets: () => this.consumerGroup.uncommittedOffsets(),
          isRunning: () => this.running,
          isStale: () => this.consumerGroup.hasSeekOffset({ topic, partition })
        });
      } catch (e) {
        if (!isKafkaJSError(e)) {
          this.logger.error(`Error when calling eachBatch`, {
            topic,
            partition,
            offset: batch.firstOffset(),
            stack: e.stack,
            error: e
          });
        }
        await this.autoCommitOffsets();
        throw e;
      }
      if (this.eachBatchAutoResolve) {
        this.consumerGroup.resolveOffset({ topic, partition, offset: batch.lastOffset() });
      }
    }
    async fetch(nodeId) {
      if (!this.running) {
        this.logger.debug("consumer not running, exiting", {
          groupId: this.consumerGroup.groupId,
          memberId: this.consumerGroup.memberId
        });
        return [];
      }
      const startFetch = Date.now();
      this.instrumentationEmitter.emit(FETCH_START, { nodeId });
      const batches = await this.consumerGroup.fetch(nodeId);
      this.instrumentationEmitter.emit(FETCH, {
        numberOfBatches: 0,
        duration: Date.now() - startFetch,
        nodeId
      });
      if (batches.length === 0) {
        await this.heartbeat();
      }
      return batches;
    }
    async handleBatch(batch) {
      if (!this.running) {
        this.logger.debug("consumer not running, exiting", {
          groupId: this.consumerGroup.groupId,
          memberId: this.consumerGroup.memberId
        });
        return;
      }
      const onBatch = async (batch2) => {
        const startBatchProcess = Date.now();
        const payload = {
          topic: batch2.topic,
          partition: batch2.partition,
          highWatermark: batch2.highWatermark,
          offsetLag: batch2.offsetLag(),
          offsetLagLow: batch2.offsetLagLow(),
          batchSize: batch2.messages.length,
          firstOffset: batch2.firstOffset(),
          lastOffset: batch2.lastOffset()
        };
        if (batch2.isEmptyDueToFiltering()) {
          this.instrumentationEmitter.emit(START_BATCH_PROCESS, payload);
          this.consumerGroup.resolveOffset({
            topic: batch2.topic,
            partition: batch2.partition,
            offset: batch2.lastOffset()
          });
          await this.autoCommitOffsetsIfNecessary();
          this.instrumentationEmitter.emit(END_BATCH_PROCESS, {
            ...payload,
            duration: Date.now() - startBatchProcess
          });
          await this.heartbeat();
          return;
        }
        if (batch2.isEmpty()) {
          await this.heartbeat();
          return;
        }
        this.instrumentationEmitter.emit(START_BATCH_PROCESS, payload);
        if (this.eachMessage) {
          await this.processEachMessage(batch2);
        } else if (this.eachBatch) {
          await this.processEachBatch(batch2);
        }
        this.instrumentationEmitter.emit(END_BATCH_PROCESS, {
          ...payload,
          duration: Date.now() - startBatchProcess
        });
        await this.autoCommitOffsets();
        await this.heartbeat();
      };
      await onBatch(batch);
    }
    autoCommitOffsets() {
      if (this.autoCommit) {
        return this.consumerGroup.commitOffsets();
      }
    }
    autoCommitOffsetsIfNecessary() {
      if (this.autoCommit) {
        return this.consumerGroup.commitOffsetsIfNecessary();
      }
    }
    commitOffsets(offsets) {
      if (!this.running) {
        this.logger.debug("consumer not running, exiting", {
          groupId: this.consumerGroup.groupId,
          memberId: this.consumerGroup.memberId,
          offsets
        });
        return;
      }
      return this.retrier(async (bail, retryCount, retryTime) => {
        try {
          await this.consumerGroup.commitOffsets(offsets);
        } catch (e) {
          if (!this.running) {
            this.logger.debug("consumer not running, exiting", {
              error: e.message,
              groupId: this.consumerGroup.groupId,
              memberId: this.consumerGroup.memberId,
              offsets
            });
            return;
          }
          if (e.name === "KafkaJSNotImplemented") {
            return bail(e);
          }
          this.logger.debug("Error while committing offsets, trying again...", {
            groupId: this.consumerGroup.groupId,
            memberId: this.consumerGroup.memberId,
            error: e.message,
            stack: e.stack,
            retryCount,
            retryTime,
            offsets
          });
          throw e;
        }
      });
    }
  };
});

// node_modules/kafkajs/src/consumer/assigners/roundRobinAssigner/index.js
var require_roundRobinAssigner = __commonJS((exports, module) => {
  var { MemberMetadata, MemberAssignment } = require_assignerProtocol();
  module.exports = ({ cluster }) => ({
    name: "RoundRobinAssigner",
    version: 0,
    async assign({ members, topics }) {
      const membersCount = members.length;
      const sortedMembers = members.map(({ memberId }) => memberId).sort();
      const assignment = {};
      const topicsPartitions = topics.flatMap((topic) => {
        const partitionMetadata = cluster.findTopicPartitionMetadata(topic);
        return partitionMetadata.map((m) => ({ topic, partitionId: m.partitionId }));
      });
      topicsPartitions.forEach((topicPartition, i) => {
        const assignee = sortedMembers[i % membersCount];
        if (!assignment[assignee]) {
          assignment[assignee] = Object.create(null);
        }
        if (!assignment[assignee][topicPartition.topic]) {
          assignment[assignee][topicPartition.topic] = [];
        }
        assignment[assignee][topicPartition.topic].push(topicPartition.partitionId);
      });
      return Object.keys(assignment).map((memberId) => ({
        memberId,
        memberAssignment: MemberAssignment.encode({
          version: this.version,
          assignment: assignment[memberId]
        })
      }));
    },
    protocol({ topics }) {
      return {
        name: this.name,
        metadata: MemberMetadata.encode({
          version: this.version,
          topics
        })
      };
    }
  });
});

// node_modules/kafkajs/src/consumer/assigners/index.js
var require_assigners = __commonJS((exports, module) => {
  var roundRobin = require_roundRobinAssigner();
  module.exports = {
    roundRobin
  };
});

// node_modules/kafkajs/src/consumer/index.js
var require_consumer = __commonJS((exports, module) => {
  var Long = require_long();
  var createRetry = require_retry();
  var { initialRetryTime } = require_defaults();
  var ConsumerGroup = require_consumerGroup();
  var Runner = require_runner();
  var { events, wrap: wrapEvent, unwrap: unwrapEvent } = require_instrumentationEvents3();
  var InstrumentationEventEmitter = require_emitter();
  var { KafkaJSNonRetriableError } = require_errors2();
  var { roundRobin } = require_assigners();
  var { EARLIEST_OFFSET, LATEST_OFFSET } = require_constants2();
  var ISOLATION_LEVEL = require_isolationLevel();
  var sharedPromiseTo = require_sharedPromiseTo();
  var { keys, values } = Object;
  var { CONNECT, DISCONNECT, STOP, CRASH } = events;
  var eventNames = values(events);
  var eventKeys = keys(events).map((key) => `consumer.events.${key}`).join(", ");
  var specialOffsets = [
    Long.fromValue(EARLIEST_OFFSET).toString(),
    Long.fromValue(LATEST_OFFSET).toString()
  ];
  module.exports = ({
    cluster,
    groupId,
    retry,
    logger: rootLogger,
    partitionAssigners = [roundRobin],
    sessionTimeout = 30000,
    rebalanceTimeout = 60000,
    heartbeatInterval = 3000,
    maxBytesPerPartition = 1048576,
    minBytes = 1,
    maxBytes = 10485760,
    maxWaitTimeInMs = 5000,
    isolationLevel = ISOLATION_LEVEL.READ_COMMITTED,
    rackId = "",
    instrumentationEmitter: rootInstrumentationEmitter,
    metadataMaxAge
  }) => {
    if (!groupId) {
      throw new KafkaJSNonRetriableError("Consumer groupId must be a non-empty string.");
    }
    const logger = rootLogger.namespace("Consumer");
    const instrumentationEmitter = rootInstrumentationEmitter || new InstrumentationEventEmitter;
    const assigners = partitionAssigners.map((createAssigner) => createAssigner({ groupId, logger, cluster }));
    const topics = {};
    let runner = null;
    let consumerGroup = null;
    let restartTimeout = null;
    if (heartbeatInterval >= sessionTimeout) {
      throw new KafkaJSNonRetriableError(`Consumer heartbeatInterval (${heartbeatInterval}) must be lower than sessionTimeout (${sessionTimeout}). It is recommended to set heartbeatInterval to approximately a third of the sessionTimeout.`);
    }
    const connect = async () => {
      await cluster.connect();
      instrumentationEmitter.emit(CONNECT);
    };
    const disconnect = async () => {
      try {
        await stop();
        logger.debug("consumer has stopped, disconnecting", { groupId });
        await cluster.disconnect();
        instrumentationEmitter.emit(DISCONNECT);
      } catch (e) {
        logger.error(`Caught error when disconnecting the consumer: ${e.message}`, {
          stack: e.stack,
          groupId
        });
        throw e;
      }
    };
    const stop = sharedPromiseTo(async () => {
      try {
        if (runner) {
          await runner.stop();
          runner = null;
          consumerGroup = null;
          instrumentationEmitter.emit(STOP);
        }
        clearTimeout(restartTimeout);
        logger.info("Stopped", { groupId });
      } catch (e) {
        logger.error(`Caught error when stopping the consumer: ${e.message}`, {
          stack: e.stack,
          groupId
        });
        throw e;
      }
    });
    const subscribe = async ({ topic, topics: subscriptionTopics, fromBeginning = false }) => {
      if (consumerGroup) {
        throw new KafkaJSNonRetriableError("Cannot subscribe to topic while consumer is running");
      }
      if (!topic && !subscriptionTopics) {
        throw new KafkaJSNonRetriableError('Missing required argument "topics"');
      }
      if (subscriptionTopics != null && !Array.isArray(subscriptionTopics)) {
        throw new KafkaJSNonRetriableError('Argument "topics" must be an array');
      }
      const subscriptions = subscriptionTopics || [topic];
      for (const subscription of subscriptions) {
        if (typeof subscription !== "string" && !(subscription instanceof RegExp)) {
          throw new KafkaJSNonRetriableError(`Invalid topic ${subscription} (${typeof subscription}), the topic name has to be a String or a RegExp`);
        }
      }
      const hasRegexSubscriptions = subscriptions.some((subscription) => subscription instanceof RegExp);
      const metadata = hasRegexSubscriptions ? await cluster.metadata() : undefined;
      const topicsToSubscribe = [];
      for (const subscription of subscriptions) {
        const isRegExp = subscription instanceof RegExp;
        if (isRegExp) {
          const topicRegExp = subscription;
          const matchedTopics = metadata.topicMetadata.map(({ topic: topicName }) => topicName).filter((topicName) => topicRegExp.test(topicName));
          logger.debug("Subscription based on RegExp", {
            groupId,
            topicRegExp: topicRegExp.toString(),
            matchedTopics
          });
          topicsToSubscribe.push(...matchedTopics);
        } else {
          topicsToSubscribe.push(subscription);
        }
      }
      for (const t of topicsToSubscribe) {
        topics[t] = { fromBeginning };
      }
      await cluster.addMultipleTargetTopics(topicsToSubscribe);
    };
    const run = async ({
      autoCommit = true,
      autoCommitInterval = null,
      autoCommitThreshold = null,
      eachBatchAutoResolve = true,
      partitionsConsumedConcurrently: concurrency = 1,
      eachBatch = null,
      eachMessage = null
    } = {}) => {
      if (consumerGroup) {
        logger.warn("consumer#run was called, but the consumer is already running", { groupId });
        return;
      }
      const start = async (onCrash2) => {
        logger.info("Starting", { groupId });
        consumerGroup = new ConsumerGroup({
          logger: rootLogger,
          topics: keys(topics),
          topicConfigurations: topics,
          retry,
          cluster,
          groupId,
          assigners,
          sessionTimeout,
          rebalanceTimeout,
          maxBytesPerPartition,
          minBytes,
          maxBytes,
          maxWaitTimeInMs,
          instrumentationEmitter,
          isolationLevel,
          rackId,
          metadataMaxAge,
          autoCommit,
          autoCommitInterval,
          autoCommitThreshold
        });
        runner = new Runner({
          logger: rootLogger,
          consumerGroup,
          instrumentationEmitter,
          heartbeatInterval,
          retry,
          autoCommit,
          eachBatchAutoResolve,
          eachBatch,
          eachMessage,
          onCrash: onCrash2,
          concurrency
        });
        await runner.start();
      };
      const onCrash = async (e) => {
        logger.error(`Crash: ${e.name}: ${e.message}`, {
          groupId,
          retryCount: e.retryCount,
          stack: e.stack
        });
        if (e.name === "KafkaJSConnectionClosedError") {
          cluster.removeBroker({ host: e.host, port: e.port });
        }
        await disconnect();
        const getOriginalCause = (error) => {
          if (error.cause) {
            return getOriginalCause(error.cause);
          }
          return error;
        };
        const isErrorRetriable = e.name === "KafkaJSNumberOfRetriesExceeded" || getOriginalCause(e).retriable === true;
        const shouldRestart = isErrorRetriable && (!retry || !retry.restartOnFailure || await retry.restartOnFailure(e).catch((error) => {
          logger.error('Caught error when invoking user-provided "restartOnFailure" callback. Defaulting to restarting.', {
            error: error.message || error,
            cause: e.message || e,
            groupId
          });
          return true;
        }));
        instrumentationEmitter.emit(CRASH, {
          error: e,
          groupId,
          restart: shouldRestart
        });
        if (shouldRestart) {
          const retryTime = e.retryTime || retry && retry.initialRetryTime || initialRetryTime;
          logger.error(`Restarting the consumer in ${retryTime}ms`, {
            retryCount: e.retryCount,
            retryTime,
            groupId
          });
          restartTimeout = setTimeout(() => start(onCrash), retryTime);
        }
      };
      await start(onCrash);
    };
    const on = (eventName, listener) => {
      if (!eventNames.includes(eventName)) {
        throw new KafkaJSNonRetriableError(`Event name should be one of ${eventKeys}`);
      }
      return instrumentationEmitter.addListener(unwrapEvent(eventName), (event) => {
        event.type = wrapEvent(event.type);
        Promise.resolve(listener(event)).catch((e) => {
          logger.error(`Failed to execute listener: ${e.message}`, {
            eventName,
            stack: e.stack
          });
        });
      });
    };
    const commitOffsets = async (topicPartitions = []) => {
      const commitsByTopic = topicPartitions.reduce((payload, { topic, partition, offset, metadata = null }) => {
        if (!topic) {
          throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);
        }
        if (isNaN(partition)) {
          throw new KafkaJSNonRetriableError(`Invalid partition, expected a number received ${partition}`);
        }
        let commitOffset;
        try {
          commitOffset = Long.fromValue(offset);
        } catch (_) {
          throw new KafkaJSNonRetriableError(`Invalid offset, expected a long received ${offset}`);
        }
        if (commitOffset.lessThan(0)) {
          throw new KafkaJSNonRetriableError("Offset must not be a negative number");
        }
        if (metadata !== null && typeof metadata !== "string") {
          throw new KafkaJSNonRetriableError(`Invalid offset metadata, expected string or null, received ${metadata}`);
        }
        const topicCommits = payload[topic] || [];
        topicCommits.push({ partition, offset: commitOffset, metadata });
        return { ...payload, [topic]: topicCommits };
      }, {});
      if (!consumerGroup) {
        throw new KafkaJSNonRetriableError("Consumer group was not initialized, consumer#run must be called first");
      }
      const topics2 = Object.keys(commitsByTopic);
      return runner.commitOffsets({
        topics: topics2.map((topic) => {
          return {
            topic,
            partitions: commitsByTopic[topic]
          };
        })
      });
    };
    const seek = ({ topic, partition, offset }) => {
      if (!topic) {
        throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);
      }
      if (isNaN(partition)) {
        throw new KafkaJSNonRetriableError(`Invalid partition, expected a number received ${partition}`);
      }
      let seekOffset;
      try {
        seekOffset = Long.fromValue(offset);
      } catch (_) {
        throw new KafkaJSNonRetriableError(`Invalid offset, expected a long received ${offset}`);
      }
      if (seekOffset.lessThan(0) && !specialOffsets.includes(seekOffset.toString())) {
        throw new KafkaJSNonRetriableError("Offset must not be a negative number");
      }
      if (!consumerGroup) {
        throw new KafkaJSNonRetriableError("Consumer group was not initialized, consumer#run must be called first");
      }
      consumerGroup.seek({ topic, partition, offset: seekOffset.toString() });
    };
    const describeGroup = async () => {
      const coordinator = await cluster.findGroupCoordinator({ groupId });
      const retrier = createRetry(retry);
      return retrier(async () => {
        const { groups } = await coordinator.describeGroups({ groupIds: [groupId] });
        return groups.find((group) => group.groupId === groupId);
      });
    };
    const pause = (topicPartitions = []) => {
      for (const topicPartition of topicPartitions) {
        if (!topicPartition || !topicPartition.topic) {
          throw new KafkaJSNonRetriableError(`Invalid topic ${topicPartition && topicPartition.topic || topicPartition}`);
        } else if (typeof topicPartition.partitions !== "undefined" && (!Array.isArray(topicPartition.partitions) || topicPartition.partitions.some(isNaN))) {
          throw new KafkaJSNonRetriableError(`Array of valid partitions required to pause specific partitions instead of ${topicPartition.partitions}`);
        }
      }
      if (!consumerGroup) {
        throw new KafkaJSNonRetriableError("Consumer group was not initialized, consumer#run must be called first");
      }
      consumerGroup.pause(topicPartitions);
    };
    const paused = () => {
      if (!consumerGroup) {
        return [];
      }
      return consumerGroup.paused();
    };
    const resume = (topicPartitions = []) => {
      for (const topicPartition of topicPartitions) {
        if (!topicPartition || !topicPartition.topic) {
          throw new KafkaJSNonRetriableError(`Invalid topic ${topicPartition && topicPartition.topic || topicPartition}`);
        } else if (typeof topicPartition.partitions !== "undefined" && (!Array.isArray(topicPartition.partitions) || topicPartition.partitions.some(isNaN))) {
          throw new KafkaJSNonRetriableError(`Array of valid partitions required to resume specific partitions instead of ${topicPartition.partitions}`);
        }
      }
      if (!consumerGroup) {
        throw new KafkaJSNonRetriableError("Consumer group was not initialized, consumer#run must be called first");
      }
      consumerGroup.resume(topicPartitions);
    };
    const getLogger = () => logger;
    return {
      connect,
      disconnect,
      subscribe,
      stop,
      run,
      commitOffsets,
      seek,
      describeGroup,
      pause,
      paused,
      resume,
      on,
      events,
      logger: getLogger
    };
  };
});

// node_modules/kafkajs/src/utils/waitFor.js
var require_waitFor = __commonJS((exports, module) => {
  var sleep = require_sleep();
  var { KafkaJSTimeout } = require_errors2();
  module.exports = (fn, { delay = 50, maxWait = 1e4, timeoutMessage = "Timeout", ignoreTimeout = false } = {}) => {
    let timeoutId;
    let totalWait = 0;
    let fulfilled = false;
    const checkCondition = async (resolve, reject) => {
      totalWait += delay;
      if (fulfilled) {
        return;
      }
      await sleep(delay);
      try {
        const result = await fn(totalWait);
        if (result) {
          fulfilled = true;
          clearTimeout(timeoutId);
          return resolve(result);
        }
        checkCondition(resolve, reject);
      } catch (e) {
        fulfilled = true;
        clearTimeout(timeoutId);
        reject(e);
      }
    };
    return new Promise((resolve, reject) => {
      checkCondition(resolve, reject);
      if (ignoreTimeout) {
        return;
      }
      timeoutId = setTimeout(() => {
        if (!fulfilled) {
          fulfilled = true;
          return reject(new KafkaJSTimeout(timeoutMessage));
        }
      }, maxWait);
    });
  };
});

// node_modules/kafkajs/src/utils/groupBy.js
var require_groupBy = __commonJS((exports, module) => {
  module.exports = async (array, groupFn) => {
    const result = new Map;
    for (const item of array) {
      const group = await Promise.resolve(groupFn(item));
      result.set(group, result.has(group) ? [...result.get(group), item] : [item]);
    }
    return result;
  };
});

// node_modules/kafkajs/src/admin/instrumentationEvents.js
var require_instrumentationEvents4 = __commonJS((exports, module) => {
  var swapObject = require_swapObject();
  var networkEvents = require_instrumentationEvents();
  var InstrumentationEventType = require_eventType();
  var adminType = InstrumentationEventType("admin");
  var events = {
    CONNECT: adminType("connect"),
    DISCONNECT: adminType("disconnect"),
    REQUEST: adminType(networkEvents.NETWORK_REQUEST),
    REQUEST_TIMEOUT: adminType(networkEvents.NETWORK_REQUEST_TIMEOUT),
    REQUEST_QUEUE_SIZE: adminType(networkEvents.NETWORK_REQUEST_QUEUE_SIZE)
  };
  var wrappedEvents = {
    [events.REQUEST]: networkEvents.NETWORK_REQUEST,
    [events.REQUEST_TIMEOUT]: networkEvents.NETWORK_REQUEST_TIMEOUT,
    [events.REQUEST_QUEUE_SIZE]: networkEvents.NETWORK_REQUEST_QUEUE_SIZE
  };
  var reversedWrappedEvents = swapObject(wrappedEvents);
  var unwrap = (eventName) => wrappedEvents[eventName] || eventName;
  var wrap = (eventName) => reversedWrappedEvents[eventName] || eventName;
  module.exports = {
    events,
    wrap,
    unwrap
  };
});

// node_modules/kafkajs/src/protocol/aclResourceTypes.js
var require_aclResourceTypes = __commonJS((exports, module) => {
  module.exports = {
    UNKNOWN: 0,
    ANY: 1,
    TOPIC: 2,
    GROUP: 3,
    CLUSTER: 4,
    TRANSACTIONAL_ID: 5,
    DELEGATION_TOKEN: 6
  };
});

// node_modules/kafkajs/src/protocol/aclOperationTypes.js
var require_aclOperationTypes = __commonJS((exports, module) => {
  module.exports = {
    UNKNOWN: 0,
    ANY: 1,
    ALL: 2,
    READ: 3,
    WRITE: 4,
    CREATE: 5,
    DELETE: 6,
    ALTER: 7,
    DESCRIBE: 8,
    CLUSTER_ACTION: 9,
    DESCRIBE_CONFIGS: 10,
    ALTER_CONFIGS: 11,
    IDEMPOTENT_WRITE: 12
  };
});

// node_modules/kafkajs/src/protocol/aclPermissionTypes.js
var require_aclPermissionTypes = __commonJS((exports, module) => {
  module.exports = {
    UNKNOWN: 0,
    ANY: 1,
    DENY: 2,
    ALLOW: 3
  };
});

// node_modules/kafkajs/src/protocol/resourcePatternTypes.js
var require_resourcePatternTypes = __commonJS((exports, module) => {
  module.exports = {
    UNKNOWN: 0,
    ANY: 1,
    MATCH: 2,
    LITERAL: 3,
    PREFIXED: 4
  };
});

// node_modules/kafkajs/src/admin/index.js
var require_admin = __commonJS((exports, module) => {
  var createRetry = require_retry();
  var waitFor = require_waitFor();
  var groupBy = require_groupBy();
  var createConsumer = require_consumer();
  var InstrumentationEventEmitter = require_emitter();
  var { events, wrap: wrapEvent, unwrap: unwrapEvent } = require_instrumentationEvents4();
  var { LEVELS } = require_loggers();
  var {
    KafkaJSNonRetriableError,
    KafkaJSDeleteGroupsError,
    KafkaJSBrokerNotFound,
    KafkaJSDeleteTopicRecordsError,
    KafkaJSAggregateError
  } = require_errors2();
  var { staleMetadata } = require_error();
  var CONFIG_RESOURCE_TYPES = require_configResourceTypes();
  var ACL_RESOURCE_TYPES = require_aclResourceTypes();
  var ACL_OPERATION_TYPES = require_aclOperationTypes();
  var ACL_PERMISSION_TYPES = require_aclPermissionTypes();
  var RESOURCE_PATTERN_TYPES = require_resourcePatternTypes();
  var { EARLIEST_OFFSET, LATEST_OFFSET } = require_constants2();
  var { CONNECT, DISCONNECT } = events;
  var NO_CONTROLLER_ID = -1;
  var { values, keys, entries } = Object;
  var eventNames = values(events);
  var eventKeys = keys(events).map((key) => `admin.events.${key}`).join(", ");
  var retryOnLeaderNotAvailable = (fn, opts = {}) => {
    const callback = async () => {
      try {
        return await fn();
      } catch (e) {
        if (e.type !== "LEADER_NOT_AVAILABLE") {
          throw e;
        }
        return false;
      }
    };
    return waitFor(callback, opts);
  };
  var isConsumerGroupRunning = (description) => ["Empty", "Dead"].includes(description.state);
  var findTopicPartitions = async (cluster, topic) => {
    await cluster.addTargetTopic(topic);
    await cluster.refreshMetadataIfNecessary();
    return cluster.findTopicPartitionMetadata(topic).map(({ partitionId }) => partitionId).sort();
  };
  var indexByPartition = (array) => array.reduce((obj, { partition, ...props }) => Object.assign(obj, { [partition]: { ...props } }), {});
  module.exports = ({
    logger: rootLogger,
    instrumentationEmitter: rootInstrumentationEmitter,
    retry,
    cluster
  }) => {
    const logger = rootLogger.namespace("Admin");
    const instrumentationEmitter = rootInstrumentationEmitter || new InstrumentationEventEmitter;
    const connect = async () => {
      await cluster.connect();
      instrumentationEmitter.emit(CONNECT);
    };
    const disconnect = async () => {
      await cluster.disconnect();
      instrumentationEmitter.emit(DISCONNECT);
    };
    const listTopics = async () => {
      const { topicMetadata } = await cluster.metadata();
      const topics = topicMetadata.map((t) => t.topic);
      return topics;
    };
    const createTopics = async ({ topics, validateOnly, timeout, waitForLeaders = true }) => {
      if (!topics || !Array.isArray(topics)) {
        throw new KafkaJSNonRetriableError(`Invalid topics array ${topics}`);
      }
      if (topics.filter(({ topic }) => typeof topic !== "string").length > 0) {
        throw new KafkaJSNonRetriableError("Invalid topics array, the topic names have to be a valid string");
      }
      const topicNames = new Set(topics.map(({ topic }) => topic));
      if (topicNames.size < topics.length) {
        throw new KafkaJSNonRetriableError("Invalid topics array, it cannot have multiple entries for the same topic");
      }
      for (const { topic, configEntries } of topics) {
        if (configEntries == null) {
          continue;
        }
        if (!Array.isArray(configEntries)) {
          throw new KafkaJSNonRetriableError(`Invalid configEntries for topic "${topic}", must be an array`);
        }
        configEntries.forEach((entry, index) => {
          if (typeof entry !== "object" || entry == null) {
            throw new KafkaJSNonRetriableError(`Invalid configEntries for topic "${topic}". Entry ${index} must be an object`);
          }
          for (const requiredProperty of ["name", "value"]) {
            if (!Object.prototype.hasOwnProperty.call(entry, requiredProperty) || typeof entry[requiredProperty] !== "string") {
              throw new KafkaJSNonRetriableError(`Invalid configEntries for topic "${topic}". Entry ${index} must have a valid "${requiredProperty}" property`);
            }
          }
        });
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          await broker.createTopics({ topics, validateOnly, timeout });
          if (waitForLeaders) {
            const topicNamesArray = Array.from(topicNames.values());
            await retryOnLeaderNotAvailable(async () => await broker.metadata(topicNamesArray), {
              delay: 100,
              maxWait: timeout,
              timeoutMessage: "Timed out while waiting for topic leaders"
            });
          }
          return true;
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not create topics", { error: e.message, retryCount, retryTime });
            throw e;
          }
          if (e instanceof KafkaJSAggregateError) {
            if (e.errors.every((error) => error.type === "TOPIC_ALREADY_EXISTS")) {
              return false;
            }
          }
          bail(e);
        }
      });
    };
    const createPartitions = async ({ topicPartitions, validateOnly, timeout }) => {
      if (!topicPartitions || !Array.isArray(topicPartitions)) {
        throw new KafkaJSNonRetriableError(`Invalid topic partitions array ${topicPartitions}`);
      }
      if (topicPartitions.length === 0) {
        throw new KafkaJSNonRetriableError(`Empty topic partitions array`);
      }
      if (topicPartitions.filter(({ topic }) => typeof topic !== "string").length > 0) {
        throw new KafkaJSNonRetriableError("Invalid topic partitions array, the topic names have to be a valid string");
      }
      const topicNames = new Set(topicPartitions.map(({ topic }) => topic));
      if (topicNames.size < topicPartitions.length) {
        throw new KafkaJSNonRetriableError("Invalid topic partitions array, it cannot have multiple entries for the same topic");
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          await broker.createPartitions({ topicPartitions, validateOnly, timeout });
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not create topics", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const deleteTopics = async ({ topics, timeout }) => {
      if (!topics || !Array.isArray(topics)) {
        throw new KafkaJSNonRetriableError(`Invalid topics array ${topics}`);
      }
      if (topics.filter((topic) => typeof topic !== "string").length > 0) {
        throw new KafkaJSNonRetriableError("Invalid topics array, the names must be a valid string");
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          await broker.deleteTopics({ topics, timeout });
          for (const topic of topics) {
            cluster.targetTopics.delete(topic);
          }
          await cluster.refreshMetadata();
        } catch (e) {
          if (["NOT_CONTROLLER", "UNKNOWN_TOPIC_OR_PARTITION"].includes(e.type)) {
            logger.warn("Could not delete topics", { error: e.message, retryCount, retryTime });
            throw e;
          }
          if (e.type === "REQUEST_TIMED_OUT") {
            logger.error('Could not delete topics, check if "delete.topic.enable" is set to "true" (the default value is "false") or increase the timeout', {
              error: e.message,
              retryCount,
              retryTime
            });
          }
          bail(e);
        }
      });
    };
    const fetchTopicOffsets = async (topic) => {
      if (!topic || typeof topic !== "string") {
        throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.addTargetTopic(topic);
          await cluster.refreshMetadataIfNecessary();
          const metadata = cluster.findTopicPartitionMetadata(topic);
          const high = await cluster.fetchTopicsOffset([
            {
              topic,
              fromBeginning: false,
              partitions: metadata.map((p) => ({ partition: p.partitionId }))
            }
          ]);
          const low = await cluster.fetchTopicsOffset([
            {
              topic,
              fromBeginning: true,
              partitions: metadata.map((p) => ({ partition: p.partitionId }))
            }
          ]);
          const { partitions: highPartitions } = high.pop();
          const { partitions: lowPartitions } = low.pop();
          return highPartitions.map(({ partition, offset }) => ({
            partition,
            offset,
            high: offset,
            low: lowPartitions.find(({ partition: lowPartition }) => lowPartition === partition).offset
          }));
        } catch (e) {
          if (e.type === "UNKNOWN_TOPIC_OR_PARTITION") {
            await cluster.refreshMetadata();
            throw e;
          }
          bail(e);
        }
      });
    };
    const fetchTopicOffsetsByTimestamp = async (topic, timestamp) => {
      if (!topic || typeof topic !== "string") {
        throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.addTargetTopic(topic);
          await cluster.refreshMetadataIfNecessary();
          const metadata = cluster.findTopicPartitionMetadata(topic);
          const partitions = metadata.map((p) => ({ partition: p.partitionId }));
          const high = await cluster.fetchTopicsOffset([
            {
              topic,
              fromBeginning: false,
              partitions
            }
          ]);
          const { partitions: highPartitions } = high.pop();
          const offsets = await cluster.fetchTopicsOffset([
            {
              topic,
              fromTimestamp: timestamp,
              partitions
            }
          ]);
          const { partitions: lowPartitions } = offsets.pop();
          return lowPartitions.map(({ partition, offset }) => ({
            partition,
            offset: parseInt(offset, 10) >= 0 ? offset : highPartitions.find(({ partition: highPartition }) => highPartition === partition).offset
          }));
        } catch (e) {
          if (e.type === "UNKNOWN_TOPIC_OR_PARTITION") {
            await cluster.refreshMetadata();
            throw e;
          }
          bail(e);
        }
      });
    };
    const fetchOffsets = async ({ groupId, topics, resolveOffsets = false }) => {
      if (!groupId) {
        throw new KafkaJSNonRetriableError(`Invalid groupId ${groupId}`);
      }
      if (!topics) {
        topics = [];
      }
      if (!Array.isArray(topics)) {
        throw new KafkaJSNonRetriableError("Expected topics array to be set");
      }
      const coordinator = await cluster.findGroupCoordinator({ groupId });
      const topicsToFetch = await Promise.all(topics.map(async (topic) => {
        const partitions = await findTopicPartitions(cluster, topic);
        const partitionsToFetch = partitions.map((partition) => ({ partition }));
        return { topic, partitions: partitionsToFetch };
      }));
      let { responses: consumerOffsets } = await coordinator.offsetFetch({
        groupId,
        topics: topicsToFetch
      });
      if (resolveOffsets) {
        consumerOffsets = await Promise.all(consumerOffsets.map(async ({ topic, partitions }) => {
          const indexedOffsets = indexByPartition(await fetchTopicOffsets(topic));
          const recalculatedPartitions = partitions.map(({ offset, partition, ...props }) => {
            let resolvedOffset = offset;
            if (Number(offset) === EARLIEST_OFFSET) {
              resolvedOffset = indexedOffsets[partition].low;
            }
            if (Number(offset) === LATEST_OFFSET) {
              resolvedOffset = indexedOffsets[partition].high;
            }
            return {
              partition,
              offset: resolvedOffset,
              ...props
            };
          });
          await setOffsets({ groupId, topic, partitions: recalculatedPartitions });
          return {
            topic,
            partitions: recalculatedPartitions
          };
        }));
      }
      return consumerOffsets.map(({ topic, partitions }) => {
        const completePartitions = partitions.map(({ partition, offset, metadata }) => ({
          partition,
          offset,
          metadata: metadata || null
        }));
        return { topic, partitions: completePartitions };
      });
    };
    const resetOffsets = async ({ groupId, topic, earliest = false }) => {
      if (!groupId) {
        throw new KafkaJSNonRetriableError(`Invalid groupId ${groupId}`);
      }
      if (!topic) {
        throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);
      }
      const partitions = await findTopicPartitions(cluster, topic);
      const partitionsToSeek = partitions.map((partition) => ({
        partition,
        offset: cluster.defaultOffset({ fromBeginning: earliest })
      }));
      return setOffsets({ groupId, topic, partitions: partitionsToSeek });
    };
    const setOffsets = async ({ groupId, topic, partitions }) => {
      if (!groupId) {
        throw new KafkaJSNonRetriableError(`Invalid groupId ${groupId}`);
      }
      if (!topic) {
        throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);
      }
      if (!partitions || partitions.length === 0) {
        throw new KafkaJSNonRetriableError(`Invalid partitions`);
      }
      const consumer = createConsumer({
        logger: rootLogger.namespace("Admin", LEVELS.NOTHING),
        cluster,
        groupId
      });
      await consumer.subscribe({ topic, fromBeginning: true });
      const description = await consumer.describeGroup();
      if (!isConsumerGroupRunning(description)) {
        throw new KafkaJSNonRetriableError(`The consumer group must have no running instances, current state: ${description.state}`);
      }
      return new Promise((resolve, reject) => {
        consumer.on(consumer.events.FETCH, async () => consumer.stop().then(resolve).catch(reject));
        consumer.run({
          eachBatchAutoResolve: false,
          eachBatch: async () => true
        }).catch(reject);
        consumer.pause([{ topic }]);
        for (const seekData of partitions) {
          consumer.seek({ topic, ...seekData });
        }
      });
    };
    const isBrokerConfig = (type) => [CONFIG_RESOURCE_TYPES.BROKER, CONFIG_RESOURCE_TYPES.BROKER_LOGGER].includes(type);
    const groupResourcesByBroker = ({ resources, defaultBroker }) => groupBy(resources, async ({ type, name: nodeId }) => {
      return isBrokerConfig(type) ? await cluster.findBroker({ nodeId: String(nodeId) }) : defaultBroker;
    });
    const describeConfigs = async ({ resources, includeSynonyms }) => {
      if (!resources || !Array.isArray(resources)) {
        throw new KafkaJSNonRetriableError(`Invalid resources array ${resources}`);
      }
      if (resources.length === 0) {
        throw new KafkaJSNonRetriableError("Resources array cannot be empty");
      }
      const validResourceTypes = Object.values(CONFIG_RESOURCE_TYPES);
      const invalidType = resources.find((r) => !validResourceTypes.includes(r.type));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid resource type ${invalidType.type}: ${JSON.stringify(invalidType)}`);
      }
      const invalidName = resources.find((r) => !r.name || typeof r.name !== "string");
      if (invalidName) {
        throw new KafkaJSNonRetriableError(`Invalid resource name ${invalidName.name}: ${JSON.stringify(invalidName)}`);
      }
      const invalidConfigs = resources.find((r) => !Array.isArray(r.configNames) && r.configNames != null);
      if (invalidConfigs) {
        const { configNames } = invalidConfigs;
        throw new KafkaJSNonRetriableError(`Invalid resource configNames ${configNames}: ${JSON.stringify(invalidConfigs)}`);
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const controller = await cluster.findControllerBroker();
          const resourcerByBroker = await groupResourcesByBroker({
            resources,
            defaultBroker: controller
          });
          const describeConfigsAction = async (broker) => {
            const targetBroker = broker || controller;
            return targetBroker.describeConfigs({
              resources: resourcerByBroker.get(targetBroker),
              includeSynonyms
            });
          };
          const brokers = Array.from(resourcerByBroker.keys());
          const responses = await Promise.all(brokers.map(describeConfigsAction));
          const responseResources = responses.reduce((result, { resources: resources2 }) => [...result, ...resources2], []);
          return { resources: responseResources };
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not describe configs", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const alterConfigs = async ({ resources, validateOnly }) => {
      if (!resources || !Array.isArray(resources)) {
        throw new KafkaJSNonRetriableError(`Invalid resources array ${resources}`);
      }
      if (resources.length === 0) {
        throw new KafkaJSNonRetriableError("Resources array cannot be empty");
      }
      const validResourceTypes = Object.values(CONFIG_RESOURCE_TYPES);
      const invalidType = resources.find((r) => !validResourceTypes.includes(r.type));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid resource type ${invalidType.type}: ${JSON.stringify(invalidType)}`);
      }
      const invalidName = resources.find((r) => !r.name || typeof r.name !== "string");
      if (invalidName) {
        throw new KafkaJSNonRetriableError(`Invalid resource name ${invalidName.name}: ${JSON.stringify(invalidName)}`);
      }
      const invalidConfigs = resources.find((r) => !Array.isArray(r.configEntries));
      if (invalidConfigs) {
        const { configEntries } = invalidConfigs;
        throw new KafkaJSNonRetriableError(`Invalid resource configEntries ${configEntries}: ${JSON.stringify(invalidConfigs)}`);
      }
      const invalidConfigValue = resources.find((r) => r.configEntries.some((e) => typeof e.name !== "string" || typeof e.value !== "string"));
      if (invalidConfigValue) {
        throw new KafkaJSNonRetriableError(`Invalid resource config value: ${JSON.stringify(invalidConfigValue)}`);
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const controller = await cluster.findControllerBroker();
          const resourcerByBroker = await groupResourcesByBroker({
            resources,
            defaultBroker: controller
          });
          const alterConfigsAction = async (broker) => {
            const targetBroker = broker || controller;
            return targetBroker.alterConfigs({
              resources: resourcerByBroker.get(targetBroker),
              validateOnly: !!validateOnly
            });
          };
          const brokers = Array.from(resourcerByBroker.keys());
          const responses = await Promise.all(brokers.map(alterConfigsAction));
          const responseResources = responses.reduce((result, { resources: resources2 }) => [...result, ...resources2], []);
          return { resources: responseResources };
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not alter configs", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const fetchTopicMetadata = async ({ topics = [] } = {}) => {
      if (topics) {
        topics.forEach((topic) => {
          if (!topic || typeof topic !== "string") {
            throw new KafkaJSNonRetriableError(`Invalid topic ${topic}`);
          }
        });
      }
      const metadata = await cluster.metadata({ topics });
      return {
        topics: metadata.topicMetadata.map((topicMetadata) => ({
          name: topicMetadata.topic,
          partitions: topicMetadata.partitionMetadata
        }))
      };
    };
    const describeCluster = async () => {
      const { brokers: nodes, clusterId, controllerId } = await cluster.metadata({ topics: [] });
      const brokers = nodes.map(({ nodeId, host, port }) => ({
        nodeId,
        host,
        port
      }));
      const controller = controllerId == null || controllerId === NO_CONTROLLER_ID ? null : controllerId;
      return {
        brokers,
        controller,
        clusterId
      };
    };
    const listGroups = async () => {
      await cluster.refreshMetadata();
      let groups = [];
      for (var nodeId in cluster.brokerPool.brokers) {
        const broker = await cluster.findBroker({ nodeId });
        const response = await broker.listGroups();
        groups = groups.concat(response.groups);
      }
      return { groups };
    };
    const describeGroups = async (groupIds) => {
      const coordinatorsForGroup = await Promise.all(groupIds.map(async (groupId) => {
        const coordinator = await cluster.findGroupCoordinator({ groupId });
        return {
          coordinator,
          groupId
        };
      }));
      const groupsByCoordinator = Object.values(coordinatorsForGroup.reduce((coordinators, { coordinator, groupId }) => {
        const group = coordinators[coordinator.nodeId];
        if (group) {
          coordinators[coordinator.nodeId] = {
            ...group,
            groupIds: [...group.groupIds, groupId]
          };
        } else {
          coordinators[coordinator.nodeId] = { coordinator, groupIds: [groupId] };
        }
        return coordinators;
      }, {}));
      const responses = await Promise.all(groupsByCoordinator.map(async ({ coordinator, groupIds: groupIds2 }) => {
        const retrier = createRetry(retry);
        const { groups: groups2 } = await retrier(() => coordinator.describeGroups({ groupIds: groupIds2 }));
        return groups2;
      }));
      const groups = [].concat.apply([], responses);
      return { groups };
    };
    const deleteGroups = async (groupIds) => {
      if (!groupIds || !Array.isArray(groupIds)) {
        throw new KafkaJSNonRetriableError(`Invalid groupIds array ${groupIds}`);
      }
      const invalidGroupId = groupIds.some((g) => typeof g !== "string");
      if (invalidGroupId) {
        throw new KafkaJSNonRetriableError(`Invalid groupId name: ${JSON.stringify(invalidGroupId)}`);
      }
      const retrier = createRetry(retry);
      let results = [];
      let clonedGroupIds = groupIds.slice();
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          if (clonedGroupIds.length === 0)
            return [];
          await cluster.refreshMetadata();
          const brokersPerGroups = {};
          const brokersPerNode = {};
          for (const groupId of clonedGroupIds) {
            const broker = await cluster.findGroupCoordinator({ groupId });
            if (brokersPerGroups[broker.nodeId] === undefined)
              brokersPerGroups[broker.nodeId] = [];
            brokersPerGroups[broker.nodeId].push(groupId);
            brokersPerNode[broker.nodeId] = broker;
          }
          const res = await Promise.all(Object.keys(brokersPerNode).map(async (nodeId) => await brokersPerNode[nodeId].deleteGroups(brokersPerGroups[nodeId])));
          const errors = res.flatMap(({ results: results2 }) => results2.map(({ groupId, errorCode, error }) => {
            return { groupId, errorCode, error };
          })).filter(({ errorCode }) => errorCode !== 0);
          clonedGroupIds = errors.map(({ groupId }) => groupId);
          if (errors.length > 0)
            throw new KafkaJSDeleteGroupsError("Error in DeleteGroups", errors);
          results = res.flatMap(({ results: results2 }) => results2);
          return results;
        } catch (e) {
          if (e.type === "NOT_CONTROLLER" || e.type === "COORDINATOR_NOT_AVAILABLE") {
            logger.warn("Could not delete groups", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const deleteTopicRecords = async ({ topic, partitions }) => {
      if (!topic || typeof topic !== "string") {
        throw new KafkaJSNonRetriableError(`Invalid topic "${topic}"`);
      }
      if (!partitions || partitions.length === 0) {
        throw new KafkaJSNonRetriableError(`Invalid partitions`);
      }
      const partitionsByBroker = cluster.findLeaderForPartitions(topic, partitions.map((p) => p.partition));
      const partitionsFound = values(partitionsByBroker).flat();
      const topicOffsets = await fetchTopicOffsets(topic);
      const leaderNotFoundErrors = [];
      partitions.forEach(({ partition, offset }) => {
        if (!partitionsFound.includes(partition)) {
          leaderNotFoundErrors.push({
            partition,
            offset,
            error: new KafkaJSBrokerNotFound("Could not find the leader for the partition", {
              retriable: false
            })
          });
          return;
        }
        const { low } = topicOffsets.find((p) => p.partition === partition) || {
          high: undefined,
          low: undefined
        };
        if (parseInt(offset) < parseInt(low) && parseInt(offset) !== -1) {
          logger.warn("The requested offset is before the earliest offset maintained on the partition - no records will be deleted from this partition", {
            topic,
            partition,
            offset
          });
        }
      });
      if (leaderNotFoundErrors.length > 0) {
        throw new KafkaJSDeleteTopicRecordsError({ topic, partitions: leaderNotFoundErrors });
      }
      const seekEntriesByBroker = entries(partitionsByBroker).reduce((obj, [nodeId, nodePartitions]) => {
        obj[nodeId] = {
          topic,
          partitions: partitions.filter((p) => nodePartitions.includes(p.partition))
        };
        return obj;
      }, {});
      const retrier = createRetry(retry);
      return retrier(async (bail) => {
        try {
          const partitionErrors = [];
          const brokerRequests = entries(seekEntriesByBroker).map(([nodeId, { topic: topic2, partitions: partitions2 }]) => async () => {
            const broker = await cluster.findBroker({ nodeId });
            await broker.deleteRecords({ topics: [{ topic: topic2, partitions: partitions2 }] });
            delete seekEntriesByBroker[nodeId];
          });
          await Promise.all(brokerRequests.map((request) => request().catch((e) => {
            if (e.name === "KafkaJSDeleteTopicRecordsError") {
              e.partitions.forEach(({ partition, offset, error }) => {
                partitionErrors.push({
                  partition,
                  offset,
                  error
                });
              });
            } else {
              throw e;
            }
          })));
          if (partitionErrors.length > 0) {
            throw new KafkaJSDeleteTopicRecordsError({
              topic,
              partitions: partitionErrors
            });
          }
        } catch (e) {
          if (e.retriable && e.partitions.some(({ error }) => staleMetadata(error) || error.name === "KafkaJSMetadataNotLoaded")) {
            await cluster.refreshMetadata();
          }
          throw e;
        }
      });
    };
    const createAcls = async ({ acl }) => {
      if (!acl || !Array.isArray(acl)) {
        throw new KafkaJSNonRetriableError(`Invalid ACL array ${acl}`);
      }
      if (acl.length === 0) {
        throw new KafkaJSNonRetriableError("Empty ACL array");
      }
      if (acl.some(({ principal }) => typeof principal !== "string")) {
        throw new KafkaJSNonRetriableError("Invalid ACL array, the principals have to be a valid string");
      }
      if (acl.some(({ host }) => typeof host !== "string")) {
        throw new KafkaJSNonRetriableError("Invalid ACL array, the hosts have to be a valid string");
      }
      if (acl.some(({ resourceName }) => typeof resourceName !== "string")) {
        throw new KafkaJSNonRetriableError("Invalid ACL array, the resourceNames have to be a valid string");
      }
      let invalidType;
      const validOperationTypes = Object.values(ACL_OPERATION_TYPES);
      invalidType = acl.find((i) => !validOperationTypes.includes(i.operation));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid operation type ${invalidType.operation}: ${JSON.stringify(invalidType)}`);
      }
      const validResourcePatternTypes = Object.values(RESOURCE_PATTERN_TYPES);
      invalidType = acl.find((i) => !validResourcePatternTypes.includes(i.resourcePatternType));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid resource pattern type ${invalidType.resourcePatternType}: ${JSON.stringify(invalidType)}`);
      }
      const validPermissionTypes = Object.values(ACL_PERMISSION_TYPES);
      invalidType = acl.find((i) => !validPermissionTypes.includes(i.permissionType));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid permission type ${invalidType.permissionType}: ${JSON.stringify(invalidType)}`);
      }
      const validResourceTypes = Object.values(ACL_RESOURCE_TYPES);
      invalidType = acl.find((i) => !validResourceTypes.includes(i.resourceType));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid resource type ${invalidType.resourceType}: ${JSON.stringify(invalidType)}`);
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          await broker.createAcls({ acl });
          return true;
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not create ACL", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const describeAcls = async ({
      resourceType,
      resourceName,
      resourcePatternType,
      principal,
      host,
      operation,
      permissionType
    }) => {
      if (typeof principal !== "string" && typeof principal !== "undefined") {
        throw new KafkaJSNonRetriableError("Invalid principal, the principal have to be a valid string");
      }
      if (typeof host !== "string" && typeof host !== "undefined") {
        throw new KafkaJSNonRetriableError("Invalid host, the host have to be a valid string");
      }
      if (typeof resourceName !== "string" && typeof resourceName !== "undefined") {
        throw new KafkaJSNonRetriableError("Invalid resourceName, the resourceName have to be a valid string");
      }
      const validOperationTypes = Object.values(ACL_OPERATION_TYPES);
      if (!validOperationTypes.includes(operation)) {
        throw new KafkaJSNonRetriableError(`Invalid operation type ${operation}`);
      }
      const validResourcePatternTypes = Object.values(RESOURCE_PATTERN_TYPES);
      if (!validResourcePatternTypes.includes(resourcePatternType)) {
        throw new KafkaJSNonRetriableError(`Invalid resource pattern filter type ${resourcePatternType}`);
      }
      const validPermissionTypes = Object.values(ACL_PERMISSION_TYPES);
      if (!validPermissionTypes.includes(permissionType)) {
        throw new KafkaJSNonRetriableError(`Invalid permission type ${permissionType}`);
      }
      const validResourceTypes = Object.values(ACL_RESOURCE_TYPES);
      if (!validResourceTypes.includes(resourceType)) {
        throw new KafkaJSNonRetriableError(`Invalid resource type ${resourceType}`);
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          const { resources } = await broker.describeAcls({
            resourceType,
            resourceName,
            resourcePatternType,
            principal,
            host,
            operation,
            permissionType
          });
          return { resources };
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not describe ACL", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const deleteAcls = async ({ filters }) => {
      if (!filters || !Array.isArray(filters)) {
        throw new KafkaJSNonRetriableError(`Invalid ACL Filter array ${filters}`);
      }
      if (filters.length === 0) {
        throw new KafkaJSNonRetriableError("Empty ACL Filter array");
      }
      if (filters.some(({ principal }) => typeof principal !== "string" && typeof principal !== "undefined")) {
        throw new KafkaJSNonRetriableError("Invalid ACL Filter array, the principals have to be a valid string");
      }
      if (filters.some(({ host }) => typeof host !== "string" && typeof host !== "undefined")) {
        throw new KafkaJSNonRetriableError("Invalid ACL Filter array, the hosts have to be a valid string");
      }
      if (filters.some(({ resourceName }) => typeof resourceName !== "string" && typeof resourceName !== "undefined")) {
        throw new KafkaJSNonRetriableError("Invalid ACL Filter array, the resourceNames have to be a valid string");
      }
      let invalidType;
      const validOperationTypes = Object.values(ACL_OPERATION_TYPES);
      invalidType = filters.find((i) => !validOperationTypes.includes(i.operation));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid operation type ${invalidType.operation}: ${JSON.stringify(invalidType)}`);
      }
      const validResourcePatternTypes = Object.values(RESOURCE_PATTERN_TYPES);
      invalidType = filters.find((i) => !validResourcePatternTypes.includes(i.resourcePatternType));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid resource pattern type ${invalidType.resourcePatternType}: ${JSON.stringify(invalidType)}`);
      }
      const validPermissionTypes = Object.values(ACL_PERMISSION_TYPES);
      invalidType = filters.find((i) => !validPermissionTypes.includes(i.permissionType));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid permission type ${invalidType.permissionType}: ${JSON.stringify(invalidType)}`);
      }
      const validResourceTypes = Object.values(ACL_RESOURCE_TYPES);
      invalidType = filters.find((i) => !validResourceTypes.includes(i.resourceType));
      if (invalidType) {
        throw new KafkaJSNonRetriableError(`Invalid resource type ${invalidType.resourceType}: ${JSON.stringify(invalidType)}`);
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          const { filterResponses } = await broker.deleteAcls({ filters });
          return { filterResponses };
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not delete ACL", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const alterPartitionReassignments = async ({ topics, timeout }) => {
      if (!topics || !Array.isArray(topics)) {
        throw new KafkaJSNonRetriableError(`Invalid topics array ${topics}`);
      }
      if (topics.filter(({ topic }) => typeof topic !== "string").length > 0) {
        throw new KafkaJSNonRetriableError("Invalid topics array, the topic names have to be a valid string");
      }
      const topicNames = new Set(topics.map(({ topic }) => topic));
      if (topicNames.size < topics.length) {
        throw new KafkaJSNonRetriableError("Invalid topics array, it cannot have multiple entries for the same topic");
      }
      for (const { topic, partitionAssignment } of topics) {
        if (!partitionAssignment || !Array.isArray(partitionAssignment)) {
          throw new KafkaJSNonRetriableError(`Invalid partitions array: ${partitionAssignment} for topic: ${topic}`);
        }
        for (const { partition, replicas } of partitionAssignment) {
          if (partition === null || partition === undefined || typeof partition !== "number" || partition < 0) {
            throw new KafkaJSNonRetriableError(`Invalid partitions index: ${partition} for topic: ${topic}`);
          }
          if (!replicas || !Array.isArray(replicas)) {
            throw new KafkaJSNonRetriableError(`Invalid replica assignment: ${replicas} for topic: ${topic} on partition: ${partition}`);
          }
          if (replicas.filter((replica) => typeof replica !== "number" || replica < 0).length >= 1) {
            throw new KafkaJSNonRetriableError(`Invalid replica assignment: ${replicas} for topic: ${topic} on partition: ${partition}. Replicas must be a non negative number`);
          }
        }
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          await broker.alterPartitionReassignments({ topics, timeout });
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not reassign partitions", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const listPartitionReassignments = async ({ topics = null, timeout }) => {
      if (topics) {
        if (!Array.isArray(topics)) {
          throw new KafkaJSNonRetriableError(`Invalid topics array ${topics}`);
        }
        if (topics.filter(({ topic }) => typeof topic !== "string").length > 0) {
          throw new KafkaJSNonRetriableError("Invalid topics array, the topic names have to be a valid string");
        }
        const topicNames = new Set(topics.map(({ topic }) => topic));
        if (topicNames.size < topics.length) {
          throw new KafkaJSNonRetriableError("Invalid topics array, it cannot have multiple entries for the same topic");
        }
        for (const { topic, partitions } of topics) {
          if (!partitions || !Array.isArray(partitions)) {
            throw new KafkaJSNonRetriableError(`Invalid partition array: ${partitions} for topic: ${topic}`);
          }
          if (partitions.filter((partition) => typeof partition !== "number" || partition < 0).length >= 1) {
            throw new KafkaJSNonRetriableError(`Invalid partition array: ${partitions} for topic: ${topic}. The partition indices have to be a valid number greater than 0.`);
          }
        }
      }
      const retrier = createRetry(retry);
      return retrier(async (bail, retryCount, retryTime) => {
        try {
          await cluster.refreshMetadata();
          const broker = await cluster.findControllerBroker();
          const response = await broker.listPartitionReassignments({ topics, timeout });
          return { topics: response.topics };
        } catch (e) {
          if (e.type === "NOT_CONTROLLER") {
            logger.warn("Could not reassign partitions", { error: e.message, retryCount, retryTime });
            throw e;
          }
          bail(e);
        }
      });
    };
    const on = (eventName, listener) => {
      if (!eventNames.includes(eventName)) {
        throw new KafkaJSNonRetriableError(`Event name should be one of ${eventKeys}`);
      }
      return instrumentationEmitter.addListener(unwrapEvent(eventName), (event) => {
        event.type = wrapEvent(event.type);
        Promise.resolve(listener(event)).catch((e) => {
          logger.error(`Failed to execute listener: ${e.message}`, {
            eventName,
            stack: e.stack
          });
        });
      });
    };
    const getLogger = () => logger;
    return {
      connect,
      disconnect,
      listTopics,
      createTopics,
      deleteTopics,
      createPartitions,
      fetchTopicMetadata,
      describeCluster,
      events,
      fetchOffsets,
      fetchTopicOffsets,
      fetchTopicOffsetsByTimestamp,
      setOffsets,
      resetOffsets,
      describeConfigs,
      alterConfigs,
      on,
      logger: getLogger,
      listGroups,
      describeGroups,
      deleteGroups,
      describeAcls,
      deleteAcls,
      createAcls,
      deleteTopicRecords,
      alterPartitionReassignments,
      listPartitionReassignments
    };
  };
});

// node_modules/kafkajs/src/network/socketFactory.js
var require_socketFactory = __commonJS((exports, module) => {
  var KEEP_ALIVE_DELAY = 60000;
  module.exports = () => {
    const net = __require("net");
    const tls = __require("tls");
    return ({ host, port, ssl, onConnect }) => {
      const socket = ssl ? tls.connect(Object.assign({ host, port }, !net.isIP(host) ? { servername: host } : {}, ssl), onConnect) : net.connect({ host, port }, onConnect);
      socket.setKeepAlive(true, KEEP_ALIVE_DELAY);
      return socket;
    };
  };
});

// node_modules/kafkajs/src/utils/once.js
var require_once = __commonJS((exports, module) => {
  module.exports = (fn) => {
    let called = false;
    return (...args) => {
      if (!called) {
        called = true;
        return fn(...args);
      }
    };
  };
});

// node_modules/kafkajs/src/index.js
var require_src = __commonJS((exports, module) => {
  var {
    createLogger,
    LEVELS: { INFO }
  } = require_loggers();
  var InstrumentationEventEmitter = require_emitter();
  var LoggerConsole = require_console();
  var Cluster = require_cluster();
  var createProducer = require_producer();
  var createConsumer = require_consumer();
  var createAdmin = require_admin();
  var ISOLATION_LEVEL = require_isolationLevel();
  var defaultSocketFactory = require_socketFactory();
  var once = require_once();
  var websiteUrl = require_websiteUrl();
  var PRIVATE = {
    CREATE_CLUSTER: Symbol("private:Kafka:createCluster"),
    CLUSTER_RETRY: Symbol("private:Kafka:clusterRetry"),
    LOGGER: Symbol("private:Kafka:logger"),
    OFFSETS: Symbol("private:Kafka:offsets")
  };
  var DEFAULT_METADATA_MAX_AGE = 300000;
  var warnOfDefaultPartitioner = once((logger) => {
    if (process.env.KAFKAJS_NO_PARTITIONER_WARNING == null) {
      logger.warn(`KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option "createPartitioner: Partitioners.LegacyPartitioner". See the migration guide at ${websiteUrl("docs/migration-guide-v2.0.0", "producer-new-default-partitioner")} for details. Silence this warning by setting the environment variable "KAFKAJS_NO_PARTITIONER_WARNING=1"`);
    }
  });
  module.exports = class Client {
    constructor({
      brokers,
      ssl,
      sasl,
      clientId,
      connectionTimeout = 1000,
      authenticationTimeout,
      reauthenticationThreshold,
      requestTimeout,
      enforceRequestTimeout = true,
      retry,
      socketFactory = defaultSocketFactory(),
      logLevel = INFO,
      logCreator = LoggerConsole
    }) {
      this[PRIVATE.OFFSETS] = new Map;
      this[PRIVATE.LOGGER] = createLogger({ level: logLevel, logCreator });
      this[PRIVATE.CLUSTER_RETRY] = retry;
      this[PRIVATE.CREATE_CLUSTER] = ({
        metadataMaxAge,
        allowAutoTopicCreation = true,
        maxInFlightRequests = null,
        instrumentationEmitter = null,
        isolationLevel
      }) => new Cluster({
        logger: this[PRIVATE.LOGGER],
        retry: this[PRIVATE.CLUSTER_RETRY],
        offsets: this[PRIVATE.OFFSETS],
        socketFactory,
        brokers,
        ssl,
        sasl,
        clientId,
        connectionTimeout,
        authenticationTimeout,
        reauthenticationThreshold,
        requestTimeout,
        enforceRequestTimeout,
        metadataMaxAge,
        instrumentationEmitter,
        allowAutoTopicCreation,
        maxInFlightRequests,
        isolationLevel
      });
    }
    producer({
      createPartitioner,
      retry,
      metadataMaxAge = DEFAULT_METADATA_MAX_AGE,
      allowAutoTopicCreation,
      idempotent,
      transactionalId,
      transactionTimeout,
      maxInFlightRequests
    } = {}) {
      const instrumentationEmitter = new InstrumentationEventEmitter;
      const cluster = this[PRIVATE.CREATE_CLUSTER]({
        metadataMaxAge,
        allowAutoTopicCreation,
        maxInFlightRequests,
        instrumentationEmitter
      });
      if (createPartitioner == null) {
        warnOfDefaultPartitioner(this[PRIVATE.LOGGER]);
      }
      return createProducer({
        retry: { ...this[PRIVATE.CLUSTER_RETRY], ...retry },
        logger: this[PRIVATE.LOGGER],
        cluster,
        createPartitioner,
        idempotent,
        transactionalId,
        transactionTimeout,
        instrumentationEmitter
      });
    }
    consumer({
      groupId,
      partitionAssigners,
      metadataMaxAge = DEFAULT_METADATA_MAX_AGE,
      sessionTimeout,
      rebalanceTimeout,
      heartbeatInterval,
      maxBytesPerPartition,
      minBytes,
      maxBytes,
      maxWaitTimeInMs,
      retry = { retries: 5 },
      allowAutoTopicCreation,
      maxInFlightRequests,
      readUncommitted = false,
      rackId = ""
    } = {}) {
      const isolationLevel = readUncommitted ? ISOLATION_LEVEL.READ_UNCOMMITTED : ISOLATION_LEVEL.READ_COMMITTED;
      const instrumentationEmitter = new InstrumentationEventEmitter;
      const cluster = this[PRIVATE.CREATE_CLUSTER]({
        metadataMaxAge,
        allowAutoTopicCreation,
        maxInFlightRequests,
        isolationLevel,
        instrumentationEmitter
      });
      return createConsumer({
        retry: { ...this[PRIVATE.CLUSTER_RETRY], ...retry },
        logger: this[PRIVATE.LOGGER],
        cluster,
        groupId,
        partitionAssigners,
        sessionTimeout,
        rebalanceTimeout,
        heartbeatInterval,
        maxBytesPerPartition,
        minBytes,
        maxBytes,
        maxWaitTimeInMs,
        isolationLevel,
        instrumentationEmitter,
        rackId,
        metadataMaxAge
      });
    }
    admin({ retry } = {}) {
      const instrumentationEmitter = new InstrumentationEventEmitter;
      const cluster = this[PRIVATE.CREATE_CLUSTER]({
        allowAutoTopicCreation: false,
        instrumentationEmitter
      });
      return createAdmin({
        retry: { ...this[PRIVATE.CLUSTER_RETRY], ...retry },
        logger: this[PRIVATE.LOGGER],
        instrumentationEmitter,
        cluster
      });
    }
    logger() {
      return this[PRIVATE.LOGGER];
    }
  };
});

// node_modules/kafkajs/index.js
var require_kafkajs = __commonJS((exports, module) => {
  var Kafka = require_src();
  var PartitionAssigners = require_assigners();
  var AssignerProtocol = require_assignerProtocol();
  var Partitioners = require_partitioners();
  var Compression = require_compression();
  var ConfigResourceTypes = require_configResourceTypes();
  var ConfigSource = require_configSource();
  var AclResourceTypes = require_aclResourceTypes();
  var AclOperationTypes = require_aclOperationTypes();
  var AclPermissionTypes = require_aclPermissionTypes();
  var ResourcePatternTypes = require_resourcePatternTypes();
  var { isRebalancing, isKafkaJSError, ...errors } = require_errors2();
  var { LEVELS } = require_loggers();
  module.exports = {
    Kafka,
    PartitionAssigners,
    AssignerProtocol,
    Partitioners,
    logLevel: LEVELS,
    CompressionTypes: Compression.Types,
    CompressionCodecs: Compression.Codecs,
    ConfigResourceTypes,
    AclResourceTypes,
    AclOperationTypes,
    AclPermissionTypes,
    ResourcePatternTypes,
    ConfigSource,
    ...errors
  };
});

// dist/index.js
var import_n32 = __toESM(require_lib(), 1);

// dist/args.js
var import_command_line_args = __toESM(require_dist(), 1);
var import_command_line_usage = __toESM(require_command_line_usage(), 1);
var validArgs = function(args) {
  if (!args.input)
    return false;
  return true;
};
var printUsage = function() {
  const usage = import_command_line_usage.default(sections);
  console.log(usage);
  process.exit(0);
};
function getArgs() {
  let args;
  try {
    args = import_command_line_args.default(optionDefinitions);
  } catch (e) {
    console.error(e);
    printUsage();
  }
  if (args.help || !validArgs(args)) {
    printUsage();
  }
  return args;
}
var optionDefinitions = [
  { name: "input", type: String, defaultOption: true, summary: "Specify what input file to start up" },
  { name: "help", alias: "h", type: Boolean, description: "Display this help message" }
];
var sections = [
  {
    header: "Js-runner",
    content: "JS-runner is part of the {italic connector architecture}. Starting from an input file start up all JsProcessors that are defined. Please do not use blank nodes, skolemize your data somewhere else!"
  },
  {
    header: "Synopsis",
    content: "$ js-runner <input>"
  },
  {
    header: "Command List",
    content: [{ name: "input", summary: "Specify what input file to start up" }]
  },
  {
    optionList: [optionDefinitions[1]]
  }
];

// dist/util.js
var import_n3 = __toESM(require_lib(), 1);
var types = __toESM(require_dist7(), 1);
import {createReadStream} from "fs";
import http from "http";
import https from "https";
function toArray(stream) {
  const output = [];
  return new Promise((res, rej) => {
    stream.on("data", (x) => output.push(x));
    stream.on("end", () => res(output));
    stream.on("close", () => res(output));
    stream.on("error", rej);
  });
}
async function get_readstream(location) {
  if (location.startsWith("https")) {
    return new Promise((res) => {
      https.get(location, res);
    });
  } else if (location.startsWith("http")) {
    return new Promise((res) => {
      http.get(location, res);
    });
  } else {
    return createReadStream(location);
  }
}
async function load_quads(location, baseIRI) {
  try {
    console.log("load_quads", location, baseIRI);
    const parser = new import_n3.StreamParser({ baseIRI: baseIRI || location });
    const rdfStream = await get_readstream(location);
    rdfStream.pipe(parser);
    const quads = await toArray(parser);
    return quads;
  } catch (ex) {
    console.error("Failed to load_quads", location, baseIRI);
    console.error(ex);
    return [];
  }
}
var load_memory_quads = function(value, baseIRI) {
  const parser = new import_n3.Parser({ baseIRI });
  return parser.parse(value);
};
async function load_store(location, store, recursive = true) {
  if (loaded.has(location))
    return;
  loaded.add(location);
  const quads = location.type === "remote" ? await load_quads(location.location) : load_memory_quads(location.value, location.baseIRI);
  store.addQuads(quads);
  if (recursive) {
    const loc = location.type === "remote" ? location.location : location.baseIRI;
    const other_imports = store.getObjects(namedNode(loc), OWL.terms.imports, null);
    for (let other of other_imports) {
      await load_store({ location: other.value, type: "remote" }, store, true);
    }
  }
}
var OWL = types.createUriAndTermNamespace("http://www.w3.org/2002/07/owl#", "imports");
var CONN2 = types.createUriAndTermNamespace("https://w3id.org/conn#", "install", "build", "GitInstall", "LocalInstall", "url", "procFile", "path");
var { namedNode } = import_n3.DataFactory;
var loaded = new Set;

// dist/connectors.js
var types2 = __toESM(require_dist7(), 1);

// dist/connectors/file.js
import {createReadStream as createReadStream2, openSync} from "fs";
import {appendFile, readFile, stat, writeFile} from "fs/promises";
import {isAbsolute} from "path";
import {watch} from "node:fs";
async function getFileSize(path) {
  return (await stat(path)).size;
}
var readPart = function(path, start, end, encoding) {
  return new Promise((res) => {
    const stream = createReadStream2(path, { encoding, start, end });
    let buffer = "";
    stream.on("data", (chunk) => {
      buffer += chunk;
    });
    stream.on("close", () => res(buffer));
  });
};
var debounce = function(func, timeout = 100) {
  let timer;
  return (...args) => {
    clearTimeout(timer);
    timer = setTimeout(() => {
      func(...args);
    }, timeout);
  };
};
var startFileStreamReader = (config) => {
  const path = isAbsolute(config.path) ? config.path : `${process.cwd()}/${config.path}`;
  openSync(path, "a+");
  const encoding = config.encoding || "utf-8";
  const reader = new SimpleStream;
  const init = async () => {
    let currentPos = await getFileSize(path);
    const watcher = watch(path, { encoding: "utf-8" });
    watcher.on("change", debounce(async () => {
      try {
        let content;
        if (config.onReplace) {
          content = await readFile(path, { encoding });
        } else {
          const newSize = await getFileSize(path);
          if (newSize <= currentPos) {
            currentPos = newSize;
            return;
          }
          content = await readPart(path, currentPos, newSize, encoding);
          currentPos = newSize;
        }
        await reader.push(content);
      } catch (error) {
        if (error.code === "ENOENT") {
          return;
        }
        throw error;
      }
    }));
    if (config.onReplace && config.readFirstContent) {
      console.log("reading first content");
      const content = await readFile(path, { encoding });
      await reader.push(content);
    }
  };
  return { reader, init };
};
var startFileStreamWriter = (config) => {
  const path = isAbsolute(config.path) ? config.path : `${process.cwd()}/${config.path}`;
  const encoding = config.encoding || "utf-8";
  const init = async () => {
    if (!config.onReplace) {
      await writeFile(path, "", { encoding });
    }
  };
  const push = async (item) => {
    if (config.onReplace) {
      await writeFile(path, item, { encoding });
    } else {
      await appendFile(path, item, { encoding });
    }
  };
  const end = async () => {
  };
  return { writer: { push, end }, init };
};
// node_modules/ws/wrapper.mjs
var stream = __toESM(require_stream2(), 1);
var receiver = __toESM(require_receiver(), 1);
var sender = __toESM(require_sender(), 1);
var websocket = __toESM(require_websocket(), 1);
var websocket_server = __toESM(require_websocket_server(), 1);

// dist/connectors/ws.js
var _connectWs = function(url, res) {
  const ws = new websocket.default(url, {});
  ws.on("error", () => {
    setTimeout(() => _connectWs(url, res), 300);
  });
  ws.on("ping", () => ws.pong());
  ws.on("open", () => {
    res(ws);
  });
};
var connectWs = function(url) {
  return new Promise((res) => _connectWs(url, res));
};
var startWsStreamReader = (config) => {
  const server = new websocket_server.default(config);
  server.on("error", (error) => {
    console.error("Ws server error:");
    console.error(error);
  });
  const connections = [];
  const interval = setInterval(() => {
    connections.forEach((instance, i) => {
      if (!instance) {
        return;
      }
      if (!instance.alive) {
        instance.socket.terminate();
        delete connections[i];
        return;
      }
      instance.socket.ping();
      instance.alive = false;
    });
  }, 30000);
  const reader = new SimpleStream(() => new Promise((res) => {
    clearInterval(interval);
    server.close(() => res());
  }));
  server.on("connection", (ws) => {
    const instance = { socket: ws, alive: true };
    connections.push(instance);
    ws.on("message", async (msg) => {
      reader.push(msg.toString()).catch((error) => {
        throw error;
      });
    });
    ws.on("pong", () => {
      instance.alive = true;
    });
  });
  return { reader, init: async () => {
  } };
};
var startWsStreamWriter = (config) => {
  let ws;
  const init = async () => {
    ws = await connectWs(config.url);
    ws.on("open", () => console.log("open"));
  };
  const push = async (item) => {
    ws.send(item);
  };
  const end = async () => {
    ws.close();
  };
  return { writer: { push, end }, init };
};
// dist/connectors/kafka.js
var import_kafkajs = __toESM(require_kafkajs(), 1);
import {readFileSync} from "node:fs";
var startKafkaStreamReader = (config) => {
  const brokerConfig = {};
  if (typeof config.broker === "string" || config.broker instanceof String) {
    Object.assign(brokerConfig, JSON.parse(readFileSync(config.broker, "utf-8")));
  } else {
    Object.assign(brokerConfig, config.broker);
  }
  if (brokerConfig && brokerConfig.hosts) {
    brokerConfig.brokers = brokerConfig.hosts;
  }
  const kafka = new import_kafkajs.Kafka(brokerConfig);
  const consumer = kafka.consumer(config.consumer);
  const stream2 = new SimpleStream(async () => {
    await consumer.disconnect();
    await consumer.stop();
  });
  const init = async () => {
    await consumer.connect();
    await consumer.subscribe({
      topic: config.topic.name,
      fromBeginning: config.topic.fromBeginning
    });
    consumer.run({
      async eachMessage({ topic, message }) {
        if (topic === config.topic.name) {
          const element = message.value?.toString() ?? "";
          stream2.push(element).catch((error) => {
            throw error;
          });
        }
      }
    }).catch((error) => {
      throw error;
    });
  };
  return { reader: stream2, init };
};
var startKafkaStreamWriter = (config) => {
  const topic = config.topic.name;
  const brokerConfig = {};
  if (typeof config.broker === "string" || config.broker instanceof String) {
    Object.assign(brokerConfig, JSON.parse(readFileSync(config.broker, "utf-8")));
  } else {
    Object.assign(brokerConfig, config.broker);
  }
  if (brokerConfig && brokerConfig.hosts) {
    brokerConfig.brokers = brokerConfig.hosts;
  }
  const kafka = new import_kafkajs.Kafka(brokerConfig);
  const producer = kafka.producer(config.producer);
  const init = () => producer.connect();
  const push = async (item) => {
    await producer.send({ topic, messages: [{ value: item }] });
  };
  const end = async () => {
    await producer.disconnect();
  };
  return { writer: { push, end }, init };
};
// dist/connectors/http.js
import * as http2 from "http";
import {createServer} from "http";
var streamToString = function(stream2, binary) {
  const datas = [];
  return new Promise((res) => {
    stream2.on("data", (data) => {
      datas.push(data);
    });
    stream2.on("end", () => {
      const streamData = Buffer.concat(datas);
      res(binary ? streamData : streamData.toString());
    });
  });
};
var startHttpStreamReader = (config) => {
  let server;
  const stream2 = new SimpleStream(() => new Promise((res) => {
    const cb = () => res();
    if (server !== undefined) {
      server.close(cb);
    } else {
      cb();
    }
  }));
  const requestListener = async function(req, res) {
    try {
      const content = await streamToString(req, config.binary);
      stream2.push(content).catch((error) => {
        throw error;
      });
    } catch (error) {
      console.error("Failed", error);
    }
    res.writeHead(200);
    res.end("OK");
  };
  server = createServer(requestListener);
  const init = () => {
    console.log("HTTP init!");
    return new Promise((res) => {
      const cb = () => res(undefined);
      if (server) {
        server.listen(config.port, config.endpoint, cb);
      } else {
        cb();
      }
    });
  };
  return { reader: stream2, init };
};
var startHttpStreamWriter = (config) => {
  const requestConfig = new URL(config.endpoint);
  const push = async (item) => {
    await new Promise((res) => {
      const options = {
        hostname: requestConfig.hostname,
        path: requestConfig.path,
        method: config.method,
        port: requestConfig.port
      };
      const cb = (response) => {
        response.on("data", () => {
        });
        response.on("end", () => {
          res(null);
        });
      };
      const req = http2.request(options, cb);
      req.write(item, () => res(null));
      req.end();
    });
  };
  const end = async () => {
  };
  return { writer: { push, end }, init: async () => {
  } };
};

// dist/connectors.js
var Conn = types2.createTermNamespace("https://w3id.org/conn#", "FileReaderChannel", "FileWriterChannel", "HttpReaderChannel", "HttpWriterChannel", "KafkaReaderChannel", "KafkaWriterChannel", "WsReaderChannel", "WsWriterChannel");
var JsOntology = types2.createTermNamespace("https://w3id.org/conn/js#", "JsProcess", "JsChannel", "JsReaderChannel", "JsWriterChannel");

class ChannelFactory {
  inits = [];
  jsChannelsNamedNodes = {};
  jsChannelsBlankNodes = {};
  createReader(config) {
    if (config.ty.equals(Conn.FileReaderChannel)) {
      const { reader, init } = startFileStreamReader(config);
      this.inits.push(init);
      return reader;
    }
    if (config.ty.equals(Conn.WsReaderChannel)) {
      const { reader, init } = startWsStreamReader(config);
      this.inits.push(init);
      return reader;
    }
    if (config.ty.equals(Conn.KafkaReaderChannel)) {
      const { reader, init } = startKafkaStreamReader(config);
      this.inits.push(init);
      return reader;
    }
    if (config.ty.equals(Conn.HttpReaderChannel)) {
      const { reader, init } = startHttpStreamReader(config);
      this.inits.push(init);
      return reader;
    }
    if (config.ty.equals(JsOntology.JsReaderChannel)) {
      const c = config;
      if (c.channel) {
        const id = c.channel.id.value;
        if (c.channel.id.termType === "NamedNode") {
          if (!this.jsChannelsNamedNodes[id]) {
            this.jsChannelsNamedNodes[id] = new SimpleStream;
          }
          return this.jsChannelsNamedNodes[id];
        }
        if (c.channel.id.termType === "BlankNode") {
          if (!this.jsChannelsBlankNodes[id]) {
            this.jsChannelsBlankNodes[id] = new SimpleStream;
          }
          return this.jsChannelsBlankNodes[id];
        }
        throw "Should have found a thing";
      }
    }
    throw "Unknown reader channel " + config.ty.value;
  }
  createWriter(config) {
    if (config.ty.equals(Conn.FileWriterChannel)) {
      const { writer, init } = startFileStreamWriter(config);
      this.inits.push(init);
      return writer;
    }
    if (config.ty.equals(Conn.WsWriterChannel)) {
      const { writer, init } = startWsStreamWriter(config);
      this.inits.push(init);
      return writer;
    }
    if (config.ty.equals(Conn.KafkaWriterChannel)) {
      const { writer, init } = startKafkaStreamWriter(config);
      this.inits.push(init);
      return writer;
    }
    if (config.ty.equals(Conn.HttpWriterChannel)) {
      const { writer, init } = startHttpStreamWriter(config);
      this.inits.push(init);
      return writer;
    }
    if (config.ty.equals(JsOntology.JsWriterChannel)) {
      const c = config;
      if (c.channel) {
        const id = c.channel.id.value;
        if (c.channel.id.termType === "NamedNode") {
          if (!this.jsChannelsNamedNodes[id]) {
            this.jsChannelsNamedNodes[id] = new SimpleStream;
          }
          return this.jsChannelsNamedNodes[id];
        }
        if (c.channel.id.termType === "BlankNode") {
          if (!this.jsChannelsBlankNodes[id]) {
            this.jsChannelsBlankNodes[id] = new SimpleStream;
          }
          return this.jsChannelsBlankNodes[id];
        }
        throw "Should have found a thing";
      }
    }
    throw "Unknown writer channel " + config.ty.value;
  }
  async init() {
    await Promise.all(this.inits.map((x) => x()));
  }
}

class SimpleStream {
  dataHandlers = [];
  endHandlers = [];
  disconnect;
  lastElement;
  constructor(onDisconnect) {
    this.disconnect = onDisconnect || (async () => {
    });
  }
  data(listener) {
    this.dataHandlers.push(listener);
    return this;
  }
  async push(data) {
    this.lastElement = data;
    await Promise.all(this.dataHandlers.map((handler) => handler(data)));
  }
  async end() {
    await this.disconnect();
    await Promise.all(this.endHandlers.map((handler) => handler()));
  }
  on(event, listener) {
    if (event === "data") {
      this.dataHandlers.push(listener);
    }
    if (event === "end") {
      this.endHandlers.push(listener);
    }
    return this;
  }
}
// dist/shacl.js
var types3 = __toESM(require_dist7(), 1);

// node_modules/rdf-lens/dist/index.js
function pred(pred2) {
  return new BasicLensM(({ quads, id }) => {
    const out = quads.filter((q) => q.subject.equals(id) && (!pred2 || q.predicate.equals(pred2)));
    return out.map((q) => ({ quads, id: q.object }));
  });
}
function invPred(pred2) {
  return new BasicLensM(({ quads, id }) => {
    const out = quads.filter((q) => q.object.equals(id) && (!pred2 || q.predicate.equals(pred2)));
    return out.map((q) => ({ quads, id: q.subject }));
  });
}
function unique() {
  return new BasicLensM((qs) => {
    const literals = {};
    const named = {};
    const blank = {};
    for (let q of qs) {
      const ty = q.id.termType;
      if (ty === "Literal")
        literals[q.id.value] = q;
      if (ty === "NamedNode")
        named[q.id.value] = q;
      if (ty === "BlankNode")
        blank[q.id.value] = q;
    }
    const out = [];
    out.push(...Object.values(literals));
    out.push(...Object.values(named));
    out.push(...Object.values(blank));
    return out;
  });
}
function subjects() {
  return new BasicLensM((quads) => {
    return quads.map((x) => ({ id: x.subject, quads }));
  });
}
function empty() {
  return new BasicLens((x) => x);
}

class BasicLens {
  _exec;
  constructor(execute) {
    this._exec = execute;
  }
  asMulti() {
    return new BasicLensM((c) => {
      const out = this.execute(c);
      return out;
    });
  }
  and(...and) {
    return new BasicLens((c) => {
      const a = this.execute(c);
      const rest = and.map((x) => x.execute(c));
      return [a, ...rest];
    });
  }
  orM(...others) {
    return new BasicLensM((c) => {
      const all = [this, ...others];
      return all.flatMap((x) => {
        try {
          return [x.execute(c)];
        } catch (ex) {
          return [];
        }
      });
    });
  }
  or(...others) {
    return new BasicLens((c) => {
      try {
        return this.execute(c);
      } catch (ex) {
        for (let i = 0;i < others.length; i++) {
          try {
            return others[i].execute(c);
          } catch (ex2) {
          }
        }
      }
      throw "nope";
    });
  }
  map(fn) {
    return new BasicLens((c) => {
      const a = this.execute(c);
      return fn(a);
    });
  }
  then(next) {
    return new BasicLens((c) => {
      const a = this.execute(c);
      return next.execute(a);
    });
  }
  execute(container) {
    return this._exec(container);
  }
}

class BasicLensM extends BasicLens {
  one(def) {
    return new BasicLens((c) => {
      const qs = this.execute(c);
      return qs[0] || def;
    });
  }
  expectOne() {
    return new BasicLens((c) => {
      const qs = this.execute(c);
      if (qs.length < 1)
        throw "Nope";
      return qs[0];
    });
  }
  thenAll(next) {
    return new BasicLensM((c) => {
      const qs = this.execute(c);
      return qs.flatMap((x) => {
        try {
          const o = next.execute(x);
          return [o];
        } catch (ex) {
          return [];
        }
      });
    });
  }
  thenSome(next) {
    return this.thenAll(next);
  }
  thenFlat(next) {
    return new BasicLensM((c) => {
      const qs = this.execute(c);
      return qs.flatMap((x) => next.execute(x));
    });
  }
  mapAll(fn) {
    return new BasicLensM((c) => {
      const qs = this.execute(c);
      return qs.map(fn);
    });
  }
  orAll(...others) {
    return new BasicLensM((c) => {
      let out = [];
      try {
        out.push(...this.execute(c));
      } catch (ex) {
      }
      for (let i = 0;i < others.length; i++) {
        try {
          out.push(...others[i].execute(c));
        } catch (ex) {
        }
      }
      return out;
    });
  }
  filter(fn) {
    return new BasicLensM((c) => {
      return this.execute(c).filter(fn);
    });
  }
}
var subject = new BasicLens(({ id, quads }) => ({
  id: id.subject,
  quads
}));
var predicate = new BasicLens(({ id, quads }) => ({
  id: id.predicate,
  quads
}));
var object = new BasicLens(({ id, quads }) => ({
  id: id.object,
  quads
}));

// dist/shacl.js
function toLens(shape) {
  if (shape.fields.length === 0)
    return empty().map(() => ({}));
  const fields = shape.fields.map((field) => {
    const minCount = field.minCount || 0;
    const maxCount = field.maxCount || Number.MAX_SAFE_INTEGER;
    const base = maxCount < 2 ? field.path.one().then(field.extract) : field.path.thenAll(field.extract).map((xs) => {
      if (xs.length < minCount) {
        throw `${shape.ty}:${field.name} required at least ${minCount} elements, found ${xs.length}`;
      }
      if (xs.length > maxCount) {
        throw `${shape.ty}:${field.name} required at most ${maxCount} elements, found ${xs.length}`;
      }
      return xs;
    });
    const asField = base.map((x) => {
      const out = {};
      out[field.name] = x;
      return out;
    });
    return minCount > 0 ? asField : asField.or(empty().map(() => ({})));
  });
  return fields[0].and(...fields.slice(1)).map((xs) => Object.assign({}, ...xs));
}
var field = function(predicate2, name, convert) {
  const conv = convert || ((x) => x);
  return pred(predicate2).one().map(({ id }) => {
    const out = {};
    out[name] = conv(id.value);
    return out;
  });
};
var optionalField = function(predicate2, name, convert) {
  const conv = convert || ((x) => x);
  return pred(predicate2).one(undefined).map((inp) => {
    const out = {};
    if (inp) {
      out[name] = conv(inp.id.value);
    }
    return out;
  });
};
var dataTypeToExtract = function(dataType, t) {
  if (dataType.equals(types3.XSD.terms.integer))
    return +t.value;
  if (dataType.equals(types3.XSD.terms.custom("float")))
    return +t.value;
  if (dataType.equals(types3.XSD.terms.custom("double")))
    return +t.value;
  if (dataType.equals(types3.XSD.terms.custom("decimal")))
    return +t.value;
  if (dataType.equals(types3.XSD.terms.string))
    return t.value;
  if (dataType.equals(types3.XSD.terms.dateTime))
    return new Date(t.value);
  if (dataType.equals(types3.XSD.terms.custom("boolean")))
    return t.value === "true";
  return t;
};
var extractProperty = function(cache, subClasses, apply) {
  const pathLens = pred(SHACL.path).one().then(ShaclPath).map((path) => ({
    path
  }));
  const nameLens = field(SHACL.name, "name");
  const minCount = optionalField(SHACL.minCount, "minCount", (x) => +x);
  const maxCount = optionalField(SHACL.maxCount, "maxCount", (x) => +x);
  const dataTypeLens = pred(SHACL.datatype).one().map(({ id }) => ({
    extract: empty().map((item) => dataTypeToExtract(id, item.id))
  }));
  const clazzLens = field(SHACL.class, "clazz").map(({ clazz: expected_class }) => {
    return {
      extract: new BasicLens(({ id, quads }) => {
        let found_class = false;
        const ty = quads.find((q) => q.subject.equals(id) && q.predicate.equals(types3.RDF.terms.type))?.object.value;
        if (!ty) {
          const lens = cache[expected_class];
          if (!lens) {
            throw `Tried extracting class ${expected_class} but no shape was defined`;
          }
          return lens.execute({ id, quads });
        }
        const lenses = [];
        let current = ty;
        while (current) {
          if (lenses.length < 2) {
            const lens = cache[current];
            if (lens) {
              lenses.push(lens);
            }
          }
          found_class = found_class || current === expected_class;
          current = subClasses[current];
        }
        if (!found_class) {
          throw `${ty} is not a subClassOf ${expected_class}`;
        }
        if (lenses.length === 0) {
          throw `Tried the classhierarchy for ${ty}, but found no shape definition`;
        }
        const finalLens = lenses.length == 1 ? lenses[0] : lenses[0].and(lenses[1]).map(([a, b]) => Object.assign({}, a, b));
        if (apply[ty]) {
          return finalLens.map(apply[ty]).execute({ id, quads });
        } else {
          return finalLens.execute({ id, quads });
        }
      })
    };
  });
  return pathLens.and(nameLens, minCount, maxCount, clazzLens.or(dataTypeLens)).map((xs) => Object.assign({}, ...xs));
};
function extractShape(cache, subclasses, apply) {
  const checkTy = pred(types3.RDF.terms.type).one().map(({ id }) => {
    if (id.equals(SHACL.NodeShape))
      return {};
    throw "Shape is not sh:NodeShape";
  });
  const idLens = empty().map(({ id }) => ({ id: id.value }));
  const clazzs = pred(SHACL.targetClass);
  const multiple = clazzs.thenAll(empty().map(({ id }) => ({ ty: id })));
  const descriptionClassLens = optionalField(SHACL.description, "description");
  const fields = pred(SHACL.property).thenSome(extractProperty(cache, subclasses, apply)).map((fields2) => ({ fields: fields2 }));
  return multiple.and(checkTy, idLens, descriptionClassLens, fields).map(([multiple2, ...others]) => multiple2.map((xs) => Object.assign({}, xs, ...others)));
}
function extractShapes(quads, apply = {}) {
  const cache = {};
  const subClasses = {};
  quads.filter((x) => x.predicate.equals(RDFS.subClassOf)).forEach((x) => subClasses[x.subject.value] = x.object.value);
  const shapes = subjects().then(unique()).asMulti().thenSome(extractShape(cache, subClasses, apply)).execute(quads).flat();
  const lenses = [];
  for (let shape of shapes) {
    const lens = toLens(shape);
    const target = cache[shape.ty.value];
    if (target) {
      cache[shape.ty.value] = target.or(lens);
    } else {
      cache[shape.ty.value] = lens;
    }
    lenses.push(lens);
  }
  return { lenses: cache, shapes, subClasses };
}
var RDFS = types3.createTermNamespace("http://www.w3.org/2000/01/rdf-schema#", "subClassOf");
var SHACL = types3.createTermNamespace("http://www.w3.org/ns/shacl#", "Shape", "NodeShape", "PropertyShape", "targetNode", "targetClass", "targetSubjectsOf", "targetObjectsOf", "property", "path", "class", "name", "description", "defaultValue", "alternativePath", "zeroOrMorePath", "inversePath", "minCount", "maxCount", "datatype");
var RDFListElement = pred(types3.RDF.terms.first).one().and(pred(types3.RDF.terms.rest).one());
var RdfList = new BasicLens((c) => {
  if (c.id.equals(types3.RDF.terms.nil)) {
    return [];
  }
  const [first, rest] = RDFListElement.execute(c);
  const els = RdfList.execute(rest);
  els.unshift(first.id);
  return els;
});
var ShaclSequencePath = new BasicLens((c) => {
  const pathList = RdfList.execute(c);
  if (pathList.length === 0) {
    return new BasicLensM((c2) => [c2]);
  }
  let start = pred(pathList[0]);
  for (let i = 1;i < pathList.length; i++) {
    start = start.thenFlat(pred(pathList[i]));
  }
  return start;
});
var ShaclAlternativepath = new BasicLens((c) => {
  const options = pred(SHACL.alternativePath).one().then(RdfList).execute(c);
  const optionLenses = options.map((id) => ShaclPath.execute({ id, quads: c.quads }));
  return optionLenses[0].orAll(...optionLenses.slice(1));
});
var ShaclPredicatePath = new BasicLens((c) => {
  return pred(c.id);
});
var ShaclInversePath = pred(SHACL.inversePath).one().then(new BasicLens((c) => {
  const pathList = RdfList.execute(c);
  if (pathList.length === 0) {
    return new BasicLensM((c2) => [c2]);
  }
  pathList.reverse();
  let start = invPred(pathList[0]);
  for (let i = 1;i < pathList.length; i++) {
    start = start.thenFlat(invPred(pathList[i]));
  }
  return start;
}).or(new BasicLens((c) => {
  return invPred(c.id);
})));
var ShaclPath = ShaclSequencePath.or(ShaclAlternativepath, ShaclInversePath, ShaclPredicatePath);

// dist/index.js
import path from "path";
var types4 = __toESM(require_dist7(), 1);
var safeJoin = function(a, b) {
  if (b.startsWith("/")) {
    return b;
  }
  return path.join(a, b);
};
async function extractProcessors(source, apply) {
  const store = new import_n32.Store;
  await load_store(source, store);
  const quads = store.getQuads(null, null, null, null);
  const config = extractShapes(quads, apply);
  const subjects2 = quads.filter((x) => x.predicate.equals(types4.RDF.terms.type) && x.object.equals(JsOntology.JsProcess)).map((x) => x.subject);
  const processorLens = config.lenses[JsOntology.JsProcess.value];
  const processors = subjects2.map((id) => processorLens.execute({ id, quads }));
  return { processors, quads, shapes: config };
}
function extractSteps(proc, quads, config) {
  const out = [];
  const subjects2 = quads.filter((x) => x.predicate.equals(types4.RDF.terms.type) && x.object.equals(proc.ty)).map((x) => x.subject);
  const processorLens = config.lenses[proc.ty.value];
  const fields = proc.mapping.parameters;
  for (let id of subjects2) {
    const obj = processorLens.execute({ id, quads });
    const functionArgs = new Array(fields.length);
    for (let field2 of fields) {
      functionArgs[field2.position] = obj[field2.parameter];
    }
    out.push(functionArgs);
  }
  return out;
}
async function jsRunner() {
  console.log("JS runner is running!");
  const args2 = getArgs();
  const cwd = process.cwd();
  const source = {
    location: safeJoin(cwd, args2.input).replaceAll("\\", "/"),
    type: "remote"
  };
  const factory = new ChannelFactory;
  const apply = {};
  for (let ty of [
    Conn.FileReaderChannel,
    Conn.WsReaderChannel,
    Conn.HttpReaderChannel,
    Conn.KafkaReaderChannel,
    JsOntology.JsReaderChannel
  ]) {
    apply[ty.value] = (x) => factory.createReader(x);
  }
  for (let ty of [
    Conn.FileWriterChannel,
    Conn.WsWriterChannel,
    Conn.HttpWriterChannel,
    Conn.KafkaWriterChannel,
    JsOntology.JsWriterChannel
  ]) {
    apply[ty.value] = (x) => factory.createWriter(x);
  }
  const { processors, quads, shapes: config } = await extractProcessors(source, apply);
  const starts = [];
  for (let proc of processors) {
    const argss = extractSteps(proc, quads, config);
    const jsProgram = await import("file://" + proc.file);
    process.chdir(proc.location);
    for (let args3 of argss) {
      starts.push(await jsProgram[proc.func](...args3));
    }
  }
  await factory.init();
  for (let s of starts) {
    if (s && typeof s === "function") {
      s();
    }
  }
}

// bin/js-runner.js
jsRunner().catch((e) => {
  console.error("Error:", e);
  console.error(e.stack);
});
